{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "《动手学习深度学习》：\n",
    "    最新书籍：http://zh.d2l.ai/chapter_preface/index.html\n",
    "    B站：https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络搭建八股-模块化设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./minist_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./minist_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./minist_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./minist_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001D9F526F828>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001D9F526F860>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001D9F526F978>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "minist = input_data.read_data_sets('./minist_data', one_hot=True)\n",
    "minist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "inputs must be a list of at least one Tensor with the same dtype and shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-771ad09bc4c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-771ad09bc4c5>\u001b[0m in \u001b[0;36mbackpropagate\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m#       1. 均方误差：MSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 定义损失函数mse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mmse_regul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'losess'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;31m#       2. 自定义\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m#       3. 交叉熵\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\miniconda3\\envs\\MachLearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36madd_n\u001b[1;34m(inputs, name)\u001b[0m\n\u001b[0;32m   1940\u001b[0m   \"\"\"\n\u001b[0;32m   1941\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1942\u001b[1;33m     raise ValueError(\"inputs must be a list of at least one Tensor with the \"\n\u001b[0m\u001b[0;32m   1943\u001b[0m                      \"same dtype and shape\")\n\u001b[0;32m   1944\u001b[0m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_n_to_tensor_or_indexed_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: inputs must be a list of at least one Tensor with the same dtype and shape"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d9879d37f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_weights(shape, REGULARIZER):\n",
    "    w = tf.Variable(tf.random_normal(shape), dtype=tf.float32)\n",
    "    if REGULARIZER != None:\n",
    "        tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(REGULARIZER)(w)) # 添加正则化\n",
    "    return w\n",
    "\n",
    "def get_bias(shape):\n",
    "    '''bias 不进行正则化'''\n",
    "    b = tf.Variable(tf.zeros(shape=shape))\n",
    "    return b\n",
    "\n",
    "def forward(x, REGULARIZER): # 数据的前向传播\n",
    "    '''\n",
    "    搭建网络，设计网络结构\n",
    "    按照计算步骤，从神经网络的各层依次进行计算（传播）\n",
    "    '''\n",
    "    # 隐藏层\n",
    "    n_hidden = 100\n",
    "    w_h = get_weights(shape=[784, n_hidden], REGULARIZER=REGULARIZER)\n",
    "    b_h = get_bias(n_hidden)\n",
    "    a_h = tf.nn.relu(tf.matmul(x, w_h) + b_h)\n",
    "    # 输出层\n",
    "    n_out = 10\n",
    "    w_o = get_weights(shape=[n_hidden, n_out], REGULARIZER=REGULARIZER)\n",
    "    b_o = get_bias(n_out)\n",
    "    z_o = tf.matmul(a_h, w_o) + b_o # 输出层不过激活函数\n",
    "    return z_o\n",
    "\n",
    "def backpropagate(): # 误差的反向传播\n",
    "    '''\n",
    "    训练网络，优化网络参数\n",
    "    反向求导，进行误差的反向传播\n",
    "    '''\n",
    "    # REGULARIZER = None # 先不正则化看看\n",
    "    REGULARIZER = 0.01\n",
    "    BATCH_SIZE= 200 # 每次提交的批量样本量\n",
    "    EPOCHS = 500 # 迭代数\n",
    "\n",
    "    ############\n",
    "    # 前向计算\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 784)) # 自变量x\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 10)) # 真实y值\n",
    "    y_hat = forward(x, REGULARIZER) # 计算的y值\n",
    "\n",
    "    ############\n",
    "    # loss function\n",
    "    mse = tf.reduce_mean(tf.square(y_hat - y)) # 定义损失函数: 1. 均方误差-MSE 2. 自定义 3. 交叉熵\n",
    "    mse_regul = mse + tf.add_n(tf.get_collection('losses')) # 正则化\n",
    "\n",
    "    ############\n",
    "    # opt优化\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss=mse_regul)\n",
    "\n",
    "    ############\n",
    "    # 开始会话\n",
    "    with tf.Session() as sess:\n",
    "        # 初始化所有变量\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        cost_list = []  \n",
    "        for i in range(EPOCHS):\n",
    "            xs, ys = minist.train.next_batch(BATCH_SIZE)\n",
    "            cost, _ = sess.run([mse, train_step], {x:xs, y:ys})\n",
    "            cost_list.append(cost)\n",
    "            # if not i % 1000:\n",
    "            #     print(f\"{i}) cost: {cost}\")\n",
    "    return cost_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # backpropagate()\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    plt.plot(backpropagate())\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "inputs must be a list of at least one Tensor with the same dtype and shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-afa18a6b4713>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-afa18a6b4713>\u001b[0m in \u001b[0;36mbackpropagate\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#       1. 均方误差：MSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 定义损失函数mse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mmse_regul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'losess'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m#       2. 自定义\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#       3. 交叉熵\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\miniconda3\\envs\\MachLearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36madd_n\u001b[1;34m(inputs, name)\u001b[0m\n\u001b[0;32m   1940\u001b[0m   \"\"\"\n\u001b[0;32m   1941\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1942\u001b[1;33m     raise ValueError(\"inputs must be a list of at least one Tensor with the \"\n\u001b[0m\u001b[0;32m   1943\u001b[0m                      \"same dtype and shape\")\n\u001b[0;32m   1944\u001b[0m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_n_to_tensor_or_indexed_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: inputs must be a list of at least one Tensor with the same dtype and shape"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d98763d7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# REGULARIZER = None # 先不正则化看看\n",
    "REGULARIZER = 0.01\n",
    "BATCH_SIZE= 200 # 每次提交的批量样本量\n",
    "EPOCHS = 500 # 迭代数\n",
    "\n",
    "def backpropagate(): # 误差的反向传播\n",
    "    '''\n",
    "    训练网络，优化网络参数\n",
    "    反向求导，进行误差的反向传播\n",
    "    '''\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 784)) # 自变量x\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 10)) # 真实y值\n",
    "\n",
    "    y_hat = forward(x, REGULARIZER) # 计算的y值\n",
    "\n",
    "    # loss:\n",
    "    #       1. 均方误差：MSE\n",
    "    mse = tf.reduce_mean(tf.square(y_hat - y)) # 定义损失函数mse\n",
    "    mse_regul = mse + tf.add_n(tf.get_collection('losess'))\n",
    "    #       2. 自定义\n",
    "    #       3. 交叉熵\n",
    "    # ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y, 1))\n",
    "    # cem = tf.reduce_mean(ce)\n",
    "\n",
    "    # loss正则化：\n",
    "    # mse_regul = mse + tf.add_n(tf.get_collection('losses')) # 正则化loss_mse\n",
    "    # loss_mse_regul = cem + tf.add_n(tf.get_collection('losses')) # 正则化loss_mse\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss=mse_regul)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # 初始化所有变量\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        cost_list = []  \n",
    "        for i in range(EPOCHS):\n",
    "            xs, ys = minist.train.next_batch(BATCH_SIZE)\n",
    "            cost, _ = sess.run([mse, train_step], {x:xs, y:ys})\n",
    "            cost_list.append(cost)\n",
    "            # if not i % 1000:\n",
    "            #     print(f\"{i}) cost: {cost}\")\n",
    "    return cost_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # backpropagate()\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    plt.plot(backpropagate())\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    return\n",
    "\n",
    "predict(minist.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 循环神经网络-RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
