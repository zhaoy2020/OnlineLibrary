{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Scientific HuggingFace](#toc1_)    \n",
    "- 2. [datas](#toc2_)    \n",
    "- 3. [Tokenizer](#toc3_)    \n",
    "  - 3.1. [Training a new tokenizer](#toc3_1_)    \n",
    "  - 3.2. [Using a pre-trained tokenizer](#toc3_2_)    \n",
    "    - 3.2.1. [ç›´æ¥åŠ è½½](#toc3_2_1_)    \n",
    "    - 3.2.2. [åœ¨Transformersä¸­ä½¿ç”¨](#toc3_2_2_)    \n",
    "      - 3.2.2.1. [å°è£…](#toc3_2_2_1_)    \n",
    "      - 3.2.2.2. [åŠ è½½](#toc3_2_2_2_)    \n",
    "- 4. [BERT](#toc4_)    \n",
    "  - 4.1. [tokenizer](#toc4_1_)    \n",
    "    - 4.1.1. [train a new tokenizer](#toc4_1_1_)    \n",
    "    - 4.1.2. [make tokenizer to be used in transformers with AutoTokenizer](#toc4_1_2_)    \n",
    "  - 4.2. [model](#toc4_2_)    \n",
    "  - 4.3. [datas](#toc4_3_)    \n",
    "  - 4.4. [trainer](#toc4_4_)    \n",
    "- 5. [LLaMa](#toc5_)    \n",
    "  - 5.1. [Tokenizer](#toc5_1_)    \n",
    "- 6. [DeepSeek](#toc6_)    \n",
    "  - 6.1. [R1](#toc6_1_)    \n",
    "- 7. [ä»€ä¹ˆæ˜¯RAGï¼Ÿ](#toc7_)    \n",
    "  - 7.1. [æ–‡æœ¬çŸ¥è¯†æ£€ç´¢](#toc7_1_)    \n",
    "    - 7.1.1. [çŸ¥è¯†åº“æ„å»º](#toc7_1_1_)    \n",
    "    - 7.1.2. [æŸ¥è¯¢æ„å»º](#toc7_1_2_)    \n",
    "    - 7.1.3. [å¦‚ä½•æ£€ç´¢ï¼Ÿ-æ–‡æœ¬æ£€ç´¢](#toc7_1_3_)    \n",
    "    - 7.1.4. [å¦‚ä½•å–‚ç»™å¤§æ¨¡å‹ï¼Ÿ-ç”Ÿæˆå¢å¼º](#toc7_1_4_)    \n",
    "  - 7.2. [å¤šæ¨¡æ€çŸ¥è¯†æ£€ç´¢](#toc7_2_)    \n",
    "  - 7.3. [åº”ç”¨](#toc7_3_)    \n",
    "- 8. [éƒ¨ç½²å¤§æ¨¡å‹](#toc8_)    \n",
    "  - 8.1. [ollama](#toc8_1_)    \n",
    "    - 8.1.1. [Install and run model](#toc8_1_1_)    \n",
    "    - 8.1.2. [API on web port](#toc8_1_2_)    \n",
    "    - 8.1.3. [Python ollama module](#toc8_1_3_)    \n",
    "      - 8.1.3.1. [demoï¼šç¿»è¯‘ä¸­æ–‡ä¸ºè‹±æ–‡](#toc8_1_3_1_)    \n",
    "  - 8.2. [ktransformers](#toc8_2_)    \n",
    "    - 8.2.1. [DeepSeek-R1_Q4_K_M with ktransformers docker container](#toc8_2_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[Scientific HuggingFace](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id='toc2_'></a>[datas](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f242f2befe4b1ea5d72d506afcee36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/360 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c4e8015e714b59bcb43bb338906a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/11.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a63403dd73c4ae8954c39bde3ee7ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/11840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets \n",
    "\n",
    "\n",
    "datas = datasets.load_dataset('dnagpt/dna_promoters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id='toc3_'></a>[Tokenizer](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. <a id='toc3_1_'></a>[Training a new tokenizer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸ªBPEæ¨¡å‹ \n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "# è®¾ç½®é¢„å¤„ç†\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False, use_regex=False) #use_regex=False,ç©ºæ ¼å½“æˆä¸€èˆ¬å­—ç¬¦ä¸²\n",
    "# è®¾ç½®è®­ç»ƒå™¨\n",
    "trainer = trainers.BpeTrainer(vocab_size=30000, special_tokens=[\"<|endoftext|>\"]) #3w words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# è®­ç»ƒ\n",
    "tokenizer.train([\"data/huggingface/dna_1g.txt\"], trainer=trainer) #all file list, take 10-20 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TG', 'GCGTGAA', 'CCCGG', 'GATCGG', 'G']\n"
     ]
    }
   ],
   "source": [
    "# ç¼–ç \n",
    "encoding = tokenizer.encode(\"TGGCGTGAACCCGGGATCGGG\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TG GCGTGAA CCCGG GATCGG G\n"
     ]
    }
   ],
   "source": [
    "# è§£ç \n",
    "decoding = tokenizer.decode(encoding.ids)\n",
    "print(decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜\n",
    "tokenizer.save(\"data/huggingface/tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. <a id='toc3_2_'></a>[Using a pre-trained tokenizer](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. <a id='toc3_2_1_'></a>[ç›´æ¥åŠ è½½](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TG', 'GCGTGAA', 'CCCGG', 'GATCGG', 'G']\n",
      "TG GCGTGAA CCCGG GATCGG G\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "\n",
    "# åŠ è½½è‡ªå®šä¹‰çš„tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"data/huggingface/tokenizer.json\")\n",
    "\n",
    "# ç¼–ç \n",
    "encoding = tokenizer.encode(\"TGGCGTGAACCCGGGATCGGG\")\n",
    "print(encoding.tokens)\n",
    "\n",
    "# è§£ç \n",
    "decoding = tokenizer.decode(encoding.ids)\n",
    "print(decoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. <a id='toc3_2_2_'></a>[åœ¨Transformersä¸­ä½¿ç”¨](#toc0_)\n",
    "ä¸ºäº†èƒ½å¤Ÿä»AutoTokenizerä¸­è°ƒç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.1. <a id='toc3_2_2_1_'></a>[å°è£…](#toc0_)\n",
    "è¦åœ¨ ğŸ¤— Transformers ä¸­ä½¿ç”¨è¿™ä¸ªæ ‡è®°å™¨ï¼Œæˆ‘ä»¬å¿…é¡»å°†å®ƒåŒ…è£¹åœ¨ä¸€ä¸ª PreTrainedTokenizerFast ç±»ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/huggingface/dna_bpe_dict/tokenizer_config.json',\n",
       " 'data/huggingface/dna_bpe_dict/special_tokens_map.json',\n",
       " 'data/huggingface/dna_bpe_dict/vocab.json',\n",
       " 'data/huggingface/dna_bpe_dict/merges.txt',\n",
       " 'data/huggingface/dna_bpe_dict/added_tokens.json',\n",
       " 'data/huggingface/dna_bpe_dict/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "\n",
    "dna_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)\n",
    "\n",
    "dna_tokenizer.save_pretrained(\"data/huggingface/dna_bpe_dict\")\n",
    "\n",
    "# dna_tokenizer.push_to_hub(\"dna_bpe_dict_1g\", organization=\"dnagpt\", use_auth_token=\"hf_*****\") # push to huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.2. <a id='toc3_2_2_2_'></a>[åŠ è½½](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer \n",
    "\n",
    "\n",
    "# æˆåŠŸ\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"data/huggingface/dna_bpe_dict\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id='toc4_'></a>[BERT](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. <a id='toc4_1_'></a>[tokenizer](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. <a id='toc4_1_1_'></a>[train a new tokenizer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from transformers import PreTrainedTokenizerFast, AutoModelForMaskedLM\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„ WordPiece æ¨¡å‹\n",
    "tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
    "\n",
    "# è®¾ç½®è®­ç»ƒå‚æ•°\n",
    "trainer = WordPieceTrainer(\n",
    "    vocab_size=30000,        # è¯æ±‡è¡¨å¤§å°\n",
    "    min_frequency=2,         # æœ€å°è¯é¢‘\n",
    "    show_progress=True,      # æ˜¾ç¤ºè¿›åº¦\n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function train:\n",
      "\n",
      "train(self, files, trainer=None) method of tokenizers.Tokenizer instance\n",
      "    Train the Tokenizer using the given files.\n",
      "\n",
      "    Reads the files line by line, while keeping all the whitespace, even new lines.\n",
      "    If you want to train from data store in-memory, you can check\n",
      "    :meth:`~tokenizers.Tokenizer.train_from_iterator`\n",
      "\n",
      "    Args:\n",
      "        files (:obj:`List[str]`):\n",
      "            A list of path to the files that we should use for training\n",
      "\n",
      "        trainer (:obj:`~tokenizers.trainers.Trainer`, `optional`):\n",
      "            An optional trainer that should be used to train our Model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tokenizer.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# è®­ç»ƒ\n",
    "tokenizer.train(files=[\"data/huggingface/dna_1g.txt\"], trainer=trainer)\n",
    "\n",
    "# ä¿å­˜\n",
    "tokenizer.save(\"data/huggingface/dna_wordpiece_dict.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. <a id='toc4_1_2_'></a>[make tokenizer to be used in transformers with AutoTokenizer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/huggingface/dna_wordpiece_dict/tokenizer_config.json',\n",
       " 'data/huggingface/dna_wordpiece_dict/special_tokens_map.json',\n",
       " 'data/huggingface/dna_wordpiece_dict/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer = Tokenizer.from_file(\"data/huggingface/dna_wordpiece_dict.json\")\n",
    "\n",
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=new_tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")\n",
    "\n",
    "# ä¿å­˜\n",
    "wrapped_tokenizer.save_pretrained(\"data/huggingface/dna_wordpiece_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# åŠ è½½\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"data/huggingface/dna_wordpiece_dict\")\n",
    "#tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [6, 766, 22, 10], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ç¼–ç \n",
    "tokenizer(\"ATCGGATCG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='data/huggingface/dna_wordpiece_dict', vocab_size=30000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. <a id='toc4_2_'></a>[model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertForMaskedLM \n",
    "\n",
    "\n",
    "# é…ç½®\n",
    "max_len = 1024 \n",
    "\n",
    "config = BertConfig(\n",
    "    vocab_size = len(tokenizer),\n",
    "    max_position_embeddings=max_len, \n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ") \n",
    "\n",
    "# æ¨¡å‹\n",
    "model = BertForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. <a id='toc4_3_'></a>[datas](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1079595\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "\n",
    "raw_dataset = load_dataset('text', data_files='data/huggingface/dna_1g.txt')\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 971635\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 107960\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = raw_dataset[\"train\"].train_test_split(test_size=0.1, shuffle=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6371b499b174ff89c4e7bb54315a9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=50):   0%|          | 0/971635 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065019d3ba1c46c598849b00771e8a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=50):   0%|          | 0/107960 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer._tokenizer.model.max_input_chars_per_word = 10000\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=max_len)\n",
    "\n",
    "\n",
    "# å¯¹æ•°æ®é›†åº”ç”¨åˆ†è¯å‡½æ•°\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=False, remove_columns=['text'], num_proc=50)  # è®¾ç½®ä¸ºä½ çš„ CPU æ ¸å¿ƒæ•°æˆ–æ ¹æ®éœ€è¦è°ƒæ•´\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªæ•°æ®æ”¶é›†å™¨ï¼Œç”¨äºåŠ¨æ€å¡«å……å’Œé®è”½,æ³¨æ„mlm=true\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'GAATATTTGTCTATTCTTCTTAACTTTCTCCACTGTAAATTAAATTGCTCCTCAGGGTGCTATATGGCATCCCTTGCTATTTTTGGAGCAAATCTTAAATTCTTCAACAATTTTATCAAGACAAACACAACTTTCAGTAAATTCATTGTTTAAATTTGGTGAAAAGTCAGATTTCTTTACACATAGTAAAGCAAATGTAAAATAATATATCAATGTGATTCTTTTAATAAAATACCATTATTGCCAATGGTTTTTAATAGTTCACTGTTTGAAAGAGACCACAAAATTCATGTGCAAAAATCACAAGCATTCTTATACAACAGTGACAGACAAACAGAGAGCCAAATCAGGAATGAACTTCCATTCACAATTGCTTCAAAGAGAATCAAATACCTAGGAATCCAACTTACAAGGGATGTAAAGGACCTCTTCAAGGAGAACTACAAACCACTGCTCAGTGAAATAAAAGAGGACACAAACAAATGGAAGAACATACCATGCTCATGGATAGGAAGAATCAATATCGTGAAAATGGCCATACTGCCCAAGGTAATTTATAGATTCAATGCCATCCCCATCAAGCTACCAATGAGTTTCTTCACAGAATTGGAAAAAACTGTTTTAAAGTTCATATGGAACCAAAAAAGAACCCACATTGCCAAGACAATCCTAAGTCAAATGAACAAAGCTGGAGGGATCATGCTACCTGACTTCAAACTATACTACAAGGCTACAGTAACCAAAATAGCATGGTACTGGTACCAAAACAGAAATATAGACCAATGGAACAGCATAGAGTCCTCAGAAATAATACCACACATCTACATCTTTGATAAATCTGACAAAAACAAGAAATGGGGAAAGGATTCTCTATATAATAAATGGTGCTGGGAAAATTGGCTAGCCATAAGTAGAAAGCTGAAACTGGATCCTTTCCTTACTCTTTATACGAAAATTAATTCAAGATGGAGTAGAGACTTAAATGTTAGACCTAATACCA'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GAA',\n",
       " '##TATTTG',\n",
       " '##TCTATT',\n",
       " '##CTTCTTAA',\n",
       " '##CTTTCTCC',\n",
       " '##A',\n",
       " '##CTGTAAATT',\n",
       " '##AAATT',\n",
       " '##GCTCC',\n",
       " '##TCAGG',\n",
       " '##GTGCTA',\n",
       " '##TATGGCA',\n",
       " '##TCCCTT',\n",
       " '##GCTATTTT',\n",
       " '##TGGAGCAA',\n",
       " '##A',\n",
       " '##TCTTAAA',\n",
       " '##T']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(dataset[\"train\"][0][\"text\"][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. <a id='toc4_4_'></a>[trainer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "run_path = \"cache/bert_run\"\n",
    "train_epoches = 5\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=run_path,\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=train_epoches,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        save_steps=2000,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=True,\n",
    "        fp16=True, #v100æ²¡æ³•ç”¨\n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"cache/dna_bert_v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. <a id='toc5_'></a>[LLaMa](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. <a id='toc5_1_'></a>[Tokenizer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=\"data/huggingface/dna_1g.txt,data/huggingface/protein_1g.txt\", \n",
    "    model_prefix=\"dna_llama\", \n",
    "    vocab_size=60000, \n",
    "    model_type=\"bpe\", \n",
    "    # max_sentence_length=1000000,\n",
    "    num_threads=50, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = spm.SentencePieceProcessor(model_file=\"dna_llama.model\")\n",
    "\n",
    "tokenizer.encode(\"ATCGGATCG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. <a id='toc6_'></a>[DeepSeek](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. <a id='toc6_1_'></a>[R1](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c6f5f30e844fd5a8922e065acd1ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee715dfaf0cf491bbffed492592c3765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-000163.safetensors:  71%|#######1  | 3.07G/4.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf-mirror.com/repos/e7/f7/e7f7b8810f2020d7ff50a46aef578773eecb7386ccba95924d21eae90685f990/d6f299f7b410b9a7806927b5d2d413fae1f2c1dfa340bb0037d02d220cd8c080?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00007-of-000163.safetensors%3B+filename%3D%22model-00007-of-000163.safetensors%22%3B&Expires=1739353834&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTM1MzgzNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U3L2Y3L2U3ZjdiODgxMGYyMDIwZDdmZjUwYTQ2YWVmNTc4NzczZWVjYjczODZjY2JhOTU5MjRkMjFlYWU5MDY4NWY5OTAvZDZmMjk5ZjdiNDEwYjlhNzgwNjkyN2I1ZDJkNDEzZmFlMWYyYzFkZmEzNDBiYjAwMzdkMDJkMjIwY2Q4YzA4MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=uWn2eRLEE%7EkEPseLsNFZx3nYDabBpqrL2gJZdKix4fRMvtXUj-QBn8R4yfwVaxb%7EzgsgIh2jRpAy6BLf1bEfzJv1SByB3-z4bCnf8OhuOM81SM2u5kO-CDNjGdbPADY6HfMFKRioqgbFlgd6PAIC6eGNUtM6B5jHJxa9yzKxEKU9PRM9O0JDJPH4IvYT-6SmKqEyDG2pZKPAojQm9FJNAytHHXordFtbH8gmhhposRmfXk8mGxEeSYGuhlDX6A129aP8hoSEosrX30-dbEZk1uVLnvIMofNS0gML2pJ7wdRcu7vJSqegpAyifcNW4FlJFDMw1Xqz7-LAzKdpX3n64g__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496ebe69cfd7465895deab93781effff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-000163.safetensors:  71%|#######1  | 3.07G/4.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf-mirror.com/repos/e7/f7/e7f7b8810f2020d7ff50a46aef578773eecb7386ccba95924d21eae90685f990/d6f299f7b410b9a7806927b5d2d413fae1f2c1dfa340bb0037d02d220cd8c080?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00007-of-000163.safetensors%3B+filename%3D%22model-00007-of-000163.safetensors%22%3B&Expires=1739353834&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTM1MzgzNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U3L2Y3L2U3ZjdiODgxMGYyMDIwZDdmZjUwYTQ2YWVmNTc4NzczZWVjYjczODZjY2JhOTU5MjRkMjFlYWU5MDY4NWY5OTAvZDZmMjk5ZjdiNDEwYjlhNzgwNjkyN2I1ZDJkNDEzZmFlMWYyYzFkZmEzNDBiYjAwMzdkMDJkMjIwY2Q4YzA4MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=uWn2eRLEE%7EkEPseLsNFZx3nYDabBpqrL2gJZdKix4fRMvtXUj-QBn8R4yfwVaxb%7EzgsgIh2jRpAy6BLf1bEfzJv1SByB3-z4bCnf8OhuOM81SM2u5kO-CDNjGdbPADY6HfMFKRioqgbFlgd6PAIC6eGNUtM6B5jHJxa9yzKxEKU9PRM9O0JDJPH4IvYT-6SmKqEyDG2pZKPAojQm9FJNAytHHXordFtbH8gmhhposRmfXk8mGxEeSYGuhlDX6A129aP8hoSEosrX30-dbEZk1uVLnvIMofNS0gML2pJ7wdRcu7vJSqegpAyifcNW4FlJFDMw1Xqz7-LAzKdpX3n64g__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cfcbea58cd43879237c4eff71f3134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-000163.safetensors:  71%|#######1  | 3.07G/4.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf-mirror.com/repos/e7/f7/e7f7b8810f2020d7ff50a46aef578773eecb7386ccba95924d21eae90685f990/d6f299f7b410b9a7806927b5d2d413fae1f2c1dfa340bb0037d02d220cd8c080?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00007-of-000163.safetensors%3B+filename%3D%22model-00007-of-000163.safetensors%22%3B&Expires=1739353834&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTM1MzgzNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U3L2Y3L2U3ZjdiODgxMGYyMDIwZDdmZjUwYTQ2YWVmNTc4NzczZWVjYjczODZjY2JhOTU5MjRkMjFlYWU5MDY4NWY5OTAvZDZmMjk5ZjdiNDEwYjlhNzgwNjkyN2I1ZDJkNDEzZmFlMWYyYzFkZmEzNDBiYjAwMzdkMDJkMjIwY2Q4YzA4MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=uWn2eRLEE%7EkEPseLsNFZx3nYDabBpqrL2gJZdKix4fRMvtXUj-QBn8R4yfwVaxb%7EzgsgIh2jRpAy6BLf1bEfzJv1SByB3-z4bCnf8OhuOM81SM2u5kO-CDNjGdbPADY6HfMFKRioqgbFlgd6PAIC6eGNUtM6B5jHJxa9yzKxEKU9PRM9O0JDJPH4IvYT-6SmKqEyDG2pZKPAojQm9FJNAytHHXordFtbH8gmhhposRmfXk8mGxEeSYGuhlDX6A129aP8hoSEosrX30-dbEZk1uVLnvIMofNS0gML2pJ7wdRcu7vJSqegpAyifcNW4FlJFDMw1Xqz7-LAzKdpX3n64g__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a458e767a8be4ae5a65c7369f0fbe2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-000163.safetensors:  73%|#######3  | 3.15G/4.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf-mirror.com/repos/e7/f7/e7f7b8810f2020d7ff50a46aef578773eecb7386ccba95924d21eae90685f990/d6f299f7b410b9a7806927b5d2d413fae1f2c1dfa340bb0037d02d220cd8c080?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00007-of-000163.safetensors%3B+filename%3D%22model-00007-of-000163.safetensors%22%3B&Expires=1739353834&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTM1MzgzNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U3L2Y3L2U3ZjdiODgxMGYyMDIwZDdmZjUwYTQ2YWVmNTc4NzczZWVjYjczODZjY2JhOTU5MjRkMjFlYWU5MDY4NWY5OTAvZDZmMjk5ZjdiNDEwYjlhNzgwNjkyN2I1ZDJkNDEzZmFlMWYyYzFkZmEzNDBiYjAwMzdkMDJkMjIwY2Q4YzA4MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=uWn2eRLEE%7EkEPseLsNFZx3nYDabBpqrL2gJZdKix4fRMvtXUj-QBn8R4yfwVaxb%7EzgsgIh2jRpAy6BLf1bEfzJv1SByB3-z4bCnf8OhuOM81SM2u5kO-CDNjGdbPADY6HfMFKRioqgbFlgd6PAIC6eGNUtM6B5jHJxa9yzKxEKU9PRM9O0JDJPH4IvYT-6SmKqEyDG2pZKPAojQm9FJNAytHHXordFtbH8gmhhposRmfXk8mGxEeSYGuhlDX6A129aP8hoSEosrX30-dbEZk1uVLnvIMofNS0gML2pJ7wdRcu7vJSqegpAyifcNW4FlJFDMw1Xqz7-LAzKdpX3n64g__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758beb60f6c644e8b8128833645d8757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-000163.safetensors:  73%|#######3  | 3.16G/4.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf-mirror.com/repos/e7/f7/e7f7b8810f2020d7ff50a46aef578773eecb7386ccba95924d21eae90685f990/d6f299f7b410b9a7806927b5d2d413fae1f2c1dfa340bb0037d02d220cd8c080?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00007-of-000163.safetensors%3B+filename%3D%22model-00007-of-000163.safetensors%22%3B&Expires=1739353834&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTM1MzgzNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U3L2Y3L2U3ZjdiODgxMGYyMDIwZDdmZjUwYTQ2YWVmNTc4NzczZWVjYjczODZjY2JhOTU5MjRkMjFlYWU5MDY4NWY5OTAvZDZmMjk5ZjdiNDEwYjlhNzgwNjkyN2I1ZDJkNDEzZmFlMWYyYzFkZmEzNDBiYjAwMzdkMDJkMjIwY2Q4YzA4MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=uWn2eRLEE%7EkEPseLsNFZx3nYDabBpqrL2gJZdKix4fRMvtXUj-QBn8R4yfwVaxb%7EzgsgIh2jRpAy6BLf1bEfzJv1SByB3-z4bCnf8OhuOM81SM2u5kO-CDNjGdbPADY6HfMFKRioqgbFlgd6PAIC6eGNUtM6B5jHJxa9yzKxEKU9PRM9O0JDJPH4IvYT-6SmKqEyDG2pZKPAojQm9FJNAytHHXordFtbH8gmhhposRmfXk8mGxEeSYGuhlDX6A129aP8hoSEosrX30-dbEZk1uVLnvIMofNS0gML2pJ7wdRcu7vJSqegpAyifcNW4FlJFDMw1Xqz7-LAzKdpX3n64g__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95084f648f2400c934fce0375602c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-000163.safetensors:  75%|#######5  | 3.23G/4.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf-mirror.com/repos/e7/f7/e7f7b8810f2020d7ff50a46aef578773eecb7386ccba95924d21eae90685f990/d6f299f7b410b9a7806927b5d2d413fae1f2c1dfa340bb0037d02d220cd8c080?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00007-of-000163.safetensors%3B+filename%3D%22model-00007-of-000163.safetensors%22%3B&Expires=1739353834&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTM1MzgzNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U3L2Y3L2U3ZjdiODgxMGYyMDIwZDdmZjUwYTQ2YWVmNTc4NzczZWVjYjczODZjY2JhOTU5MjRkMjFlYWU5MDY4NWY5OTAvZDZmMjk5ZjdiNDEwYjlhNzgwNjkyN2I1ZDJkNDEzZmFlMWYyYzFkZmEzNDBiYjAwMzdkMDJkMjIwY2Q4YzA4MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=uWn2eRLEE%7EkEPseLsNFZx3nYDabBpqrL2gJZdKix4fRMvtXUj-QBn8R4yfwVaxb%7EzgsgIh2jRpAy6BLf1bEfzJv1SByB3-z4bCnf8OhuOM81SM2u5kO-CDNjGdbPADY6HfMFKRioqgbFlgd6PAIC6eGNUtM6B5jHJxa9yzKxEKU9PRM9O0JDJPH4IvYT-6SmKqEyDG2pZKPAojQm9FJNAytHHXordFtbH8gmhhposRmfXk8mGxEeSYGuhlDX6A129aP8hoSEosrX30-dbEZk1uVLnvIMofNS0gML2pJ7wdRcu7vJSqegpAyifcNW4FlJFDMw1Xqz7-LAzKdpX3n64g__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bcd2179c974d6f967599b4cae777e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-000163.safetensors:  75%|#######5  | 3.23G/4.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf-mirror.com/repos/e7/f7/e7f7b8810f2020d7ff50a46aef578773eecb7386ccba95924d21eae90685f990/d6f299f7b410b9a7806927b5d2d413fae1f2c1dfa340bb0037d02d220cd8c080?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00007-of-000163.safetensors%3B+filename%3D%22model-00007-of-000163.safetensors%22%3B&Expires=1739353834&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTM1MzgzNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U3L2Y3L2U3ZjdiODgxMGYyMDIwZDdmZjUwYTQ2YWVmNTc4NzczZWVjYjczODZjY2JhOTU5MjRkMjFlYWU5MDY4NWY5OTAvZDZmMjk5ZjdiNDEwYjlhNzgwNjkyN2I1ZDJkNDEzZmFlMWYyYzFkZmEzNDBiYjAwMzdkMDJkMjIwY2Q4YzA4MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=uWn2eRLEE%7EkEPseLsNFZx3nYDabBpqrL2gJZdKix4fRMvtXUj-QBn8R4yfwVaxb%7EzgsgIh2jRpAy6BLf1bEfzJv1SByB3-z4bCnf8OhuOM81SM2u5kO-CDNjGdbPADY6HfMFKRioqgbFlgd6PAIC6eGNUtM6B5jHJxa9yzKxEKU9PRM9O0JDJPH4IvYT-6SmKqEyDG2pZKPAojQm9FJNAytHHXordFtbH8gmhhposRmfXk8mGxEeSYGuhlDX6A129aP8hoSEosrX30-dbEZk1uVLnvIMofNS0gML2pJ7wdRcu7vJSqegpAyifcNW4FlJFDMw1Xqz7-LAzKdpX3n64g__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19069b4fe22f43c49ef63b2e5cef8c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-000163.safetensors:  83%|########2 | 3.55G/4.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf-mirror.com/repos/e7/f7/e7f7b8810f2020d7ff50a46aef578773eecb7386ccba95924d21eae90685f990/d6f299f7b410b9a7806927b5d2d413fae1f2c1dfa340bb0037d02d220cd8c080?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00007-of-000163.safetensors%3B+filename%3D%22model-00007-of-000163.safetensors%22%3B&Expires=1739353834&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTM1MzgzNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U3L2Y3L2U3ZjdiODgxMGYyMDIwZDdmZjUwYTQ2YWVmNTc4NzczZWVjYjczODZjY2JhOTU5MjRkMjFlYWU5MDY4NWY5OTAvZDZmMjk5ZjdiNDEwYjlhNzgwNjkyN2I1ZDJkNDEzZmFlMWYyYzFkZmEzNDBiYjAwMzdkMDJkMjIwY2Q4YzA4MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=uWn2eRLEE%7EkEPseLsNFZx3nYDabBpqrL2gJZdKix4fRMvtXUj-QBn8R4yfwVaxb%7EzgsgIh2jRpAy6BLf1bEfzJv1SByB3-z4bCnf8OhuOM81SM2u5kO-CDNjGdbPADY6HfMFKRioqgbFlgd6PAIC6eGNUtM6B5jHJxa9yzKxEKU9PRM9O0JDJPH4IvYT-6SmKqEyDG2pZKPAojQm9FJNAytHHXordFtbH8gmhhposRmfXk8mGxEeSYGuhlDX6A129aP8hoSEosrX30-dbEZk1uVLnvIMofNS0gML2pJ7wdRcu7vJSqegpAyifcNW4FlJFDMw1Xqz7-LAzKdpX3n64g__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344791e3ca5e41e799fdd04c30b10910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-000163.safetensors:  83%|########2 | 3.55G/4.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe = pipeline(\"text-generation\", model=\"deepseek-ai/DeepSeek-R1\", trust_remote_code=True)\n",
    "\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-R1\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. <a id='toc7_'></a>[ä»€ä¹ˆæ˜¯RAGï¼Ÿ](#toc0_)\n",
    "\n",
    "RAGçš„åˆ†ç±»ï¼š\n",
    "\n",
    "|Model | æ£€ç´¢å™¨å¾®è°ƒ | å¤§é¢„è¨€æ¨¡å‹å¾®è°ƒ| ä¾‹å¦‚ |\n",
    "|---|---|---| --- |\n",
    "| é»‘ç›’ | - | - | e.g. In-context ralm |\n",
    "| é»‘ç›’ | æ˜¯ | - | e.g. Rplug |\n",
    "| ç™½ç›’ | - | æ˜¯ | e.g. realm, self-rag |\n",
    "| ç™½ç›’ | æ˜¯ | æ˜¯ | e.g. altas |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. <a id='toc7_1_'></a>[æ–‡æœ¬çŸ¥è¯†æ£€ç´¢](#toc0_)\n",
    "å¦‚ä½•æ£€ç´¢å‡ºç›¸å…³ä¿¡æ¯æ¥è¾…åŠ©æ”¹å–„å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆè´¨é‡çš„ç³»ç»Ÿã€‚çŸ¥è¯†æ£€ç´¢é€šå¸¸åŒ…æ‹¬çŸ¥è¯†åº“æ„å»ºã€æŸ¥è¯¢æ„å»ºã€æ–‡æœ¬æ£€ç´¢å’Œæ£€ç´¢ç»“æœé‡æ’å››éƒ¨åˆ†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1. <a id='toc7_1_1_'></a>[çŸ¥è¯†åº“æ„å»º](#toc0_)\n",
    "æ–‡æœ¬å—çš„çŸ¥è¯†åº“æ„å»ºï¼Œå¦‚ç»´åŸºç™¾ç§‘ã€æ–°é—»ã€è®ºæ–‡ç­‰ã€‚\n",
    "\n",
    "æ–‡æœ¬åˆ†å—ï¼šå°†æ–‡æœ¬åˆ†æˆå¤šä¸ªå—ï¼Œæ¯ä¸ªå—åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå¥å­ã€‚\n",
    "- å›ºå®šå¤§å°å—ï¼šå°†æ–‡æœ¬åˆ†æˆå›ºå®šå¤§å°çš„å—ï¼Œå¦‚æ¯ä¸ªå—åŒ…å«512ä¸ªå­—ç¬¦ã€‚\n",
    "- åŸºäºå†…å®¹å—ï¼šå°†æ–‡æœ¬åˆ†æˆåŸºäºå†…å®¹çš„å—ï¼Œå¦‚æ¯ä¸ªå—åŒ…å«ä¸€ä¸ªå¥å­ã€‚\n",
    "  - é€šè¿‡å¥å­åˆ†å‰²ç¬¦åˆ†å‰²å¥å­ã€‚\n",
    "  - ç”¨LLMè¿›è¡Œåˆ†å‰²\n",
    "\n",
    "çŸ¥è¯†åº“å¢å¼ºï¼šçŸ¥è¯†åº“å¢å¼ºæ˜¯é€šè¿‡æ”¹è¿›å’Œä¸°å¯ŒçŸ¥è¯†åº“çš„å†…å®¹å’Œç»“æ„ï¼Œä¸ºæŸ¥è¯¢æä¾›\"æŠ“æ‰‹â€ï¼ŒåŒ…æ‹¬æŸ¥è¯¢ç”Ÿæˆä¸æ ‡é¢˜ç”Ÿæˆä¸¤ç§æ–¹æ³•ã€‚\n",
    "- ä¼ªæŸ¥è¯¢ç”Ÿæˆ\n",
    "- æ ‡é¢˜ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2. <a id='toc7_1_2_'></a>[æŸ¥è¯¢æ„å»º](#toc0_)\n",
    "æŸ¥è¯¢æ„å»ºï¼šæ—¨åœ¨é€šè¿‡æŸ¥è¯¢å¢å¼ºçš„æ–¹å¼ï¼Œæ‰©å±•å’Œä¸°å¯Œç”¨æˆ·æŸ¥è¯¢çš„è¯­ä¹‰å’Œå†…å®¹ï¼Œæé«˜æ£€ç´¢ç»“æœçš„å‡†ç¡®æ€§å’Œå…¨é¢æ€§ï¼Œâ€œé’©\"å‡ºç›¸åº”å†…å®¹ã€‚å¢å¼ºæ–¹å¼å¯åˆ†ä¸ºè¯­ä¹‰å¢å¼ºä¸å†…å®¹å¢å¼ºã€‚\n",
    "- è¯­ä¹‰å¢å¼ºï¼šåŒä¸€å¥è¯å¤šç§è¡¨è¾¾æ–¹å¼\n",
    "- å†…å®¹å¢å¼ºï¼šå¢åŠ èƒŒæ™¯çŸ¥è¯†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3. <a id='toc7_1_3_'></a>[å¦‚ä½•æ£€ç´¢ï¼Ÿ-æ–‡æœ¬æ£€ç´¢](#toc0_)\n",
    "`æ£€ç´¢å™¨`ï¼šç»™å®šçŸ¥è¯†åº“å’Œç”¨æˆ·æŸ¥è¯¢ï¼Œæ–‡æœ¬æ£€ç´¢æ—¨åœ¨æ‰¾åˆ°çŸ¥è¯†åº“ä¸­ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³çš„çŸ¥è¯†æ–‡æœ¬;æ£€ç´¢æ•ˆç‡å¢å¼ºæ—¨åœ¨è§£å†³æ£€ç´¢æ—¶çš„æ€§èƒ½ç“¶é¢ˆé—®é¢˜ã€‚æ‰€ä»¥æ£€ç´¢è´¨é‡ã€æ£€ç´¢æ•ˆç‡å¾ˆé‡è¦ã€‚å¸¸è§æ£€ç´¢å™¨æœ‰ä¸‰ç±»ï¼š\n",
    "- åˆ¤åˆ«å¼æ£€ç´¢å™¨ï¼š\n",
    "  - ç¨€ç–æ£€ç´¢å™¨ï¼Œe.g. TF-IDF\n",
    "  - åŒå‘ç¼–ç æ£€ç´¢å™¨ï¼Œe.g. ç”¨berté¢„å…ˆå°†æ–‡æœ¬å—è¿›è¡Œç¼–ç æˆå‘é‡\n",
    "  - äº¤å‰ç¼–ç æ£€ç´¢å™¨ï¼Œe.g. \n",
    "- ç”Ÿæˆå¼æ£€ç´¢å™¨ï¼šå™¨ç›´æ¥å°†çŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£ä¿¡æ¯è®°å¿†åœ¨æ¨¡å‹å‚æ•°ä¸­ã€‚ç„¶åï¼Œåœ¨æ¥æ”¶åˆ°æŸ¥è¯¢è¯·æ±‚æ—¶ï¼Œèƒ½å¤Ÿç›´æ¥ç”Ÿæˆç›¸å…³æ–‡æ¡£çš„æ ‡è¯†ç¬¦å¤ºï¼ˆå³Doc IDï¼‰ï¼Œä»¥å®Œæˆæ£€ç´¢ã€‚\n",
    "- å›¾æ£€ç´¢å™¨ï¼šå›¾æ£€ç´¢å™¨çš„çŸ¥è¯†åº“ä¸ºå›¾æ•°æ®åº“ï¼ŒåŒ…æ‹¬å¼€æ”¾çŸ¥è¯†å›¾è°±å’Œè‡ªå»ºå›¾ä¸¤ç§ï¼Œå®ƒä»¬ä¸€èˆ¬ç”±<ä¸»ä½“ã€è°“è¯å’Œå®¢ä½“>ä¸‰å…ƒç»„æ„æˆã€‚è¿™æ ·åšä¸ä»…å¯ä»¥æ•æ‰æ¦‚å¿µé—´çš„è¯­ä¹‰å…³ç³»ï¼Œè¿˜å…è®¸äººç±»å’Œæœºå™¨å¯ä»¥å…±åŒå¯¹çŸ¥è¯†è¿›è¡Œç†è§£ä¸æ¨ç†ã€‚\n",
    "\n",
    "`é‡æ’å™¨`ï¼šæ£€ç´¢é˜¶æ®µä¸ºäº†ä¿è¯æ£€ç´¢é€Ÿåº¦é€šå¸¸ä¼šæŸå¤±ä¸€å®šçš„æ€§èƒ½ï¼Œå¯èƒ½æ£€ç´¢åˆ°è´¨é‡è¾ƒä½çš„æ–‡æ¡£ã€‚é‡æ’çš„ç›®çš„æ˜¯å¯¹æ£€ç´¢åˆ°çš„æ®µè½è¿›è¡Œè¿›ä¸€æ­¥çš„æ’åºç²¾é€‰ã€‚é‡æ’å¯ä»¥åˆ†ä¸ºåŸºäºäº¤å‰ç¼–ç çš„æ–¹æ³•å’ŒåŸºäºä¸Šä¸‹æ–‡å­¦ä¹ çš„æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.4. <a id='toc7_1_4_'></a>[å¦‚ä½•å–‚ç»™å¤§æ¨¡å‹ï¼Ÿ-ç”Ÿæˆå¢å¼º](#toc0_)\n",
    "RAGå¢å¼ºæ¯”è¾ƒï¼š\n",
    "\n",
    "|æ¶æ„åˆ†ç±»|ä¼˜ç‚¹|ç¼ºç‚¹|\n",
    "|-|-|-|\n",
    "|è¾“å…¥ç«¯prompt|ç®€å•|tokenså¤ªå¤š|\n",
    "|ä¸­é—´å±‚|é«˜æ•ˆ|è€—GPUèµ„æº|\n",
    "|è¾“å‡ºç«¯|-|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. <a id='toc7_2_'></a>[å¤šæ¨¡æ€çŸ¥è¯†æ£€ç´¢](#toc0_)\n",
    "## 7.3. <a id='toc7_3_'></a>[åº”ç”¨](#toc0_)\n",
    "å¯¹è¯æœºå™¨äººã€çŸ¥è¯†åº“æ–‡ç­”..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. <a id='toc8_'></a>[éƒ¨ç½²å¤§æ¨¡å‹](#toc0_)\n",
    "## 8.1. <a id='toc8_1_'></a>[ollama](#toc0_)\n",
    "### 8.1.1. <a id='toc8_1_1_'></a>[Install and run model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the serve\n",
    "ollama serve\n",
    "\n",
    "# list all model images\n",
    "ollama list \n",
    "\n",
    "# run model from image\n",
    "ollama run model_card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2. <a id='toc8_1_2_'></a>[API on web port](#toc0_)\n",
    "communicatation with local model via web port.\n",
    "\n",
    "`generate` and `chat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   456  100   315  100   141    142     64  0:00:02  0:00:02 --:--:--   206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\":\"deepseek-r1:7b\",\"created_at\":\"2025-02-18T02:49:32.744934023Z\",\"response\":\"{\\\"}\\u003cthink\\u003e{\\\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n:\\n\\n{\\n\\n}\\n\\n}\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n\",\"done\":false}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl http://localhost:11434/api/generate -d '{\n",
    "  \"model\": \"deepseek-r1:7b\",\n",
    "  \"prompt\": \"Who are you?\",\n",
    "  \"stream\": false,\n",
    "  \"options\": {\n",
    "    \"temperature\": 0.6\n",
    "  },\n",
    "  \"format\": \"json\"\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  5034    0  4905  100   129    326      8  0:00:16  0:00:15  0:00:01   719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\":\"deepseek-r1:7b\",\"created_at\":\"2025-02-18T02:49:26.56791501Z\",\"message\":{\"role\":\"assistant\",\"content\":\"\\u003cthink\\u003e\\nOkay, so I just read that \\\"Why is the sky blue?\\\" and now I'm trying to figure it out myself. Let me think through this step by step.\\n\\nFirst off, when you look at the sky on a clear day, it's usually blue, especially during the day when the sun is out. But sometimes I've seen it turn other colors too, like red in the evening or during sunrise. So why is it mostly blue?\\n\\nI know that light travels through the atmosphere, but how does it get colored? I remember learning about something called Rayleigh scattering from my science class. Let me try to recall what that was about. Rayleigh scattering involves light interacting with particles much smaller than the wavelength of light itself. When sunlight enters the Earth's atmosphere, it reaches tiny molecules in the air, like nitrogen and oxygen.\\n\\nWait, so these small particles scatter the sunlight in all directions. But why does this result in a blue sky? I think it has something to do with the wavelengths of light. Visible light ranges from violet to red, right? And I remember that violet light has a shorter wavelength than blue. So maybe the shorter wavelengths are scattered more.\\n\\nBut if blue is scattered more, wouldn't it be easier to see at night when there's less atmosphere overhead? Hmm, but then why does the sky turn red in the evening or during sunrise?\\n\\nOh right! During sunrise and sunset, the light has to pass through a much thicker layer of atmosphere. That makes sense because we're looking at the light after it's been scattered through more particles. The longer path means that all the shorter wavelengths (like violet) are scattered out, leaving red to dominate because it has a longer wavelength.\\n\\nSo during the day, when the sun is directly overhead, blue and green wavelengths get scattered away by Rayleigh scattering, making the sky appear blue. But in the early morning or late afternoon, as the sun is near the horizon, the light has to pass through more atmosphere, so red comes through because it's not scattered as much.\\n\\nWait, but isn't there also something called Mie scattering? I think that happens when particles are larger than the wavelength of light. Does that affect the color of the sky too?\\n\\nI believe Mie scattering is more significant for larger particles, like dust or droplets in clouds. So it might cause some effects we see during sunrise and sunset, but not as much as Rayleigh does for small molecules.\\n\\nSo to summarize: The sky appears blue on a clear day because blue light scatters more in the atmosphere due to Rayleigh scattering by tiny gas molecules. During sunrise and sunset, the longer path allows red light to dominate, giving the sky its reddish hues.\\n\\nBut wait, what about when we see other colors? I mean, sometimes during the day it's not just blue; I've seen green or yellow in some places. Is that because of Rayleigh scattering changing as the atmosphere gets thicker?\\n\\nOr maybe it's due to other factors like pollution or particles in the air affecting light differently. That might complicate things.\\n\\nAlso, does humidity play a role? Sometimes when it's humid, does the sky appear clearer instead of blue? I think higher humidity can affect how light scatters because more water vapor means more molecules to scatter off.\\n\\nSo maybe on days with high humidity, the Rayleigh scattering is less effective, making the sky look different. But that's probably a secondary effect compared to the basic reason for the color being blue.\\n\\nIn any case, I think the primary reason is Rayleigh scattering by nitrogen and oxygen in the atmosphere causing shorter wavelengths like blue to scatter more, resulting in a blue sky during clear days.\\n\\u003c/think\\u003e\\n\\nThe sky appears blue primarily due to a phenomenon known as Rayleigh scattering. When sunlight enters Earth's atmosphere, it interacts with tiny molecules of nitrogen and oxygen. These particles scatter shorter wavelengths of light, such as blue and violet, which have shorter wavelengths than red or orange. This scattering is more effective for shorter wavelengths, causing the sky to appear blue during the day.\\n\\nDuring sunrise and sunset, the light passes through a thicker layer of atmosphere, where all shorter wavelengths are scattered away, leaving longer wavelengths like red to dominate, resulting in the reddish hues observed at these times.\\n\\nOther factors such as humidity, pollution, or atmospheric particles can influence how light scatters, but the primary reason for the sky's blue color remains Rayleigh scattering by nitrogen and oxygen molecules.\"},\"done_reason\":\"stop\",\"done\":true,\"total_duration\":15024265818,\"load_duration\":22057058,\"prompt_eval_count\":9,\"prompt_eval_duration\":7000000,\"eval_count\":901,\"eval_duration\":14993000000}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl http://localhost:11434/api/chat -d '{\n",
    "  \"model\": \"deepseek-r1:7b\",\n",
    "  \"messages\": [\n",
    "    { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n",
    "  ],\n",
    "  \"stream\": false\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.3. <a id='toc8_1_3_'></a>[Python ollama module](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "\n",
    "texts = '''\n",
    "è¯¦ç»†æ¯”è¾ƒdeepseekæ¯å…¬å¸å’ŒopenAIå…¬å¸çš„åŒºåˆ«\n",
    "'''\n",
    "\n",
    "# model_card = \"deepseek-r1:7b\"\n",
    "model_card = \"modelscope.cn/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF\"\n",
    "\n",
    "# æ–¹å¼ä¸€ï¼ˆéæµå¼è¾“å‡ºï¼‰ï¼š\n",
    "# outputs = ollama.generate(model_card, inputs)\n",
    "# print(f'{outputs['response']}')\n",
    "\n",
    "# æ–¹å¼äºŒï¼ˆæµå¼è¾“å‡ºï¼‰ï¼š\n",
    "outputs = ollama.generate(\n",
    "    stream=True,\n",
    "    model=model_card,\n",
    "    prompt=texts,\n",
    ")\n",
    "for chunk in outputs:\n",
    "    if not chunk['done']:\n",
    "        print(f'{chunk['response']}', end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.3.1. <a id='toc8_1_3_1_'></a>[demoï¼šç¿»è¯‘ä¸­æ–‡ä¸ºè‹±æ–‡](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "å—¯ï¼Œé¦–å…ˆæˆ‘è¦ç†è§£è¿™ä¸ªé¢˜ç›®çš„æ„æ€ã€‚â€œåŸºäºæ·±åº¦å­¦ä¹ â€æŒ‡çš„æ˜¯ä½¿ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯æ¥è¿›è¡Œç ”ç©¶ã€‚è€Œâ€œå¯¹æ¯è‰èŠ½èƒæ†èŒèŠ½èƒå½¢æˆç›¸å…³åŸºå› çš„ç ”ç©¶â€åˆ™æ˜¯å…·ä½“çš„ç ”ç©¶å†…å®¹ï¼Œæ¶‰åŠåˆ°æ¯è‰èŠ½èƒæ†èŒåœ¨å½¢æˆèŠ½èƒè¿‡ç¨‹ä¸­ç›¸å…³çš„åŸºå› ã€‚\n",
      "\n",
      "æˆ‘éœ€è¦æŠŠè¿™æ•´ä¸ªå¥å­å‡†ç¡®åœ°ç¿»è¯‘æˆè‹±æ–‡ã€‚é¦–å…ˆï¼Œâ€œåŸºäºæ·±åº¦å­¦ä¹ â€å¯ä»¥ç›´æ¥ç¿»è¯‘ä¸ºâ€œBased on deep learningâ€ã€‚æ¥ä¸‹æ¥æ˜¯â€œç ”ç©¶â€ï¼Œå¯¹åº”çš„è‹±æ–‡æ˜¯â€œstudyâ€ã€‚ç„¶åæ˜¯â€œæ¯è‰èŠ½èƒæ†èŒâ€ï¼Œè¿™ä¸ªåº”è¯¥æ˜¯ä¸€ä¸ªä¸“æœ‰åè¯ï¼Œå¯èƒ½éœ€è¦æŸ¥ä¸€ä¸‹æ­£ç¡®çš„è‹±è¯‘åç§°ï¼Œæ¯”å¦‚â€œBacillus subtilisâ€ã€‚\n",
      "\n",
      "æ¥ç€æ˜¯â€œèŠ½èƒå½¢æˆç›¸å…³åŸºå› â€ï¼Œè¿™éƒ¨åˆ†å¯ä»¥ç¿»è¯‘ä¸ºâ€œgenes related to spore formationâ€ã€‚æœ€åï¼ŒæŠŠæ•´ä¸ªå¥å­è¿è´¯èµ·æ¥ï¼Œå°±æ˜¯â€œBased on deep learning study of genes related to spore formation in Bacillus subtilis.â€\n",
      "\n",
      "è¿™æ ·ç»„åˆèµ·æ¥ï¼Œæ—¢å‡†ç¡®ä¼ è¾¾äº†åŸæ„ï¼Œåˆç¬¦åˆè‹±æ–‡çš„è¡¨è¾¾ä¹ æƒ¯ã€‚æˆ‘è§‰å¾—è¿™ä¸ªç¿»è¯‘åº”è¯¥æ˜¯æ¯”è¾ƒä¸“ä¸šå’Œå‡†ç¡®çš„ã€‚\n",
      "</think>\n",
      "\n",
      "Study of Genes Related to Spore Formation in *Bacillus subtilis* Based on Deep Learningâš¡\n",
      "<think>\n",
      "å¥½çš„ï¼Œé¦–å…ˆæˆ‘è¦ç†è§£ç”¨æˆ·çš„éœ€æ±‚ã€‚ä»–ç»™äº†ä¸€ä¸ªä¸­è‹±å¯¹ç…§çš„å¥å­ï¼Œè¦æ±‚ä¸“ä¸šç¿»è¯‘ï¼Œå¹¶ä¸”éœ€è¦å°†ä¸­æ–‡å¥å­â€œé€šè¿‡å®åŸºå› ç»„ç ”ç©¶å¾®ç”Ÿç‰©ä¸æ¤ç‰©ç›¸äº’ä½œç”¨çš„æœºåˆ¶ã€‚â€å‡†ç¡®åœ°ç¿»è¯‘æˆè‹±æ–‡ã€‚\n",
      "\n",
      "æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦åˆ†æåŸæ–‡çš„æ„æ€ã€‚å¥å­çš„ä¸»å¹²æ˜¯â€œé€šè¿‡å®åŸºå› ç»„ç ”ç©¶â€¦â€ï¼Œè¿™é‡Œçš„å…³é”®è¯æœ‰â€œå®åŸºå› ç»„â€ã€â€œå¾®ç”Ÿç‰©â€ã€â€œæ¤ç‰©â€ä»¥åŠâ€œç›¸äº’ä½œç”¨çš„æœºåˆ¶â€ã€‚æ‰€ä»¥ï¼Œé¦–å…ˆè¦ç¡®å®šè¿™äº›æœ¯è¯­åœ¨è‹±æ–‡ä¸­çš„å‡†ç¡®å¯¹åº”è¯ã€‚\n",
      "\n",
      "â€œå®åŸºå› ç»„â€é€šå¸¸ç¿»è¯‘ä¸ºâ€œmetagenomeâ€æˆ–è€…â€œmeta-genomicsâ€ï¼Œä½†æ›´å¸¸è§çš„æ˜¯ä½¿ç”¨â€œmetagenomicsâ€æ¥è¡¨ç¤ºè¿™ä¸€ç ”ç©¶é¢†åŸŸã€‚å› æ­¤ï¼Œè¿™é‡Œé€‰æ‹©â€œmetagenomicsâ€ä½œä¸ºç¿»è¯‘ã€‚\n",
      "\n",
      "ç„¶åï¼Œâ€œé€šè¿‡â€¦ç ”ç©¶â€¦â€çš„ç»“æ„åœ¨è‹±æ–‡ä¸­å¯ä»¥ç”¨â€œthroughâ€æˆ–è€…â€œby means ofâ€æ¥è¡¨è¾¾ï¼Œä½†ä¸ºäº†ç®€æ´å’Œä¸“ä¸šï¼Œç›´æ¥ä½¿ç”¨â€œThroughâ€æ¯”è¾ƒåˆé€‚ã€‚\n",
      "\n",
      "æ¥ä¸‹æ¥æ˜¯â€œå¾®ç”Ÿç‰©ä¸æ¤ç‰©ç›¸äº’ä½œç”¨çš„æœºåˆ¶â€ã€‚è¿™é‡Œéœ€è¦æ³¨æ„è¯­åºå’Œç”¨è¯ã€‚æ•´ä½“ç»“æ„åº”è¯¥æ˜¯â€œthe mechanisms underlying the interactions between microorganisms and plants.â€ è¿™æ ·ä¸ä»…æ¸…æ™°ï¼Œè€Œä¸”ç¬¦åˆå­¦æœ¯å†™ä½œçš„è§„èŒƒã€‚\n",
      "\n",
      "æœ€åï¼ŒæŠŠè¿™äº›éƒ¨åˆ†ç»„åˆèµ·æ¥ï¼Œç¡®ä¿å¥å­é€šé¡ºä¸”å‡†ç¡®ã€‚æ‰€ä»¥ï¼Œæœ€ç»ˆç¿»è¯‘ä¸ºï¼šâ€œThrough metagenomics research on the mechanisms of interaction between microorganisms and plants.â€\n",
      "\n",
      "åœ¨æ•´ä¸ªæ€è€ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘æ³¨æ„åˆ°ç”¨æˆ·å¯èƒ½æ˜¯åœ¨æ’°å†™å­¦æœ¯è®ºæ–‡æˆ–è€…å‡†å¤‡ç ”ç©¶æŠ¥å‘Šï¼Œå› æ­¤å‡†ç¡®æ€§å’Œä¸“ä¸šæ€§æ˜¯å…³é”®ã€‚æ­¤å¤–ï¼Œä¿æŒå¥å­çš„ç®€æ´ä¹Ÿæ˜¯å¿…è¦çš„ï¼Œä»¥ä¾¿è¯»è€…èƒ½å¤Ÿå¿«é€Ÿç†è§£å†…å®¹ã€‚\n",
      "\n",
      "æœ€åï¼Œå†æ£€æŸ¥ä¸€éç¿»è¯‘æ˜¯å¦å¿ å®äºåŸæ–‡ï¼Œå¹¶ä¸”ç¬¦åˆè‹±è¯­è¡¨è¾¾ä¹ æƒ¯ã€‚ç¡®è®¤æ— è¯¯åï¼Œå°±å¯ä»¥å°†è¿™ä¸ªç¿»è¯‘ç»“æœæä¾›ç»™ç”¨æˆ·äº†ã€‚\n",
      "</think>\n",
      "\n",
      "Through metagenomics research on the mechanisms of interaction between microorganisms and plants.âš¡\n"
     ]
    }
   ],
   "source": [
    "import ollama \n",
    "\n",
    "\n",
    "class zh2en():\n",
    "    def __init__(self, model_card):\n",
    "        self.model_card = model_card\n",
    "        \n",
    "    def build_prompt(self, texts):\n",
    "        # with open(prompt_template_path, 'r') as f:\n",
    "        #     prompt_template = f.read()\n",
    "        #     # str with replace function\n",
    "        #     prompt = prompt_template.replace(var, texts)\n",
    "        prompt_template = \"\"\"\n",
    "        ä¸“ä¸šç¿»è¯‘ï¼š\\n\n",
    "        ---\\n\n",
    "        {Chinese_words} \\n\n",
    "        --- \\n\n",
    "        ä½œä¸ºç¿»è¯‘ä¸“å®¶ï¼Œå°†ä¸Šè¿°ä¸­æ–‡å‡†ç¡®ç¿»è¯‘ä¸ºè‹±æ–‡ã€‚ \\n\n",
    "        \"\"\"\n",
    "        prompt = prompt_template.replace(\"{Chinese_words}\", texts)\n",
    "        return prompt\n",
    "\n",
    "    def translate(self, texts):\n",
    "        prompt = self.build_prompt(texts = texts)\n",
    "        # key step\n",
    "        outputs = ollama.generate(\n",
    "            stream=True,\n",
    "            model=self.model_card,\n",
    "            prompt=prompt,\n",
    "        )\n",
    "        for chunk in outputs:\n",
    "            if not chunk['done']:\n",
    "                print(f'{chunk['response']}', end='', flush=True)\n",
    "            else:\n",
    "                print('âš¡')\n",
    "\n",
    "\n",
    "translater = zh2en(model_card='modelscope.cn/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF')\n",
    "\n",
    "translater.translate('åŸºäºæ·±åº¦å­¦ä¹ çš„å¯¹æ¯è‰èŠ½èƒæ†èŒèŠ½èƒå½¢æˆç›¸å…³åŸºå› çš„ç ”ç©¶ã€‚')\n",
    "translater.translate('é€šè¿‡å®åŸºå› ç»„ç ”ç©¶å¾®ç”Ÿç‰©ä¸æ¤ç‰©ç›¸äº’ä½œç”¨çš„æœºåˆ¶ã€‚')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. <a id='toc8_2_'></a>[ktransformers](#toc0_)\n",
    "### 8.2.1. <a id='toc8_2_1_'></a>[DeepSeek-R1_Q4_K_M with ktransformers docker container](#toc0_)\n",
    "\n",
    "[https://github.com/kvcache-ai/ktransformers-private/blob/main/doc/en/Docker.md](https://github.com/kvcache-ai/ktransformers-private/blob/main/doc/en/Docker.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the image from docker hub \n",
    "# about 19 GB\n",
    "docker pull approachingai/ktransformers:0.1.1\n",
    "\n",
    "# docker run \\\n",
    "#     --gpus all \\\n",
    "#     -v /path/to/models:/models \\\n",
    "#     -p 10002:10002 \\\n",
    "#     approachingai/ktransformers:v0.1.1 \\\n",
    "#     --port 10002 \\\n",
    "#     --gguf_path /models/path/to/gguf_path \\\n",
    "#     --model_path /models/path/to/model_path \\\n",
    "#     --web True\n",
    "\n",
    "# maybe happen some errors\n",
    "docker run  \\\n",
    "    -v /bmp/backup/zhaosy/ws/ktransformers/models:/models \\\n",
    "    -p 10002:10002 \\\n",
    "    approachingai/ktransformers:0.1.1 \\\n",
    "    --port 10002 \\\n",
    "    --model_path /bmp/backup/zhaosy/ProgramFiles/hf/deepseek-ai/DeepSeek-R1 \\\n",
    "    --gguf_path /bmp/backup/zhaosy/ProgramFiles/hf/deepseek-ai/DeepSeek-R1-Q4_K_M_GGUF \\\n",
    "    --web True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
