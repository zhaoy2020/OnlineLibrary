<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Learn-Pytorch</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KIDxnIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzQxNDE0MSI+CiAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiA8L2c+CiA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSguNDMgLjA0MDEpIiBmaWxsPSIjZmZmIj4KICA8cGF0aCBkPSJtNC4xNCA4Ljc2cTAuMDY4Mi0xLjg5IDIuNDItMS44OSAxLjE2IDAgMS42OCAwLjQyIDAuNTY3IDAuNDEgMC41NjcgMS4xNnYzLjQ3cTAgMC40NjIgMC41MTQgMC40NjIgMC4xMDMgMCAwLjItMC4wMjMxdjAuNzE0cS0wLjM5OSAwLjEwMy0wLjY1MSAwLjEwMy0wLjQ1MiAwLTAuNjkzLTAuMjItMC4yMzEtMC4yLTAuMjg0LTAuNjYyLTAuOTU2IDAuODcyLTIgMC44NzItMC45MDMgMC0xLjQ3LTAuNDcyLTAuNTI1LTAuNDcyLTAuNTI1LTEuMjYgMC0wLjI2MiAwLjA0NTItMC40NzIgMC4wNTY3LTAuMjIgMC4xMTYtMC4zNzggMC4wNjgyLTAuMTY4IDAuMjMxLTAuMzA0IDAuMTU4LTAuMTQ3IDAuMjYyLTAuMjQyIDAuMTE2LTAuMDkxNCAwLjM2OC0wLjE2OCAwLjI2Mi0wLjA5MTQgMC4zOTktMC4xMjYgMC4xMzYtMC4wNDUyIDAuNDcyLTAuMTAzIDAuMzM2LTAuMDU3OCAwLjUwNC0wLjA3OTggMC4xNTgtMC4wMjMxIDAuNTY3LTAuMDc5OCAwLjU1Ni0wLjA2ODIgMC43NzctMC4yMjEgMC4yMi0wLjE1MiAwLjIyLTAuNDQxdi0wLjI1MnEwLTAuNDMtMC4zNTctMC42NjItMC4zMzYtMC4yMzEtMC45NzYtMC4yMzEtMC42NjIgMC0wLjk5OCAwLjI2Mi0wLjMzNiAwLjI1Mi0wLjM5OSAwLjc5OHptMS44OSAzLjY4cTAuNzg4IDAgMS4yNi0wLjQxIDAuNTA0LTAuNDIgMC41MDQtMC45MDN2LTEuMDVxLTAuMjg0IDAuMTM2LTAuODYxIDAuMjMxLTAuNTY3IDAuMDkxNC0wLjk4NyAwLjE1OC0wLjQyIDAuMDY4Mi0wLjc2NiAwLjMyNi0wLjMzNiAwLjI1Mi0wLjMzNiAwLjcwNHQwLjMwNCAwLjcwNCAwLjg2MSAwLjI1MnoiIHN0cm9rZS13aWR0aD0iMS4wNSIvPgogIDxwYXRoIGQ9Im0xMCA0LjU2aDAuOTQ1djMuMTVxMC42NTEtMC45NzYgMS44OS0wLjk3NiAxLjE2IDAgMS44OSAwLjg0IDAuNjgyIDAuODQgMC42ODIgMi4zMSAwIDEuNDctMC43MDQgMi40Mi0wLjcwNCAwLjg4Mi0xLjg5IDAuODgyLTEuMjYgMC0xLjg5LTEuMDJ2MC43NjZoLTAuODV6bTIuNjIgMy4wNHEtMC43NDYgMC0xLjE2IDAuNjQtMC40NTIgMC42My0wLjQ1MiAxLjY4IDAgMS4wNSAwLjQ1MiAxLjY4dDEuMTYgMC42M3EwLjc3NyAwIDEuMjYtMC42MyAwLjQ5NC0wLjY0IDAuNDk0LTEuNjggMC0xLjA1LTAuNDcyLTEuNjgtMC40NjItMC42NC0xLjI2LTAuNjR6IiBzdHJva2Utd2lkdGg9IjEuMDUiLz4KICA8cGF0aCBkPSJtMi43MyAxNS44IDEzLjYgMC4wMDgxYzAuMDA2OSAwIDAtMi42IDAtMi42IDAtMC4wMDc4LTEuMTUgMC0xLjE1IDAtMC4wMDY5IDAtMC4wMDgzIDEuNS0wLjAwODMgMS41LTJlLTMgLTAuMDAxNC0xMS4zLTAuMDAxNC0xMS4zLTAuMDAxNGwtMC4wMDU5Mi0xLjVjMC0wLjAwNzgtMS4xNyAwLjAwMTMtMS4xNyAwLjAwMTN6IiBzdHJva2Utd2lkdGg9Ii45NzUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><strong>Table of contents</strong><a id="toc0_"></a></p>
<ul>
<li><ol>
<li><a href="#toc1_"></a></li>
</ol>
</li>
<li><ol start="2">
<li><a href="#toc2_"></a></li>
</ol>
</li>
<li><ol start="3">
<li><a href="#toc3_">utils</a></li>
</ol>
<ul>
<li>3.1. <a href="#toc3_1_"></a></li>
<li>3.2. <a href="#toc3_2_"></a><ul>
<li>3.2.1. <a href="#toc3_2_1_">cpu</a></li>
<li>3.2.2. <a href="#toc3_2_2_">gpu</a></li>
</ul>
</li>
<li>3.3. <a href="#toc3_3_">numpypytorch</a></li>
</ul>
</li>
<li><ol start="4">
<li><a href="#toc4_">GPU</a></li>
</ol>
<ul>
<li>4.1. <a href="#toc4_1_"></a></li>
<li>4.2. <a href="#toc4_2_"></a></li>
<li>4.3. <a href="#toc4_3_">-CUDA Driver</a><ul>
<li>4.3.1. <a href="#toc4_3_1_">CUDA Driver</a></li>
<li>4.3.2. <a href="#toc4_3_2_">nouveau</a></li>
<li>4.3.3. <a href="#toc4_3_3_">CUDA Driver</a></li>
<li>4.3.4. <a href="#toc4_3_4_"></a></li>
<li>4.3.5. <a href="#toc4_3_5_">nvcc</a></li>
</ul>
</li>
<li>4.4. <a href="#toc4_4_">CUDA ToolkitCuDNN</a><ul>
<li>4.4.1. <a href="#toc4_4_1_">CUDA Toolkit</a></li>
<li>4.4.2. <a href="#toc4_4_2_">CUDA Toolkit</a></li>
<li>4.4.3. <a href="#toc4_4_3_">CuDNN</a></li>
<li>4.4.4. <a href="#toc4_4_4_">CuDNN</a></li>
</ul>
</li>
<li>4.5. <a href="#toc4_5_">Pytorch</a></li>
<li>4.6. <a href="#toc4_6_">A100</a></li>
<li>4.7. <a href="#toc4_7_">GPU</a><ul>
<li>4.7.1. <a href="#toc4_7_1_"></a></li>
<li>4.7.2. <a href="#toc4_7_2_"></a></li>
<li>4.7.3. <a href="#toc4_7_3_">GPU burn</a></li>
</ul>
</li>
</ul>
</li>
<li><ol start="5">
<li><a href="#toc5_">Pytorch</a></li>
</ol>
<ul>
<li>5.1. <a href="#toc5_1_"></a></li>
</ul>
</li>
<li><ol start="6">
<li><a href="#toc6_"></a></li>
</ol>
<ul>
<li>6.1. <a href="#toc6_1_">torchvison.datasetsDataset</a></li>
<li>6.2. <a href="#toc6_2_">Dataset</a><ul>
<li>6.2.1. <a href="#toc6_2_1_">TensorDataset()Dataset</a></li>
<li>6.2.2. <a href="#toc6_2_2_">Dataset</a></li>
<li>6.2.3. <a href="#toc6_2_3_">Pytoch.utils.data.Dataset</a></li>
</ul>
</li>
<li>6.3. <a href="#toc6_3_">-DataLoader()</a><ul>
<li>6.3.1. <a href="#toc6_3_1_"></a></li>
<li>6.3.2. <a href="#toc6_3_2_">collate_fntensor</a></li>
<li>6.3.3. <a href="#toc6_3_3_">DataLoader</a></li>
</ul>
</li>
</ul>
</li>
<li><ol start="7">
<li><a href="#toc7_">(Tensors)</a></li>
</ol>
<ul>
<li>7.1. <a href="#toc7_1_">Tensors</a></li>
<li>7.2. <a href="#toc7_2_">Tensors</a><ul>
<li>7.2.1. <a href="#toc7_2_1_">-dtype</a><ul>
<li>7.2.1.1. <a href="#toc7_2_1_1_"></a></li>
</ul>
</li>
<li>7.2.2. <a href="#toc7_2_2_">-device</a></li>
<li>7.2.3. <a href="#toc7_2_3_">-size/shape</a><ul>
<li>7.2.3.1. <a href="#toc7_2_3_1_"></a></li>
<li>7.2.3.2. <a href="#toc7_2_3_2_"></a></li>
<li>7.2.3.3. <a href="#toc7_2_3_3_"></a></li>
</ul>
</li>
<li>7.2.4. <a href="#toc7_2_4_"></a><ul>
<li>7.2.4.1. <a href="#toc7_2_4_1_"></a></li>
<li>7.2.4.2. <a href="#toc7_2_4_2_"></a><ul>
<li>7.2.4.2.1. <a href="#toc7_2_4_2_1_"></a></li>
</ul>
</li>
<li>7.2.4.3. <a href="#toc7_2_4_3_"></a></li>
</ul>
</li>
</ul>
</li>
<li>7.3. <a href="#toc7_3_">Tensors</a><ul>
<li>7.3.1. <a href="#toc7_3_1_"></a></li>
<li>7.3.2. <a href="#toc7_3_2_"></a><ul>
<li>7.3.2.1. <a href="#toc7_3_2_1_">reshape</a></li>
<li>7.3.2.2. <a href="#toc7_3_2_2_">view</a></li>
<li>7.3.2.3. <a href="#toc7_3_2_3_">transpose</a><ul>
<li>7.3.2.3.1. <a href="#toc7_3_2_3_1_"></a></li>
<li>7.3.2.3.2. <a href="#toc7_3_2_3_2_"></a></li>
</ul>
</li>
<li>7.3.2.4. <a href="#toc7_3_2_4_">permute</a><ul>
<li>7.3.2.4.1. <a href="#toc7_3_2_4_1_"></a></li>
<li>7.3.2.4.2. <a href="#toc7_3_2_4_2_"></a></li>
</ul>
</li>
<li>7.3.2.5. <a href="#toc7_3_2_5_">unsqueeze</a><ul>
<li>7.3.2.5.1. <a href="#toc7_3_2_5_1_">1</a></li>
<li>7.3.2.5.2. <a href="#toc7_3_2_5_2_"></a></li>
</ul>
</li>
<li>7.3.2.6. <a href="#toc7_3_2_6_">squeeze</a></li>
<li>7.3.2.7. <a href="#toc7_3_2_7_"> (concat)</a></li>
<li>7.3.2.8. <a href="#toc7_3_2_8_"> (split)</a></li>
<li>7.3.2.9. <a href="#toc7_3_2_9_"> (chunk)</a></li>
<li>7.3.2.10. <a href="#toc7_3_2_10_"> (stack)</a><ul>
<li>7.3.2.10.1. <a href="#toc7_3_2_10_1_">catstack</a></li>
</ul>
</li>
<li>7.3.2.11. <a href="#toc7_3_2_11_"> (expand)</a></li>
</ul>
</li>
</ul>
</li>
<li>7.4. <a href="#toc7_4_"></a><ul>
<li>7.4.1. <a href="#toc7_4_1_"></a></li>
<li>7.4.2. <a href="#toc7_4_2_">-</a><ul>
<li>7.4.2.1. <a href="#toc7_4_2_1_"></a></li>
<li>7.4.2.2. <a href="#toc7_4_2_2_">Dot Product</a></li>
<li>7.4.2.3. <a href="#toc7_4_2_3_">-</a></li>
<li>7.4.2.4. <a href="#toc7_4_2_4_">-</a></li>
<li>7.4.2.5. <a href="#toc7_4_2_5_"></a></li>
<li>7.4.2.6. <a href="#toc7_4_2_6_"></a></li>
</ul>
</li>
<li>7.4.3. <a href="#toc7_4_3_"></a></li>
</ul>
</li>
<li>7.5. <a href="#toc7_5_"> (Broadcasting)</a><ul>
<li>7.5.1. <a href="#toc7_5_1_"></a></li>
</ul>
</li>
<li>7.6. <a href="#toc7_6_">Pytorch   (autograd)</a><ul>
<li>7.6.1. <a href="#toc7_6_1_"> (backward)-</a></li>
<li>7.6.2. <a href="#toc7_6_2_"> ()</a></li>
</ul>
</li>
<li>7.7. <a href="#toc7_7_">-autograd</a><ul>
<li>7.7.1. <a href="#toc7_7_1_"></a><ul>
<li>7.7.1.1. <a href="#toc7_7_1_1_">-</a></li>
<li>7.7.1.2. <a href="#toc7_7_1_2_">/-</a></li>
<li>7.7.1.3. <a href="#toc7_7_1_3_">/-</a></li>
<li>7.7.1.4. <a href="#toc7_7_1_4_"></a></li>
</ul>
</li>
<li>7.7.2. <a href="#toc7_7_2_"></a></li>
<li>7.7.3. <a href="#toc7_7_3_"></a></li>
<li>7.7.4. <a href="#toc7_7_4_"></a></li>
<li>7.7.5. <a href="#toc7_7_5_"></a></li>
<li>7.7.6. <a href="#toc7_7_6_">Python</a></li>
</ul>
</li>
<li>7.8. <a href="#toc7_8_"></a></li>
</ul>
</li>
<li><ol start="8">
<li><a href="#toc8_">-</a></li>
</ol>
<ul>
<li>8.1. <a href="#toc8_1_">-</a><ul>
<li>8.1.1. <a href="#toc8_1_1_"></a></li>
<li>8.1.2. <a href="#toc8_1_2_"></a></li>
<li>8.1.3. <a href="#toc8_1_3_"></a></li>
<li>8.1.4. <a href="#toc8_1_4_"></a></li>
<li>8.1.5. <a href="#toc8_1_5_"></a></li>
<li>8.1.6. <a href="#toc8_1_6_"></a></li>
<li>8.1.7. <a href="#toc8_1_7_"></a></li>
</ul>
</li>
<li>8.2. <a href="#toc8_2_">-</a><ul>
<li>8.2.1. <a href="#toc8_2_1_"></a></li>
<li>8.2.2. <a href="#toc8_2_2_"></a></li>
<li>8.2.3. <a href="#toc8_2_3_"></a></li>
<li>8.2.4. <a href="#toc8_2_4_"></a></li>
<li>8.2.5. <a href="#toc8_2_5_"></a></li>
<li>8.2.6. <a href="#toc8_2_6_"></a></li>
<li>8.2.7. <a href="#toc8_2_7_"></a></li>
<li>8.2.8. <a href="#toc8_2_8_"></a></li>
<li>8.2.9. <a href="#toc8_2_9_"></a></li>
</ul>
</li>
<li>8.3. <a href="#toc8_3_">-y_hat</a><ul>
<li>8.3.1. <a href="#toc8_3_1_">torch.nn</a></li>
<li>8.3.2. <a href="#toc8_3_2_"></a><ul>
<li>8.3.2.1. <a href="#toc8_3_2_1_"></a></li>
<li>8.3.2.2. <a href="#toc8_3_2_2_"></a></li>
<li>8.3.2.3. <a href="#toc8_3_2_3_"></a></li>
</ul>
</li>
<li>8.3.3. <a href="#toc8_3_3_">/</a><ul>
<li>8.3.3.1. <a href="#toc8_3_3_1_">.children()</a></li>
<li>8.3.3.2. <a href="#toc8_3_3_2_">.named_children()</a></li>
<li>8.3.3.3. <a href="#toc8_3_3_3_">.modules()</a></li>
<li>8.3.3.4. <a href="#toc8_3_3_4_">.named_modules()</a></li>
<li>8.3.3.5. <a href="#toc8_3_3_5_"></a></li>
<li>8.3.3.6. <a href="#toc8_3_3_6_"></a></li>
<li>8.3.3.7. <a href="#toc8_3_3_7_">add_module()</a></li>
</ul>
</li>
<li>8.3.4. <a href="#toc8_3_4_"></a><ul>
<li>8.3.4.1. <a href="#toc8_3_4_1_"></a><ul>
<li>8.3.4.1.1. <a href="#toc8_3_4_1_1_">state_dict</a></li>
<li>8.3.4.1.2. <a href="#toc8_3_4_1_2_">parameters</a></li>
<li>8.3.4.1.3. <a href="#toc8_3_4_1_3_">named_parameters</a></li>
</ul>
</li>
<li>8.3.4.2. <a href="#toc8_3_4_2_"></a><ul>
<li>8.3.4.2.1. <a href="#toc8_3_4_2_1_"></a></li>
<li>8.3.4.2.2. <a href="#toc8_3_4_2_2_"></a></li>
<li>8.3.4.2.3. <a href="#toc8_3_4_2_3_"></a></li>
</ul>
</li>
</ul>
</li>
<li>8.3.5. <a href="#toc8_3_5_"></a><ul>
<li>8.3.5.1. <a href="#toc8_3_5_1_"></a></li>
<li>8.3.5.2. <a href="#toc8_3_5_2_"></a></li>
</ul>
</li>
</ul>
</li>
<li>8.4. <a href="#toc8_4_">- (loss_fn)</a><ul>
<li>8.4.1. <a href="#toc8_4_1_"></a></li>
<li>8.4.2. <a href="#toc8_4_2_"></a></li>
<li>8.4.3. <a href="#toc8_4_3_"></a></li>
</ul>
</li>
<li>8.5. <a href="#toc8_5_">-</a></li>
<li>8.6. <a href="#toc8_6_">-</a><ul>
<li>8.6.1. <a href="#toc8_6_1_">SGD</a></li>
<li>8.6.2. <a href="#toc8_6_2_">adam</a></li>
<li>8.6.3. <a href="#toc8_6_3_">RMSprop</a></li>
<li>8.6.4. <a href="#toc8_6_4_"></a><ul>
<li>8.6.4.1. <a href="#toc8_6_4_1_">StepLR </a></li>
<li>8.6.4.2. <a href="#toc8_6_4_2_">MultiStepLR milestones</a></li>
<li>8.6.4.3. <a href="#toc8_6_4_3_">ExponentialLR </a></li>
<li>8.6.4.4. <a href="#toc8_6_4_4_">CosineAnnealingLR </a></li>
<li>8.6.4.5. <a href="#toc8_6_4_5_">ReduceLROnPlateau </a></li>
<li>8.6.4.6. <a href="#toc8_6_4_6_">LambdaLR </a></li>
<li>8.6.4.7. <a href="#toc8_6_4_7_"></a></li>
</ul>
</li>
</ul>
</li>
<li>8.7. <a href="#toc8_7_">-</a><ul>
<li>8.7.1. <a href="#toc8_7_1_"></a></li>
<li>8.7.2. <a href="#toc8_7_2_"></a><ul>
<li>8.7.2.1. <a href="#toc8_7_2_1_">lr</a></li>
<li>8.7.2.2. <a href="#toc8_7_2_2_"></a></li>
</ul>
</li>
<li>8.7.3. <a href="#toc8_7_3_">K</a></li>
</ul>
</li>
<li>8.8. <a href="#toc8_8_"></a></li>
</ul>
</li>
<li><ol start="9">
<li><a href="#toc9_"> GPU </a></li>
</ol>
<ul>
<li>9.1. <a href="#toc9_1_">GPU</a></li>
<li>9.2. <a href="#toc9_2_">GPU</a></li>
<li>9.3. <a href="#toc9_3_">GPU</a><ul>
<li>9.3.1. <a href="#toc9_3_1_">DP</a></li>
<li>9.3.2. <a href="#toc9_3_2_">DDP</a><ul>
<li>9.3.2.1. <a href="#toc9_3_2_1_">colab</a></li>
</ul>
</li>
</ul>
</li>
<li>9.4. <a href="#toc9_4_">GPU- </a></li>
</ul>
</li>
<li><ol start="10">
<li><a href="#toc10_"></a></li>
</ol>
<ul>
<li>10.1. <a href="#toc10_1_">-</a></li>
<li>10.2. <a href="#toc10_2_">-</a></li>
</ul>
</li>
<li><ol start="11">
<li><a href="#toc11_"></a></li>
</ol>
<ul>
<li>11.1. <a href="#toc11_1_">CNN</a><ul>
<li>11.1.1. <a href="#toc11_1_1_"></a></li>
<li>11.1.2. <a href="#toc11_1_2_">CNN</a><ul>
<li>11.1.2.1. <a href="#toc11_1_2_1_"></a><ul>
<li>11.1.2.1.1. <a href="#toc11_1_2_1_1_"></a></li>
<li>11.1.2.1.2. <a href="#toc11_1_2_1_2_"></a></li>
</ul>
</li>
<li>11.1.2.2. <a href="#toc11_1_2_2_"></a></li>
<li>11.1.2.3. <a href="#toc11_1_2_3_"></a></li>
<li>11.1.2.4. <a href="#toc11_1_2_4_"></a></li>
<li>11.1.2.5. <a href="#toc11_1_2_5_">Pooling ()</a><ul>
<li>11.1.2.5.1. <a href="#toc11_1_2_5_1_">Pooling</a></li>
<li>11.1.2.5.2. <a href="#toc11_1_2_5_2_">Pooling</a></li>
</ul>
</li>
</ul>
</li>
<li>11.1.3. <a href="#toc11_1_3_">LeNet</a></li>
<li>11.1.4. <a href="#toc11_1_4_">AlexNet</a></li>
<li>11.1.5. <a href="#toc11_1_5_">VGG</a></li>
<li>11.1.6. <a href="#toc11_1_6_">NiN</a></li>
<li>11.1.7. <a href="#toc11_1_7_">GoogLeNet</a></li>
<li>11.1.8. <a href="#toc11_1_8_"></a></li>
<li>11.1.9. <a href="#toc11_1_9_">ResNet</a><ul>
<li>11.1.9.1. <a href="#toc11_1_9_1_"></a></li>
</ul>
</li>
</ul>
</li>
<li>11.2. <a href="#toc11_2_"></a><ul>
<li>11.2.1. <a href="#toc11_2_1_"></a></li>
<li>11.2.2. <a href="#toc11_2_2_"></a></li>
<li>11.2.3. <a href="#toc11_2_3_"></a><ul>
<li>11.2.3.1. <a href="#toc11_2_3_1_">Time machine</a></li>
<li>11.2.3.2. <a href="#toc11_2_3_2_">Tokenization</a></li>
<li>11.2.3.3. <a href="#toc11_2_3_3_">Vocabulary</a></li>
<li>11.2.3.4. <a href="#toc11_2_3_4_"></a></li>
<li>11.2.3.5. <a href="#toc11_2_3_5_"></a><ul>
<li>11.2.3.5.1. <a href="#toc11_2_3_5_1_">word2vec</a></li>
</ul>
</li>
</ul>
</li>
<li>11.2.4. <a href="#toc11_2_4_"></a><ul>
<li>11.2.4.1. <a href="#toc11_2_4_1_"> (Sequential Sampling)</a></li>
<li>11.2.4.2. <a href="#toc11_2_4_2_"> (Random Sampling)</a></li>
<li>11.2.4.3. <a href="#toc11_2_4_3_"></a></li>
<li>11.2.4.4. <a href="#toc11_2_4_4_"></a></li>
</ul>
</li>
</ul>
</li>
<li>11.3. <a href="#toc11_3_">RNN</a><ul>
<li>11.3.1. <a href="#toc11_3_1_">RNN-</a><ul>
<li>11.3.1.1. <a href="#toc11_3_1_1_"></a></li>
<li>11.3.1.2. <a href="#toc11_3_1_2_"></a></li>
<li>11.3.1.3. <a href="#toc11_3_1_3_"></a></li>
<li>11.3.1.4. <a href="#toc11_3_1_4_">warm-up </a></li>
<li>11.3.1.5. <a href="#toc11_3_1_5_">RNN</a></li>
<li>11.3.1.6. <a href="#toc11_3_1_6_">RNN</a></li>
</ul>
</li>
<li>11.3.2. <a href="#toc11_3_2_">GRU</a><ul>
<li>11.3.2.1. <a href="#toc11_3_2_1_"></a></li>
<li>11.3.2.2. <a href="#toc11_3_2_2_"></a></li>
</ul>
</li>
<li>11.3.3. <a href="#toc11_3_3_">LSTM</a><ul>
<li>11.3.3.1. <a href="#toc11_3_3_1_"></a></li>
<li>11.3.3.2. <a href="#toc11_3_3_2_"></a></li>
</ul>
</li>
<li>11.3.4. <a href="#toc11_3_4_">Encoder-Decoder</a><ul>
<li>11.3.4.1. <a href="#toc11_3_4_1_">Encoder</a></li>
<li>11.3.4.2. <a href="#toc11_3_4_2_">Decoder</a></li>
<li>11.3.4.3. <a href="#toc11_3_4_3_">Encoder-Decoder</a></li>
</ul>
</li>
</ul>
</li>
<li>11.4. <a href="#toc11_4_">seq2seq (Sequence to sequence learning)</a><ul>
<li>11.4.1. <a href="#toc11_4_1_"></a><ul>
<li>11.4.1.1. <a href="#toc11_4_1_1_"></a></li>
<li>11.4.1.2. <a href="#toc11_4_1_2_"></a></li>
<li>11.4.1.3. <a href="#toc11_4_1_3_"></a></li>
<li>11.4.1.4. <a href="#toc11_4_1_4_"></a></li>
<li>11.4.1.5. <a href="#toc11_4_1_5_"></a></li>
</ul>
</li>
<li>11.4.2. <a href="#toc11_4_2_">-</a></li>
<li>11.4.3. <a href="#toc11_4_3_"></a></li>
<li>11.4.4. <a href="#toc11_4_4_"></a><ul>
<li>11.4.4.1. <a href="#toc11_4_4_1_"></a></li>
<li>11.4.4.2. <a href="#toc11_4_4_2_">softmax</a></li>
</ul>
</li>
<li>11.4.5. <a href="#toc11_4_5_"></a></li>
<li>11.4.6. <a href="#toc11_4_6_"></a></li>
</ul>
</li>
<li>11.5. <a href="#toc11_5_">Attention</a><ul>
<li>11.5.1. <a href="#toc11_5_1_">Attention Pooling-qk</a></li>
<li>11.5.2. <a href="#toc11_5_2_">Attention Pooling-qk</a></li>
<li>11.5.3. <a href="#toc11_5_3_">-qk</a><ul>
<li>11.5.3.1. <a href="#toc11_5_3_1_"> (Additive Attention)-qk</a></li>
<li>11.5.3.2. <a href="#toc11_5_3_2_"> (Scaled Dot-Product Attention)-qk</a></li>
</ul>
</li>
<li>11.5.4. <a href="#toc11_5_4_">-qkv</a></li>
<li>11.5.5. <a href="#toc11_5_5_">-hqkv</a></li>
<li>11.5.6. <a href="#toc11_5_6_">attention-seq2seq</a></li>
</ul>
</li>
<li>11.6. <a href="#toc11_6_">Transformer</a><ul>
<li>11.6.1. <a href="#toc11_6_1_"></a></li>
<li>11.6.2. <a href="#toc11_6_2_"></a><ul>
<li>11.6.2.1. <a href="#toc11_6_2_1_"></a></li>
<li>11.6.2.2. <a href="#toc11_6_2_2_"></a></li>
</ul>
</li>
<li>11.6.3. <a href="#toc11_6_3_"></a></li>
<li>11.6.4. <a href="#toc11_6_4_"></a></li>
<li>11.6.5. <a href="#toc11_6_5_"></a></li>
<li>11.6.6. <a href="#toc11_6_6_"></a></li>
<li>11.6.7. <a href="#toc11_6_7_">TransformerSeq2Seq</a></li>
</ul>
</li>
<li>11.7. <a href="#toc11_7_">BERT</a><ul>
<li>11.7.1. <a href="#toc11_7_1_">BERT encode block</a></li>
<li>11.7.2. <a href="#toc11_7_2_">Masked Language Modeling</a></li>
<li>11.7.3. <a href="#toc11_7_3_">Next Sentence Prediction</a></li>
<li>11.7.4. <a href="#toc11_7_4_">BERT</a></li>
<li>11.7.5. <a href="#toc11_7_5_">Datasets for Pre-training</a><ul>
<li>11.7.5.1. <a href="#toc11_7_5_1_"></a></li>
<li>11.7.5.2. <a href="#toc11_7_5_2_"></a></li>
<li>11.7.5.3. <a href="#toc11_7_5_3_"></a></li>
<li>11.7.5.4. <a href="#toc11_7_5_4_"></a></li>
</ul>
</li>
<li>11.7.6. <a href="#toc11_7_6_">BERT</a></li>
<li>11.7.7. <a href="#toc11_7_7_">BERT</a></li>
</ul>
</li>
<li>11.8. <a href="#toc11_8_">BERT</a><ul>
<li>11.8.1. <a href="#toc11_8_1_"></a><ul>
<li>11.8.1.1. <a href="#toc11_8_1_1_">RNN</a></li>
<li>11.8.1.2. <a href="#toc11_8_1_2_">CNN</a></li>
</ul>
</li>
<li>11.8.2. <a href="#toc11_8_2_"></a><ul>
<li>11.8.2.1. <a href="#toc11_8_2_1_">Attention</a></li>
<li>11.8.2.2. <a href="#toc11_8_2_2_">BERT</a></li>
</ul>
</li>
</ul>
</li>
<li>11.9. <a href="#toc11_9_">GPT</a></li>
<li>11.10. <a href="#toc11_10_">Mamba</a></li>
</ul>
</li>
<li><ol start="12">
<li><a href="#toc12_">==============</a></li>
</ol>
</li>
<li><ol start="13">
<li><a href="#toc13_"></a></li>
</ol>
<ul>
<li>13.1. <a href="#toc13_1_"></a></li>
<li>13.2. <a href="#toc13_2_"></a></li>
<li>13.3. <a href="#toc13_3_">one-hot</a></li>
<li>13.4. <a href="#toc13_4_">embedding</a></li>
<li>13.5. <a href="#toc13_5_">BNLN</a></li>
<li>13.6. <a href="#toc13_6_"> (masked)</a></li>
<li>13.7. <a href="#toc13_7_">MLPFCFNNCNNRNN</a></li>
<li>13.8. <a href="#toc13_8_"></a><ul>
<li>13.8.1. <a href="#toc13_8_1_"></a></li>
<li>13.8.2. <a href="#toc13_8_2_">(Mixed Precision Training)</a></li>
<li>13.8.3. <a href="#toc13_8_3_">Gradient Checkpointing</a></li>
<li>13.8.4. <a href="#toc13_8_4_"> (Chunking)</a></li>
</ul>
</li>
</ul>
</li>
<li><ol start="14">
<li><a href="#toc14_">PyTorch</a></li>
</ol>
<ul>
<li>14.1. <a href="#toc14_1_">Fine-tuning</a><ul>
<li>14.1.1. <a href="#toc14_1_1_">lr</a></li>
<li>14.1.2. <a href="#toc14_1_2_"></a></li>
</ul>
</li>
<li>14.2. <a href="#toc14_2_">torchvision</a></li>
<li>14.3. <a href="#toc14_3_"></a></li>
</ul>
</li>
<li><ol start="15">
<li><a href="#toc15_">TorchMetrics</a></li>
</ol>
<ul>
<li>15.1. <a href="#toc15_1_">F1</a></li>
<li>15.2. <a href="#toc15_2_"></a></li>
<li>15.3. <a href="#toc15_3_">PyTorch Lightning</a></li>
</ul>
</li>
<li><ol start="16">
<li><a href="#toc16_">PyTorch lightning</a></li>
</ol>
<ul>
<li>16.1. <a href="#toc16_1_"></a></li>
<li>16.2. <a href="#toc16_2_">Data.py</a></li>
<li>16.3. <a href="#toc16_3_">Model.py</a></li>
<li>16.4. <a href="#toc16_4_">ModelWrapper.py</a><ul>
<li>16.4.1. <a href="#toc16_4_1_">Training and vlidation</a></li>
<li>16.4.2. <a href="#toc16_4_2_">Validation</a></li>
<li>16.4.3. <a href="#toc16_4_3_">Test</a></li>
<li>16.4.4. <a href="#toc16_4_4_">Prediction</a><ul>
<li>16.4.4.1. <a href="#toc16_4_4_1_">PyTorch lightningTrainerpredict</a></li>
<li>16.4.4.2. <a href="#toc16_4_4_2_">PyTorch lightning</a></li>
<li>16.4.4.3. <a href="#toc16_4_4_3_">PyTorch</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><ol start="17">
<li><a href="#toc17_">Torchvision</a></li>
</ol>
<ul>
<li>17.1. <a href="#toc17_1_">Models</a><ul>
<li>17.1.1. <a href="#toc17_1_1_"></a></li>
<li>17.1.2. <a href="#toc17_1_2_"></a></li>
<li>17.1.3. <a href="#toc17_1_3_"></a></li>
<li>17.1.4. <a href="#toc17_1_4_"></a></li>
</ul>
</li>
<li>17.2. <a href="#toc17_2_">Dataset</a></li>
</ul>
</li>
<li><ol start="18">
<li><a href="#toc18_">Hugging face</a></li>
</ol>
</li>
<li><ol start="19">
<li><a href="#toc19_"> (Supervised learning)</a></li>
</ol>
</li>
<li><ol start="20">
<li><a href="#toc20_"> (Semi-supervised learning)</a></li>
</ol>
</li>
<li><ol start="21">
<li><a href="#toc21_"> (Unsupervised learning)</a></li>
</ol>
</li>
<li><ol start="22">
<li><a href="#toc22_"> (DRL, Deep Reforcement Learning)</a></li>
</ol>
<ul>
<li>22.1. <a href="#toc22_1_"></a></li>
<li>22.2. <a href="#toc22_2_"></a></li>
<li>22.3. <a href="#toc22_3_"></a></li>
<li>22.4. <a href="#toc22_4_"></a><ul>
<li>22.4.1. <a href="#toc22_4_1_"> Q Deep Q-Network, DQN</a></li>
<li>22.4.2. <a href="#toc22_4_2_">Policy Gradient Methods</a></li>
<li>22.4.3. <a href="#toc22_4_3_">-Actor-Critic Methods</a></li>
<li>22.4.4. <a href="#toc22_4_4_">Deep Deterministic Policy Gradient, DDPG</a></li>
</ul>
</li>
<li>22.5. <a href="#toc22_5_"></a></li>
</ul>
</li>
<li><ol start="23">
<li><a href="#toc23_"> (GAN, Generative Adversarial Networks)</a></li>
</ol>
</li>
<li><ol start="24">
<li><a href="#toc24_"> (DM, Diffusion Models)</a></li>
</ol>
</li>
<li><ol start="25">
<li><a href="#toc25_"> (GNN, Graph Neural Networks)</a></li>
</ol>
</li>
<li><ol start="26">
<li><a href="#toc26_"> (ML, MultiModal Learning)</a></li>
</ol>
<ul>
<li>26.1. <a href="#toc26_1_"></a><ul>
<li>26.1.1. <a href="#toc26_1_1_">concatenate</a></li>
<li>26.1.2. <a href="#toc26_1_2_"></a></li>
<li>26.1.3. <a href="#toc26_1_3_"></a></li>
<li>26.1.4. <a href="#toc26_1_4_"></a></li>
<li>26.1.5. <a href="#toc26_1_5_"></a></li>
<li>26.1.6. <a href="#toc26_1_6_"></a></li>
</ul>
</li>
<li>26.2. <a href="#toc26_2_"></a></li>
</ul>
</li>
<li><ol start="27">
<li><a href="#toc27_">argparse</a></li>
</ol>
</li>
<li><ol start="28">
<li><a href="#toc28_">ml_collections</a></li>
</ol>
</li>
<li><ol start="29">
<li><a href="#toc29_">functools</a></li>
</ol>
<ul>
<li>29.1. <a href="#toc29_1_">partial</a></li>
</ul>
</li>
<li><ol start="30">
<li><a href="#toc30_">copy</a></li>
</ol>
<ul>
<li>30.1. <a href="#toc30_1_"></a></li>
<li>30.2. <a href="#toc30_2_"></a></li>
</ul>
</li>
<li><ol start="31">
<li><a href="#toc31_"></a></li>
</ol>
</li>
</ul>
<!-- vscode-jupyter-toc-config
	numbering=true
	anchor=true
	flat=false
	minLevel=1
	maxLevel=6
	/vscode-jupyter-toc-config -->
<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="1.-%E6%A6%82%E8%BF%B0">1. <a id="toc1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#1.-%E6%A6%82%E8%BF%B0"></a></h1><p></p>
<ul>
<li>d2l EN (): <a href="https://d2l.ai/index.html">https://d2l.ai/index.html</a></li>
<li>d2l ZH: <a href="https://zh-v2.d2l.ai/">https://zh-v2.d2l.ai/</a></li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="2.-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE">2. <a id="toc2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#2.-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"></a></h1><ul>
<li><p>PyTorch <a href="https://pytorch.org/">https://pytorch.org/</a></p>
</li>
<li><p>PyTorch lightning <a href="https://lightning.ai/docs/pytorch/stable/">https://lightning.ai/docs/pytorch/stable/</a></p>
</li>
<li><p>condacondapip</p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Create environment </span>
<span class="c1"># and entry the environment</span>
<span class="n">conda</span> <span class="n">create</span> <span class="o">-</span><span class="n">n</span> <span class="n">pytorch</span> <span class="o">-</span><span class="n">y</span> <span class="o">&amp;&amp;</span> <span class="n">conda</span> <span class="n">activate</span> <span class="n">pytorch</span>

<span class="c1"># Install ipykernel and related packages via conda</span>
<span class="n">conda</span> <span class="n">install</span> <span class="n">ipykernel</span> <span class="n">matplotlib</span> <span class="n">pandas</span> <span class="n">seaborn</span> <span class="o">-</span><span class="n">y</span>

<span class="c1"># Install PyTorch</span>
<span class="n">conda</span> <span class="n">install</span> <span class="n">pytorch</span> <span class="n">torchvision</span> <span class="n">torchaudio</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">cuda</span><span class="o">=</span><span class="mf">12.4</span> <span class="o">-</span><span class="n">c</span> <span class="n">pytorch</span> <span class="o">-</span><span class="n">c</span> <span class="n">nvidia</span> <span class="o">-</span><span class="n">y</span>

<span class="c1"># Instll PyTorch lightning</span>
<span class="n">conda</span> <span class="n">install</span> <span class="n">lightning</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="o">-</span><span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="3.-utils">3. <a id="toc3_"></a><a href="#toc0_">utils</a><a class="anchor-link" href="#3.-utils"></a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="3.1.-%E5%AE%9E%E9%AA%8C%E5%8F%AF%E9%87%8D%E5%A4%8D%E6%80%A7">3.1. <a id="toc3_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#3.1.-%E5%AE%9E%E9%AA%8C%E5%8F%AF%E9%87%8D%E5%A4%8D%E6%80%A7"></a></h2><p><br/>
GPUCUDA</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 

<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Function for setting the seed</span>
<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>  <span class="c1"># GPU operation have separate seed</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Additionally, some operations on a GPU are implemented stochastic for efficiency</span>
<span class="c1"># We want to ensure that all operations are deterministic on GPU (if used) for reproducibility</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Fetching the device that will be used throughout this notebook</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Using device"</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Using device cuda:0
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="3.2.-%E8%AE%A1%E6%97%B6%E5%99%A8">3.2. <a id="toc3_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#3.2.-%E8%AE%A1%E6%97%B6%E5%99%A8"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="3.2.1.-cpu%E8%AE%A1%E6%97%B6%E5%99%A8">3.2.1. <a id="toc3_2_1_"></a><a href="#toc0_">cpu</a><a class="anchor-link" href="#3.2.1.-cpu%E8%AE%A1%E6%97%B6%E5%99%A8"></a></h3><ul>
<li></li>
</ul>
<pre><code class="language-sehll">sehll
    __init__(self) # 
    __call__(self) # 
</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">cpuTimer</span><span class="p">():</span>
<span class="w">    </span><span class="sd">''''''</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">seconds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start</span>
        <span class="n">days</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">//</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">)</span>
        <span class="n">hours</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">))</span> <span class="o">//</span> <span class="mi">3600</span>
        <span class="n">minutes</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="mi">3600</span><span class="p">)</span> <span class="o">//</span> <span class="mi">60</span>
        <span class="n">remaining_seconds</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">%</span> <span class="mi">60</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">20</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"Total</span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">days</span><span class="si">}</span><span class="s2"> d </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">hours</span><span class="si">}</span><span class="s2"> h </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">minutes</span><span class="si">}</span><span class="s2"> m </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">remaining_seconds</span><span class="si">}</span><span class="s2"> s"</span><span class="p">)</span>
        
<span class="c1"># Tiemr</span>
<span class="n">timer_on_cpu</span> <span class="o">=</span> <span class="n">cpuTimer</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">timer_on_cpu</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================== 
 Total
 0.0 d 
 0.0 h 
 0.0 m 
 0.030319690704345703 s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="3.2.2.-gpu%E8%AE%A1%E6%97%B6%E5%99%A8">3.2.2. <a id="toc3_2_2_"></a><a href="#toc0_">gpu</a><a class="anchor-link" href="#3.2.2.-gpu%E8%AE%A1%E6%97%B6%E5%99%A8"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">'''</span>
<span class="sd">GPUCPU</span>
<span class="sd">'''</span>

<span class="kn">import</span> <span class="nn">torch</span> 

<span class="k">class</span> <span class="nc">gpuTimer</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># CUDA is asynchronous, so we need to use different timing functions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>  <span class="c1"># Waits for everything to finish running on the GPU</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">""</span><span class="o">*</span><span class="mi">20</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">GPU time: </span><span class="si">{</span><span class="mf">0.001</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="o">.</span><span class="n">elapsed_time</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">end</span><span class="p">)</span><span class="si">:</span><span class="s2">6.5f</span><span class="si">}</span><span class="s2">s"</span><span class="p">)</span>  <span class="c1"># Milliseconds to seconds</span>

<span class="c1"># Demo for Timer on GPU devices</span>
<span class="n">timer_on_gpu</span> <span class="o">=</span> <span class="n">gpuTimer</span><span class="p">()</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">timer_on_gpu</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre> 
GPU time: 0.00125s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="3.3.-numpy%E5%92%8Cpytorch%E8%AE%A1%E7%AE%97%E9%80%9F%E5%BA%A6%E6%AF%94%E8%BE%83">3.3. <a id="toc3_3_"></a><a href="#toc0_">numpypytorch</a><a class="anchor-link" href="#3.3.-numpy%E5%92%8Cpytorch%E8%AE%A1%E7%AE%97%E9%80%9F%E5%BA%A6%E6%AF%94%E8%BE%83"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Datas on cpu with arrary</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Datas on cpu with tensor</span>
<span class="n">at</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>
<span class="n">bt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>

<span class="c1"># Datas on gpu with tensor</span>
<span class="n">at_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cuda:0'</span><span class="p">)</span>
<span class="n">bt_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cuda:0'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">timeit</span> a + b   # On cpu via numpy
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>1.5 ms  15.7 s per loop (mean  std. dev. of 7 runs, 1,000 loops each)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">timeit</span> at + bt # On cpu via PyTorch
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>24.8 s  332 ns per loop (mean  std. dev. of 7 runs, 10,000 loops each)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">start</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
<span class="n">at_gpu</span> <span class="o">+</span> <span class="n">bt_gpu</span>
<span class="n">stop</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>

<span class="c1"># Waits for everything to finish running</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Time: </span><span class="si">{</span><span class="mf">0.001</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">start</span><span class="o">.</span><span class="n">elapsed_time</span><span class="p">(</span><span class="n">stop</span><span class="p">)</span><span class="si">}</span><span class="s1"> s'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Time: 0.08263510131835938 s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="4.-%E5%AE%89%E8%A3%85GPU%E9%A9%B1%E5%8A%A8">4. <a id="toc4_"></a><a href="#toc0_">GPU</a><a class="anchor-link" href="#4.-%E5%AE%89%E8%A3%85GPU%E9%A9%B1%E5%8A%A8"></a></h1><p>CentOS8NVIDIA Tesla A100CUDA ToolkitCuDNNcudnncuda</p>
<ul>
<li><p>1.NVIDIA DriverNVIDIANVIDIA<code></code>CUDACuDNN<a href="https://www.nvidia.com/Download/index.aspx%E3%80%82">https://www.nvidia.com/Download/index.aspx</a></p>
</li>
<li><p>2.CUDA ToolkitCUDA Toolkit<code></code>CUDAIDECUDACUDA Toolkit CUDA Driver</p>
</li>
<li><p>3.NVCC<code>CUDA</code>,CUDA Toolkit/bin,gccc</p>
</li>
<li><p>4.CUDA Deep Neural Network (cuDNN)CuDNNNVIDIA<code></code>CuDNNCUDA Toolkit</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="4.1.-%E5%AE%89%E8%A3%85%E7%AD%96%E7%95%A5">4.1. <a id="toc4_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#4.1.-%E5%AE%89%E8%A3%85%E7%AD%96%E7%95%A5"></a></h2><ul>
<li><p> <code>cuda</code></p>
<ul>
<li><code>NVIDIA Tesla A100drivercondaCUDA ToolkitcuDNNPytorch</code></li>
</ul>
</li>
<li><p> <code>cuda</code></p>
<ul>
<li><code>DriverCUDA Toolkit ()</code></li>
</ul>
</li>
<li><p> <code>docker</code></p>
<ul>
<li><code>DriverNVIDIA docker (docker)</code></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="4.2.-%E9%A6%96%E5%85%88%E7%A1%AE%E8%AE%A4%E5%86%85%E6%A0%B8%E7%89%88%E6%9C%AC%E5%92%8C%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC%EF%BC%8C%E5%86%8D%E7%A1%AE%E8%AE%A4%E6%98%BE%E5%8D%A1%E5%9E%8B%E5%8F%B7">4.2. <a id="toc4_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#4.2.-%E9%A6%96%E5%85%88%E7%A1%AE%E8%AE%A4%E5%86%85%E6%A0%B8%E7%89%88%E6%9C%AC%E5%92%8C%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC%EF%BC%8C%E5%86%8D%E7%A1%AE%E8%AE%A4%E6%98%BE%E5%8D%A1%E5%9E%8B%E5%8F%B7"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span>%%bash<span class="w"> </span>
<span class="nb">echo</span><span class="w"> </span>linux
uname<span class="w"> </span>-a
<span class="c1"># Linux 135.91.205.202.cau.edu.cn 4.18.0-147.el8.x86_64 #1 SMP Wed Dec 4 21:51:45 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux</span>
<span class="c1"># x86_64</span>

<span class="nb">echo</span><span class="w"> </span>
cat<span class="w"> </span>/etc/redhat-release
<span class="c1"># CentOS Linux release 8.1.1911 (Core)</span>
<span class="c1"># CentOS</span>

<span class="nb">echo</span><span class="w"> </span><span class="w"> </span>
lspci<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-i<span class="w"> </span>nvidia
<span class="c1"># 04:00.0 3D controller: NVIDIA Corporation GK208M [GeForce GT 730M] (rev a1)</span>

<span class="nb">echo</span><span class="w"> </span>gcc
gcc<span class="w"> </span>--version

<span class="c1"># sudo yum install kernel-devel-$(uname -r) kernel-headers-$(uname -r)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>linux
Linux 135.91.205.202.cau.edu.cn 4.18.0-348.7.1.el8_5.x86_64 #1 SMP Wed Dec 22 13:25:12 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux

CentOS Linux release 8.1.1911 (Core) 
 
2f:00.0 3D controller: NVIDIA Corporation Device 20b0 (rev a1)
86:00.0 3D controller: NVIDIA Corporation Device 20b0 (rev a1)
gcc
gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-4)
Copyright (C) 2018 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="4.3.-%E5%AE%89%E8%A3%85%E9%A9%B1%E5%8A%A8-CUDA-Driver">4.3. <a id="toc4_3_"></a><a href="#toc0_">-CUDA Driver</a><a class="anchor-link" href="#4.3.-%E5%AE%89%E8%A3%85%E9%A9%B1%E5%8A%A8-CUDA-Driver"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.3.1.-%E4%B8%8B%E8%BD%BDCUDA-Driver">4.3.1. <a id="toc4_3_1_"></a><a href="#toc0_">CUDA Driver</a><a class="anchor-link" href="#4.3.1.-%E4%B8%8B%E8%BD%BDCUDA-Driver"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 1. NVIDIA</span>
<span class="c1"># https://www.nvidia.cn/Download/index.aspx?lang=cn</span>

<span class="c1"># 2. dnf search nvidia*</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.3.2.-%E7%A6%81%E7%94%A8nouveau">4.3.2. <a id="toc4_3_2_"></a><a href="#toc0_">nouveau</a><a class="anchor-link" href="#4.3.2.-%E7%A6%81%E7%94%A8nouveau"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># centos8lsmod | grep nouveau</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.3.3.-%E5%AE%89%E8%A3%85CUDA-Driver">4.3.3. <a id="toc4_3_3_"></a><a href="#toc0_">CUDA Driver</a><a class="anchor-link" href="#4.3.3.-%E5%AE%89%E8%A3%85CUDA-Driver"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># !chmod a+x *.run</span>
<span class="c1"># !sudo ./*.run</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>'chmod' 

'sudo' 

</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.3.4.-%E6%9F%A5%E7%9C%8B%E6%98%BE%E5%8D%A1%E6%98%AF%E5%90%A6%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F">4.3.4. <a id="toc4_3_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#4.3.4.-%E6%9F%A5%E7%9C%8B%E6%98%BE%E5%8D%A1%E6%98%AF%E5%90%A6%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>nvidia-smi
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Thu Oct 10 14:55:44 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:2F:00.0 Off |                    0 |
| N/A   38C    P0             36W /  400W |   31186MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-40GB          Off |   00000000:86:00.0 Off |                    0 |
| N/A   38C    P0             38W /  400W |     425MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   1128336      C   .../miniconda3/envs/pytorch/bin/python        510MiB |
|    0   N/A  N/A   1159477      C   python                                      30662MiB |
|    1   N/A  N/A   1159477      C   python                                        416MiB |
+-----------------------------------------------------------------------------------------+
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.3.5.-%E6%9F%A5%E7%9C%8Bnvcc">4.3.5. <a id="toc4_3_5_"></a><a href="#toc0_">nvcc</a><a class="anchor-link" href="#4.3.5.-%E6%9F%A5%E7%9C%8Bnvcc"></a></h3><div class="highlight"><pre><span></span>nvccCUDA<span class="w"> </span>ToolkitCUDA<span class="w"> </span>Toolkitnvcc
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span><span class="nb">source</span><span class="w"> </span>/bmp/backup/zhaosy/miniconda3/etc/profile.d/conda.sh
<span class="o">!</span>conda<span class="w"> </span>activate<span class="w"> </span>pytorch
<span class="o">!</span>nvcc<span class="w"> </span>--version<span class="w"> </span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="4.4.-CUDA-Toolkit%E5%92%8CCuDNN">4.4. <a id="toc4_4_"></a><a href="#toc0_">CUDA ToolkitCuDNN</a><a class="anchor-link" href="#4.4.-CUDA-Toolkit%E5%92%8CCuDNN"></a></h2><div class="highlight"><pre><span></span>rootLinuxCUDA<span class="w"> </span>ToolkitCUDA<span class="w"> </span>Toolkit
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.4.1.-%E4%B8%8B%E8%BD%BD%E5%AF%B9%E5%BA%94%E7%9A%84CUDA-Toolkit%E7%89%88%E6%9C%AC">4.4.1. <a id="toc4_4_1_"></a><a href="#toc0_">CUDA Toolkit</a><a class="anchor-link" href="#4.4.1.-%E4%B8%8B%E8%BD%BD%E5%AF%B9%E5%BA%94%E7%9A%84CUDA-Toolkit%E7%89%88%E6%9C%AC"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span>%%bash
nvcc<span class="w"> </span>-V<span class="w"> </span><span class="c1"># CUDA Toolkit</span>

wget<span class="w"> </span>https://us.download.nvidia.cn/tesla/535.129.03/NVIDIA-Linux-x86_64-535.129.03.run
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.4.2.-%E5%AE%89%E8%A3%85CUDA-Toolkit">4.4.2. <a id="toc4_4_2_"></a><a href="#toc0_">CUDA Toolkit</a><a class="anchor-link" href="#4.4.2.-%E5%AE%89%E8%A3%85CUDA-Toolkit"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span>%%bash
<span class="c1"># cuda</span>
sudo<span class="w"> </span>dnf<span class="w"> </span>remove<span class="w"> </span>nvidia*
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Couldn't find program: 'bash'
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span>%%bash<span class="w"> </span>
chmod<span class="w"> </span>+x<span class="w"> </span>NVIDIA-Linux-x86_64-535.129.03.run
sudo<span class="w"> </span>sh<span class="w"> </span>NVIDIA-Linux-x86_64-535.129.03.run
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Couldn't find program: 'bash'
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.4.3.-%E4%B8%8B%E8%BD%BD%E5%AF%B9%E5%BA%94%E7%9A%84CuDNN">4.4.3. <a id="toc4_4_3_"></a><a href="#toc0_">CuDNN</a><a class="anchor-link" href="#4.4.3.-%E4%B8%8B%E8%BD%BD%E5%AF%B9%E5%BA%94%E7%9A%84CuDNN"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># https://link.zhihu.com/?target=https%3A//developer.nvidia.com/rdp/cudnn-download</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.4.4.-%E5%AE%89%E8%A3%85CuDNN">4.4.4. <a id="toc4_4_4_"></a><a href="#toc0_">CuDNN</a><a class="anchor-link" href="#4.4.4.-%E5%AE%89%E8%A3%85CuDNN"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># %%bash </span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="4.5.-%E5%AE%89%E8%A3%85%E5%AF%B9%E5%BA%94%E7%89%88%E6%9C%AC%E7%9A%84Pytorch">4.5. <a id="toc4_5_"></a><a href="#toc0_">Pytorch</a><a class="anchor-link" href="#4.5.-%E5%AE%89%E8%A3%85%E5%AF%B9%E5%BA%94%E7%89%88%E6%9C%AC%E7%9A%84Pytorch"></a></h2><div class="highlight"><pre><span></span>Pytorchcuda
</pre></div>
<p><a href="https://pytorch.org/">https://pytorch.org/</a></p>
<p><img alt="PyTorch" src="./Pytorch_Pictures/Install_PyTorch/PyTorch_website.jpg"/></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># https://pytorch.org/</span>
<span class="c1"># CUDA 12.1</span>
<span class="n">conda</span> <span class="n">create</span> <span class="o">-</span><span class="n">n</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">gpu</span> <span class="o">-</span><span class="n">y</span> <span class="o">&amp;&amp;</span> <span class="n">conda</span> <span class="n">activate</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">gpu</span> 
<span class="n">conda</span> <span class="n">install</span> <span class="n">pytorch</span> <span class="n">torchvision</span> <span class="n">torchaudio</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">cuda</span><span class="o">=</span><span class="mf">12.1</span> <span class="o">-</span><span class="n">c</span> <span class="n">pytorch</span> <span class="o">-</span><span class="n">c</span> <span class="n">nvidia</span> <span class="c1"># CUDA 12.1</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="4.6.-%E6%8E%A8%E8%8D%90A100">4.6. <a id="toc4_6_"></a><a href="#toc0_">A100</a><a class="anchor-link" href="#4.6.-%E6%8E%A8%E8%8D%90A100"></a></h2><ul>
<li><p>A100</p>
</li>
<li><p>condacuda toolkitpytorch</p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># enviroment and actiate environment</span>
<span class="n">conda</span> <span class="n">create</span> <span class="o">-</span><span class="n">n</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">gpu</span> <span class="o">&amp;&amp;</span> <span class="n">conda</span> <span class="n">activate</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">gpu</span> 

<span class="c1"># Install cudatoolkit via conda containing nvcc etc.</span>
<span class="c1"># Instead of :</span>
<span class="c1"># conda install cudatoolkit</span>
<span class="c1"># or </span>
<span class="c1"># conda install cuda-nvcc</span>
<span class="n">conda</span> <span class="n">install</span> <span class="n">nvidia</span><span class="o">/</span><span class="n">label</span><span class="o">/</span><span class="n">cuda</span><span class="o">-</span><span class="mf">12.6.0</span><span class="p">::</span><span class="n">cuda</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="4.7.-GPU%E6%B5%8B%E8%AF%95%E7%A8%8B%E5%BA%8F">4.7. <a id="toc4_7_"></a><a href="#toc0_">GPU</a><a class="anchor-link" href="#4.7.-GPU%E6%B5%8B%E8%AF%95%E7%A8%8B%E5%BA%8F"></a></h2><h3 id="4.7.1.-%E5%8D%95%E6%9C%BA%E5%8D%95%E5%8D%A1">4.7.1. <a id="toc4_7_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#4.7.1.-%E5%8D%95%E6%9C%BA%E5%8D%95%E5%8D%A1"></a></h3><div class="highlight"><pre><span></span>net.to<span class="o">(</span><span class="s1">'cuda:0'</span><span class="o">)</span>
<span class="nv">x_gpu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>x.to<span class="o">(</span><span class="s1">'cuda:0'</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span> 
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">data</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">time</span> 

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">dbs</span> <span class="o">=</span> <span class="s1">'./Pytorch_datasets/'</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
        <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
        <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="c1"># </span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="c1"># test_iter = data.DataLoader(dataset=test_dataset) # testbatch</span>

<span class="c1"># </span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
<span class="c1"># </span>
<span class="k">def</span> <span class="nf">train_steps</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">    </span>
<span class="sd">    epochs = epochs                         # epoch</span>
<span class="sd">    train_dataset = train_dataset           # train</span>
<span class="sd">    train_iter = train_iter                 # batchtrain</span>
<span class="sd">    test_dataset = test_dataset             # test</span>
<span class="sd">    net = net                               # </span>
<span class="sd">    loss_fn = loss_fn                       # </span>
<span class="sd">    opt = opt                               # </span>
<span class="sd">    device = device                         # device GPU/CPU</span>
<span class="sd">    '''</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Runing on </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">train_all_data_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">train_all_targets_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">test_all_data_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">test_all_targets_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># </span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_record</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch_record</span>                 <span class="c1"># X, y</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># deviceGPU/CPU</span>
            <span class="c1"># print(X[0])</span>
            <span class="c1"># print(X[0].dtype)</span>
            <span class="c1"># break</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>                         <span class="c1"># </span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>                          <span class="c1"># y_hat</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>                <span class="c1"># loss</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>                         <span class="c1"># </span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>                              <span class="c1"># </span>

        <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># </span>
                    <span class="c1"># net.train()</span>
                    <span class="c1"># netBNDropouttesttraintest</span>
                    <span class="c1"># netBNDropoutnet.eval()</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># withgrad</span>
            <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">),</span> <span class="n">train_all_targets_gpu</span><span class="p">)</span>
            <span class="c1"># print(train_loss)</span>
            <span class="n">train_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">train_all_targets_gpu</span>
            <span class="n">train_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_acc_cmp</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="c1"># print(train_acc)</span>
            <span class="n">test_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">test_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">test_all_targets_gpu</span>
            <span class="n">test_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_acc_cmp</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="c1"># print(test_acc)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">: train_loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s2">, train_acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s2">, test_acc=</span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">stop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">seconds</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>
    <span class="k">def</span> <span class="nf">convert_seconds</span><span class="p">(</span><span class="n">seconds</span><span class="p">):</span>
        <span class="n">days</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">//</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">)</span>
        <span class="n">hours</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">))</span> <span class="o">//</span> <span class="mi">3600</span>
        <span class="n">minutes</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="mi">3600</span><span class="p">)</span> <span class="o">//</span> <span class="mi">60</span>
        <span class="n">remaining_seconds</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">%</span> <span class="mi">60</span>
        <span class="k">return</span> <span class="n">days</span><span class="p">,</span> <span class="n">hours</span><span class="p">,</span> <span class="n">minutes</span><span class="p">,</span> <span class="n">remaining_seconds</span>
    <span class="n">days</span><span class="p">,</span> <span class="n">hours</span><span class="p">,</span> <span class="n">minutes</span><span class="p">,</span> <span class="n">remaining_seconds</span> <span class="o">=</span> <span class="n">convert_seconds</span><span class="p">(</span><span class="n">seconds</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"Total</span><span class="si">{</span><span class="n">days</span><span class="si">}</span><span class="s2"> d/ </span><span class="si">{</span><span class="n">hours</span><span class="si">}</span><span class="s2"> h/ </span><span class="si">{</span><span class="n">minutes</span><span class="si">}</span><span class="s2"> m/ </span><span class="si">{</span><span class="n">remaining_seconds</span><span class="si">}</span><span class="s2"> s"</span><span class="p">)</span>
    <span class="c1"># return (train_loss, train_acc, test_acc)</span>
    <span class="k">return</span> <span class="kc">None</span>

<span class="c1"># lr 0.01 -&gt; 0.5</span>
<span class="c1"># </span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>  
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>   
<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span> 
<span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>====================================================================================================
Runing on cuda:0
====================================================================================================
epoch 1/10: train_loss=1.6274998188018799, train_acc=84.3983383178711, test_acc=84.86000061035156
epoch 2/10: train_loss=1.5564780235290527, train_acc=91.80333709716797, test_acc=92.20999145507812
epoch 3/10: train_loss=1.5359078645706177, train_acc=93.42666625976562, test_acc=93.30999755859375
epoch 4/10: train_loss=1.5250604152679443, train_acc=94.48833465576172, test_acc=94.14999389648438
epoch 5/10: train_loss=1.5173759460449219, train_acc=95.15666961669922, test_acc=94.68999481201172
epoch 6/10: train_loss=1.5116100311279297, train_acc=95.62833404541016, test_acc=94.97000122070312
epoch 7/10: train_loss=1.5059237480163574, train_acc=96.125, test_acc=95.5199966430664
epoch 8/10: train_loss=1.5021032094955444, train_acc=96.46500396728516, test_acc=95.77999877929688
epoch 9/10: train_loss=1.4987181425094604, train_acc=96.77667236328125, test_acc=96.22000122070312
epoch 10/10: train_loss=1.4955240488052368, train_acc=97.086669921875, test_acc=96.41000366210938
==================================================================================================== 
 Total0.0 d/ 0.0 h/ 0.0 m/ 55.98274064064026 s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.7.2.-%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1">4.7.2. <a id="toc4_7_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#4.7.2.-%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1"></a></h3><div class="highlight"><pre><span></span>torch.nn.DataParallel<span class="o">()</span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span> 
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">data</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">time</span> 

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">dbs</span> <span class="o">=</span> <span class="s1">'./Pytorch_datasets/'</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
            <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
            <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># </span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="c1"># test_iter = data.DataLoader(dataset=test_dataset) # testbatch</span>

<span class="c1"># </span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
<span class="c1"># </span>
<span class="k">def</span> <span class="nf">train_steps</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">    </span>
<span class="sd">    epochs = epochs                         # epoch</span>
<span class="sd">    train_dataset = train_dataset           # train</span>
<span class="sd">    train_iter = train_iter                 # batchtrain</span>
<span class="sd">    test_dataset = test_dataset             # test</span>
<span class="sd">    net = net                               # </span>
<span class="sd">    loss_fn = loss_fn                       # </span>
<span class="sd">    opt = opt                               # </span>
<span class="sd">    device = device                         # device GPU/CPU</span>
<span class="sd">    '''</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Runing on </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">train_all_data_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">train_all_targets_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">test_all_data_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">test_all_targets_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># </span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_record</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch_record</span>                 <span class="c1"># X, y</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># deviceGPU/CPU</span>
            <span class="c1"># print(X[0])</span>
            <span class="c1"># print(X[0].dtype)</span>
            <span class="c1"># break</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>                     <span class="c1"># </span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>          <span class="c1"># y_hat</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="c1"># loss</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>         <span class="c1"># </span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>              <span class="c1"># </span>

        <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># </span>
                    <span class="c1"># net.train()</span>
                    <span class="c1"># netBNDropouttesttraintest</span>
                    <span class="c1"># netBNDropoutnet.eval()</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># withgrad</span>
            <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">),</span> <span class="n">train_all_targets_gpu</span><span class="p">)</span>
            <span class="c1"># print(train_loss)</span>
            <span class="n">train_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">train_all_targets_gpu</span>
            <span class="n">train_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_acc_cmp</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="c1"># print(train_acc)</span>
            <span class="n">test_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">test_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">test_all_targets_gpu</span>
            <span class="n">test_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_acc_cmp</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="c1"># print(test_acc)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">: train_loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s2">, train_acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s2">, test_acc=</span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">stop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">seconds</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>
    <span class="k">def</span> <span class="nf">convert_seconds</span><span class="p">(</span><span class="n">seconds</span><span class="p">):</span>
        <span class="n">days</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">//</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">)</span>
        <span class="n">hours</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">))</span> <span class="o">//</span> <span class="mi">3600</span>
        <span class="n">minutes</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="mi">3600</span><span class="p">)</span> <span class="o">//</span> <span class="mi">60</span>
        <span class="n">remaining_seconds</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">%</span> <span class="mi">60</span>
        <span class="k">return</span> <span class="n">days</span><span class="p">,</span> <span class="n">hours</span><span class="p">,</span> <span class="n">minutes</span><span class="p">,</span> <span class="n">remaining_seconds</span>
    <span class="n">days</span><span class="p">,</span> <span class="n">hours</span><span class="p">,</span> <span class="n">minutes</span><span class="p">,</span> <span class="n">remaining_seconds</span> <span class="o">=</span> <span class="n">convert_seconds</span><span class="p">(</span><span class="n">seconds</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"Total</span><span class="si">{</span><span class="n">days</span><span class="si">}</span><span class="s2"> d/ </span><span class="si">{</span><span class="n">hours</span><span class="si">}</span><span class="s2"> h/ </span><span class="si">{</span><span class="n">minutes</span><span class="si">}</span><span class="s2"> m/ </span><span class="si">{</span><span class="n">remaining_seconds</span><span class="si">}</span><span class="s2"> s"</span><span class="p">)</span>
    <span class="c1"># return (train_loss, train_acc, test_acc)</span>
    <span class="k">return</span> <span class="kc">None</span>

<span class="c1"># lr 0.01 -&gt; 0.5</span>
<span class="c1"># </span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>  
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>   
<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span> 
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>====================================================================================================
Runing on cuda:0
====================================================================================================
epoch 1/10: train_loss=1.575600504875183, train_acc=90.44833374023438, test_acc=90.77999877929688
epoch 2/10: train_loss=1.547834038734436, train_acc=92.36333465576172, test_acc=92.48999786376953
epoch 3/10: train_loss=1.5322562456130981, train_acc=93.78500366210938, test_acc=93.61000061035156
epoch 4/10: train_loss=1.5213903188705444, train_acc=94.74333190917969, test_acc=94.43999481201172
epoch 5/10: train_loss=1.5164926052093506, train_acc=95.19166564941406, test_acc=94.81999969482422
epoch 6/10: train_loss=1.5106992721557617, train_acc=95.68499755859375, test_acc=95.27999877929688
epoch 7/10: train_loss=1.5050891637802124, train_acc=96.26000213623047, test_acc=95.63999938964844
epoch 8/10: train_loss=1.5017056465148926, train_acc=96.55667114257812, test_acc=95.9000015258789
epoch 9/10: train_loss=1.4975892305374146, train_acc=96.89666748046875, test_acc=96.29000091552734
epoch 10/10: train_loss=1.4955655336380005, train_acc=97.086669921875, test_acc=96.52999877929688
==================================================================================================== 
 Total0.0 d/ 0.0 h/ 1.0 m/ 7.511963844299316 s
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># device = [ 'cpu' if not torch.cuda.is_available() else ]</span>
<span class="n">device</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">'cuda:</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">'</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">())]</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="p">[</span><span class="s1">'cpu'</span><span class="p">]</span>
<span class="n">device</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.7.3.-GPU-burn%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95">4.7.3. <a id="toc4_7_3_"></a><a href="#toc0_">GPU burn</a><a class="anchor-link" href="#4.7.3.-GPU-burn%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95"></a></h3><div class="highlight"><pre><span></span>GPUGPU_burngithub
</pre></div>
<ul>
<li>gpu_burn:<ul>
<li>github<code>git clone https://github.com/wilicc/gpu-burn.git</code></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span>%%bash<span class="w"> </span>
<span class="c1"># git clone:</span>
git<span class="w"> </span>clone<span class="w"> </span>https://github.com/wilicc/gpu-burn.git

<span class="nb">cd</span><span class="w"> </span>gpu-burn

<span class="c1"># make </span>
make

<span class="c1"># </span>
<span class="c1"># make CUDAPATH=~/minicnoda3/pytorch-gpu/</span>

<span class="c1"># help</span>
gpu_burn<span class="w"> </span>--help
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span>%%bash<span class="w"> </span>
<span class="c1"># 2h * 60min * 60s = 7200s with tensor core (avaliable)</span>
gpu_burn<span class="w"> </span>-tc<span class="w"> </span><span class="k">$((</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">60</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">60</span><span class="k">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="5.-Pytorch%E6%A8%A1%E5%9D%97%E4%BB%8B%E7%BB%8D">5. <a id="toc5_"></a><a href="#toc0_">Pytorch</a><a class="anchor-link" href="#5.-Pytorch%E6%A8%A1%E5%9D%97%E4%BB%8B%E7%BB%8D"></a></h1><h2 id="5.1.-%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9D%97">5.1. <a id="toc5_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#5.1.-%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9D%97"></a></h2><div class="highlight"><pre><span></span><span class="n">torchvision</span>
  <span class="n">models</span>
  <span class="n">datasets</span>
  <span class="n">transforms</span>
  <span class="n">utils</span>
<span class="n">torch</span>
  <span class="n">utils</span>
    <span class="n">data</span>            <span class="c1"># </span>
      <span class="n">TensorDataset</span>
      <span class="n">Dataset</span>
      <span class="n">DataLoader</span>
  <span class="n">nn</span>
    <span class="n">functional</span>
    <span class="n">Sequential</span>
    <span class="n">DataParallel</span>
    <span class="n">Linear</span>
    <span class="n">Softmax</span>
  <span class="n">optim</span>
    <span class="n">SGD</span>
    <span class="n">Adam</span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># </span>
<span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>                                             <span class="c1"># from torch.utils import data</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span>     <span class="c1"># data.Dataset, data.TensorDataset, data.DataLoader</span>

<span class="c1"># </span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="c1"># import torch.nn.DataParallel</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">DataParallel</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">distributed</span> <span class="k">as</span> <span class="n">dist</span>

<span class="c1"># </span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span> 

<span class="nb">print</span><span class="p">(</span><span class="s1">'pytorch version: '</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"torchvision version: </span><span class="si">{</span><span class="n">torchvision</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>pytorch version:  2.4.0
torchvision version: 0.19.0
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="6.-%E6%95%B0%E6%8D%AE%E5%B0%81%E8%A3%85%E5%92%8C%E5%8A%A0%E8%BD%BD">6. <a id="toc6_"></a><a href="#toc0_"></a><a class="anchor-link" href="#6.-%E6%95%B0%E6%8D%AE%E5%B0%81%E8%A3%85%E5%92%8C%E5%8A%A0%E8%BD%BD"></a></h1><p>PyTorch<code>Dataset</code><code>DataLoader</code>Pytorhc<code></code><code></code></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="6.1.-torchvison.datasets%E8%8E%B7%E5%BE%97Dataset">6.1. <a id="toc6_1_"></a><a href="#toc0_">torchvison.datasetsDataset</a><a class="anchor-link" href="#6.1.-torchvison.datasets%E8%8E%B7%E5%BE%97Dataset"></a></h2><ul>
<li><p><code>tochvision</code>  torchvisionPyTorch</p>
<ul>
<li><p>torchvision.<code>models</code>: Alex-NetVGGResNetInception</p>
</li>
<li><p>torchvision.<code>datasets</code> torch.utils.data.DatasetMNISTCIFAR10/100ImageNetCOCO</p>
</li>
<li><p>torchvision.<code>transforms</code>TensorPIL Image</p>
</li>
<li><p>torchvision.<code>utils</code></p>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision</span>

<span class="n">dbs</span> <span class="o">=</span> <span class="s1">'./Pytorch_datasets/'</span>

<span class="n">trans</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>                  <span class="c1"># PILtensor</span>
        <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">1.0</span><span class="p">,))</span>    <span class="c1"># </span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> 
<span class="c1">#   target_transform=False</span>
<span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> 
<span class="c1">#   target_transform=False</span>
<span class="p">)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[11]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torchvision.datasets.mnist.FashionMNIST,
 torchvision.datasets.mnist.FashionMNIST)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># torchdataset</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[12]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(Dataset FashionMNIST
     Number of datapoints: 60000
     Root location: ./Pytorch_datasets/
     Split: Train
     StandardTransform
 Transform: Compose(
                ToTensor()
                Normalize(mean=(0.5,), std=(1.0,))
            ),
 Dataset FashionMNIST
     Number of datapoints: 10000
     Root location: ./Pytorch_datasets/
     Split: Test
     StandardTransform
 Transform: Compose(
                ToTensor()
                Normalize(mean=(0.5,), std=(1.0,))
            ))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="6.2.-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86%E8%8E%B7%E5%BE%97Dataset">6.2. <a id="toc6_2_"></a><a href="#toc0_">Dataset</a><a class="anchor-link" href="#6.2.-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86%E8%8E%B7%E5%BE%97Dataset"></a></h2><h3 id="6.2.1.-%E5%88%A9%E7%94%A8TensorDataset()%E5%B0%81%E8%A3%85%E6%88%90Dataset">6.2.1. <a id="toc6_2_1_"></a><a href="#toc0_">TensorDataset()Dataset</a><a class="anchor-link" href="#6.2.1.-%E5%88%A9%E7%94%A8TensorDataset()%E5%B0%81%E8%A3%85%E6%88%90Dataset"></a></h3><ul>
<li><p><code>TensorDataset</code><code></code></p>
</li>
<li><p> TensorDataset</p>
<ul>
<li><code>dataset = torch.utils.data.TensorDataset( input_features, labels )</code> # input_featureslabels</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[48]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span>

<span class="c1"># 1.  (Tensor)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>   <span class="c1"># tensor</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">features</span> <span class="o">*</span> <span class="mi">2</span>                               <span class="c1"># labels = torch.mul(features, 2)</span>

<span class="c1"># 2. dataset</span>
<span class="n">datasets</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> 
<span class="nb">type</span><span class="p">(</span><span class="n">datasets</span><span class="p">),</span> <span class="n">datasets</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[48]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.utils.data.dataset.TensorDataset,
 &lt;torch.utils.data.dataset.TensorDataset at 0x7f9030b56ab0&gt;)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[50]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">features0</span><span class="p">,</span> <span class="n">labels0</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># </span>
<span class="n">features0</span><span class="p">,</span> <span class="n">labels0</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[50]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(0), tensor(0))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[47]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[47]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(0), tensor(0))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[45]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[45]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(1), tensor(2))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[46]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[46]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(1), tensor(2))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[49]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()</span>  <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[49]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>1000</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[51]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">my_datasets</span> <span class="o">=</span> <span class="n">datasets</span>

<span class="c1"># 3. batch</span>
<span class="n">data_iter</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">data_iter</span><span class="p">),</span> <span class="n">data_iter</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[51]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.utils.data.dataloader.DataLoader,
 &lt;torch.utils.data.dataloader.DataLoader at 0x7f9030d214c0&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="6.2.2.-%E9%87%8D%E8%BD%BDDataset%E7%B1%BB">6.2.2. <a id="toc6_2_2_"></a><a href="#toc0_">Dataset</a><a class="anchor-link" href="#6.2.2.-%E9%87%8D%E8%BD%BDDataset%E7%B1%BB"></a></h3><ul>
<li><p><code>torch.utils.data.Dataset</code></p>
<ul>
<li><p><code>__init__(self, *args, **kwargs)</code>: </p>
</li>
<li><p><code>__len(self)__</code>: </p>
</li>
<li><p><code>__getitem__(self, index)</code>: </p>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="c1"># 1. Dataset</span>
<span class="k">class</span> <span class="nc">MyData</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nums</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">15</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nums</span> <span class="o">=</span> <span class="n">nums</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">nums</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<span class="w">        </span><span class="sd">'''indexidx'''</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nums</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nums</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">features</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

<span class="c1"># 2. Dataset</span>
<span class="n">datasets</span> <span class="o">=</span> <span class="n">MyData</span><span class="p">()</span>
<span class="n">datasets</span><span class="p">,</span> <span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">datasets</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">datasets</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">datasets</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">datasets</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">datasets</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()</span>

<span class="c1"># 3. DataLoader</span>
<span class="c1"># data_iter = DataLoader(dataset=datasets, batch_size=256, shuffle=True, num_workers=3)</span>
<span class="c1"># data_iter</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[5]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(&lt;__main__.MyData at 0x7f08a6f3fc50&gt;,
 (tensor(0), tensor(0)),
 (tensor(1), tensor(1)),
 (tensor(1), tensor(1)),
 (tensor(2), tensor(2)),
 (tensor(2), tensor(2)),
 15)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="6.2.3.-Pytoch.utils.data.Dataset%E7%B1%BB%E5%88%86%E6%9E%90%E5%92%8C%E6%80%BB%E7%BB%93">6.2.3. <a id="toc6_2_3_"></a><a href="#toc0_">Pytoch.utils.data.Dataset</a><a class="anchor-link" href="#6.2.3.-Pytoch.utils.data.Dataset%E7%B1%BB%E5%88%86%E6%9E%90%E5%92%8C%E6%80%BB%E7%BB%93"></a></h3><ul>
<li><p>PyTorchtorch.utils.data.Dataset</p>
</li>
<li><p><code>torchvision.datasets</code>Dataset</p>
</li>
<li><p></p>
<ul>
<li><p><code>Tensordataset(features, labels)</code>featureslabelsDataset ()</p>
</li>
<li><p><code>Dataset</code></p>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="6.3.-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD-DataLoader()">6.3. <a id="toc6_3_"></a><a href="#toc0_">-DataLoader()</a><a class="anchor-link" href="#6.3.-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD-DataLoader()"></a></h2><ol>
<li><p>data.TensorDataset<code>dataset</code></p>
</li>
<li><p>data.DataLoaderdatasetbatch_size<code>DataLoader</code></p>
</li>
<li><p></p>
</li>
<li><p></p>
</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="c1"># torchvisontorch.utils.data.Dataset</span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">my_datasets</span><span class="p">,</span>          <span class="c1"># Dataset</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>                 <span class="c1"># batch size</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>                 <span class="c1"># </span>
    <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">3</span>                 <span class="c1"># </span>
    <span class="n">drop_last</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>              <span class="c1"># batch</span>
    <span class="c1"># collate_fn=collate_function     # </span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[54]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">train_iter</span><span class="p">),</span> <span class="n">train_iter</span>        <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[54]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.utils.data.dataloader.DataLoader,
 &lt;torch.utils.data.dataloader.DataLoader at 0x7f90308f7770&gt;)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_iter</span><span class="p">):</span>  <span class="c1"># batch_size</span>
    <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">==</span> <span class="mi">10</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">':'</span><span class="p">,</span> <span class="n">batch_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>: 1 [tensor([666, 761, 701, 637, 154]), tensor([1332, 1522, 1402, 1274,  308])]
: 2 [tensor([212,  58, 496, 383, 731]), tensor([ 424,  116,  992,  766, 1462])]
: 3 [tensor([641, 116, 414, 257, 748]), tensor([1282,  232,  828,  514, 1496])]
: 4 [tensor([507, 849, 451, 523, 613]), tensor([1014, 1698,  902, 1046, 1226])]
: 5 [tensor([422, 488, 671, 974, 195]), tensor([ 844,  976, 1342, 1948,  390])]
: 6 [tensor([258, 848, 583, 454, 328]), tensor([ 516, 1696, 1166,  908,  656])]
: 7 [tensor([ 73, 920, 288, 245, 486]), tensor([ 146, 1840,  576,  490,  972])]
: 8 [tensor([792, 152, 462,  71, 190]), tensor([1584,  304,  924,  142,  380])]
: 9 [tensor([599, 133,  26, 979, 789]), tensor([1198,  266,   52, 1958, 1578])]
: 10 [tensor([983, 301, 228, 236, 447]), tensor([1966,  602,  456,  472,  894])]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="6.3.1.-%E4%BC%B0%E8%AE%A1%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4">6.3.1. <a id="toc6_3_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#6.3.1.-%E4%BC%B0%E8%AE%A1%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4"></a></h3><p></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># epochbatch</span>
<span class="n">timer</span> <span class="o">=</span> <span class="n">cpuTimer</span><span class="p">()</span>
<span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
    <span class="k">break</span> 
<span class="n">timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================== 
 Total
 0.0 d 
 0.0 h 
 0.0 m 
 0.08644580841064453 s
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[58]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># epochbatch</span>
<span class="n">timer</span> <span class="o">=</span> <span class="n">cpuTimer</span><span class="p">()</span>
<span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
    <span class="k">continue</span> 
<span class="n">timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================== 
 Total
 0.0 d 
 0.0 h 
 0.0 m 
 0.2713015079498291 s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="6.3.2.-collate_fn%E5%A4%84%E7%90%86%E4%B8%8D%E7%AD%89%E9%95%BFtensor">6.3.2. <a id="toc6_3_2_"></a><a href="#toc0_">collate_fntensor</a><a class="anchor-link" href="#6.3.2.-collate_fn%E5%A4%84%E7%90%86%E4%B8%8D%E7%AD%89%E9%95%BFtensor"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#  collate_fn </span>
<span class="k">def</span> <span class="nf">collate_function</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="c1">#  batch  msa, pair  labels</span>
    <span class="n">msa_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'msa'</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
    <span class="n">pair_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'pair'</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
    <span class="n">labels_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>

    <span class="c1">#  batch  num_residues</span>
    <span class="n">max_residues</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="n">msa</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">msa</span> <span class="ow">in</span> <span class="n">msa_batch</span><span class="p">])</span>

    <span class="c1">#  MSA  num_residues </span>
    <span class="n">padded_msa_batch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">msa</span> <span class="ow">in</span> <span class="n">msa_batch</span><span class="p">:</span>
        <span class="n">pad_size</span> <span class="o">=</span> <span class="n">max_residues</span> <span class="o">-</span> <span class="n">msa</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">padded_msa</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">msa</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">))</span>  <span class="c1"># </span>
        <span class="n">padded_msa_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">padded_msa</span><span class="p">)</span>

    <span class="c1">#  Pair  num_residues </span>
    <span class="n">padded_pair_batch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pair_batch</span><span class="p">:</span>
        <span class="n">pad_size</span> <span class="o">=</span> <span class="n">max_residues</span> <span class="o">-</span> <span class="n">pair</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">padded_pair</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">))</span>  <span class="c1"># </span>
        <span class="n">padded_pair_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">padded_pair</span><span class="p">)</span>

    <span class="c1">#  MSA  Pair </span>
    <span class="n">padded_msa_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">padded_msa_batch</span><span class="p">)</span>
    <span class="n">padded_pair_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">padded_pair_batch</span><span class="p">)</span>

    <span class="c1"># </span>
    <span class="n">labels_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">labels_batch</span><span class="p">)</span>

    <span class="c1"># </span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">'msa'</span><span class="p">:</span> <span class="n">padded_msa_batch</span><span class="p">,</span> <span class="s1">'pair'</span><span class="p">:</span> <span class="n">padded_pair_batch</span><span class="p">},</span> <span class="n">labels_batch</span>

<span class="n">train_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">train_datasets</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> 
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_function</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="6.3.3.-%E9%87%8D%E8%BD%BDDataLoader">6.3.3. <a id="toc6_3_3_"></a><a href="#toc0_">DataLoader</a><a class="anchor-link" href="#6.3.3.-%E9%87%8D%E8%BD%BDDataLoader"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span> 

<span class="k">class</span> <span class="nc">RebuildDataLoader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">return</span> 
    
    <span class="c1">#  __iter__ </span>
    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># </span>
        <span class="n">iterator</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__iter__</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">:</span>
            <span class="c1"># </span>
            <span class="k">yield</span> <span class="n">batch</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="7.-%E5%BC%A0%E9%87%8F(Tensors)">7. <a id="toc7_"></a><a href="#toc0_">(Tensors)</a><a class="anchor-link" href="#7.-%E5%BC%A0%E9%87%8F(Tensors)"></a></h1><h2 id="7.1.-Tensors%E5%AE%9A%E4%B9%89">7.1. <a id="toc7_1_"></a><a href="#toc0_">Tensors</a><a class="anchor-link" href="#7.1.-Tensors%E5%AE%9A%E4%B9%89"></a></h2><p>PyTorch  Numpy  Tensors  Numpy (ndarrays)</p>
<ul>
<li><p></p>
<ul>
<li><p><code></code> (<code>Tensors</code>)</p>
</li>
<li><p><code></code> (<code>Array</code>)</p>
</li>
</ul>
</li>
<li><p></p>
</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">torch.tensor()</td>
<td style="text-align:left">tensor</td>
</tr>
<tr>
<td style="text-align:left">torch.asarray()</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.from_numpy()</td>
<td style="text-align:left">numpy2tensor</td>
</tr>
<tr>
<td style="text-align:left">torch.empty(size)</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.zeros(size)</td>
<td style="text-align:left">0</td>
</tr>
<tr>
<td style="text-align:left">torch.ones(size)</td>
<td style="text-align:left">1</td>
</tr>
<tr>
<td style="text-align:left">torch.rand(size)</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.randn(size)</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.normal(mean,std,size)</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.arange(start,end,step,size)</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">.reshape(size)</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">.numpy()</td>
<td style="text-align:left">numpyndarray</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>torch.tensor()</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[59]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># tensor()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[59]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([1., 2., 3.])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>torch.asarray()</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[60]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># asarray()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[60]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([1., 2., 3.])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>torch.from_numpy()</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[61]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># numpytensor, from_numpy()</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[61]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(array([[ 0,  1,  2],
        [ 3,  4,  5],
        [ 6,  7,  8],
        [ 9, 10, 11],
        [12, 13, 14]]),
 tensor([[ 0,  1,  2],
         [ 3,  4,  5],
         [ 6,  7,  8],
         [ 9, 10, 11],
         [12, 13, 14]]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>torch.empty()</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[62]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># empty()</span>

<span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[62]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.0000e+00, 0.0000e+00, 2.0114e-25],
        [3.0742e-41, 1.3127e-29, 3.0742e-41],
        [9.2368e-10, 4.5761e-41, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>torch.zeros()</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[63]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># zeros()</span>

<span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># 0</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[63]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>torch.ones()</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># ones()</span>

<span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[64]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>torch.rand()</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[69]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># rand()</span>

<span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[69]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.8833, 0.0454, 0.5669],
        [0.2422, 0.8501, 0.7177],
        [0.5687, 0.7171, 0.8636],
        [0.3550, 0.5657, 0.5965],
        [0.4050, 0.6776, 0.9841]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>torch.randn()</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[70]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># randn()</span>

<span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[70]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0.7855, -0.0245, -0.9618, -1.4634, -0.2726],
        [ 1.1404, -0.9721,  0.4194,  0.1732, -1.2649],
        [ 0.0139,  1.0817, -2.1748,  0.5782, -1.0274]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>torch.normal()meanstdsize</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[72]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[72]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0.4510,  0.2798, -0.8032, -0.5851,  0.7675],
        [ 2.0413,  1.1163, -0.1891,  0.9543,  0.6753],
        [ 1.4002,  0.8864,  0.6356, -1.2399,  1.1891]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>torch.arange()</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[73]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># arange()</span>

<span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># 0, 1, 2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[73]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0, 1, 2])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>.reshape()</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[74]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># reshape()</span>

<span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># reshape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[74]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0,  1,  2],
        [ 3,  4,  5],
        [ 6,  7,  8],
        [ 9, 10, 11],
        [12, 13, 14]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>.numpy()tensornumpyndarray</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[75]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># tensornumpy</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[75]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[ 0,  1,  2],
         [ 3,  4,  5],
         [ 6,  7,  8],
         [ 9, 10, 11],
         [12, 13, 14]]),
 array([[ 0,  1,  2],
        [ 3,  4,  5],
        [ 6,  7,  8],
        [ 9, 10, 11],
        [12, 13, 14]], dtype=int64))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="7.2.-Tensors%E5%B1%9E%E6%80%A7">7.2. <a id="toc7_2_"></a><a href="#toc0_">Tensors</a><a class="anchor-link" href="#7.2.-Tensors%E5%B1%9E%E6%80%A7"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.2.1.-%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-dtype">7.2.1. <a id="toc7_2_1_"></a><a href="#toc0_">-dtype</a><a class="anchor-link" href="#7.2.1.-%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-dtype"></a></h3><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>       <span class="c1"># </span>
<span class="n">torch</span><span class="o">.</span><span class="n">float32</span>       <span class="c1"># torch.FloatTensor()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">float64</span>       <span class="c1"># torch.DoubleTensor()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">int8</span>
<span class="n">torch</span><span class="o">.</span><span class="n">int16</span>         <span class="c1"># </span>
<span class="n">torch</span><span class="o">.</span><span class="n">int32</span>         <span class="c1"># torch.IntTensor()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">int64</span>         <span class="c1"># torch.LongTensor()</span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
    <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
    <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> 
    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="s1">'cpu'</span>
<span class="p">)</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[19]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([128, 12, 5]), device(type='cpu'), torch.float32)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.2.1.1.-%E8%BD%AC%E5%8C%96%E6%A0%BC%E5%BC%8F">7.2.1.1. <a id="toc7_2_1_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.2.1.1.-%E8%BD%AC%E5%8C%96%E6%A0%BC%E5%BC%8F"></a></h4><p></p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>tensor.double()</td>
<td>tensortorch.float64 </td>
</tr>
<tr>
<td>tensor.float()</td>
<td>tensortorch.float32 </td>
</tr>
<tr>
<td>tensor.int()</td>
<td>tensortorch.int32 </td>
</tr>
<tr>
<td>tensor.long():</td>
<td>tensortorch.int64 </td>
</tr>
</tbody>
</table>
<p></p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>float to int</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>x.int()</td>
<td>float to int32</td>
</tr>
<tr>
<td></td>
<td>x.long()</td>
<td>float to int64</td>
</tr>
<tr>
<td>int to float</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>x.float()</td>
<td>int32 to float</td>
</tr>
<tr>
<td></td>
<td>x.double()</td>
<td>int64 to float</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">double</span><span class="p">()</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">dtype</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[35]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.float32, torch.float32, torch.float64, torch.int32, torch.int64)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.2.2.-%E5%BC%A0%E9%87%8F%E7%9A%84%E8%AE%BE%E5%A4%87-device">7.2.2. <a id="toc7_2_2_"></a><a href="#toc0_">-device</a><a class="anchor-link" href="#7.2.2.-%E5%BC%A0%E9%87%8F%E7%9A%84%E8%AE%BE%E5%A4%87-device"></a></h3><p>PyTorch: cpu, cuda:0, cuda:1, ...</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 

<span class="k">def</span> <span class="nf">try_gpu</span><span class="p">():</span>
<span class="w">    </span><span class="sd">'''cpugpu [cuda:0, cuda:1]'''</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">num_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
        <span class="n">device</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">'cuda:</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">'</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_gpu</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">device</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'cpu'</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">device</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
    <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
    <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> 
    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">try_gpu</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[10]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([128, 12, 5]), device(type='cuda', index=0))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.2.3.-%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%B4%E5%BA%A6-size/shape">7.2.3. <a id="toc7_2_3_"></a><a href="#toc0_">-size/shape</a><a class="anchor-link" href="#7.2.3.-%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%B4%E5%BA%A6-size/shape"></a></h3><ul>
<li><p></p>
<p>|||
|:-|:-|
|x.size()||
|x.shape||</p>
</li>
<li><p>tensor([[[]]]) <code></code>:</p>
<ul>
<li><code>[[[</code></li>
<li><code>[]</code>0</li>
</ul>
</li>
<li><p>Size[] <code></code></p>
<ul>
<li><code>[2, 3]</code>: </li>
<li><code>[2, 3]</code>: </li>
<li><code>[]</code>: 0</li>
<li><code>[2]</code>: </li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.2.3.1.-%E6%A0%87%E9%87%8F">7.2.3.1. <a id="toc7_2_3_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.2.3.1.-%E6%A0%87%E9%87%8F"></a></h4><p>dim=0  <code></code></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[36]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([]), tensor(1))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.2.3.2.-%E4%B8%80%E7%BB%B4">7.2.3.2. <a id="toc7_2_3_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.2.3.2.-%E4%B8%80%E7%BB%B4"></a></h4><p>dim=1</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>   <span class="c1"># []</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[37]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([1]), tensor([1]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[38]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[38]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.2.3.3.-%E5%A4%9A%E7%BB%B4">7.2.3.3. <a id="toc7_2_3_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.2.3.3.-%E5%A4%9A%E7%BB%B4"></a></h4><p>dim  2</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[39]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[39]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 6]),
 tensor([[ 0,  1,  2,  3,  4,  5],
         [ 6,  7,  8,  9, 10, 11]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[40]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 3, 2]),
 tensor([[[ 0,  1],
          [ 2,  3],
          [ 4,  5]],
 
         [[ 6,  7],
          [ 8,  9],
          [10, 11]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[54]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[54]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 1, 3, 2]),
 tensor([[[[ 0,  1],
           [ 2,  3],
           [ 4,  5]]],
 
 
         [[[ 6,  7],
           [ 8,  9],
           [10, 11]]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[7]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 2, 3, 2]),
 tensor([[[[ 0,  1],
           [ 2,  3],
           [ 4,  5]],
 
          [[ 6,  7],
           [ 8,  9],
           [10, 11]]],
 
 
         [[[12, 13],
           [14, 15],
           [16, 17]],
 
          [[18, 19],
           [20, 21],
           [22, 23]]]]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.2.4.-%E7%89%B9%E6%AE%8A%E7%9A%84%E4%B8%80%E7%BB%B4%E5%BC%A0%E9%87%8F">7.2.4. <a id="toc7_2_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.2.4.-%E7%89%B9%E6%AE%8A%E7%9A%84%E4%B8%80%E7%BB%B4%E5%BC%A0%E9%87%8F"></a></h3><p><code>PyTorchTensor</code></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.2.4.1.-%E4%B8%80%E7%BB%B4%E5%BC%A0%E9%87%8F%E7%9A%84%E4%BE%8B%E5%AD%90">7.2.4.1. <a id="toc7_2_4_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.2.4.1.-%E4%B8%80%E7%BB%B4%E5%BC%A0%E9%87%8F%E7%9A%84%E4%BE%8B%E5%AD%90"></a></h4><p> <code>tensor</code> <code>(n,)</code> <code>n</code> </p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[41]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># </span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>  <span class="c1"># : tensor([1, 2, 3, 4, 5])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([1, 2, 3, 4, 5])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.2.4.2.-%E5%8C%BA%E5%88%86%E8%A1%8C%E5%90%91%E9%87%8F%E5%92%8C%E5%88%97%E5%90%91%E9%87%8F">7.2.4.2. <a id="toc7_2_4_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.2.4.2.-%E5%8C%BA%E5%88%86%E8%A1%8C%E5%90%91%E9%87%8F%E5%92%8C%E5%88%97%E5%90%91%E9%87%8F"></a></h4><p><code></code></p>
<ul>
<li><strong></strong> <code>.unsqueeze(-1)</code>  <code>(n, 1)</code></li>
<li><strong></strong> <code>.unsqueeze(0)</code>  <code>(1, n)</code></li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="7.2.4.2.1.-%E7%A4%BA%E4%BE%8B">7.2.4.2.1. <a id="toc7_2_4_2_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.2.4.2.1.-%E7%A4%BA%E4%BE%8B"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[43]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">vector</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[43]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([1, 2, 3, 4, 5])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[45]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">row_vector</span> <span class="o">=</span> <span class="n">vector</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Row Vector:"</span><span class="p">,</span> <span class="n">row_vector</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>  <span class="c1"># : tensor([[1], [2], [3], [4], [5]])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Row Vector:
tensor([[1],
        [2],
        [3],
        [4],
        [5]])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[46]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">column_vector</span> <span class="o">=</span> <span class="n">vector</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Column Vector:"</span><span class="p">,</span> <span class="n">column_vector</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>  <span class="c1"># : tensor([[1, 2, 3, 4, 5]])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Column Vector:
tensor([[1, 2, 3, 4, 5]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.2.4.3.-%E5%B0%8F%E7%BB%93">7.2.4.3. <a id="toc7_2_4_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.2.4.3.-%E5%B0%8F%E7%BB%93"></a></h4><p>PyTorch</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="7.3.-Tensors%E6%93%8D%E4%BD%9C">7.3. <a id="toc7_3_"></a><a href="#toc0_">Tensors</a><a class="anchor-link" href="#7.3.-Tensors%E6%93%8D%E4%BD%9C"></a></h2><h3 id="7.3.1.-%E7%B4%A2%E5%BC%95%E5%92%8C%E5%88%87%E7%89%87">7.3.1. <a id="toc7_3_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.3.1.-%E7%B4%A2%E5%BC%95%E5%92%8C%E5%88%87%E7%89%87"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[47]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[47]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0,  1,  2],
        [ 3,  4,  5],
        [ 6,  7,  8],
        [ 9, 10, 11],
        [12, 13, 14]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[66]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[66]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0, 1, 2])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[67]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[67]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([3, 4, 5])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[68]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># 1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[68]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([ 0,  3,  6,  9, 12])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[84]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="c1"># 2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[84]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([ 1,  4,  7, 10, 13])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.3.2.-%E4%BF%AE%E6%94%B9%E7%BB%B4%E5%BA%A6">7.3.2. <a id="toc7_3_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.3.2.-%E4%BF%AE%E6%94%B9%E7%BB%B4%E5%BA%A6"></a></h3><ul>
<li><p>/<code></code><code>/</code></p>
</li>
<li><p></p>
<ul>
<li> (n, c, h, w) 4  n  (c, h, w)  3 </li>
<li> (c, h, w) 3  c  (h, w)  2 </li>
<li> (h, w) 2  h  w  1 h w </li>
</ul>
</li>
<li><p>/reshapeviewtensorshapeviewcontiguoustensorreshapetensorviewreshapeviewreshape</p>
</li>
</ul>
<ul>
<li><p><code></code></p>
<ul>
<li><p><code>.reshape()</code></p>
</li>
<li><p><code>.view()</code></p>
</li>
</ul>
</li>
<li><p><code></code></p>
<ul>
<li><p><code>permute()</code></p>
</li>
<li><p><code>transpose()</code></p>
</li>
</ul>
</li>
<li><p><a href="https://blog.csdn.net/weixin_44115575/article/details/140742574">https://blog.csdn.net/weixin_44115575/article/details/140742574</a></p>
<ul>
<li><p><code> (shape)</code><code> (stride)</code><code> (dtype)</code>reshapeviewtransposepermuteviewcontiguous()transposepermutestridestride</p>
</li>
<li><p></p>
<ul>
<li><p> (H, W, C)  (C, H, W) (H, W, C)  (C, H, W)</p>
<div class="highlight"><pre><span></span><span class="c1">#  (Batch, Channels, Height, Width)</span>
<span class="n">image_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

<span class="c1">#  (Batch, Height, Width, Channels)</span>
<span class="n">image_tensor_permuted</span> <span class="o">=</span> <span class="n">image_tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</li>
<li><p>:RNN  Transformer  (sequence_length, batch_size, features) </p>
<div class="highlight"><pre><span></span><span class="c1">#  (Batch, Sequence Length, Features)</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>

<span class="c1">#  (Sequence Length, Batch, Features)</span>
<span class="n">input_tensor_permuted</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</li>
<li><p>:</p>
<div class="highlight"><pre><span></span><span class="c1">#  4D </span>
<span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">data_tensor_permuted</span> <span class="o">=</span> <span class="n">data_tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.3.2.1.-reshape%E5%87%BD%E6%95%B0">7.3.2.1. <a id="toc7_3_2_1_"></a><a href="#toc0_">reshape</a><a class="anchor-link" href="#7.3.2.1.-reshape%E5%87%BD%E6%95%B0"></a></h4><p></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[48]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[48]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),
 torch.Size([15]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[49]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># reshape</span>

<span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[49]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[ 0,  1,  2,  3,  4],
         [ 5,  6,  7,  8,  9],
         [10, 11, 12, 13, 14]]),
 torch.Size([3, 5]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.3.2.2.-view%E5%87%BD%E6%95%B0">7.3.2.2. <a id="toc7_3_2_2_"></a><a href="#toc0_">view</a><a class="anchor-link" href="#7.3.2.2.-view%E5%87%BD%E6%95%B0"></a></h4><p></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[81]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># view</span>

<span class="n">X</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">X</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[81]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[ 0,  1,  2,  3,  4],
         [ 5,  6,  7,  8,  9],
         [10, 11, 12, 13, 14]]),
 torch.Size([3, 5]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.3.2.3.-transpose%E5%87%BD%E6%95%B0">7.3.2.3. <a id="toc7_3_2_3_"></a><a href="#toc0_">transpose</a><a class="anchor-link" href="#7.3.2.3.-transpose%E5%87%BD%E6%95%B0"></a></h4><p><code>transpose()</code><code></code> 0, 1, 2, 3,  </p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="7.3.2.3.1.-%E4%BA%8C%E7%BB%B4">7.3.2.3.1. <a id="toc7_3_2_3_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.3.2.3.1.-%E4%BA%8C%E7%BB%B4"></a></h5><p>transposeT</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 2  (h, w)</span>
<span class="c1">#  transpose()  (0, 1) </span>
<span class="c1">#  transpose(0, 1)  h, w </span>
<span class="c1"># </span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">X</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[8]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0,  1,  2,  3,  4],
        [ 5,  6,  7,  8,  9],
        [10, 11, 12, 13, 14]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[9]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0,  5, 10],
        [ 1,  6, 11],
        [ 2,  7, 12],
        [ 3,  8, 13],
        [ 4,  9, 14]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[10]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0,  5, 10],
        [ 1,  6, 11],
        [ 2,  7, 12],
        [ 3,  8, 13],
        [ 4,  9, 14]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="7.3.2.3.2.-%E4%B8%89%E7%BB%B4">7.3.2.3.2. <a id="toc7_3_2_3_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.3.2.3.2.-%E4%B8%89%E7%BB%B4"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[3]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 3, 4]),
 tensor([[[ 0,  1,  2,  3],
          [ 4,  5,  6,  7],
          [ 8,  9, 10, 11]],
 
         [[12, 13, 14, 15],
          [16, 17, 18, 19],
          [20, 21, 22, 23]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[4]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([3, 2, 4]),
 tensor([[[ 0,  1,  2,  3],
          [12, 13, 14, 15]],
 
         [[ 4,  5,  6,  7],
          [16, 17, 18, 19]],
 
         [[ 8,  9, 10, 11],
          [20, 21, 22, 23]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[5]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([4, 3, 2]),
 tensor([[[ 0, 12],
          [ 4, 16],
          [ 8, 20]],
 
         [[ 1, 13],
          [ 5, 17],
          [ 9, 21]],
 
         [[ 2, 14],
          [ 6, 18],
          [10, 22]],
 
         [[ 3, 15],
          [ 7, 19],
          [11, 23]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[6]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 4, 3]),
 tensor([[[ 0,  4,  8],
          [ 1,  5,  9],
          [ 2,  6, 10],
          [ 3,  7, 11]],
 
         [[12, 16, 20],
          [13, 17, 21],
          [14, 18, 22],
          [15, 19, 23]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[69]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[69]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([4, 3, 2]),
 tensor([[[ 0, 12],
          [ 4, 16],
          [ 8, 20]],
 
         [[ 1, 13],
          [ 5, 17],
          [ 9, 21]],
 
         [[ 2, 14],
          [ 6, 18],
          [10, 22]],
 
         [[ 3, 15],
          [ 7, 19],
          [11, 23]]]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.3.2.4.-permute%E5%87%BD%E6%95%B0">7.3.2.4. <a id="toc7_3_2_4_"></a><a href="#toc0_">permute</a><a class="anchor-link" href="#7.3.2.4.-permute%E5%87%BD%E6%95%B0"></a></h4><p><code>permute()</code><code></code> 0, 1, 2, 3,   transpose()  permute()  transpose() </p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="7.3.2.4.1.-%E4%BA%8C%E7%BB%B4">7.3.2.4.1. <a id="toc7_3_2_4_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.3.2.4.1.-%E4%BA%8C%E7%BB%B4"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[78]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[78]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([3, 5]),
 tensor([[ 0,  1,  2,  3,  4],
         [ 5,  6,  7,  8,  9],
         [10, 11, 12, 13, 14]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[79]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[79]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([5, 3]),
 tensor([[ 0,  5, 10],
         [ 1,  6, 11],
         [ 2,  7, 12],
         [ 3,  8, 13],
         [ 4,  9, 14]]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="7.3.2.4.2.-%E4%B8%89%E7%BB%B4">7.3.2.4.2. <a id="toc7_3_2_4_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.3.2.4.2.-%E4%B8%89%E7%BB%B4"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[80]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[80]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 3, 4]),
 tensor([[[ 0,  1,  2,  3],
          [ 4,  5,  6,  7],
          [ 8,  9, 10, 11]],
 
         [[12, 13, 14, 15],
          [16, 17, 18, 19],
          [20, 21, 22, 23]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[77]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[77]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([3, 2, 4]),
 tensor([[[ 0,  1,  2,  3],
          [12, 13, 14, 15]],
 
         [[ 4,  5,  6,  7],
          [16, 17, 18, 19]],
 
         [[ 8,  9, 10, 11],
          [20, 21, 22, 23]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[81]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[81]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 4, 3]),
 tensor([[[ 0,  4,  8],
          [ 1,  5,  9],
          [ 2,  6, 10],
          [ 3,  7, 11]],
 
         [[12, 16, 20],
          [13, 17, 21],
          [14, 18, 22],
          [15, 19, 23]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[82]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[82]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([4, 3, 2]),
 tensor([[[ 0, 12],
          [ 4, 16],
          [ 8, 20]],
 
         [[ 1, 13],
          [ 5, 17],
          [ 9, 21]],
 
         [[ 2, 14],
          [ 6, 18],
          [10, 22]],
 
         [[ 3, 15],
          [ 7, 19],
          [11, 23]]]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.3.2.5.-unsqueeze%E5%87%BD%E6%95%B0%E5%A2%9E%E5%8A%A0%E7%BB%B4%E5%BA%A6">7.3.2.5. <a id="toc7_3_2_5_"></a><a href="#toc0_">unsqueeze</a><a class="anchor-link" href="#7.3.2.5.-unsqueeze%E5%87%BD%E6%95%B0%E5%A2%9E%E5%8A%A0%E7%BB%B4%E5%BA%A6"></a></h4><p>unsqueeze  1 <br/>
/<code>1</code></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="7.3.2.5.1.-1%E7%BB%B4">7.3.2.5.1. <a id="toc7_3_2_5_1_"></a><a href="#toc0_">1</a><a class="anchor-link" href="#7.3.2.5.1.-1%E7%BB%B4"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'x size: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'x1 size: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>          <span class="c1"># 1 x 4</span>

<span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'x1 size: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>          <span class="c1"># 4 x 1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>x size: torch.Size([4])
tensor([1, 2, 3, 4])
x1 size: torch.Size([4])
tensor([[1, 2, 3, 4]])
x1 size: torch.Size([4])
tensor([[1],
        [2],
        [3],
        [4]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="7.3.2.5.2.-%E5%A4%9A%E7%BB%B4%E5%BA%A6">7.3.2.5.2. <a id="toc7_3_2_5_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.3.2.5.2.-%E5%A4%9A%E7%BB%B4%E5%BA%A6"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[3]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([3, 3]),
 tensor([[0, 1, 2],
         [3, 4, 5],
         [6, 7, 8]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[4]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([1, 3, 3]),
 tensor([[[0, 1, 2],
          [3, 4, 5],
          [6, 7, 8]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[5]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([3, 1, 3]),
 tensor([[[0, 1, 2]],
 
         [[3, 4, 5]],
 
         [[6, 7, 8]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">x3</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x3</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[6]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([3, 3, 1]),
 tensor([[[0],
          [1],
          [2]],
 
         [[3],
          [4],
          [5]],
 
         [[6],
          [7],
          [8]]]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.3.2.6.-squeeze%E5%87%BD%E6%95%B0%E5%87%8F%E5%B0%91%E7%BB%B4%E5%BA%A6">7.3.2.6. <a id="toc7_3_2_6_"></a><a href="#toc0_">squeeze</a><a class="anchor-link" href="#7.3.2.6.-squeeze%E5%87%BD%E6%95%B0%E5%87%8F%E5%B0%91%E7%BB%B4%E5%BA%A6"></a></h4><p>squeeze  1 <br/>
<code>1</code></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[7]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([3, 1, 3]), torch.Size([3, 3]), torch.Size([3, 1, 3]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.3.2.7.-%E6%8B%BC%E6%8E%A5-(concat)">7.3.2.7. <a id="toc7_3_2_7_"></a><a href="#toc0_"> (concat)</a><a class="anchor-link" href="#7.3.2.7.-%E6%8B%BC%E6%8E%A5-(concat)"></a></h4><ul>
<li>torch.cat </li>
<li></li>
<li></li>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[86]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># </span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>

<span class="c1"># dim=0 ()</span>
<span class="n">cat_result_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cat_result_0</span><span class="p">)</span>
<span class="c1"># :</span>
<span class="c1"># tensor([[1, 2],</span>
<span class="c1">#         [3, 4],</span>
<span class="c1">#         [5, 6],</span>
<span class="c1">#         [7, 8]])</span>

<span class="c1"># dim=1 ()</span>
<span class="n">cat_result_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cat_result_1</span><span class="p">)</span>
<span class="c1"># :</span>
<span class="c1"># tensor([[1, 2, 5, 6],</span>
<span class="c1">#         [3, 4, 7, 8]])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1, 2],
        [3, 4],
        [5, 6],
        [7, 8]])
tensor([[1, 2, 5, 6],
        [3, 4, 7, 8]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.3.2.8.-%E6%8B%86%E5%88%86-(split)">7.3.2.8. <a id="toc7_3_2_8_"></a><a href="#toc0_"> (split)</a><a class="anchor-link" href="#7.3.2.8.-%E6%8B%86%E5%88%86-(split)"></a></h4><ul>
<li>: </li>
<li>:<ul>
<li>input: </li>
<li>split_size_or_sections: </li>
<li>dim: </li>
</ul>
</li>
<li>: </li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[53]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>


<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">splits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># 3</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">split</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">splits</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre> 0: tensor([0, 1, 2])
 1: tensor([3, 4, 5])
 2: tensor([6, 7, 8])
 3: tensor([9])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.3.2.9.-%E5%88%86%E5%9D%97-(chunk)">7.3.2.9. <a id="toc7_3_2_9_"></a><a href="#toc0_"> (chunk)</a><a class="anchor-link" href="#7.3.2.9.-%E5%88%86%E5%9D%97-(chunk)"></a></h4><ul>
<li>torch.chunk </li>
<li></li>
<li></li>
<li>
x = torch.arange(12).reshape(2, 6)</li>
</ul>
<p>x, torch.chunk(x, chunks=2, dim=0)</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[52]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>


<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">chunks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># 3</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chunks</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">chunk</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre> 0: tensor([0, 1, 2, 3])
 1: tensor([4, 5, 6, 7])
 2: tensor([8, 9])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.3.2.10.-%E6%8B%BC%E6%8E%A5-(stack)">7.3.2.10. <a id="toc7_3_2_10_"></a><a href="#toc0_"> (stack)</a><a class="anchor-link" href="#7.3.2.10.-%E6%8B%BC%E6%8E%A5-(stack)"></a></h4><ul>
<li>torch.stack <code></code></li>
<li><code></code></li>
<li><code></code></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[87]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># ab</span>
<span class="c1"># </span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>

<span class="n">stack_result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stack_result</span><span class="p">)</span>
<span class="c1"># :</span>
<span class="c1"># tensor([[[1, 2],</span>
<span class="c1">#          [3, 4]],</span>
<span class="c1"># </span>
<span class="c1">#         [[5, 6],</span>
<span class="c1">#          [7, 8]]])</span>

<span class="c1"># 0 (2, 2, 2)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[[1, 2],
         [3, 4]],

        [[5, 6],
         [7, 8]]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="7.3.2.10.1.-cat%E5%92%8Cstack%E7%9A%84%E6%AF%94%E8%BE%83">7.3.2.10.1. <a id="toc7_3_2_10_1_"></a><a href="#toc0_">catstack</a><a class="anchor-link" href="#7.3.2.10.1.-cat%E5%92%8Cstack%E7%9A%84%E6%AF%94%E8%BE%83"></a></h5><table>
<thead>
<tr>
<th></th>
<th>torch.cat</th>
<th>torch.stack</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>torch.cat  torch.stack </p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.3.2.11.-%E5%B9%BF%E6%92%AD-(expand)">7.3.2.11. <a id="toc7_3_2_11_"></a><a href="#toc0_"> (expand)</a><a class="anchor-link" href="#7.3.2.11.-%E5%B9%BF%E6%92%AD-(expand)"></a></h4><p>expand </p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>expand </li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1">#  (5, 1) </span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">]])</span>

<span class="n">a</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[10]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1],
        [2],
        [3],
        [4],
        [5]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#  (5, 3) (5, 3) </span>
<span class="n">a_expanded</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">a_expanded</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[12]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1, 1, 1],
        [2, 2, 2],
        [3, 3, 3],
        [4, 4, 4],
        [5, 5, 5]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li><ul>
<li>expand </li>
<li> 1 expand  1 </li>
<li>expand  expand </li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="7.4.-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E8%BF%90%E7%AE%97">7.4. <a id="toc7_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.4.-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E8%BF%90%E7%AE%97"></a></h2><p>PyTorch<code>-</code><code>/</code></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.4.1.-%E6%95%B0%E5%80%BC%E8%BF%90%E7%AE%97">7.4.1. <a id="toc7_4_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.4.1.-%E6%95%B0%E5%80%BC%E8%BF%90%E7%AE%97"></a></h3><ul>
<li><ul>
<li>x, ysize<code> (0)</code><code>1</code></li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">+</td>
<td style="text-align:left">torch.add(X, Y)</td>
</tr>
<tr>
<td style="text-align:left">-</td>
<td style="text-align:left">torch.sub(X, Y)</td>
</tr>
<tr>
<td style="text-align:left">*</td>
<td style="text-align:left">torch.mul(X, Y</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[17]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.]]),
 tensor([[ 0.,  1.,  2.],
         [ 3.,  4.,  5.],
         [ 6.,  7.,  8.],
         [ 9., 10., 11.],
         [12., 13., 14.]]),
 tensor([[ 0.,  1.,  2.,  3.,  4.],
         [ 5.,  6.,  7.,  8.,  9.],
         [10., 11., 12., 13., 14.]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[59]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[59]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[ 1.,  2.,  3.],
         [ 4.,  5.,  6.],
         [ 7.,  8.,  9.],
         [10., 11., 12.],
         [13., 14., 15.]]),
 tensor([[ 1.,  2.,  3.],
         [ 4.,  5.,  6.],
         [ 7.,  8.,  9.],
         [10., 11., 12.],
         [13., 14., 15.]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#  ()</span>
<span class="c1"># tensor</span>
<span class="c1"># xy1</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>   <span class="c1">#  (10, 2, 9, 9, 9, 9)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>   <span class="c1">#  (10, 2, 9, 9, 9, 9)</span>

<span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[18]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([10, 2, 1, 1, 9, 9]),
 torch.Size([10, 1, 9, 9, 1, 1]),
 torch.Size([10, 2, 9, 9, 9, 9]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#  ()</span>
<span class="c1"># tensor</span>
<span class="c1"># xy1</span>
<span class="c1"># </span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>   <span class="c1">#  (10, 2, 1, 9, 9, 9)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>             <span class="c1">#  (10, 2, 1, 9, 9, 9)</span>

<span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[19]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([10, 2, 1, 1, 9, 9]),
 torch.Size([9, 1, 1]),
 torch.Size([10, 2, 1, 9, 9, 9]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[60]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[60]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[  1.,   0.,  -1.],
         [ -2.,  -3.,  -4.],
         [ -5.,  -6.,  -7.],
         [ -8.,  -9., -10.],
         [-11., -12., -13.]]),
 tensor([[  1.,   0.,  -1.],
         [ -2.,  -3.,  -4.],
         [ -5.,  -6.,  -7.],
         [ -8.,  -9., -10.],
         [-11., -12., -13.]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[61]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">*</span> <span class="mi">3</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[61]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[3., 3., 3.],
        [3., 3., 3.],
        [3., 3., 3.],
        [3., 3., 3.],
        [3., 3., 3.]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[88]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[88]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[3., 3., 3.],
        [3., 3., 3.],
        [3., 3., 3.],
        [3., 3., 3.],
        [3., 3., 3.]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[62]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[62]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[15., 18., 21., 24., 27.],
        [15., 18., 21., 24., 27.],
        [15., 18., 21., 24., 27.],
        [15., 18., 21., 24., 27.],
        [15., 18., 21., 24., 27.]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.4.2.-%E6%95%B0%E5%80%BC%E8%BF%90%E7%AE%97-%E4%B9%98%E6%B3%95">7.4.2. <a id="toc7_4_2_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#7.4.2.-%E6%95%B0%E5%80%BC%E8%BF%90%E7%AE%97-%E4%B9%98%E6%B3%95"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.4.2.1.-%E5%93%88%E8%BE%BE%E7%8E%9B%E7%A7%AF">7.4.2.1. <a id="toc7_4_2_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.4.2.1.-%E5%93%88%E8%BE%BE%E7%8E%9B%E7%A7%AF"></a></h4><ul>
<li><code></code></li>
<li></li>
<li>x * x</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">x</span><span class="p">,</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[20]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[0, 1, 2],
         [3, 4, 5]]),
 tensor([[ 0,  1,  4],
         [ 9, 16, 25]]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.4.2.2.-%E7%82%B9%E7%A7%AF%EF%BC%88Dot-Product%EF%BC%89">7.4.2.2. <a id="toc7_4_2_2_"></a><a href="#toc0_">Dot Product</a><a class="anchor-link" href="#7.4.2.2.-%E7%82%B9%E7%A7%AF%EF%BC%88Dot-Product%EF%BC%89"></a></h4><ul>
<li></li>
<li><code></code></li>
<li><code>torch.dot(x, x)</code> # dot</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="n">x</span><span class="p">,</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="c1">#   </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[21]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([0, 1, 2]), tensor([0, 1, 4]), tensor(5))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.4.2.3.-%E7%9F%A9%E9%98%B5-%E5%90%91%E9%87%8F%E7%A7%AF">7.4.2.3. <a id="toc7_4_2_3_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#7.4.2.3.-%E7%9F%A9%E9%98%B5-%E5%90%91%E9%87%8F%E7%A7%AF"></a></h4><ul>
<li></li>
<li><code></code></li>
<li><code>torch.mv(A, x)</code> # matrix-vector</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[22]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([3, 4]), torch.Size([4]), torch.Size([3]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[66]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">A</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[66]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([3, 4]),)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.4.2.4.-%E7%9F%A9%E9%98%B5-%E7%9F%A9%E9%98%B5%E7%A7%AF">7.4.2.4. <a id="toc7_4_2_4_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#7.4.2.4.-%E7%9F%A9%E9%98%B5-%E7%9F%A9%E9%98%B5%E7%A7%AF"></a></h4><ul>
<li><strong></strong></li>
<li><code>torch.matmul(X, Y)</code>  # <code></code></li>
<li><code>X @ Y</code>               # </li>
<li><code>torch.mm(X, Y)</code>      # <code></code></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[23]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([3, 5]),
 torch.Size([5, 3]),
 torch.Size([3, 3]),
 torch.Size([3, 3]),
 torch.Size([3, 3]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.4.2.5.-%E6%89%B9%E9%87%8F%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95">7.4.2.5. <a id="toc7_4_2_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.4.2.5.-%E6%89%B9%E9%87%8F%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95"></a></h4><ul>
<li>A: (b x n x m)</li>
<li>B: (b x m x p)</li>
<li><code>torch.bmm(A, B)</code>   # b x n x p</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[24]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([3, 3, 5]), torch.Size([3, 5, 3]), torch.Size([3, 3, 3]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.4.2.6.-%E4%B9%98%E6%80%BB%E7%BB%93">7.4.2.6. <a id="toc7_4_2_6_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.4.2.6.-%E4%B9%98%E6%80%BB%E7%BB%93"></a></h4><p>PyTorch lightning <a href="https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/01-introduction-to-pytorch.html">https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/01-introduction-to-pytorch.html</a></p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">A * B</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">dot(A, B)</td>
</tr>
<tr>
<td style="text-align:left">-</td>
<td style="text-align:left">mv(A, x)</td>
</tr>
<tr>
<td style="text-align:left">-</td>
<td style="text-align:left">matmul(A, B)   A @ Bmm(A, B)</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left"><code>bmm(A, B)</code></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.4.3.-%E7%BB%9F%E8%AE%A1%E8%BF%90%E7%AE%97">7.4.3. <a id="toc7_4_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.4.3.-%E7%BB%9F%E8%AE%A1%E8%BF%90%E7%AE%97"></a></h3><table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">torch.mean()</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.median()</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.mode()</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.min()</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.max()</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.std()</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.var()</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.squar()</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.argmax()</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.argmin()</td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[25]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,
        14.])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[95]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[95]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(7.), tensor(7.))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[101]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">median</span><span class="p">()</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[101]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(7.), tensor(7.))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[103]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>   <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[103]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(0.), tensor(0.))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[104]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>   <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[104]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(14.), tensor(14.))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[108]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">mode</span><span class="p">()</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[108]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.return_types.mode(
 values=tensor(0.),
 indices=tensor(0)),
 torch.return_types.mode(
 values=tensor(0.),
 indices=tensor(0)))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>   <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[97]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(4.4721), tensor(4.4721))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[99]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>   <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[99]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(20.), tensor(20.))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[50]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># dim = 0, </span>
<span class="c1"># dim = 1, </span>
<span class="c1"># keepdim = True, </span>

<span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[50]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[ 0,  1,  2,  3,  4],
         [ 5,  6,  7,  8,  9],
         [10, 11, 12, 13, 14]]),
 tensor([[2, 2, 2, 2, 2]]),
 tensor([[4],
         [4],
         [4]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[52]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># keepdim = False </span>

<span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[52]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([2, 2, 2, 2, 2]), tensor([4, 4, 4]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[40]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[False, False,  True, False, False],
        [False, False, False, False, False],
        [False, False, False, False, False]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[55]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[10, 11, 12, 13, 14],
        [10, 11, 12, 13, 14],
        [10, 11, 12, 13, 14],
        [10, 11, 12, 13, 14],
        [10, 11, 12, 13, 14]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[56]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([10, 11, 12, 13, 14])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="7.5.-%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6-(Broadcasting)">7.5. <a id="toc7_5_"></a><a href="#toc0_"> (Broadcasting)</a><a class="anchor-link" href="#7.5.-%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6-(Broadcasting)"></a></h2><p>PyTorchBroadcasting</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.5.1.-%E5%B9%BF%E6%92%AD%E8%A7%84%E5%88%99">7.5.1. <a id="toc7_5_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.5.1.-%E5%B9%BF%E6%92%AD%E8%A7%84%E5%88%99"></a></h3><ol>
<li><code></code></li>
<li><code></code><code>1</code></li>
<li></li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol>
<li><p><strong></strong></p>
<p></p>
</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">scalar</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]);</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'tensor size: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">scalar</span> <span class="o">*</span> <span class="n">tensor</span>

<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1">#  tensor([2., 4., 6.])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor size: torch.Size([3])
tensor([2., 4., 6.]) torch.Size([3])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="2">
<li><p><strong>1</strong></p>
<p>1</p>
</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[58]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tensor1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">]])</span>  <span class="c1">#  (3, 1)  3 x 1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'tensor1 size: </span><span class="si">{</span><span class="n">tensor1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">tensor2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>        <span class="c1">#  (3,)    1 x 3</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'tensor2 size: </span><span class="si">{</span><span class="n">tensor2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">tensor1</span> <span class="o">+</span> <span class="n">tensor2</span>

<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>  <span class="c1">#  tensor([[2., 3., 4.],</span>
<span class="c1">#                     [3., 4., 5.],</span>
<span class="c1">#                     [4., 5., 6.]])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor1 size: torch.Size([3, 1])
tensor2 size: torch.Size([3])
tensor([[2., 3., 4.],
        [3., 4., 5.],
        [4., 5., 6.]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="3">
<li><p><strong></strong></p>
<p>1</p>
</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[59]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tensor1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>    <span class="c1">#  (128, 10, 20, 100)        </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'tensor1 size: </span><span class="si">{</span><span class="n">tensor1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># tensor2 = torch.randn(size=(100,))                #  (1, 100)  : 1 x 100(128, 10, 20, 100) </span>
<span class="n">tensor2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>                <span class="c1">#  (1, 100)  : 1 x 100(128, 10, 20, 100) </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'tensor2 size: </span><span class="si">{</span><span class="n">tensor2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">tensor1</span> <span class="o">+</span> <span class="n">tensor2</span>

<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor1 size: torch.Size([128, 10, 20, 100])
tensor2 size: torch.Size([1, 100])
torch.Size([128, 10, 20, 100])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="4">
<li><p><strong></strong></p>
<p>1</p>
</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tensor1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]])</span>  <span class="c1">#  (2, 2), 2 x 2</span>
<span class="n">tensor2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>          <span class="c1">#  (3,),   1 x 3</span>
<span class="c1"># </span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tensor1</span> <span class="o">+</span> <span class="n">tensor2</span>
<span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>  <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="5">
<li></li>
</ol>
<p>PyTorch</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="7.6.-Pytorch%E7%9A%84%E8%AE%A1%E7%AE%97%E5%9B%BE-%E5%92%8C-%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86-(autograd)">7.6. <a id="toc7_6_"></a><a href="#toc0_">Pytorch   (autograd)</a><a class="anchor-link" href="#7.6.-Pytorch%E7%9A%84%E8%AE%A1%E7%AE%97%E5%9B%BE-%E5%92%8C-%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86-(autograd)"></a></h2><ul>
<li><p>PyTorchTensorFlow</p>
</li>
<li><p>pytorch<code>tensor</code> <code>operation</code></p>
<ul>
<li><p></p>
</li>
<li><p><code>leaf node</code><code></code></p>
<ul>
<li></li>
<li></li>
<li><code>y.backward()</code><code></code><code>retain_grad()</code></li>
</ul>
</li>
</ul>
</li>
<li><p>torch.tensor </p>
<ul>
<li>  <code>requires_grad</code></li>
<li>  <code>grad_fn</code></li>
<li>  <code>is_leaf</code></li>
<li>  <code>grad</code></li>
</ul>
</li>
<li><p>requires_gradFalseTrueTrueTrue/Falseloss</p>
</li>
</ul>
<hr/>
<ul>
<li>PyTorch<code>backward()</code>  <code>torch.autograd.grad()</code> .grady.backward()<code>torch.autograd.backward(y)</code></li>
</ul>
<p><img alt="PyTorch" src="./Pytorch_Pictures/PyTorch_graphacial_demo/graph.jpg"/></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.6.1.-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-(backward)-%E6%89%B9%E9%87%8F%E6%B1%82%E6%A2%AF%E5%BA%A6%EF%BC%8C%E4%BD%86%E6%9C%AA%E8%BF%9B%E8%A1%8C%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0">7.6.1. <a id="toc7_6_1_"></a><a href="#toc0_"> (backward)-</a><a class="anchor-link" href="#7.6.1.-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-(backward)-%E6%89%B9%E9%87%8F%E6%B1%82%E6%A2%AF%E5%BA%A6%EF%BC%8C%E4%BD%86%E6%9C%AA%E8%BF%9B%E8%A1%8C%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0"></a></h3><p><code> (Tensor)</code> <code>grad</code> ()</p>
<ul>
<li><code>y.backward()</code>  <code>torch.autograd.backward(y)</code></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[42]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>       <span class="c1"># </span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>      <span class="c1"># </span>

<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x1</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">x2</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>   <span class="c1"># </span>

<span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y</span>   
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[42]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]], requires_grad=True),
 tensor([[ 1.1690,  1.1080, -1.3046, -0.0044, -1.4428],
         [ 0.9029, -1.0754,  0.1783, -0.5008, -0.0571],
         [ 1.5950, -0.4997, -0.5458,  0.8798, -0.9804]], requires_grad=True),
 tensor(15.6153, grad_fn=&lt;SumBackward0&gt;))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[236]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 1. is_leaf</span>
<span class="n">x1</span><span class="o">.</span><span class="n">is_leaf</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">is_leaf</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">is_leaf</span>   
<span class="c1"># x1, x2y</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[236]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(True, True, False)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[44]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 2. requires_grad</span>
<span class="n">x1</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">requires_grad</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[44]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(True, True, True)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[45]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 3. grad_fn</span>
<span class="n">x1</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">grad_fn</span>   
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[45]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(None, None, &lt;SumBackward0 at 0x7fce06bff0d0&gt;)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[46]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 4. grad</span>
<span class="n">x1</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">grad</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/tmp/ipykernel_32820/1085795512.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538439675/work/build/aten/src/ATen/core/TensorBody.h:489.)
  x1.grad, x2.grad, y.grad
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[46]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(None, None, None)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[47]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="c1"># torch.autograd.backward(y)  # </span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[48]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 4. grad</span>
<span class="n">x1</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">grad</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/tmp/ipykernel_32820/1085795512.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538439675/work/build/aten/src/ATen/core/TensorBody.h:489.)
  x1.grad, x2.grad, y.grad
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[48]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[2., 2., 2., 2., 2.],
         [2., 2., 2., 2., 2.],
         [2., 2., 2., 2., 2.]]),
 tensor([[4.0998e+00, 3.6832e+00, 5.1059e+00, 5.9216e-05, 6.2451e+00],
         [2.4456e+00, 3.4693e+00, 9.5398e-02, 7.5255e-01, 9.7835e-03],
         [7.6321e+00, 7.4899e-01, 8.9373e-01, 2.3219e+00, 2.8837e+00]]),
 None)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.6.2.-%E4%BB%85%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6-(%E6%B1%82%E5%AF%BC%E8%AE%A1%E7%AE%97)">7.6.2. <a id="toc7_6_2_"></a><a href="#toc0_"> ()</a><a class="anchor-link" href="#7.6.2.-%E4%BB%85%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6-(%E6%B1%82%E5%AF%BC%E8%AE%A1%E7%AE%97)"></a></h3><p>backwardtorch.autograd.grad<code> (output)</code> <code> (input)</code><code> ()</code><code></code></p>
<ul>
<li><code>torch.autograd.grad(output=y, input=x, retain_grad=False/True)</code></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[54]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># float</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[54]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[[3., 3., 3., 3., 3.],
          [3., 3., 3., 3., 3.],
          [3., 3., 3., 3., 3.]],
 
         [[3., 3., 3., 3., 3.],
          [3., 3., 3., 3., 3.],
          [3., 3., 3., 3., 3.]],
 
         [[3., 3., 3., 3., 3.],
          [3., 3., 3., 3., 3.],
          [3., 3., 3., 3., 3.]]]),)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="7.7.-%E8%87%AA%E5%8A%A8%E5%BE%AE%E7%A7%AF-autograd">7.7. <a id="toc7_7_"></a><a href="#toc0_">-autograd</a><a class="anchor-link" href="#7.7.-%E8%87%AA%E5%8A%A8%E5%BE%AE%E7%A7%AF-autograd"></a></h2><div class="highlight"><pre><span></span>
</pre></div>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1. </td>
<td style="text-align:left">x.requires_grad_(True)</td>
</tr>
<tr>
<td style="text-align:left">2. </td>
<td style="text-align:left">y = x * x (grad_fn)</td>
</tr>
<tr>
<td style="text-align:left">3. ()</td>
<td style="text-align:left">y.backward()</td>
</tr>
<tr>
<td style="text-align:left">4. </td>
<td style="text-align:left">x.grad</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.7.1.-%E8%87%AA%E5%B7%B1%E6%8E%A2%E7%B4%A2">7.7.1. <a id="toc7_7_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.7.1.-%E8%87%AA%E5%B7%B1%E6%8E%A2%E7%B4%A2"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.7.1.1.-%E6%A0%87%E9%87%8F-%E4%B8%80%E9%98%B6%E5%AF%BC%E6%95%B0%EF%BC%88%E5%BE%97%E6%A0%87%E9%87%8F%EF%BC%89">7.7.1.1. <a id="toc7_7_1_1_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#7.7.1.1.-%E6%A0%87%E9%87%8F-%E4%B8%80%E9%98%B6%E5%AF%BC%E6%95%B0%EF%BC%88%E5%BE%97%E6%A0%87%E9%87%8F%EF%BC%89"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[129]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># </span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>                                                        <span class="c1"># </span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[129]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(2., requires_grad=True), tensor(4., grad_fn=&lt;PowBackward0&gt;))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[70]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># xNone</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[70]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(None, True)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[71]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># yx</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[73]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># x2 * 2 = 4</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span>                                                          <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[73]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor(4.)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[74]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="c1"># yx2*x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[74]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor(True)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[75]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># xz = x**3</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
<span class="n">z</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[75]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor(4., grad_fn=&lt;PowBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[76]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># x</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="c1"># 0# x.grad.zero_()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[76]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor(0.)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[77]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># zx</span>
<span class="n">z</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[78]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># x</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="c1"># 44 + 4 = 8</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[78]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor(4.)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.7.1.2.-%E6%A0%87%E9%87%8F/%E5%90%91%E9%87%8F-%E4%B8%80%E9%98%B6%E5%AF%BC%E6%95%B0%EF%BC%88%E5%BE%97%E5%90%91%E9%87%8F%EF%BC%89">7.7.1.2. <a id="toc7_7_1_2_"></a><a href="#toc0_">/-</a><a class="anchor-link" href="#7.7.1.2.-%E6%A0%87%E9%87%8F/%E5%90%91%E9%87%8F-%E4%B8%80%E9%98%B6%E5%AF%BC%E6%95%B0%EF%BC%88%E5%BE%97%E5%90%91%E9%87%8F%EF%BC%89"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># </span>
<span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[20]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0., 1., 2., 3.], requires_grad=True)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>                                              <span class="c1"># </span>
<span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[21]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor(14., grad_fn=&lt;DotBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span>                                                          <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[22]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0., 2., 4., 6.])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[23]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([True, True, True, True])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.7.1.3.-%E5%90%91%E9%87%8F/%E5%90%91%E9%87%8F-%E4%B8%80%E9%98%B6%E5%AF%BC%E6%95%B0%EF%BC%88%E5%BE%97%E7%9F%A9%E9%98%B5%EF%BC%89">7.7.1.3. <a id="toc7_7_1_3_"></a><a href="#toc0_">/-</a><a class="anchor-link" href="#7.7.1.3.-%E5%90%91%E9%87%8F/%E5%90%91%E9%87%8F-%E4%B8%80%E9%98%B6%E5%AF%BC%E6%95%B0%EF%BC%88%E5%BE%97%E7%9F%A9%E9%98%B5%EF%BC%89"></a></h4><ul>
<li><p>pytorch//<code>xy</code></p>
</li>
<li><p><code>y</code></p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>    <span class="c1"># </span>
<span class="n">i</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[24]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0., 1., 2., 3.], requires_grad=True)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">h</span> <span class="o">=</span> <span class="n">i</span> <span class="o">**</span> <span class="mi">2</span>                                                      <span class="c1"># </span>
<span class="n">h</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[25]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0., 1., 4., 9.], grad_fn=&lt;PowBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[27]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># h.backward()      # </span>
<span class="n">h</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># </span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[27]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0., 2., 4., 6.])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="7.7.1.4.-%E6%B1%82%E9%AB%98%E9%98%B6%E5%AF%BC%E6%95%B0">7.7.1.4. <a id="toc7_7_1_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.7.1.4.-%E6%B1%82%E9%AB%98%E9%98%B6%E5%AF%BC%E6%95%B0"></a></h4><ul>
<li><p><code>torch.autograd.grad(outputs=y, inputs=x, create_grad=True)</code></p>
</li>
<li><p> (), <code>create_grad=True </code></p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">3</span>
<span class="n">grad1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># create_graph=True, </span>
<span class="n">grad1</span> <span class="c1"># 3 * x**2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[55]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(12., grad_fn=&lt;MulBackward0&gt;),)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">grad2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">grad1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">grad2</span> <span class="c1"># 6 * x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[56]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(12., grad_fn=&lt;MulBackward0&gt;),)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">grad3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">grad2</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad3</span> <span class="c1"># 6</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[57]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(6.),)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.7.2.-%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BE%8B%E5%AD%90">7.7.2. <a id="toc7_7_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.7.2.-%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BE%8B%E5%AD%90"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>
<span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0., 1., 2., 3.])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">x</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># x=torch.arange(4.0,requires_grad=True)</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span>                  <span class="c1"># None</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">y</span>                       <span class="c1"># x4xxy</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor(28., grad_fn=&lt;MulBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># yx</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>            <span class="c1"># [4x, 4x, 4x, 4x] </span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span>                  <span class="c1"># [4*0, 4*1, 4*2, 4*3] </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([ 0.,  4.,  8., 12.])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">x</span>         <span class="c1"># [4x, 4x, 4x, 4x] </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([True, True, True, True])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.7.3.-%E8%AE%A1%E7%AE%97%E5%8F%A6%E4%B8%80%E4%B8%AA">7.7.3. <a id="toc7_7_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.7.3.-%E8%AE%A1%E7%AE%97%E5%8F%A6%E4%B8%80%E4%B8%AA"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># PyTorch</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0., 0., 0., 0.])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([0., 1., 2., 3.], requires_grad=True),
 tensor(6., grad_fn=&lt;SumBackward0&gt;))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([1., 1., 1., 1.])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.7.4.-%E9%9D%9E%E6%A0%87%E9%87%8F%E5%8F%98%E9%87%8F%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD">7.7.4. <a id="toc7_7_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.7.4.-%E9%9D%9E%E6%A0%87%E9%87%8F%E5%8F%98%E9%87%8F%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"></a></h3><ul>
<li><p>yyx</p>
</li>
<li><p>yx</p>
</li>
<li><p>  <strong></strong></p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># backwardgradientself</span>
<span class="c1"># 1</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
<span class="c1"># y.backward(torch.ones(len(x)))</span>
<span class="n">y</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0., 2., 4., 6.])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span> 
<span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([0., 1., 2., 3.], requires_grad=True),
 tensor([0., 1., 4., 9.], grad_fn=&lt;MulBackward0&gt;))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([0., 0., 0., 0.]), tensor([0., 0., 0., 0.]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(None, tensor([0., 2., 4., 6.]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.7.5.-%E5%88%86%E7%A6%BB%E8%AE%A1%E7%AE%97">7.7.5. <a id="toc7_7_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.7.5.-%E5%88%86%E7%A6%BB%E8%AE%A1%E7%AE%97"></a></h3><ul>
<li><p> yxzyx zxy xy</p>
</li>
<li><p>yuy y ux z=u<em>xxu z=x</em>x*xx</p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">u</span> <span class="o">*</span> <span class="n">x</span>

<span class="n">z</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">u</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([True, True, True, True])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># yy y=x*xx2*x</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">y</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([True, True, True, True])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="7.7.6.-Python%E6%8E%A7%E5%88%B6%E6%B5%81%E7%9A%84%E6%A2%AF%E5%BA%A6%E8%AE%A1%E7%AE%97">7.7.6. <a id="toc7_7_6_"></a><a href="#toc0_">Python</a><a class="anchor-link" href="#7.7.6.-Python%E6%8E%A7%E5%88%B6%E6%B5%81%E7%9A%84%E6%A2%AF%E5%BA%A6%E8%AE%A1%E7%AE%97"></a></h3><ul>
<li> Python whileifa</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="k">while</span> <span class="n">b</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">b</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">b</span>
    <span class="k">return</span> <span class="n">c</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">d</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[30]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># f a akf(a)=k*akad/a</span>
<span class="n">a</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">d</span> <span class="o">/</span> <span class="n">a</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[30]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor(True)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="7.8.-%E6%A6%82%E7%8E%87%E8%AE%BA">7.8. <a id="toc7_8_"></a><a href="#toc0_"></a><a class="anchor-link" href="#7.8.-%E6%A6%82%E7%8E%87%E8%AE%BA"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">device</span> <span class="o">=</span> <span class="s1">'cpu'</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([-0.7607, -0.3525, -0.6538,  0.3404, -1.0323, -0.4394,  0.0676,  0.7667,
         1.7211, -0.0475, -1.1181,  0.7353, -1.7605,  1.4901, -0.9803,  0.8902,
        -0.0931, -1.7484,  2.3997,  0.6524,  0.6782, -1.1440, -1.3923,  0.1212,
        -1.0076, -1.7668, -1.4322, -0.6901,  0.2830,  0.5470,  1.4634,  0.6256,
         1.2161, -1.3545, -1.2281, -0.6693,  0.2557,  0.2750, -0.1981,  0.4620,
         0.5137, -0.3635,  0.7580,  0.6187, -2.0609, -1.9659, -0.0752,  0.7554,
        -0.6792, -1.2573, -0.1298, -0.4564,  0.3095,  1.2856, -0.7012,  0.5607,
        -1.0115,  1.1368,  1.0839,  1.5874, -1.1725,  0.8335, -1.8986,  1.1627,
         1.5963, -1.7788,  1.4887,  2.6236,  0.0521, -0.5584, -1.2956, -1.0912,
         1.0101,  0.6228,  0.3619,  1.4112,  0.1833,  0.4523, -0.5056,  0.2020,
         1.4686,  1.8315, -0.8283,  0.6796, -0.1077,  0.0794, -0.2321,  1.2689,
        -0.5188,  0.6315,  1.2953, -0.0427,  0.0622, -0.6244, -0.6351, -1.3894,
         0.1629, -0.7895, -0.0437,  1.6747])
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[13]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[&lt;matplotlib.lines.Line2D at 0x7f350d9c5df0&gt;]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="8.-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E8%AE%AD%E7%BB%83%E5%85%AB%E8%82%A1">8. <a id="toc8_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#8.-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E8%AE%AD%E7%BB%83%E5%85%AB%E8%82%A1"></a></h1><table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left"></td>
<td style="text-align:left">-&gt;<code>y_hat</code></td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:left"></td>
<td style="text-align:left">-&gt;<code>loss</code></td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td style="text-align:left"></td>
<td style="text-align:left">-&gt;<code></code></td>
</tr>
<tr>
<td style="text-align:left">4</td>
<td style="text-align:left"></td>
<td style="text-align:left">-&gt;123</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.1.-%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E4%BA%8E%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B">8.1. <a id="toc8_1_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#8.1.-%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E4%BA%8E%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.1.1.-%E8%99%9A%E6%8B%9F%E5%87%BA%E6%95%B0%E6%8D%AE">8.1.1. <a id="toc8_1_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.1.1.-%E8%99%9A%E6%8B%9F%E5%87%BA%E6%95%B0%E6%8D%AE"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">synthetic_data</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">):</span>  
<span class="w">    </span><span class="sd">"""y=Xw+b+"""</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_examples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
    <span class="n">y</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">true_w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4</span><span class="p">])</span>
<span class="n">true_b</span> <span class="o">=</span> <span class="mf">4.2</span>

<span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">synthetic_data</span><span class="p">(</span><span class="n">true_w</span><span class="p">,</span> <span class="n">true_b</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'features:'</span><span class="p">,</span> <span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'label:'</span><span class="p">,</span> <span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>features: tensor([1.6710, 0.3170])
label: tensor([6.4774])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">d2l</span><span class="o">.</span><span class="n">set_figsize</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">features</span><span class="p">[:,</span> <span class="p">(</span><span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> 
                <span class="n">labels</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="231.442187pt" height="169.678125pt" viewBox="0 0 231.442187 169.678125" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-05-18T15:08:53.316260</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 169.678125 
L 231.442187 169.678125 
L 231.442187 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 28.942188 145.8 
L 224.242188 145.8 
L 224.242188 7.2 
L 28.942188 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="PathCollection_1">
    <defs>
     <path id="m18bb6ce550" d="M 0 0.5 
C 0.132602 0.5 0.25979 0.447317 0.353553 0.353553 
C 0.447317 0.25979 0.5 0.132602 0.5 0 
C 0.5 -0.132602 0.447317 -0.25979 0.353553 -0.353553 
C 0.25979 -0.447317 0.132602 -0.5 0 -0.5 
C -0.132602 -0.5 -0.25979 -0.447317 -0.353553 -0.353553 
C -0.447317 -0.25979 -0.5 -0.132602 -0.5 0 
C -0.5 0.132602 -0.447317 0.25979 -0.353553 0.353553 
C -0.25979 0.447317 -0.132602 0.5 0 0.5 
z
" style="stroke: #1f77b4"/>
    </defs>
    <g clip-path="url(#p149bb96678)">
     <use xlink:href="#m18bb6ce550" x="89.095479" y="47.161377" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.851713" y="83.62544" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.208597" y="87.238868" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="87.729918" y="40.397538" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.573273" y="74.594754" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.717888" y="60.945456" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="145.324851" y="78.7769" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.745046" y="79.445989" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="100.425785" y="38.908429" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.929806" y="116.402206" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.433764" y="88.486938" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.993977" y="81.085971" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.88151" y="87.997522" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.448528" y="88.393808" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="120.731191" y="76.554431" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.365738" y="73.519191" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.023584" y="74.321666" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.343054" y="93.603985" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.480389" y="88.551763" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="82.783874" y="35.366294" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.40635" y="58.043827" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="164.163633" y="103.28369" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="101.402431" y="57.861658" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="111.67707" y="81.847122" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.810681" y="77.415171" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.459828" y="90.031881" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="74.291277" y="35.628451" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.353451" y="92.726373" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.567219" y="65.921645" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.252503" y="67.827082" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.357592" y="73.868138" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.556005" y="81.497491" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.588391" y="57.255578" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="95.873451" y="56.665809" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.53247" y="72.549742" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.363962" y="85.38564" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.858176" y="58.074153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.627228" y="51.205587" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="101.274568" y="46.708364" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.191399" y="111.673949" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.057851" y="75.989104" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.467418" y="67.739194" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="115.631192" y="59.798297" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.163912" y="74.989388" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="95.397586" y="59.375105" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.25971" y="59.267597" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="144.847122" y="93.854999" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.1543" y="71.690158" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="145.433433" y="87.617628" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.147698" y="63.623364" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.640488" y="73.829216" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.738102" y="89.36582" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="155.302647" y="94.878713" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="161.085924" y="98.631002" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="118.452017" y="69.606532" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="105.770517" y="77.322051" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.949251" y="72.458828" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="75.617311" y="44.551745" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.242985" y="71.231531" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="145.456331" y="87.507944" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.942623" y="89.154946" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="172.84967" y="115.023299" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.293778" y="57.941606" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.996861" y="64.990028" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="173.079155" y="124.951583" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="94.600268" y="47.266292" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.097375" y="82.798065" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="171.793196" y="84.905216" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.647189" y="63.342156" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="118.612985" y="71.311502" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="109.608414" y="71.440978" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="160.656532" y="109.509315" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.409678" y="76.930463" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.748237" y="81.979596" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="96.86734" y="45.388764" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.971797" y="96.679841" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="111.111144" y="39.170635" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="172.522205" y="104.843924" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="215.364915" y="136.669454" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.039242" y="64.485384" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.026192" y="92.242205" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="87.829908" y="58.495525" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="102.715044" y="43.485036" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.536737" y="66.785002" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.411851" y="75.943248" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="164.084039" y="105.039855" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.865947" y="90.586554" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.345475" y="70.239975" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.715025" y="86.234712" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="105.761775" y="72.272405" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="90.937862" y="42.120415" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="108.620502" y="52.733002" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.71258" y="91.534395" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.038561" y="78.277075" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.303632" y="80.007046" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="167.680851" y="123.495815" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.102381" y="87.647679" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.983381" y="68.147087" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="109.287017" y="77.973753" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.728341" y="102.953634" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="100.255003" y="48.117778" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.176357" y="79.685957" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.072006" y="105.065753" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="153.081318" y="94.163776" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="95.789688" y="39.249632" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.093641" y="94.996263" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="179.020821" y="110.657126" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="118.413335" y="56.029453" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.839972" y="95.454916" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.064537" y="95.256836" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.861671" y="79.859375" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="107.424467" y="86.897922" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.523298" y="94.19315" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="174.220273" y="100.574648" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.411392" y="95.633883" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="99.245321" y="77.128793" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="104.974341" y="42.823713" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="118.346943" y="71.69238" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="109.730968" y="43.229075" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.599003" y="84.788153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.921167" y="72.66032" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="87.318025" y="58.450722" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="194.960884" y="131.832798" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.851446" y="54.265354" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.738185" y="79.788226" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="94.232769" y="39.581108" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.609002" y="74.271061" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.604959" y="96.641912" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.290707" y="95.322537" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="86.920401" y="37.140992" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="162.569027" y="88.381482" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.631163" y="82.87251" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="173.473124" y="114.644034" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.089957" y="81.887664" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="171.2269" y="110.831563" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.389193" y="79.688158" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.145673" y="72.500684" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="102.439791" y="64.647256" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.448923" y="83.772278" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="167.538471" y="126.892836" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="104.310948" y="52.077508" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="110.07802" y="71.031701" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.269235" y="77.309642" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.764291" y="95.714536" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.771941" y="78.662995" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="88.05873" y="52.853989" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.825865" y="85.024525" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.04984" y="65.790707" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.985694" y="73.972357" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="144.372596" y="73.366803" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="179.97065" y="103.786181" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="118.344855" y="70.019699" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="93.447802" y="46.796222" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.990588" y="71.131398" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.143886" y="67.727624" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="162.66859" y="87.823199" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="115.899883" y="74.458643" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="155.576442" y="119.338468" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="115.434056" y="65.114343" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.373461" y="90.545777" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="74.95746" y="32.072086" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.379211" y="89.646188" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="179.659058" y="131.976622" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="94.916788" y="37.519916" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.311539" y="68.471924" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.407896" y="58.213502" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.98083" y="67.209455" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.578836" y="83.648026" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.530611" y="81.247013" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="120.676106" y="78.386436" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="188.590076" y="110.099002" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.701229" y="79.870857" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.85927" y="86.82456" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.10514" y="55.800128" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="163.751938" y="95.543365" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.73323" y="80.716385" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="97.229499" y="49.869361" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.169676" y="78.313592" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="181.657673" y="108.965791" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="164.523107" y="89.407648" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.105095" y="102.732158" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="168.184204" y="130.289923" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.883837" y="77.297087" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.828564" y="77.985982" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="162.511402" y="86.539024" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="162.205736" y="88.497173" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.420465" y="82.445164" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.183605" y="100.566278" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.508009" y="78.2606" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.071365" y="104.95213" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.33869" y="90.006435" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="118.497756" y="66.676858" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="95.538572" y="44.376892" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="114.319541" y="50.800963" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.013391" y="73.130755" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.436765" y="90.054365" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.851902" y="88.832337" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="163.298429" y="109.265351" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.81924" y="105.520126" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="99.125532" y="45.042519" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="110.520817" y="71.352702" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.616857" y="87.712444" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.361615" y="93.431903" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="161.955365" y="115.084394" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="105.302701" y="65.664837" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="96.00782" y="41.543072" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.22642" y="65.483171" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.02213" y="73.541159" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.117686" y="107.280884" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.369294" y="81.808232" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.787771" y="92.773059" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.140729" y="110.615348" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.002826" y="87.620506" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.425689" y="95.841866" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.446106" y="67.122825" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.509686" y="77.513579" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.088532" y="65.123268" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="172.731574" y="108.43805" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.832592" y="59.570065" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.975699" y="71.318317" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.907336" y="103.523987" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="92.159527" y="43.963427" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="105.55038" y="71.800816" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="86.639005" y="50.486663" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.806314" y="80.491925" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.015768" y="101.020893" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="163.847569" y="103.960201" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.777105" y="64.961187" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="178.333764" y="108.101154" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="114.172839" y="71.272436" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="86.066135" y="54.533553" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.714613" y="77.715356" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.050538" y="85.805685" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.294464" y="84.457284" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.123238" y="110.462091" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="101.150669" y="40.894705" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="115.184716" y="69.718393" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="173.640153" y="99.022385" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="103.863809" y="47.724193" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.626844" y="94.62609" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.241278" y="69.007238" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="178.5462" y="115.545579" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.599468" y="50.701739" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.598236" y="93.231596" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="104.028281" y="48.494835" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="120.972378" y="60.52896" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="175.093025" y="115.579612" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="109.674163" y="57.422106" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="81.816997" y="48.033332" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.268201" y="92.460497" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.982868" y="94.537197" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="166.366972" y="105.885217" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.981166" y="89.998881" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="96.909952" y="57.369795" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="163.800072" y="109.391435" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="118.3025" y="68.146646" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="145.112621" y="77.863288" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.019004" y="82.309716" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="120.437598" y="64.998791" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.85551" y="62.189196" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.337286" y="90.072432" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.260642" y="75.777629" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.736644" y="88.600963" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.817745" y="62.371521" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.558975" y="81.635209" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="100.054067" y="54.280767" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.664876" y="73.743823" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="120.419599" y="70.005569" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.615409" y="67.434763" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.973077" y="76.827061" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.851912" y="83.246127" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.465775" y="62.814925" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.69414" y="82.432944" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.5567" y="66.571063" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.865298" y="61.460029" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.895165" y="84.160395" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.69307" y="68.818434" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.775156" y="52.552853" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.131616" y="95.612473" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.314575" y="60.307027" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="102.398024" y="65.64585" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="157.260952" y="90.950681" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="107.303587" y="67.75297" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.26854" y="53.050234" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="184.810641" y="106.433803" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="98.187906" y="49.907413" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="160.298809" y="81.185502" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="106.691714" y="64.86224" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="107.551724" y="63.739985" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="190.442405" y="101.59375" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="168.636939" y="110.318736" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="189.434988" y="122.525807" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="83.010608" y="38.326326" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.135154" y="91.321178" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.262778" y="77.393835" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="96.275451" y="49.56985" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.832572" y="85.533263" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.746231" y="72.671207" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="144.820777" y="99.386596" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="120.683545" y="67.775845" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.196624" y="74.056585" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.203098" y="75.661508" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.907138" y="61.146314" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="155.719176" y="105.44496" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="90.349765" y="37.429393" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.196461" y="78.800497" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.30426" y="76.243697" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.995264" y="65.434945" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.206289" y="95.744662" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="101.555366" y="60.535636" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.926729" y="87.970989" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="155.454368" y="86.192893" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="107.242903" y="57.788411" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.740043" y="75.358756" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="114.248791" y="35.551553" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.69951" y="78.30334" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="106.329754" y="64.711556" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.247098" y="101.88973" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.406229" y="97.819789" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.031335" y="88.734081" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.843379" y="45.330227" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="107.434758" y="44.209348" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.13027" y="76.632356" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.58724" y="108.769978" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.484005" y="100.102314" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.946035" y="88.620482" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.437023" y="96.788656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.015895" y="60.901465" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="153.169374" y="93.607883" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.803278" y="74.933473" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.571926" y="82.22746" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.47718" y="95.62631" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="98.262069" y="60.61157" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.718515" y="81.496522" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="92.181732" y="41.516842" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.331169" y="88.36295" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.890814" y="70.030588" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.969004" y="78.772412" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.483839" y="69.940603" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.305641" y="72.17007" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.064401" y="108.453568" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.168083" y="66.977319" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="186.070028" y="121.685772" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="160.440592" y="96.364357" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.615906" y="83.36262" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.334251" y="77.685671" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.832708" y="77.021255" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="163.584402" y="81.933449" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.030805" y="56.89179" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="169.2568" y="109.930138" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="81.284677" y="46.477058" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="163.833589" y="107.725896" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.628025" y="95.836344" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="105.51822" y="25.80849" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.05078" y="83.93642" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="111.24022" y="41.798879" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="176.812922" y="100.699816" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="206.112711" y="132.059178" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="94.459017" y="61.119264" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="166.340598" y="102.003628" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.568646" y="90.938355" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="178.466042" y="135.076353" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="157.576191" y="89.697253" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.493513" y="84.102082" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.957632" y="70.643879" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="116.199816" y="77.271077" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="175.249178" y="118.26173" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.033036" y="100.42625" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.798255" y="85.449113" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.32953" y="91.51232" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="157.504324" y="98.445219" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.286187" y="69.827219" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.735623" y="96.551888" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.230718" y="69.991721" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.659505" y="77.144345" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="106.011388" y="53.943991" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="97.674035" y="42.491325" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.566322" y="71.860096" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.753018" y="71.452624" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="120.905282" y="87.64505" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="96.361549" y="59.370096" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.572454" y="71.761607" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="97.975877" y="59.617879" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="115.789529" y="76.742222" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="161.474806" y="104.341687" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.264875" y="68.026442" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.512114" y="87.193492" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.937993" y="69.71948" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="108.383548" y="45.774082" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.136088" y="64.811021" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="106.571522" y="54.048753" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="98.810063" y="47.273691" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.294015" y="79.306596" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="153.120782" y="90.852565" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.06859" y="66.468719" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.146701" y="63.262394" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="106.221559" y="65.665216" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.708983" y="89.563288" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.273493" y="66.439287" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.837173" y="83.170556" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.803884" y="65.386806" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.632525" y="94.60237" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.695338" y="77.253336" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="94.70951" y="40.351655" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.687648" y="79.915883" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="88.793452" y="52.793148" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.863376" y="74.635042" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.501331" y="91.09296" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="120.99569" y="73.305529" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.416351" y="88.123721" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="167.367629" y="93.357726" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="162.029471" y="96.797956" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.194088" y="101.376634" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.180676" y="59.779791" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.57167" y="83.17462" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.986711" y="58.26251" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="164.046832" y="93.280006" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="164.214217" y="89.448882" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="162.969972" y="92.86561" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.20047" y="76.563584" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="102.767122" y="73.075454" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.681444" y="59.21978" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="116.292355" y="66.063946" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.960186" y="93.067459" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.53253" y="74.32969" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="177.84401" y="120.319759" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.647964" y="89.083226" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="75.729887" y="21.716144" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="105.927387" y="67.650078" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="106.175365" y="65.223208" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.556223" y="97.346334" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="163.029483" y="110.278113" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="92.402947" y="55.04702" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="88.987071" y="36.320377" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.230393" y="66.727421" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.536374" y="54.699249" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.740495" y="68.524397" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="68.20164" y="18.152251" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.864201" y="96.415787" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="103.393444" y="53.098791" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="102.272119" y="55.945706" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.119748" y="67.417656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.167812" y="50.437323" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="107.387767" y="53.971836" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="104.477571" y="60.758656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="173.02508" y="108.205526" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.285307" y="67.258656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="145.331823" y="82.418834" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.486232" y="77.876968" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.91161" y="82.143424" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.717006" y="57.152768" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.891315" y="94.68598" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="144.848712" y="112.619282" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.33896" y="84.338058" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="169.909578" y="105.269701" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.05359" y="90.123526" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.726965" y="103.768415" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="145.333197" y="90.380013" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="105.915242" y="55.457805" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.672469" y="80.84138" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.840902" y="70.947599" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="89.958121" y="23.162991" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.110344" y="77.873558" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.218008" y="105.443857" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.779349" y="91.711486" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="89.503636" y="44.255994" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.471323" y="95.849579" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="145.37937" y="83.283928" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="104.675286" y="47.93496" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="76.540277" y="41.384245" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="155.953678" y="78.467352" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="99.887518" y="50.069211" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="160.066197" y="94.835505" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.852849" y="108.472892" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="164.112367" y="104.72846" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="157.869502" y="106.281367" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="96.342459" y="51.793366" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="116.511957" y="70.717656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.192634" y="98.065695" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="159.357245" y="93.409271" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.565301" y="91.783085" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="114.027944" y="60.077816" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="98.546238" y="51.08775" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.902369" y="70.340151" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.13645" y="64.663011" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="110.119843" y="55.93901" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.90781" y="54.780247" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.844246" y="88.241005" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.684121" y="81.15877" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="144.593471" y="81.571363" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.760849" y="62.661631" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.407119" y="69.693332" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.228326" y="74.384589" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.196136" y="98.598832" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="97.523503" y="66.33793" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="206.761358" y="125.79795" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.095197" y="98.4751" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="111.539013" y="64.56139" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.164185" y="81.606658" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="153.702628" y="98.219326" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.258917" y="94.831201" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.037722" y="104.699339" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.170226" y="89.41371" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.059483" y="72.784708" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.702482" y="87.411776" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="88.989185" y="52.687565" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="87.075942" y="50.725829" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.970726" y="65.130989" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.883673" y="63.986565" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.96272" y="80.834248" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="118.150811" y="81.052541" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.807994" y="68.298331" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.10131" y="63.476082" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.210835" y="84.375522" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.352392" y="73.802402" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.34687" y="91.968214" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="103.696498" y="35.232469" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="114.963518" y="78.597462" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.385956" y="70.788778" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="107.184783" y="59.685314" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.853204" y="90.993283" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="165.690509" y="129.760231" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.434951" y="95.79107" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="105.306675" y="49.856484" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.074512" y="86.650945" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.928025" y="84.532026" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.962191" y="63.882353" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="100.203076" y="56.071804" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="157.794781" y="91.749217" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.275888" y="88.082351" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.2505" y="105.130473" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.045802" y="51.890282" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.08613" y="58.570508" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="106.192583" y="59.913878" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.382741" y="77.805222" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.026704" y="88.190008" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.660371" y="52.29818" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.102869" y="74.407627" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.28041" y="86.544145" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.533615" y="97.2812" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.039942" y="47.401588" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.798571" y="72.467508" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="159.605425" y="117.705185" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.117282" y="77.578839" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="116.863978" y="68.35539" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.916677" y="67.610349" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="70.69861" y="29.829656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.49309" y="101.365519" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.800132" y="65.258895" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.875062" y="77.986457" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="37.81946" y="22.041043" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.9688" y="82.919953" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="184.717724" y="139.5" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.23157" y="93.679042" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="177.22424" y="110.310029" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="153.395139" y="96.225358" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="98.573684" y="51.327124" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.758672" y="58.736199" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.570633" y="66.047748" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.098949" y="80.562145" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="180.18112" y="122.612181" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.484323" y="72.588527" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.19446" y="68.419977" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.194549" y="69.203448" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.39048" y="99.604671" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.836511" y="95.278895" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="168.276288" y="116.960095" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="116.729036" y="62.502891" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.406236" y="75.34703" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.079402" y="65.876611" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.053701" y="59.436446" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.071025" y="94.729298" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.838797" y="65.936659" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="115.557707" y="66.413173" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.492099" y="71.617763" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="110.297919" y="65.554642" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.249566" y="50.537598" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="114.751482" y="60.66267" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.829179" y="85.850677" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.804102" y="69.59409" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="104.009757" y="33.39075" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="155.889071" y="84.740389" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="92.930904" y="56.896367" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.109569" y="80.144903" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.085701" y="78.820328" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="163.607475" y="90.114192" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.197228" y="90.689906" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.888189" y="86.676935" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.803833" y="100.273606" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.385509" y="71.28935" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="168.428015" y="93.395327" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="114.227251" y="75.908799" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="83.610668" y="47.334452" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="77.11768" y="42.681032" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.21452" y="68.254932" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="194.397655" y="121.483361" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="162.216604" y="92.04012" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.076437" y="84.291729" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.395224" y="80.507211" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="189.387072" y="111.456825" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.094041" y="70.558834" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.844024" y="99.113743" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.045958" y="79.203896" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="111.793533" y="43.082933" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="115.747365" y="49.999154" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="144.860075" y="80.905868" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.956165" y="53.759361" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="106.715826" y="57.926678" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="86.062914" y="30.864672" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.261816" y="84.073393" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="144.33017" y="85.092948" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="102.086697" y="59.609608" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.664584" y="85.599525" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="89.832551" y="37.233837" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="100.292719" y="57.501901" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="197.885911" y="136.476002" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.417242" y="93.124352" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.590631" y="79.8113" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="95.826924" y="62.819942" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.21641" y="81.136541" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="165.116507" y="106.779282" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.198812" y="73.861437" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="166.610014" y="107.285008" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.8329" y="86.318162" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="85.447827" y="41.339427" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="159.662964" y="98.494541" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.15241" y="55.854203" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.675945" y="74.743863" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.303793" y="96.890186" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.650283" y="68.410737" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.823973" y="86.884353" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.11893" y="48.318827" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.12326" y="82.182124" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="86.71922" y="43.483263" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.301609" y="72.569612" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.466356" y="72.806161" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="94.890497" y="47.114905" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="69.84394" y="49.194621" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.667698" y="66.412408" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="167.492479" y="105.564466" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.887408" y="100.306264" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.067891" y="106.950633" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.148809" y="64.954008" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.429482" y="90.1105" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.664646" y="86.995488" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.867215" y="62.85089" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="164.549793" y="93.940841" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.053745" y="79.150901" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.650576" y="68.84641" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.230696" y="101.662611" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="110.701619" y="49.77235" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.691186" y="69.579363" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="169.18138" y="111.892028" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.551708" y="60.302929" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="165.733292" y="103.65314" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="58.010948" y="15.765491" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="163.198177" y="94.586921" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="110.120971" y="54.787315" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.041368" y="83.67882" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.275511" y="68.62897" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.086569" y="82.079448" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="107.750245" y="67.164617" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.120777" y="97.354337" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.347228" y="90.121634" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.348334" y="79.292481" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.444262" y="61.17923" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.839766" y="64.295246" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.445458" y="116.605219" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.649238" y="82.715272" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="160.715663" y="92.86394" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="102.159696" y="70.888666" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="65.476058" y="13.5" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.099375" y="69.149559" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="107.263962" y="42.032186" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.166695" y="57.837107" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.732869" y="75.377153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="169.679882" y="131.895592" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="116.939425" y="59.141719" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="167.714627" y="111.353278" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.763694" y="96.236795" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="116.906559" y="64.276207" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="101.604701" y="60.290799" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.973405" y="106.724808" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.629961" y="85.050771" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="167.981322" y="107.254549" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="180.513474" y="111.184544" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="161.836516" y="95.462359" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.914484" y="67.259161" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.479348" y="70.232714" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="96.272523" y="49.957704" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.135323" y="66.102736" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.628174" y="83.945404" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.519095" y="77.177288" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.061573" y="76.923153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.333124" y="90.314048" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.929194" y="62.515236" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.347144" y="59.281458" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.947892" y="101.318345" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.997123" y="64.226513" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.902053" y="102.041242" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.913735" y="77.644053" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="161.177522" y="91.387142" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="109.664466" y="27.810463" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.855771" y="81.917821" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.229796" y="89.348764" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="79.634661" y="35.092983" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.891549" y="65.048166" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="93.968327" y="43.871166" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.907416" y="75.364399" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.486247" y="76.088841" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.810386" y="72.693093" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.978057" y="83.175531" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.110827" y="79.505546" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="144.016312" y="100.975342" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="173.702803" y="124.807206" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="153.412038" y="90.983812" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="153.235486" y="83.077619" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.534762" y="83.761282" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.610104" y="87.596558" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.090768" y="84.604151" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="187.20176" y="116.228875" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="105.439972" y="77.64884" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="162.274607" y="113.955505" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.646856" y="68.287306" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.591017" y="71.528892" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.994477" y="74.031821" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.041914" y="98.097999" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="103.900527" y="48.35415" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.638862" y="86.280172" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.804202" y="67.597294" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.845581" y="77.180758" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.671126" y="64.412474" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="174.310451" y="112.626968" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.847771" y="95.91145" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.881409" y="79.49606" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.306849" y="84.052712" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.250617" y="83.414741" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.994616" y="75.428867" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.067052" y="78.310834" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.191582" y="70.326748" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.147501" y="73.301386" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.13053" y="71.147066" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="167.426643" y="99.081935" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.168215" y="78.237334" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.189183" y="89.874683" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="116.419576" y="74.284852" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.419249" y="72.372303" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.053958" y="75.555399" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="161.359279" y="121.223819" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.815822" y="80.050575" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.911547" y="78.240407" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.923255" y="75.147613" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.133718" y="102.542952" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="159.329025" y="87.033987" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="93.422504" y="45.301327" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.517571" y="91.822422" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.024305" y="76.642438" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.614931" y="77.949601" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="64.970981" y="30.519615" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.081606" y="73.579209" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.838706" y="82.110649" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.292935" y="79.188468" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.982502" y="104.574014" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.096378" y="61.68454" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.129246" y="62.090174" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.758126" y="64.382054" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="165.906803" y="114.576675" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="145.911888" y="93.266282" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="104.247932" y="45.160321" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="164.519383" y="104.21218" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="111.846885" y="71.754109" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.148961" y="68.087322" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.615576" y="81.411749" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="90.316396" y="50.130527" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="95.132399" y="50.705691" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.188074" y="63.967413" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.547703" y="57.232677" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.194564" y="84.365181" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.661788" y="77.832046" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.034306" y="113.094996" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="144.93483" y="91.140991" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="165.505665" y="105.741195" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="105.334975" y="68.392803" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.794785" y="75.12353" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.469321" y="90.649089" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.66032" y="104.070657" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.906548" y="63.468873" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.338784" y="82.86794" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.549296" y="85.608542" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="162.546588" y="97.206753" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.718311" y="68.260558" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.147706" y="56.226981" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="97.842273" y="60.232185" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="115.668063" y="51.873542" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="84.617334" y="18.103516" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.451103" y="93.246023" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.265351" y="73.027207" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="101.902407" y="43.075637" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="101.954757" y="67.577574" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.89097" y="79.029583" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="187.621362" y="119.915368" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.612109" y="83.74487" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.686826" y="76.370095" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.799684" y="92.48442" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.290279" y="49.338792" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.838858" y="100.184448" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="155.269882" y="97.096052" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.038635" y="67.031251" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.041575" y="87.363325" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="84.014338" y="21.562226" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.515553" y="69.816669" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.565861" y="78.500167" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.95154" y="89.430395" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="145.14065" y="91.456843" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="103.202022" y="56.366234" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.22455" y="64.606874" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="131.958635" y="78.651995" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.252548" y="72.41565" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.756206" y="107.662652" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="164.515326" y="99.172621" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="162.706676" y="96.370217" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.105019" y="79.02333" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.779544" y="89.016402" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="155.200818" y="104.754022" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.632423" y="96.801986" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="172.282279" y="111.927308" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.18855" y="82.793202" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="111.458103" y="41.859056" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.123526" y="93.851658" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.584503" y="60.980031" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.909372" y="74.145029" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.550977" y="94.163492" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.472081" y="68.159095" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="159.929361" y="102.06078" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="118.826549" y="57.863059" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.134436" y="85.641259" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.168939" y="94.75956" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="169.293359" y="112.293427" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="144.506265" y="90.257794" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="99.356788" y="65.223327" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.398334" y="83.79076" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.570078" y="75.850764" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.328916" y="55.738297" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.610495" y="72.706857" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="115.378193" y="78.429072" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.583122" y="73.384083" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.425629" y="88.150926" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="120.353432" y="84.380879" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.209797" y="89.189101" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.685341" y="62.18428" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="104.618398" y="71.018209" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.333136" y="70.038488" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.322245" y="72.531255" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.823646" y="74.393081" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="98.608225" y="53.162821" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="202.783655" y="121.830153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.99309" y="80.320939" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="104.391942" y="64.345249" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.876304" y="80.548704" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.58977" y="63.643561" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.906441" y="81.658512" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.266019" y="101.152384" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.281286" y="66.060699" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.366461" y="92.592949" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.516261" y="67.56122" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.92194" y="90.036556" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.144481" y="57.539528" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.135178" y="79.329016" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.908034" y="78.861112" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="137.491266" y="83.921422" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="113.807697" y="75.450786" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.051651" y="66.182709" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="166.019487" y="98.983666" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.111516" y="65.131705" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.162638" y="69.319809" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.660903" y="78.456473" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="91.734064" y="51.867579" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="109.351045" y="82.685242" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="116.6349" y="73.055611" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.068739" y="84.355827" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.63787" y="87.599534" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="155.409568" y="93.319693" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="102.704529" y="67.56309" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="101.300494" y="63.42464" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="120.499743" y="48.451007" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.69255" y="55.90116" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.128581" y="62.556877" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.883643" y="67.885119" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.241836" y="77.585043" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.797919" y="87.156956" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="107.0616" y="58.183763" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.015626" y="82.54097" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="110.302346" y="63.575948" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.302998" y="76.863967" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="155.911611" y="99.133675" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="114.123813" y="66.921095" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.865968" y="52.645248" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.78829" y="79.424332" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="110.709863" y="63.33256" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="89.644056" y="39.476263" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="124.256625" y="86.515271" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="153.738507" y="99.654722" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.612702" y="91.443661" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="159.821672" y="93.766817" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="119.388459" y="72.543665" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="159.919281" y="96.980838" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.278235" y="93.142453" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="179.94484" y="130.32799" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="89.820298" y="37.928601" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.650908" y="62.978298" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.414425" y="73.937807" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.594095" y="88.439678" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="170.995955" y="109.732608" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.47018" y="97.713903" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="91.416199" y="51.397677" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.637216" y="69.78173" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="135.319177" y="71.655387" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.374822" y="74.834836" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.427259" y="52.43887" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.449895" y="78.713174" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.719218" y="70.531854" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="108.072781" y="61.076881" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.88235" y="74.547729" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="88.217137" y="52.674687" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="114.762105" y="59.810942" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="117.558407" y="61.533266" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="165.053974" y="105.538605" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="134.286644" y="83.827882" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.266477" y="73.022932" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.574237" y="72.99407" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="102.381512" y="64.55689" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.693437" y="83.376626" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="154.460302" y="91.934398" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.00611" y="85.236683" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.702211" y="80.325857" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="94.346003" y="53.38592" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="125.269631" y="86.51086" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.152682" y="68.541043" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.952226" y="100.24009" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="171.111968" y="118.103977" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.53369" y="90.561111" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.717881" y="69.697515" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.815171" y="62.456778" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.308034" y="94.957518" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="157.427407" y="92.102869" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="116.582537" y="66.853116" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.54365" y="90.435422" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="123.207181" y="71.333254" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="151.161298" y="103.614709" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="158.907013" y="98.96007" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.818717" y="81.294635" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="141.449835" y="81.23083" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.090995" y="102.947303" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="150.379022" y="79.235428" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.079829" y="82.178295" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.273181" y="91.059508" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.334522" y="86.045153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="100.770433" y="65.405451" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="108.552052" y="69.00258" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="161.765937" y="82.574475" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="161.607644" y="115.920234" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.087753" y="89.551559" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.319823" y="77.133567" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="132.731657" y="68.029976" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.131994" y="84.591819" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="160.73471" y="95.674044" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="128.18093" y="83.951852" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="118.339812" y="48.107719" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="126.868383" y="91.144692" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="111.915862" y="77.966158" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="159.038497" y="101.867718" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="121.953976" y="69.104578" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="147.381854" y="95.437832" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="163.145448" y="91.398395" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="140.161531" y="82.985289" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="164.390359" y="113.470475" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="139.705958" y="87.582783" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="122.643029" y="80.594545" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.61515" y="75.882131" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="129.371491" y="83.48542" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="136.091775" y="75.831255" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="164.084409" y="84.442152" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="107.313126" y="66.885205" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="138.356645" y="87.367559" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="112.569709" y="75.389946" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="99.88968" y="62.102534" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="130.395297" y="89.780347" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.960033" y="73.903159" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="156.651549" y="115.759169" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="149.600207" y="99.445677" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="173.972016" y="100.660773" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="146.195861" y="95.951702" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="143.305644" y="91.992748" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="142.934713" y="93.511792" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="148.517035" y="93.644631" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="114.15317" y="39.124589" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="152.259368" y="89.347345" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="127.762384" y="69.862951" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="153.40995" y="101.115803" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m18bb6ce550" x="133.643811" y="68.037402" style="fill: #1f77b4; stroke: #1f77b4"/>
    </g>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <defs>
       <path id="m2cbfe66e94" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m2cbfe66e94" x="37.108605" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- −4 -->
      <g transform="translate(29.737511 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-34" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <g>
       <use xlink:href="#m2cbfe66e94" x="84.839648" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- −2 -->
      <g transform="translate(77.468554 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-32" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_3">
      <g>
       <use xlink:href="#m2cbfe66e94" x="132.57069" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 0 -->
      <g transform="translate(129.38944 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_4">
      <g>
       <use xlink:href="#m2cbfe66e94" x="180.301733" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 2 -->
      <g transform="translate(177.120483 160.398438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_5">
      <defs>
       <path id="m67ee9f9fc6" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m67ee9f9fc6" x="28.942188" y="125.71812" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- −5 -->
      <g transform="translate(7.2 129.517339) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-35" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_6">
      <g>
       <use xlink:href="#m67ee9f9fc6" x="28.942188" y="99.751174" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_6">
      <!-- 0 -->
      <g transform="translate(15.579688 103.550393) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_7">
      <g>
       <use xlink:href="#m67ee9f9fc6" x="28.942188" y="73.784228" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 5 -->
      <g transform="translate(15.579688 77.583446) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-35"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_8">
      <g>
       <use xlink:href="#m67ee9f9fc6" x="28.942188" y="47.817281" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 10 -->
      <g transform="translate(9.217188 51.6165) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_9">
      <g>
       <use xlink:href="#m67ee9f9fc6" x="28.942188" y="21.850335" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <!-- 15 -->
      <g transform="translate(9.217188 25.649554) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-35" x="63.623047"/>
      </g>
     </g>
    </g>
   </g>
   <g id="patch_3">
    <path d="M 28.942188 145.8 
L 28.942188 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 224.242188 145.8 
L 224.242188 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 28.942188 145.8 
L 224.242188 145.8 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 28.942188 7.2 
L 224.242188 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="p149bb96678">
   <rect x="28.942188" y="7.2" width="195.3" height="138.6"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">d2l</span><span class="o">.</span><span class="n">set_figsize</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">features</span><span class="p">[:,</span> <span class="p">(</span><span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> 
                <span class="n">labels</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="231.442187pt" height="169.678125pt" viewBox="0 0 231.442187 169.678125" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-05-18T15:08:56.251352</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 169.678125 
L 231.442187 169.678125 
L 231.442187 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 28.942188 145.8 
L 224.242188 145.8 
L 224.242188 7.2 
L 28.942188 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="PathCollection_1">
    <defs>
     <path id="m823589f946" d="M 0 0.5 
C 0.132602 0.5 0.25979 0.447317 0.353553 0.353553 
C 0.447317 0.25979 0.5 0.132602 0.5 0 
C 0.5 -0.132602 0.447317 -0.25979 0.353553 -0.353553 
C 0.25979 -0.447317 0.132602 -0.5 0 -0.5 
C -0.132602 -0.5 -0.25979 -0.447317 -0.353553 -0.353553 
C -0.447317 -0.25979 -0.5 -0.132602 -0.5 0 
C -0.5 0.132602 -0.447317 0.25979 -0.353553 0.353553 
C -0.25979 0.447317 -0.132602 0.5 0 0.5 
z
" style="stroke: #1f77b4"/>
    </defs>
    <g clip-path="url(#p4610e2cf3f)">
     <use xlink:href="#m823589f946" x="122.049598" y="47.161377" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.963107" y="83.62544" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="119.927232" y="87.238868" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.499187" y="40.397538" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.738829" y="74.594754" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="168.177498" y="60.945456" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="149.120588" y="78.7769" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.100157" y="79.445989" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="167.203315" y="38.908429" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="66.24924" y="116.402206" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="96.90644" y="88.486938" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.287288" y="81.085971" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.367315" y="87.997522" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.325299" y="88.393808" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.647682" y="76.554431" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.127695" y="73.519191" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="174.422087" y="74.321666" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="112.875464" y="93.603985" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="136.86115" y="88.551763" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.341229" y="35.366294" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="153.2019" y="58.043827" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.565749" y="103.28369" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.72149" y="57.861658" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="73.517474" y="81.847122" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.731428" y="77.415171" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.879391" y="90.031881" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.688161" y="35.628451" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="93.386178" y="92.726373" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.192063" y="65.921645" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="112.646121" y="67.827082" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.295666" y="73.868138" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="127.981588" y="81.497491" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.834866" y="57.255578" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="109.896673" y="56.665809" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="144.227189" y="72.549742" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="109.329422" y="85.38564" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.058958" y="58.074153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="178.342288" y="51.205587" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="147.373088" y="46.708364" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="77.803974" y="111.673949" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.240795" y="75.989104" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.312012" y="67.739194" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="140.926694" y="59.798297" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="144.913672" y="74.989388" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.635024" y="59.375105" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="149.512233" y="59.267597" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.543894" y="93.854999" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.832725" y="71.690158" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.390046" y="87.617628" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="147.727296" y="63.623364" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.260721" y="73.829216" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.220665" y="89.36582" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.38085" y="94.878713" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="126.725452" y="98.631002" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="119.94471" y="69.606532" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="73.676253" y="77.322051" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.217505" y="72.458828" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.958828" y="44.551745" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="121.123908" y="71.231531" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.629155" y="87.507944" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.86245" y="89.154946" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.219201" y="115.023299" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="189.643748" y="57.941606" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.691932" y="64.990028" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="79.878438" y="124.951583" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.820831" y="47.266292" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.795653" y="82.798065" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="185.46487" y="84.905216" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="143.289184" y="63.342156" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.790243" y="71.311502" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="97.555683" y="71.440978" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="96.680579" y="109.509315" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.142542" y="76.930463" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.204389" y="81.979596" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="142.270455" y="45.388764" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="37.81946" y="96.679841" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="187.724045" y="39.170635" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.818021" y="104.843924" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.548633" y="136.669454" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.098167" y="64.485384" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="69.900495" y="92.242205" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="89.078741" y="58.495525" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="159.047477" y="43.485036" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="145.94966" y="66.785002" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="170.966781" y="75.943248" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.77618" y="105.039855" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.366653" y="90.586554" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.319769" y="70.239975" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.740655" y="86.234712" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="87.564353" y="72.272405" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.289525" y="42.120415" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="145.977459" y="52.733002" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.326608" y="91.534395" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.793803" y="78.277075" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.637716" y="80.007046" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="72.535262" y="123.495815" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="142.666409" y="87.647679" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.243464" y="68.147087" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="79.233118" y="77.973753" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.615171" y="102.953634" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.83466" y="48.117778" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.245982" y="79.685957" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="85.339264" y="105.065753" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.043811" y="94.163776" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.807544" y="39.249632" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.697482" y="94.996263" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.091272" y="110.657126" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.549356" y="56.029453" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="86.928383" y="95.454916" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.897108" y="95.256836" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="119.102496" y="79.859375" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="51.276685" y="86.897922" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.651787" y="94.19315" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="147.784394" y="100.574648" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="113.524805" y="95.633883" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="61.405454" y="77.128793" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="165.479099" y="42.823713" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.107527" y="71.69238" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="174.024353" y="43.229075" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="97.383267" y="84.788153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.958005" y="72.66032" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="87.9598" y="58.450722" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="104.732142" y="131.832798" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="204.588149" y="54.265354" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.193145" y="79.788226" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="152.838601" y="39.581108" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="121.481894" y="74.271061" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="113.181891" y="96.641912" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="126.217305" y="95.322537" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="144.981023" y="37.140992" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="157.457846" y="88.381482" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.444136" y="82.87251" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.320171" y="114.644034" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.182927" y="81.887664" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.052671" y="110.831563" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.614091" y="79.688158" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.600058" y="72.500684" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.438867" y="64.647256" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.804829" y="83.772278" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="63.421576" y="126.892836" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.066561" y="52.077508" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="99.440322" y="71.031701" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.984559" y="77.309642" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.146232" y="95.714536" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.036364" y="78.662995" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="104.580275" y="52.853989" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="159.086729" y="85.024525" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="151.583032" y="65.790707" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="99.297572" y="73.972357" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="161.872947" y="73.366803" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.728672" y="103.786181" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.589504" y="70.019699" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.80647" y="46.796222" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.874851" y="71.131398" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="170.34891" y="67.727624" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="159.207703" y="87.823199" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="102.000766" y="74.458643" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="60.052055" y="119.338468" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="126.077031" y="65.114343" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="109.30747" y="90.545777" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="134.660782" y="32.072086" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.63782" y="89.646188" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="74.008351" y="131.976622" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="159.802539" y="37.519916" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="147.031993" y="68.471924" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="160.842431" y="58.213502" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.530854" y="67.209455" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.319874" y="83.648026" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.749716" y="81.247013" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="100.943817" y="78.386436" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.952825" y="110.099002" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.80105" y="79.870857" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.17755" y="86.82456" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="164.775787" y="55.800128" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="140.787785" y="95.543365" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.680858" y="80.716385" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.31618" y="49.869361" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="83.986793" y="78.313592" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="140.027008" y="108.965791" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="158.632561" y="89.407648" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="86.120077" y="102.732158" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="55.340667" y="130.289923" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.168331" y="77.297087" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="134.052556" y="77.985982" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="162.276859" y="86.539024" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.447145" y="88.497173" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.160475" y="82.445164" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="77.770008" y="100.566278" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="155.059892" y="78.2606" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.837459" y="104.95213" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="104.805963" y="90.006435" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.199906" y="66.676858" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="142.479051" y="44.376892" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="162.643194" y="50.800963" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.651571" y="73.130755" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.739921" y="90.054365" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="88.782681" y="88.832337" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="102.722082" y="109.265351" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="87.765036" y="105.520126" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="147.92917" y="45.042519" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="99.462902" y="71.352702" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.305053" y="87.712444" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="89.404515" y="93.431903" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="84.110943" y="115.084394" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="104.583832" y="65.664837" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.929312" y="41.543072" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.699533" y="65.483171" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="152.61974" y="73.541159" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="79.611058" y="107.280884" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.971819" y="81.808232" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="86.09323" y="92.773059" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="80.631611" y="110.615348" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.394381" y="87.620506" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.171816" y="95.841866" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.954207" y="67.122825" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.024508" y="77.513579" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="163.642053" y="65.123268" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.571848" y="108.43805" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="187.924902" y="59.570065" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.405573" y="71.318317" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="93.291421" y="103.523987" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="136.894751" y="43.963427" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="88.396273" y="71.800816" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.090681" y="50.486663" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="119.573461" y="80.491925" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="72.203491" y="101.020893" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.981394" y="103.960201" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.084978" y="64.961187" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.747365" y="108.101154" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.659146" y="71.272436" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.896406" y="54.533553" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.622954" y="77.715356" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.506828" y="85.805685" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="89.689788" y="84.457284" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="88.744492" y="110.462091" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="162.914233" y="40.894705" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="113.029819" y="69.718393" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.924367" y="99.022385" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.206793" y="47.724193" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.371572" y="94.62609" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.283811" y="69.007238" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.098857" y="115.545579" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="187.707201" y="50.701739" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.111841" y="93.231596" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.278095" y="48.494835" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="149.721283" y="60.52896" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="109.206497" y="115.579612" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.264923" y="57.422106" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.301552" y="48.033332" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.042311" y="92.460497" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="81.554385" y="94.537197" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.620078" y="105.885217" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.920391" y="89.998881" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="109.870621" y="57.369795" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.159061" y="109.391435" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.698184" y="68.146646" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.944293" y="77.863288" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.880527" y="82.309716" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="136.515502" y="64.998791" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="162.94588" y="62.189196" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="82.297836" y="90.072432" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.01675" y="75.777629" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="149.402728" y="88.600963" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.38606" y="62.371521" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.955738" y="81.635209" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.671034" y="54.280767" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.351852" y="73.743823" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.858871" y="70.005569" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="140.11235" y="67.434763" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.694098" y="76.827061" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.895866" y="83.246127" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="172.46799" y="62.814925" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.1394" y="82.432944" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.65086" y="66.571063" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="154.977175" y="61.460029" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="93.67534" y="84.160395" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.576162" y="68.818434" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="178.764923" y="52.552853" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.268663" y="95.612473" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="146.919849" y="60.307027" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="98.769421" y="65.64585" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="140.102148" y="90.950681" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="102.715173" y="67.75297" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="154.335523" y="53.050234" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="153.15796" y="106.433803" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.824974" y="49.907413" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="172.53108" y="81.185502" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="109.397239" y="64.86224" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.153422" y="63.739985" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="177.608589" y="101.59375" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.390429" y="110.318736" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="119.027687" y="122.525807" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.667361" y="38.326326" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="88.64613" y="91.321178" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="96.587818" y="77.393835" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.031757" y="49.56985" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.687921" y="85.533263" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="102.260207" y="72.671207" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="92.050953" y="99.386596" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.476967" y="67.775845" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.306363" y="74.056585" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="92.989877" y="75.661508" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="163.810489" y="61.146314" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="97.631908" y="105.44496" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="151.028653" y="37.429393" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.080218" y="78.800497" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.75805" y="76.243697" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="162.333868" y="65.434945" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.884273" y="95.744662" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.75585" y="60.535636" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.694347" y="87.970989" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="149.355425" y="86.192893" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.322212" y="57.788411" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="169.078373" y="75.358756" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="203.677167" y="35.551553" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="112.900537" y="78.30334" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="109.003074" y="64.711556" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.375884" y="101.88973" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="93.776485" y="97.819789" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="143.548848" y="88.734081" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="174.623095" y="45.330227" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="166.504097" y="44.209348" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="112.490532" y="76.632356" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="42.223604" y="108.769978" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="79.483809" y="100.102314" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.557705" y="88.620482" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.493029" y="96.788656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.602751" y="60.901465" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.314864" y="93.607883" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.405215" y="74.933473" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.2544" y="82.22746" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.82136" y="95.62631" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.820357" y="60.61157" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.426303" y="81.496522" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="143.750114" y="41.516842" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="100.995442" y="88.36295" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.801026" y="70.030588" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="94.461677" y="78.772412" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.195137" y="69.940603" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.935805" y="72.17007" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="76.383706" y="108.453568" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="146.861479" y="66.977319" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.519279" y="121.685772" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.620947" y="96.364357" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="127.402655" y="83.36262" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.037137" y="77.685671" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="126.506589" y="77.021255" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="177.185268" y="81.933449" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="159.590134" y="56.89179" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="112.6819" y="109.930138" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.241482" y="46.477058" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.572872" y="107.725896" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.637728" y="95.836344" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="212.651217" y="25.80849" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.587829" y="83.93642" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="180.754959" y="41.798879" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="152.633346" y="100.699816" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="126.661397" y="132.059178" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.076599" y="61.119264" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.355169" y="102.003628" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.63579" y="90.938355" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="62.976754" y="135.076353" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="144.202629" y="89.697253" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.238987" y="84.102082" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="168.109165" y="70.643879" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="94.793745" y="77.271077" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.972281" y="118.26173" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="93.883808" y="100.42625" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.039785" y="85.449113" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.66428" y="91.51232" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.241492" y="98.445219" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="121.03768" y="69.827219" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="75.822165" y="96.551888" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="164.904047" y="69.991721" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.273474" y="77.144345" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.75058" y="53.943991" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="151.731207" y="42.491325" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="162.123343" y="71.860096" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="157.473095" y="71.452624" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="76.20589" y="87.64505" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.625086" y="59.370096" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.623662" y="71.761607" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.872865" y="59.617879" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.328513" y="76.742222" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="112.067496" y="104.341687" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.101" y="68.026442" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="84.540093" y="87.193492" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.715822" y="69.71948" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="164.45679" y="45.774082" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="172.390465" y="64.811021" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.321209" y="54.048753" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.308722" y="47.273691" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.437076" y="79.306596" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.410571" y="90.852565" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="155.786144" y="66.468719" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.533711" y="63.262394" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.389089" y="65.665216" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.792984" y="89.563288" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.134847" y="66.439287" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="144.283384" y="83.170556" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="154.321473" y="65.386806" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.674786" y="94.60237" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="146.015272" y="77.253336" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="151.597825" y="40.351655" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.524061" y="79.915883" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.986621" y="52.793148" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.451529" y="74.635042" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.319855" y="91.09296" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.287857" y="73.305529" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="81.69111" y="88.123721" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="153.736298" y="93.357726" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.638866" y="96.797956" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="63.749778" y="101.376634" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.916784" y="59.779791" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="89.478063" y="83.17462" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="153.579643" y="58.26251" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="147.260889" y="93.280006" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="157.856746" y="89.448882" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="146.132326" y="92.86561" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.64914" y="76.563584" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="78.98032" y="73.075454" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="146.448037" y="59.21978" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.196027" y="66.063946" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.623498" y="93.067459" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="167.48427" y="74.32969" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.613633" y="120.319759" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.849133" y="89.083226" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="164.136872" y="21.716144" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="100.194044" y="67.650078" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.50902" y="65.223208" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="89.345405" y="97.346334" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="99.290961" y="110.278113" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.149373" y="55.04702" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="151.172144" y="36.320377" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="155.482255" y="66.727421" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="162.525141" y="54.699249" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.40025" y="68.524397" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="158.578988" y="18.152251" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="112.351455" y="96.415787" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="134.619062" y="53.098791" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.703068" y="55.945706" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="153.422522" y="67.417656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="179.246541" y="50.437323" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="140.299476" y="53.971836" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.247584" y="60.758656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.829639" y="108.205526" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="152.127188" y="67.258656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.219419" y="82.418834" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.733263" y="77.876968" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.098952" y="82.143424" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="172.306709" y="57.152768" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.29035" y="94.68598" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="56.441672" y="112.619282" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="100.18383" y="84.338058" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="126.610361" y="105.269701" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.990516" y="90.123526" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.297022" y="103.768415" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.657461" y="90.380013" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.048586" y="55.457805" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.176953" y="80.84138" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="161.15855" y="70.947599" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="188.818438" y="23.162991" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.81954" y="77.873558" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="52.788866" y="105.443857" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.073555" y="91.711486" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.648184" y="44.255994" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.24535" y="95.849579" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="136.719859" y="83.283928" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.82831" y="47.93496" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="112.600949" y="41.384245" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="170.925208" y="78.467352" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.491491" y="50.069211" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.285578" y="94.835505" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="87.612509" y="108.472892" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.57265" y="104.72846" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="99.8394" y="106.281367" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.025283" y="51.793366" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="113.112622" y="70.717656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="90.392245" y="98.065695" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.588362" y="93.409271" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.28" y="91.783085" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.005108" y="60.077816" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.487075" y="51.08775" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.931134" y="70.340151" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="134.782326" y="64.663011" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="140.487126" y="55.93901" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.874491" y="54.780247" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="102.387538" y="88.241005" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="147.230036" y="81.15877" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.805315" y="81.571363" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="175.518051" y="62.661631" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.912117" y="69.693332" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.50853" y="74.384589" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.022979" y="98.598832" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="87.308852" y="66.33793" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="144.66247" y="125.79795" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="89.230846" y="98.4751" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="119.927235" y="64.56139" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.136891" y="81.606658" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="113.011061" y="98.219326" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="109.433355" y="94.831201" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="90.01999" y="104.699339" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="102.124803" y="89.41371" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="136.731162" y="72.784708" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.449115" y="87.411776" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.901989" y="52.687565" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.230845" y="50.725829" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="149.264013" y="65.130989" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="174.363999" y="63.986565" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.755118" y="80.834248" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="88.336992" y="81.052541" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="172.442112" y="68.298331" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.985402" y="63.476082" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.662602" y="84.375522" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="158.727325" y="73.802402" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="91.581023" y="91.968214" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="183.538607" y="35.232469" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="88.842907" y="78.597462" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.752634" y="70.788778" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.254133" y="59.685314" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="94.991266" y="90.993283" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="51.962785" y="129.760231" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.49515" y="95.79107" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="147.077792" y="49.856484" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.310112" y="86.650945" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.556629" y="84.532026" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="152.689037" y="63.882353" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.347151" y="56.071804" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.809807" y="91.749217" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="113.976101" y="88.082351" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.36503" y="105.130473" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="175.369996" y="51.890282" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="151.0653" y="58.570508" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="121.694646" y="59.913878" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.833458" y="77.805222" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.038152" y="88.190008" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="157.299748" y="52.29818" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="164.303556" y="74.407627" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="109.91774" y="86.544145" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="83.32546" y="97.2812" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="209.389793" y="47.401588" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="181.015184" y="72.467508" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="72.360497" y="117.705185" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.733952" y="77.578839" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.36438" y="68.35539" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.414222" y="67.610349" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.119107" y="29.829656" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="80.299656" y="101.365519" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.623621" y="65.258895" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.323999" y="77.986457" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="87.074237" y="22.041043" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="161.23561" y="82.919953" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="63.623552" y="139.5" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="98.357694" y="93.679042" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="127.611059" y="110.310029" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.936631" y="96.225358" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.522297" y="51.327124" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.057859" y="58.736199" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="145.800353" y="66.047748" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.564327" y="80.562145" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="100.434737" y="122.612181" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.082975" y="72.588527" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="134.615517" y="68.419977" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.593645" y="69.203448" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.359412" y="99.604671" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="93.507215" y="95.278895" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="91.779967" y="116.960095" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.826354" y="62.502891" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="142.243687" y="75.34703" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.302767" y="65.876611" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="175.021664" y="59.436446" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.267938" y="94.729298" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="171.014277" y="65.936659" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.896302" y="66.413173" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.794339" y="71.617763" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.880567" y="65.554642" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="169.210858" y="50.537598" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="136.656678" y="60.66267" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.911634" y="85.850677" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.673002" y="69.59409" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="189.161769" y="33.39075" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="153.753796" y="84.740389" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.063714" y="56.896367" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.889163" y="80.144903" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.337622" y="78.820328" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="155.048405" y="90.114192" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.60175" y="90.689906" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.546441" y="86.676935" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.150959" y="100.273606" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.452988" y="71.28935" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="155.797849" y="93.395327" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="94.605712" y="75.908799" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.511792" y="47.334452" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.202954" y="42.681032" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.34902" y="68.254932" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.52931" y="121.483361" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="147.118569" y="92.04012" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.717182" y="84.291729" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="136.564481" y="80.507211" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.997267" y="111.456825" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.925205" y="70.558834" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.319636" y="99.113743" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="143.278791" y="79.203896" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="178.434161" y="43.082933" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="167.558883" y="49.999154" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="142.350653" y="80.905868" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="154.014254" y="53.759361" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="127.995502" y="57.926678" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="160.34066" y="30.864672" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="104.452077" y="84.073393" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.964594" y="85.092948" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.420073" y="59.609608" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="97.2422" y="85.599525" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.279531" y="37.233837" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.299046" y="57.501901" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="98.090431" y="136.476002" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.285742" y="93.124352" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.883758" y="79.8113" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="93.341734" y="62.819942" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.614272" y="81.136541" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="112.947694" y="106.779282" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.874459" y="73.861437" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.434917" y="107.285008" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.587661" y="86.318162" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.568218" y="41.339427" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.334003" y="98.494541" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="162.792341" y="55.854203" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.765284" y="74.743863" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="65.950443" y="96.890186" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.953128" y="68.410737" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.076785" y="86.884353" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="165.077753" y="48.318827" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.557638" y="82.182124" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="127.465336" y="43.483263" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="153.999096" y="72.569612" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="175.658194" y="72.806161" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.614113" y="47.114905" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="78.097028" y="49.194621" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.168313" y="66.412408" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.900855" y="105.564466" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.904687" y="100.306264" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="90.283924" y="106.950633" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="144.055145" y="64.954008" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="102.513609" y="90.1105" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.437905" y="86.995488" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="151.146056" y="62.85089" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="146.417844" y="93.940841" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="161.497704" y="79.150901" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.479509" y="68.84641" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="104.86093" y="101.662611" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="158.037075" y="49.77235" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="142.592107" y="69.579363" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.298391" y="111.892028" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.540151" y="60.302929" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.701447" y="103.65314" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="144.675451" y="15.765491" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="142.119625" y="94.586921" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="143.41555" y="54.787315" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.166349" y="83.67882" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.124819" y="68.62897" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.697529" y="82.079448" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.465559" y="67.164617" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.395364" y="97.354337" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.4787" y="90.121634" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.71934" y="79.292481" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="162.647301" y="61.17923" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.39114" y="64.295246" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="68.965886" y="116.605219" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.765768" y="82.715272" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.540192" y="92.86394" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="83.89068" y="70.888666" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="165.89304" y="13.5" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="176.577749" y="69.149559" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="172.099286" y="42.032186" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="171.240875" y="57.837107" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.595161" y="75.377153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="54.132348" y="131.895592" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="145.467119" y="59.141719" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.744611" y="111.353278" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.646477" y="96.236795" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.454028" y="64.276207" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.72858" y="60.290799" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="86.81705" y="106.724808" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="154.66873" y="85.050771" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.426944" y="107.254549" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.781012" y="111.184544" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.073136" y="95.462359" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="175.5756" y="67.259161" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="164.399948" y="70.232714" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.661228" y="49.957704" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="143.02515" y="66.102736" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="121.587138" y="83.945404" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.828517" y="77.177288" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="97.246521" y="76.923153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="85.757621" y="90.314048" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.148795" y="62.515236" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="157.402578" y="59.281458" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="71.00132" y="101.318345" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="163.57908" y="64.226513" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="73.297553" y="102.041242" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="149.14116" y="77.644053" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="146.532508" y="91.387142" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="215.364915" y="27.810463" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="113.557131" y="81.917821" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.399975" y="89.348764" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.696899" y="35.092983" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="143.216523" y="65.048166" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="140.750923" y="43.871166" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="153.567312" y="75.364399" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="126.841989" y="76.088841" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="174.497954" y="72.693093" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="82.079833" y="83.175531" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.359196" y="79.505546" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="86.410509" y="100.975342" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="81.404638" y="124.807206" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.355983" y="90.983812" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="153.025712" y="83.077619" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.753408" y="83.761282" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="89.473648" y="87.596558" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="76.848333" y="84.604151" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.54825" y="116.228875" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="72.241611" y="77.64884" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="87.800053" y="113.955505" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.94458" y="68.287306" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="151.352201" y="71.528892" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.151741" y="74.031821" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.390124" y="98.097999" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.295013" y="48.35415" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.282461" y="86.280172" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="158.137694" y="67.597294" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.418614" y="77.180758" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="180.585042" y="64.412474" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.505276" y="112.626968" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.83676" y="95.91145" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="81.953483" y="79.49606" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.450492" y="84.052712" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.20357" y="83.414741" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.473731" y="75.428867" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.974924" y="78.310834" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.555073" y="70.326748" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="155.47176" y="73.301386" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.135547" y="71.147066" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.265214" y="99.081935" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.139364" y="78.237334" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.121391" y="89.874683" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.026376" y="74.284852" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="126.496048" y="72.372303" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="121.263738" y="75.555399" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="66.330597" y="121.223819" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="98.496239" y="80.050575" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="163.746725" y="78.240407" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.019036" y="75.147613" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="94.167031" y="102.542952" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="154.733378" y="87.033987" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.758837" y="45.301327" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="110.225777" y="91.822422" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="134.013595" y="76.642438" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.577436" y="77.949601" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.717064" y="30.519615" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.419942" y="73.579209" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="100.874708" y="82.110649" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.592761" y="79.188468" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="70.614825" y="104.574014" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.928618" y="61.68454" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="173.787735" y="62.090174" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="136.897787" y="64.382054" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="93.262547" y="114.576675" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.003667" y="93.266282" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="157.857955" y="45.160321" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.470098" y="104.21218" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="100.86453" y="71.754109" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.791658" y="68.087322" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="102.37824" y="81.411749" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.522723" y="50.130527" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.619915" y="50.705691" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="164.740067" y="63.967413" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.503223" y="57.232677" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.90262" y="84.365181" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="140.082842" y="77.832046" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="73.714402" y="113.094996" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.922321" y="91.140991" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.429953" y="105.741195" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="97.251272" y="68.392803" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.652541" y="75.12353" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.281016" y="90.649089" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.225874" y="104.070657" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.851862" y="63.468873" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.874801" y="82.86794" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.361829" y="85.608542" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="133.679553" y="97.206753" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="142.433652" y="68.260558" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="143.707459" y="56.226981" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="104.466984" y="60.232185" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="162.211002" y="51.873542" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="191.749207" y="18.103516" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.151989" y="93.246023" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.586849" y="73.027207" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="158.664094" y="43.075637" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="92.632218" y="67.577574" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.688456" y="79.029583" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.443717" y="119.915368" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="142.064883" y="83.74487" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="166.324197" y="76.370095" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.687512" y="92.48442" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="184.488892" y="49.338792" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="74.158453" y="100.184448" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="119.142167" y="97.096052" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.452225" y="67.031251" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="127.464654" y="87.363325" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="180.956995" y="21.562226" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="169.849401" y="69.816669" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="146.234793" y="78.500167" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="147.43934" y="89.430395" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.511813" y="91.456843" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.525078" y="56.366234" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="145.370516" y="64.606874" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.840956" y="78.651995" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="99.986175" y="72.41565" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="67.812426" y="107.662652" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.24277" y="99.172621" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="136.122348" y="96.370217" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="121.984574" y="79.02333" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="78.10275" y="89.016402" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="98.469622" y="104.754022" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="113.055326" y="96.801986" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="113.311371" y="111.927308" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.977943" y="82.793202" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="181.183955" y="41.859056" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.899333" y="93.851658" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="157.641859" y="60.980031" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.884806" y="74.145029" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="82.031302" y="94.163492" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.943946" y="68.159095" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.227504" y="102.06078" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="152.542706" y="57.863059" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.00117" y="85.641259" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="119.462926" y="94.75956" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.415666" y="112.293427" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.501266" y="90.257794" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="93.875095" y="65.223327" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.522966" y="83.79076" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.38404" y="75.850764" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="191.302369" y="55.738297" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.952036" y="72.706857" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="90.052766" y="78.429072" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="142.100739" y="73.384083" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="119.68414" y="88.150926" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="83.949254" y="84.380879" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="126.488359" y="89.189101" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.403712" y="62.18428" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="88.634546" y="71.018209" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="158.618662" y="70.038488" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="159.950225" y="72.531255" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="117.796374" y="74.393081" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="124.97434" y="53.162821" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="147.619682" y="121.830153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="102.26606" y="80.320939" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.049219" y="64.345249" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="107.42358" y="80.548704" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="144.697011" y="63.643561" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.620693" y="81.658512" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.167502" y="101.152384" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="153.36571" y="66.060699" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="87.537929" y="92.592949" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.695567" y="67.56122" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.542432" y="90.036556" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="168.065405" y="57.539528" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.202409" y="79.329016" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="98.17291" y="78.861112" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="119.472423" y="83.921422" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.067353" y="75.450786" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="158.600733" y="66.182709" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="135.687881" y="98.983666" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="145.388839" y="65.131705" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.364471" y="69.319809" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="144.523987" y="78.456473" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.684456" y="51.867579" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="66.500922" y="82.685242" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.931686" y="73.055611" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.580351" y="84.355827" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.128055" y="87.599534" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="130.042181" y="93.319693" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="94.098316" y="67.56309" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="102.452956" y="63.42464" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="181.400577" y="48.451007" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="159.510389" y="55.90116" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="136.469543" y="62.556877" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="141.694968" y="67.885119" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="106.093586" y="77.585043" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="85.199189" y="87.156956" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.044037" y="58.183763" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="112.598942" y="82.54097" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.157904" y="63.575948" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.28948" y="76.863967" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.132618" y="99.133675" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.697074" y="66.921095" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="182.751259" y="52.645248" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="136.206545" y="79.424332" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="121.563205" y="63.33256" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="143.903969" y="39.476263" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="85.87899" y="86.515271" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="109.267502" y="99.654722" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.307719" y="91.443661" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.555387" y="93.766817" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.017868" y="72.543665" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.969671" y="96.980838" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="118.293017" y="93.142453" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="78.994584" y="130.32799" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.427291" y="37.928601" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="166.354605" y="62.978298" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.483096" y="73.937807" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="89.54527" y="88.439678" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.541587" y="109.732608" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.425463" y="97.713903" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.188517" y="51.397677" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.721828" y="69.78173" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.177918" y="71.655387" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="129.965602" y="74.834836" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="188.57917" y="52.43887" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.583692" y="78.713174" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.018702" y="70.531854" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="122.213885" y="61.076881" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="157.605197" y="74.547729" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.640975" y="52.674687" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="139.011495" y="59.810942" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="140.194426" y="61.533266" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="116.221769" y="105.538605" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="113.302124" y="83.827882" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.453243" y="73.022932" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="157.00141" y="72.99407" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.698996" y="64.55689" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.138168" y="83.376626" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.811148" y="91.934398" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="120.818379" y="85.236683" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="111.508163" y="80.325857" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.762443" y="53.38592" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="87.850859" y="86.51086" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="132.383111" y="68.541043" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="68.207159" y="100.24009" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="94.417239" y="118.103977" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="99.672379" y="90.561111" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="156.416054" y="69.697515" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="148.346262" y="62.456778" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="131.383049" y="94.957518" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.253293" y="92.102869" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="123.880967" y="66.853116" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="84.0285" y="90.435422" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="125.009441" y="71.333254" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="93.573869" y="103.614709" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="121.573603" y="98.96007" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="145.108641" y="81.294635" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="134.700306" y="81.23083" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="85.120846" y="102.947303" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="157.863831" y="79.235428" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="91.39912" y="82.178295" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.719783" y="91.059508" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="119.136266" y="86.045153" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="95.852558" y="65.405451" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.931748" y="69.00258" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="171.923474" y="82.574475" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="81.203872" y="115.920234" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.399908" y="89.551559" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.549853" y="77.133567" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="152.650045" y="68.029976" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="146.900625" y="84.591819" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="134.236454" y="95.674044" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="100.441901" y="83.951852" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="178.453651" y="48.107719" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="78.528815" y="91.144692" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="84.272931" y="77.966158" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.235085" y="101.867718" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="128.639236" y="69.104578" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="108.173343" y="95.437832" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="150.640558" y="91.398395" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="127.366991" y="82.985289" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="93.357063" y="113.470475" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="114.19085" y="87.582783" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="98.92588" y="80.594545" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="163.507434" y="75.882131" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="104.130443" y="83.48542" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="138.525102" y="75.831255" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="171.416936" y="84.442152" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="105.333151" y="66.885205" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="112.185721" y="87.367559" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="92.657561" y="75.389946" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="103.15855" y="62.102534" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="89.341837" y="89.780347" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="159.317039" y="73.903159" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="71.70301" y="115.759169" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="101.533778" y="99.445677" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="146.90197" y="100.660773" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="104.346168" y="95.951702" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="109.431077" y="91.992748" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="104.271051" y="93.511792" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="115.176293" y="93.644631" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="193.891924" y="39.124589" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="134.574687" y="89.347345" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="137.69041" y="69.862951" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="104.956908" y="101.115803" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m823589f946" x="154.691024" y="68.037402" style="fill: #1f77b4; stroke: #1f77b4"/>
    </g>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <defs>
       <path id="m6ff9f381ac" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m6ff9f381ac" x="69.573382" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- −2 -->
      <g transform="translate(62.202288 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-32" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <g>
       <use xlink:href="#m6ff9f381ac" x="125.776441" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 0 -->
      <g transform="translate(122.595191 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_3">
      <g>
       <use xlink:href="#m6ff9f381ac" x="181.979501" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 2 -->
      <g transform="translate(178.798251 160.398438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_4">
      <defs>
       <path id="m28622f4ef6" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m28622f4ef6" x="28.942188" y="125.71812" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- −5 -->
      <g transform="translate(7.2 129.517339) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-35" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_5">
      <g>
       <use xlink:href="#m28622f4ef6" x="28.942188" y="99.751174" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- 0 -->
      <g transform="translate(15.579688 103.550393) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_6">
      <g>
       <use xlink:href="#m28622f4ef6" x="28.942188" y="73.784228" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_6">
      <!-- 5 -->
      <g transform="translate(15.579688 77.583446) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-35"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_7">
      <g>
       <use xlink:href="#m28622f4ef6" x="28.942188" y="47.817281" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 10 -->
      <g transform="translate(9.217188 51.6165) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_8">
      <g>
       <use xlink:href="#m28622f4ef6" x="28.942188" y="21.850335" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 15 -->
      <g transform="translate(9.217188 25.649554) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-35" x="63.623047"/>
      </g>
     </g>
    </g>
   </g>
   <g id="patch_3">
    <path d="M 28.942188 145.8 
L 28.942188 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 224.242188 145.8 
L 224.242188 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 28.942188 145.8 
L 224.242188 145.8 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 28.942188 7.2 
L 224.242188 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="p4610e2cf3f">
   <rect x="28.942188" y="7.2" width="195.3" height="138.6"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.1.2.-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE">8.1.2. <a id="toc8_1_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.1.2.-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">data_iter</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">))</span>
    <span class="c1"># </span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>                                 <span class="c1"># indices</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">)])</span>
        <span class="k">yield</span> <span class="n">features</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">]</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0.7269, -0.1631],
        [ 2.0933, -0.5410],
        [ 0.7562, -0.6686],
        [-0.4302,  0.3302],
        [-0.1591,  1.4465],
        [ 0.7235, -0.8781],
        [ 0.0123,  0.3597],
        [ 1.0409, -2.0936],
        [ 0.6744, -0.2588],
        [-0.2561, -0.4138]]) 
 tensor([[ 6.2141],
        [10.2228],
        [ 7.9691],
        [ 2.2033],
        [-1.0338],
        [ 8.6305],
        [ 2.9873],
        [13.3875],
        [ 6.4233],
        [ 5.0989]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.1.3.-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0">8.1.3. <a id="toc8_1_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.1.3.-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[60]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.1.4.-%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B">8.1.4. <a id="toc8_1_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.1.4.-%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[61]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">linreg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span> 
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.1.5.-%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0">8.1.5. <a id="toc8_1_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.1.5.-%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[62]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">squared_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>  
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_hat</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.1.6.-%E5%AE%9A%E4%B9%89%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95">8.1.6. <a id="toc8_1_6_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.1.6.-%E5%AE%9A%E4%B9%89%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[63]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sgd</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>  
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">param</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">/</span> <span class="n">batch_size</span>
            <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.1.7.-%E8%AE%AD%E7%BB%83">8.1.7. <a id="toc8_1_7_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.1.7.-%E8%AE%AD%E7%BB%83"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">linreg</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">squared_loss</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># Xy</span>
        <span class="c1"># l(batch_size,1)l</span>
        <span class="c1"># [w,b]</span>
        <span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">sgd</span><span class="p">([</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># </span>
        
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">train_l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">, loss </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'w: </span><span class="si">{</span><span class="n">true_w</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">true_w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'b: </span><span class="si">{</span><span class="n">true_b</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">b</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>epoch 1, loss 0.000051
epoch 2, loss 0.000056
epoch 3, loss 0.000051
epoch 4, loss 0.000050
epoch 5, loss 0.000048
epoch 6, loss 0.000052
epoch 7, loss 0.000052
epoch 8, loss 0.000049
epoch 9, loss 0.000049
epoch 10, loss 0.000049
w: tensor([-0.0010,  0.0004], grad_fn=&lt;SubBackward0&gt;)
b: tensor([-0.0013], grad_fn=&lt;RsubBackward1&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.2.-%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E4%BA%8E%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0">8.2. <a id="toc8_2_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#8.2.-%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E4%BA%8E%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"></a></h2><h3 id="8.2.1.-%E8%99%9A%E6%8B%9F%E6%95%B0%E6%8D%AE">8.2.1. <a id="toc8_2_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.2.1.-%E8%99%9A%E6%8B%9F%E6%95%B0%E6%8D%AE"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">true_w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4</span><span class="p">])</span>
<span class="n">true_b</span> <span class="o">=</span> <span class="mf">4.2</span>
<span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">synthetic_data</span><span class="p">(</span><span class="n">true_w</span><span class="p">,</span> <span class="n">true_b</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.2.2.-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE">8.2.2. <a id="toc8_2_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.2.2.-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">load_array</span><span class="p">(</span><span class="n">data_arrays</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">"""PyTorch"""</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span><span class="o">*</span><span class="n">data_arrays</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">is_train</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">data_iter</span> <span class="o">=</span> <span class="n">load_array</span><span class="p">((</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.2.3.-%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B">8.2.3. <a id="toc8_2_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.2.3.-%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.2.4.-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0">8.2.4. <a id="toc8_2_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.2.4.-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[19]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0.])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.2.5.-%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0">8.2.5. <a id="toc8_2_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.2.5.-%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.2.6.-%E5%AE%9A%E4%B9%89%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95">8.2.6. <a id="toc8_2_6_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.2.6.-%E5%AE%9A%E4%B9%89%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.2.7.-%E8%AE%AD%E7%BB%83">8.2.7. <a id="toc8_2_7_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.2.7.-%E8%AE%AD%E7%BB%83"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[71]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>                  <span class="c1"># 1. y_hat</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span> <span class="p">,</span><span class="n">y</span><span class="p">)</span>        <span class="c1"># 2. loss</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>                 <span class="c1"># 2.            </span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>                  <span class="c1"># 3. </span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">, loss </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="n">w</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'w'</span><span class="p">,</span> <span class="n">true_w</span> <span class="o">-</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">true_w</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">true_b</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>epoch 1, loss 0.000298
epoch 2, loss 0.000098
epoch 3, loss 0.000099
epoch 4, loss 0.000098
epoch 5, loss 0.000100
epoch 6, loss 0.000099
epoch 7, loss 0.000099
epoch 8, loss 0.000099
epoch 9, loss 0.000100
epoch 10, loss 0.000098
w tensor([-0.0003,  0.0004])
b tensor([-0.0004])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.2.8.-%E5%8F%82%E6%95%B0%E4%BF%9D%E5%AD%98">8.2.8. <a id="toc8_2_8_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.2.8.-%E5%8F%82%E6%95%B0%E4%BF%9D%E5%AD%98"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[72]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">"epoch"</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span> 
        <span class="s1">'mode_state_dict'</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> 
        <span class="s1">'opt_state_dict'</span><span class="p">:</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> 
        <span class="s1">'loss'</span><span class="p">:</span> <span class="s1">'loss'</span>
    <span class="p">},</span> 
    <span class="s1">'Pytorch_params/line_params.pt'</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.2.9.-%E9%87%8D%E8%BD%BD">8.2.9. <a id="toc8_2_9_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.2.9.-%E9%87%8D%E8%BD%BD"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[74]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">check_point</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'./Pytorch_params/line_params.pt'</span><span class="p">)</span>

<span class="n">new_net</span> <span class="o">=</span> <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">new_net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">check_point</span><span class="p">[</span><span class="s1">'mode_state_dict'</span><span class="p">])</span>

<span class="n">new_opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">new_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>
<span class="n">new_opt</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">check_point</span><span class="p">[</span><span class="s1">'opt_state_dict'</span><span class="p">])</span>

<span class="c1"># Stop BNDropout ...</span>
<span class="n">new_net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># </span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">pre</span> <span class="o">=</span> <span class="n">new_net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">pre</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([3.0603])
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/tmp/ipykernel_32820/1977999358.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  check_point = torch.load('./Pytorch_params/line_params.pt')
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.3.-%E4%B8%93%E9%A2%98-%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89%EF%BC%88%E8%AE%A1%E7%AE%97%E9%A2%84%E6%B5%8B%E5%80%BCy_hat%EF%BC%89">8.3. <a id="toc8_3_"></a><a href="#toc0_">-y_hat</a><a class="anchor-link" href="#8.3.-%E4%B8%93%E9%A2%98-%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89%EF%BC%88%E8%AE%A1%E7%AE%97%E9%A2%84%E6%B5%8B%E5%80%BCy_hat%EF%BC%89"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.3.1.-%E5%9D%97%EF%BC%9Atorch.nn%E6%A8%A1%E5%9D%97">8.3.1. <a id="toc8_3_1_"></a><a href="#toc0_">torch.nn</a><a class="anchor-link" href="#8.3.1.-%E5%9D%97%EF%BC%9Atorch.nn%E6%A8%A1%E5%9D%97"></a></h3><div class="highlight"><pre><span></span><span class="mf">1.</span> <span class="n"></span><span class="err"></span><span class="n"></span><span class="err"></span><span class="n"></span>
<span class="n"></span><span class="err"></span>
    <span class="n"></span><span class="err"></span><span class="n">pytorchnn</span><span class="o">.</span><span class="n">Sequentail</span><span class="err"></span>
    <span class="n"></span><span class="err"></span><span class="n">nn</span><span class="err"></span><span class="n">CNN</span><span class="err"></span><span class="n">RNN</span><span class="err"></span>
<span class="n"></span><span class="err"></span>
    <span class="n"></span><span class="err"></span><span class="n"></span><span class="err"></span>
</pre></div>
<ol>
<li><p>nn.<code>Sequential</code>(module1, module2, module3, ...)</p>
<ol>
<li>.append()</li>
<li>.extend()</li>
<li>.insert()</li>
<li>.pop()</li>
<li>add_module()</li>
</ol>
</li>
<li><p>nn.<code>ModuleList</code>([module1, module2, modeul3, ...])</p>
<ol>
<li>.append()    # </li>
<li>.extend()    # ModuleList</li>
<li>.insert()    # </li>
<li>.add_module()</li>
</ol>
</li>
<li><p>nn.<code>ModuleDict</code>({'m1': module1, 'm2': module2, 'm3': module3, ...})</p>
<ol>
<li>clear()  # ModuleDict</li>
<li>items()  # key: value</li>
<li>keys()   # keys</li>
<li>values() # values</li>
<li>pop()    # key: value</li>
<li>add_module</li>
</ol>
</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># help(nn.ModuleDict), help(nn.ModuleList), help(nn.Sequential)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[61]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">786</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">net</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[61]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
  (1): Linear(in_features=786, out_features=256, bias=True)
  (2): ReLU()
  (3): Linear(in_features=256, out_features=256, bias=True)
  (4): Tanh()
  (5): Linear(in_features=256, out_features=10, bias=True)
  (6): Softmax(dim=None)
)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[63]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">net</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">net</span><span class="p">])</span>

<span class="n">net1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[63]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>ModuleList(
  (0-2): 3 x Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=786, out_features=256, bias=True)
    (2): ReLU()
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Tanh()
    (5): Linear(in_features=256, out_features=10, bias=True)
    (6): Softmax(dim=None)
  )
)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s1">'m1'</span><span class="p">:</span> <span class="n">net</span><span class="p">,</span>
        <span class="s1">'m2'</span><span class="p">:</span> <span class="n">net</span><span class="p">,</span> 
        <span class="s1">'m3'</span><span class="p">:</span> <span class="n">net</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">net2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[64]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>ModuleDict(
  (m1): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=786, out_features=256, bias=True)
    (2): ReLU()
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Tanh()
    (5): Linear(in_features=256, out_features=10, bias=True)
    (6): Softmax(dim=None)
  )
  (m2): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=786, out_features=256, bias=True)
    (2): ReLU()
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Tanh()
    (5): Linear(in_features=256, out_features=10, bias=True)
    (6): Softmax(dim=None)
  )
  (m3): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=786, out_features=256, bias=True)
    (2): ReLU()
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Tanh()
    (5): Linear(in_features=256, out_features=10, bias=True)
    (6): Softmax(dim=None)
  )
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.3.2.-%E5%9D%97%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89">8.3.2. <a id="toc8_3_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.2.-%E5%9D%97%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89"></a></h3><div class="highlight"><pre><span></span><span class="m">2</span>.<span class="w"> </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.2.1.-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9D%97">8.3.2.1. <a id="toc8_3_2_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.2.1.-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9D%97"></a></h4><ul>
<li><p>Class</p>
</li>
<li><p><code>nn.Module</code><code>forward()</code></p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[65]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.2.2.-%E9%A1%BA%E5%BA%8F%E5%9D%97">8.3.2.2. <a id="toc8_3_2_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.2.2.-%E9%A1%BA%E5%BA%8F%E5%9D%97"></a></h4><pre><code>SequentialSequential
</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[66]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">class</span> <span class="nc">MySequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="o">=</span> <span class="n">module</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MySequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.2.3.-%E6%95%88%E7%8E%87">8.3.2.3. <a id="toc8_3_2_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.2.3.-%E6%95%88%E7%8E%87"></a></h4><div class="highlight"><pre><span></span><span class="m">1</span>.<span class="w"> </span>
<span class="m">2</span>.<span class="w"> </span>
<span class="m">3</span>.<span class="w"> </span>
<span class="m">4</span>.<span class="w"> </span>Sequential
</pre></div>
<div class="highlight"><pre><span></span><span class="w"> </span><span class="w"> </span>Python<span class="w"> </span>Python<span class="w"> </span><span class="w"> </span>GPUCPUPython
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.3.3.-%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84/%E7%BB%84%E6%88%90">8.3.3. <a id="toc8_3_3_"></a><a href="#toc0_">/</a><a class="anchor-link" href="#8.3.3.-%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84/%E7%BB%84%E6%88%90"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decode</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bloack</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="c1"># Init the Net()</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.3.1.-.children()">8.3.3.1. <a id="toc8_3_3_1_"></a><a href="#toc0_">.children()</a><a class="anchor-link" href="#8.3.3.1.-.children()"></a></h4><p><code></code>module</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># net</span>
<span class="nb">list</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">children</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[32]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[Linear(in_features=2, out_features=3, bias=True),
 Sequential(
   (0): Linear(in_features=3, out_features=128, bias=True)
 ),
 Linear(in_features=128, out_features=2, bias=True)]</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.3.2.-.named_children()">8.3.3.2. <a id="toc8_3_3_2_"></a><a href="#toc0_">.named_children()</a><a class="anchor-link" href="#8.3.3.2.-.named_children()"></a></h4><p><code></code>module</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">children</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> <span class="n">children</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>linear 	 Linear(in_features=2, out_features=3, bias=True)
block 	 Sequential(
  (0): Linear(in_features=3, out_features=128, bias=True)
)
decode 	 Linear(in_features=128, out_features=2, bias=True)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.3.3.-.modules()">8.3.3.3. <a id="toc8_3_3_3_"></a><a href="#toc0_">.modules()</a><a class="anchor-link" href="#8.3.3.3.-.modules()"></a></h4><p><code></code>module</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span> <span class="n">module</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Net(
  (linear): Linear(in_features=2, out_features=3, bias=True)
  (block): Sequential(
    (0): Linear(in_features=3, out_features=128, bias=True)
  )
  (decode): Linear(in_features=128, out_features=2, bias=True)
)
==========
Linear(in_features=2, out_features=3, bias=True)
==========
Sequential(
  (0): Linear(in_features=3, out_features=128, bias=True)
)
==========
Linear(in_features=3, out_features=128, bias=True)
==========
Linear(in_features=128, out_features=2, bias=True)
==========
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.3.4.-.named_modules()">8.3.3.4. <a id="toc8_3_3_4_"></a><a href="#toc0_">.named_modules()</a><a class="anchor-link" href="#8.3.3.4.-.named_modules()"></a></h4><p><code></code>module</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[34]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">'&gt;&gt;&gt;'</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre> &gt;&gt;&gt; Net(
  (linear): Linear(in_features=2, out_features=3, bias=True)
  (block): Sequential(
    (0): Linear(in_features=3, out_features=128, bias=True)
  )
  (decode): Linear(in_features=128, out_features=2, bias=True)
)
==========
linear &gt;&gt;&gt; Linear(in_features=2, out_features=3, bias=True)
==========
block &gt;&gt;&gt; Sequential(
  (0): Linear(in_features=3, out_features=128, bias=True)
)
==========
block.0 &gt;&gt;&gt; Linear(in_features=3, out_features=128, bias=True)
==========
decode &gt;&gt;&gt; Linear(in_features=128, out_features=2, bias=True)
==========
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.3.5.-%E5%88%A0%E9%99%A4%E5%92%8C%E6%B7%BB%E5%8A%A0">8.3.3.5. <a id="toc8_3_3_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.3.5.-%E5%88%A0%E9%99%A4%E5%92%8C%E6%B7%BB%E5%8A%A0"></a></h4><p> net<code>.children()</code><code> (list())</code> <code></code></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decode</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bloack</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">class</span> <span class="nc">NetDel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># self.net = Net()                                              ## </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netdel_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Net</span><span class="p">()</span><span class="o">.</span><span class="n">children</span><span class="p">())[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>                 <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netdel_list</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]</span>    <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netdel</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">netdel_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">netdel</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">netdel</span> <span class="o">=</span> <span class="n">NetDel</span><span class="p">()</span>
<span class="c1"># netdel</span>
<span class="nb">list</span><span class="p">(</span><span class="n">netdel</span><span class="o">.</span><span class="n">children</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[35]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[Sequential(
   (0): Linear(in_features=2, out_features=3, bias=True)
   (1): Sequential(
     (0): Linear(in_features=3, out_features=128, bias=True)
   )
   (2): Linear(in_features=128, out_features=256, bias=True)
   (3): Linear(in_features=256, out_features=2, bias=True)
 )]</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.3.6.-%E6%9B%BF%E6%8D%A2">8.3.3.6. <a id="toc8_3_3_6_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.3.6.-%E6%9B%BF%E6%8D%A2"></a></h4><p><code></code><code></code></p>
<ul>
<li><p> <code>Sequential</code>  <code> ()</code> </p>
</li>
<li><p><code>nn.Module</code> layer1layer2net<code>.</code>layer1net<code>.</code>layer2</p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[88]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decode</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bloack</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">class</span> <span class="nc">NetMod</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
        <span class="n">in_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decode</span><span class="o">.</span><span class="n">in_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decode</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="n">netmod</span> <span class="o">=</span> <span class="n">NetMod</span><span class="p">()</span>
<span class="n">netmod</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[88]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>NetMod(
  (model): Net(
    (linear): Linear(in_features=2, out_features=3, bias=True)
    (block): Sequential(
      (0): Linear(in_features=3, out_features=128, bias=True)
    )
    (decode): Linear(in_features=128, out_features=10, bias=True)
  )
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.3.7.-add_module()">8.3.3.7. <a id="toc8_3_3_7_"></a><a href="#toc0_">add_module()</a><a class="anchor-link" href="#8.3.3.7.-add_module()"></a></h4><p><code>add_module()</code> </p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[43]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decode</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bloack</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>


<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'add_demo'</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
<span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'final_demo'</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">net</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[43]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Net(
  (linear): Linear(in_features=2, out_features=3, bias=True)
  (block): Sequential(
    (0): Linear(in_features=3, out_features=128, bias=True)
  )
  (decode): Linear(in_features=128, out_features=2, bias=True)
  (add_demo): Linear(in_features=2, out_features=256, bias=True)
  (final_demo): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=2, bias=True)
  )
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.3.4.-%E6%A8%A1%E5%9E%8B%EF%BC%9A%E5%8F%82%E6%95%B0%E7%AE%A1%E7%90%86">8.3.4. <a id="toc8_3_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.4.-%E6%A8%A1%E5%9E%8B%EF%BC%9A%E5%8F%82%E6%95%B0%E7%AE%A1%E7%90%86"></a></h3><ul>
<li><code>nn.Sequential</code>Python<code>list</code><code></code></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[95]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[95]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[-0.0865],
        [-0.0746]], grad_fn=&lt;AddmmBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.4.1.-%E5%8F%82%E6%95%B0%E8%AE%BF%E9%97%AE">8.3.4.1. <a id="toc8_3_4_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.4.1.-%E5%8F%82%E6%95%B0%E8%AE%BF%E9%97%AE"></a></h4><ul>
<li><p></p>
</li>
<li><p> <code>Sequential</code>  <code> ()</code> </p>
</li>
<li><p><code>nn.Module</code> layer1layer2net<code>.</code>layer1net<code>.</code>layer2</p>
</li>
<li><p></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="8.3.4.1.1.-state_dict">8.3.4.1.1. <a id="toc8_3_4_1_1_"></a><a href="#toc0_">state_dict</a><a class="anchor-link" href="#8.3.4.1.1.-state_dict"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[96]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net</span> <span class="c1"># nn.Sequential</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[96]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Sequential(
  (0): Linear(in_features=4, out_features=8, bias=True)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=1, bias=True)
)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">net</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">net</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="c1"># nn.Sequential</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[97]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(Linear(in_features=4, out_features=8, bias=True),
 ReLU(),
 Linear(in_features=8, out_features=1, bias=True))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[98]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[98]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>OrderedDict([('weight',
              tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],
                      [-0.1280, -0.2531, -0.0131, -0.2696],
                      [ 0.0538,  0.1759, -0.1103, -0.3805],
                      [-0.2477, -0.0914,  0.1431,  0.2419],
                      [ 0.1345, -0.0516, -0.0536, -0.4364],
                      [ 0.1144, -0.3585, -0.2615,  0.1957],
                      [ 0.2924,  0.0015,  0.4087,  0.3759],
                      [ 0.4440, -0.2937, -0.0911, -0.4929]])),
             ('bias',
              tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880]))])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[99]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[99]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Parameter containing:
tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],
        [-0.1280, -0.2531, -0.0131, -0.2696],
        [ 0.0538,  0.1759, -0.1103, -0.3805],
        [-0.2477, -0.0914,  0.1431,  0.2419],
        [ 0.1345, -0.0516, -0.0536, -0.4364],
        [ 0.1144, -0.3585, -0.2615,  0.1957],
        [ 0.2924,  0.0015,  0.4087,  0.3759],
        [ 0.4440, -0.2937, -0.0911, -0.4929]], requires_grad=True)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[100]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[100]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],
        [-0.1280, -0.2531, -0.0131, -0.2696],
        [ 0.0538,  0.1759, -0.1103, -0.3805],
        [-0.2477, -0.0914,  0.1431,  0.2419],
        [ 0.1345, -0.0516, -0.0536, -0.4364],
        [ 0.1144, -0.3585, -0.2615,  0.1957],
        [ 0.2924,  0.0015,  0.4087,  0.3759],
        [ 0.4440, -0.2937, -0.0911, -0.4929]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[101]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[101]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Parameter containing:
tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880],
       requires_grad=True)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[102]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[102]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[103]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># net[1]relu</span>
<span class="c1"># torch.save(net.state_dict(), 'Pytorch_datasets/net_params)</span>

<span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[103]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>OrderedDict([('0.weight',
              tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],
                      [-0.1280, -0.2531, -0.0131, -0.2696],
                      [ 0.0538,  0.1759, -0.1103, -0.3805],
                      [-0.2477, -0.0914,  0.1431,  0.2419],
                      [ 0.1345, -0.0516, -0.0536, -0.4364],
                      [ 0.1144, -0.3585, -0.2615,  0.1957],
                      [ 0.2924,  0.0015,  0.4087,  0.3759],
                      [ 0.4440, -0.2937, -0.0911, -0.4929]])),
             ('0.bias',
              tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880])),
             ('2.weight',
              tensor([[-0.0894, -0.1603, -0.1185,  0.0858, -0.0592, -0.1632,  0.1876, -0.0784]])),
             ('2.bias', tensor([-0.1285]))])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="8.3.4.1.2.-parameters">8.3.4.1.2. <a id="toc8_3_4_1_2_"></a><a href="#toc0_">parameters</a><a class="anchor-link" href="#8.3.4.1.2.-parameters"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[104]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[104]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(&lt;generator object Module.parameters at 0x7f0dc565da80&gt;,
 &lt;bound method Module.parameters of Sequential(
   (0): Linear(in_features=4, out_features=8, bias=True)
   (1): ReLU()
   (2): Linear(in_features=8, out_features=1, bias=True)
 )&gt;)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[105]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">is_leaf</span><span class="p">)</span>
    <span class="c1"># break</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>&lt;class 'torch.nn.parameter.Parameter'&gt;
Parameter containing:
tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],
        [-0.1280, -0.2531, -0.0131, -0.2696],
        [ 0.0538,  0.1759, -0.1103, -0.3805],
        [-0.2477, -0.0914,  0.1431,  0.2419],
        [ 0.1345, -0.0516, -0.0536, -0.4364],
        [ 0.1144, -0.3585, -0.2615,  0.1957],
        [ 0.2924,  0.0015,  0.4087,  0.3759],
        [ 0.4440, -0.2937, -0.0911, -0.4929]], requires_grad=True)
True
None
True
&lt;class 'torch.nn.parameter.Parameter'&gt;
Parameter containing:
tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880],
       requires_grad=True)
True
None
True
&lt;class 'torch.nn.parameter.Parameter'&gt;
Parameter containing:
tensor([[-0.0894, -0.1603, -0.1185,  0.0858, -0.0592, -0.1632,  0.1876, -0.0784]],
       requires_grad=True)
True
None
True
&lt;class 'torch.nn.parameter.Parameter'&gt;
Parameter containing:
tensor([-0.1285], requires_grad=True)
True
None
True
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[106]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">param</span>  <span class="ow">in</span> <span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">is_leaf</span><span class="p">)</span>
    <span class="c1"># break</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Parameter containing:
tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],
        [-0.1280, -0.2531, -0.0131, -0.2696],
        [ 0.0538,  0.1759, -0.1103, -0.3805],
        [-0.2477, -0.0914,  0.1431,  0.2419],
        [ 0.1345, -0.0516, -0.0536, -0.4364],
        [ 0.1144, -0.3585, -0.2615,  0.1957],
        [ 0.2924,  0.0015,  0.4087,  0.3759],
        [ 0.4440, -0.2937, -0.0911, -0.4929]], requires_grad=True)
True
None
True
Parameter containing:
tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880],
       requires_grad=True)
True
None
True
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="8.3.4.1.3.-named_parameters">8.3.4.1.3. <a id="toc8_3_4_1_3_"></a><a href="#toc0_">named_parameters</a><a class="anchor-link" href="#8.3.4.1.3.-named_parameters"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[114]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># list(net.named_parameters())</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>0.weight 	 Parameter containing:
tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],
        [-0.1280, -0.2531, -0.0131, -0.2696],
        [ 0.0538,  0.1759, -0.1103, -0.3805],
        [-0.2477, -0.0914,  0.1431,  0.2419],
        [ 0.1345, -0.0516, -0.0536, -0.4364],
        [ 0.1144, -0.3585, -0.2615,  0.1957],
        [ 0.2924,  0.0015,  0.4087,  0.3759],
        [ 0.4440, -0.2937, -0.0911, -0.4929]], requires_grad=True)
0.bias 	 Parameter containing:
tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880],
       requires_grad=True)
2.weight 	 Parameter containing:
tensor([[-0.0894, -0.1603, -0.1185,  0.0858, -0.0592, -0.1632,  0.1876, -0.0784]],
       requires_grad=True)
2.bias 	 Parameter containing:
tensor([-0.1285], requires_grad=True)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.4.2.-%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96">8.3.4.2. <a id="toc8_3_4_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.4.2.-%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96"></a></h4><ul>
<li><p></p>
</li>
<li><p>PyTorch </p>
</li>
<li><p>PyTorchnn.init</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="8.3.4.2.1.-%E5%86%85%E7%BD%AE%E5%88%9D%E5%A7%8B%E5%8C%96">8.3.4.2.1. <a id="toc8_3_4_2_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.4.2.1.-%E5%86%85%E7%BD%AE%E5%88%9D%E5%A7%8B%E5%8C%96"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[50]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[50]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="8.3.4.2.2.-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%9D%E5%A7%8B%E5%8C%96">8.3.4.2.2. <a id="toc8_3_4_2_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.4.2.2.-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%9D%E5%A7%8B%E5%8C%96"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="8.3.4.2.3.-%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A">8.3.4.2.3. <a id="toc8_3_4_2_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.4.2.3.-%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A"></a></h5><pre><code> 
</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># </span>
<span class="n">shared</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">shared</span><span class="p">,</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">shared</span><span class="p">,</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># </span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">net</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">net</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># </span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">net</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.3.5.-%E5%B1%82%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89">8.3.5. <a id="toc8_3_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.5.-%E5%B1%82%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89"></a></h3><p>
</p>
<div class="highlight"><pre><span></span><span class="n"></span><span class="err"></span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span>
<span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span> 
    <span class="n"></span><span class="err"></span><span class="n">FC</span><span class="err"></span>
    <span class="n"></span><span class="err"></span><span class="n">Pooling</span><span class="err"></span>
    <span class="n">BN</span>
    <span class="n">Dropout</span>
    <span class="o">...</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.5.1.-%E4%B8%8D%E5%B8%A6%E5%8F%82%E6%95%B0%E7%9A%84%E5%B1%82">8.3.5.1. <a id="toc8_3_5_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.5.1.-%E4%B8%8D%E5%B8%A6%E5%8F%82%E6%95%B0%E7%9A%84%E5%B1%82"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[53]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">class</span> <span class="nc">CenteredLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    
<span class="n">layer</span> <span class="o">=</span> <span class="n">CenteredLayer</span><span class="p">()</span>
<span class="n">layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[53]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([-1.,  0.,  1.])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[54]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> 
    <span class="n">CenteredLayer</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">Y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[54]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor(-9.3132e-09, grad_fn=&lt;MeanBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.3.5.2.-%E5%B8%A6%E5%8F%82%E6%95%B0%E7%9A%84%E5%B1%82">8.3.5.2. <a id="toc8_3_5_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.3.5.2.-%E5%B8%A6%E5%8F%82%E6%95%B0%E7%9A%84%E5%B1%82"></a></h4><p><code>nn.Parameter()</code></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MyLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_units</span><span class="p">,</span> <span class="n">units</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_units</span><span class="p">,</span> <span class="n">units</span><span class="p">))</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">units</span><span class="p">,))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span>
    
<span class="n">linear</span> <span class="o">=</span> <span class="n">MyLinear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="c1"># linear.weight</span>

<span class="n">linear</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[55]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.0000, 0.0000, 0.0000],
        [0.1466, 0.0000, 0.0000]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">MyLinear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> 
    <span class="n">MyLinear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.4.-%E4%B8%93%E9%A2%98-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-(loss_fn)">8.4. <a id="toc8_4_"></a><a href="#toc0_">- (loss_fn)</a><a class="anchor-link" href="#8.4.-%E4%B8%93%E9%A2%98-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-(loss_fn)"></a></h2><p> (output, target) </p>
<ol>
<li><p></p>
</li>
<li><p></p>
</li>
<li><p></p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.4.1.-%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE">8.4.1. <a id="toc8_4_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.4.1.-%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE"></a></h3><p></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.4.2.-%E4%BA%A4%E5%8F%89%E7%86%B5">8.4.2. <a id="toc8_4_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.4.2.-%E4%BA%A4%E5%8F%89%E7%86%B5"></a></h3><p></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.4.3.-%E8%87%AA%E5%AE%9A%E4%B9%89">8.4.3. <a id="toc8_4_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.4.3.-%E8%87%AA%E5%AE%9A%E4%B9%89"></a></h3><p></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[58]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''''''</span>
    <span class="n">error_values</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span>
    <span class="k">return</span> <span class="n">error_values</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.5.-%E4%B8%93%E9%A2%98-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%88%E6%B1%82%E6%A2%AF%E5%BA%A6%EF%BC%89">8.5. <a id="toc8_5_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#8.5.-%E4%B8%93%E9%A2%98-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%88%E6%B1%82%E6%A2%AF%E5%BA%A6%EF%BC%89"></a></h2><pre><code>
</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># autograd</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.6.-%E4%B8%93%E9%A2%98-%E6%9B%B4%E6%96%B0%E6%9D%83%E9%87%8D%EF%BC%88%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%EF%BC%89">8.6. <a id="toc8_6_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#8.6.-%E4%B8%93%E9%A2%98-%E6%9B%B4%E6%96%B0%E6%9D%83%E9%87%8D%EF%BC%88%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%EF%BC%89"></a></h2><ul>
<li></li>
<li>softmaxMLPCNNRNN</li>
<li></li>
<li></li>
<li></li>
<li>Adam</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> 


<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'y'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Function'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[1]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Text(0.5, 1.0, 'Function')</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">y</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">x_grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_grad</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">x_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">x_grads</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'y`'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'grad'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[2]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Text(0.5, 1.0, 'grad')</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">gd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">iter</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">x_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>    <span class="c1"># </span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">iter</span><span class="p">):</span>
        <span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">x_grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x_tensor</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="p">(</span><span class="n">eta</span> <span class="o">*</span> <span class="n">x_grad</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">x_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">x_list</span>

<span class="c1"># xiter</span>
<span class="k">def</span> <span class="nf">demo</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="nb">iter</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    <span class="n">xx</span> <span class="o">=</span> <span class="n">gd</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="nb">iter</span> <span class="p">)</span>
    <span class="n">yy</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">xx</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">c</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'y'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Function'</span><span class="p">)</span>

<span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">demo</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">)</span>    <span class="c1"># lr</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[3]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[&lt;matplotlib.lines.Line2D at 0x7fc46c4198e0&gt;]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'y'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Function'</span><span class="p">)</span>

<span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">demo</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span>    <span class="c1"># lr</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[5]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[&lt;matplotlib.lines.Line2D at 0x7fc46c2c5580&gt;]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'y'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Function'</span><span class="p">)</span>

<span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">demo</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span>    <span class="c1"># 0</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[6]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[&lt;matplotlib.lines.Line2D at 0x7fc46c30f380&gt;]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'y'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Function'</span><span class="p">)</span>

<span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">demo</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span>   <span class="c1"># lr</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[7]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[&lt;matplotlib.lines.Line2D at 0x7fc46c37d5b0&gt;]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.6.1.-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%88SGD%EF%BC%89">8.6.1. <a id="toc8_6_1_"></a><a href="#toc0_">SGD</a><a class="anchor-link" href="#8.6.1.-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%88SGD%EF%BC%89"></a></h3><ul>
<li></li>
<li><code></code></li>
<li>batch_size<code></code></li>
<li><code> (momentum)</code> 0.5, 0.90, 0.99 </li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[68]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> 
    <span class="n">momentum</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> 
    <span class="c1"># weight_decay=</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[68]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    momentum: 0.99
    nesterov: False
    weight_decay: 0
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.6.2.-adam">8.6.2. <a id="toc8_6_2_"></a><a href="#toc0_">adam</a><a class="anchor-link" href="#8.6.2.-adam"></a></h3><ul>
<li>AdamSGDlr</li>
<li>AdamSGD</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[59]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
    <span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[59]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.6.3.-RMSprop">8.6.3. <a id="toc8_6_3_"></a><a href="#toc0_">RMSprop</a><a class="anchor-link" href="#8.6.3.-RMSprop"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[60]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span>
    <span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[60]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>RMSprop (
Parameter Group 0
    alpha: 0.99
    centered: False
    differentiable: False
    eps: 1e-08
    foreach: None
    lr: 0.01
    maximize: False
    momentum: 0
    weight_decay: 0
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.6.4.-%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E5%BA%A6%E5%99%A8">8.6.4. <a id="toc8_6_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.6.4.-%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E5%BA%A6%E5%99%A8"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.6.4.1.-StepLR%EF%BC%9A-%E6%8C%89%E7%85%A7%E5%9B%BA%E5%AE%9A%E7%9A%84%E6%AD%A5%E9%95%BF%E8%B0%83%E6%95%B4%E5%AD%A6%E4%B9%A0%E7%8E%87">8.6.4.1. <a id="toc8_6_4_1_"></a><a href="#toc0_">StepLR </a><a class="anchor-link" href="#8.6.4.1.-StepLR%EF%BC%9A-%E6%8C%89%E7%85%A7%E5%9B%BA%E5%AE%9A%E7%9A%84%E6%AD%A5%E9%95%BF%E8%B0%83%E6%95%B4%E5%AD%A6%E4%B9%A0%E7%8E%87"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[92]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">StepLR</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">train</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">validate</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.6.4.2.-MultiStepLR%EF%BC%9A-%E5%9C%A8%E6%8C%87%E5%AE%9A%E7%9A%84%E9%87%8C%E7%A8%8B%E7%A2%91%EF%BC%88milestones%EF%BC%89%E4%B8%8A%E8%B0%83%E6%95%B4%E5%AD%A6%E4%B9%A0%E7%8E%87">8.6.4.2. <a id="toc8_6_4_2_"></a><a href="#toc0_">MultiStepLR milestones</a><a class="anchor-link" href="#8.6.4.2.-MultiStepLR%EF%BC%9A-%E5%9C%A8%E6%8C%87%E5%AE%9A%E7%9A%84%E9%87%8C%E7%A8%8B%E7%A2%91%EF%BC%88milestones%EF%BC%89%E4%B8%8A%E8%B0%83%E6%95%B4%E5%AD%A6%E4%B9%A0%E7%8E%87"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">MultiStepLR</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">MultiStepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">milestones</span><span class="o">=</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">80</span><span class="p">],</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.6.4.3.-ExponentialLR%EF%BC%9A-%E4%BB%A5%E6%8C%87%E6%95%B0%E8%A1%B0%E5%87%8F%E7%9A%84%E6%96%B9%E5%BC%8F%E8%B0%83%E6%95%B4%E5%AD%A6%E4%B9%A0%E7%8E%87">8.6.4.3. <a id="toc8_6_4_3_"></a><a href="#toc0_">ExponentialLR </a><a class="anchor-link" href="#8.6.4.3.-ExponentialLR%EF%BC%9A-%E4%BB%A5%E6%8C%87%E6%95%B0%E8%A1%B0%E5%87%8F%E7%9A%84%E6%96%B9%E5%BC%8F%E8%B0%83%E6%95%B4%E5%AD%A6%E4%B9%A0%E7%8E%87"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">ExponentialLR</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.6.4.4.-CosineAnnealingLR%EF%BC%9A-%E4%BD%99%E5%BC%A6%E9%80%80%E7%81%AB%E8%B0%83%E6%95%B4%E5%AD%A6%E4%B9%A0%E7%8E%87">8.6.4.4. <a id="toc8_6_4_4_"></a><a href="#toc0_">CosineAnnealingLR </a><a class="anchor-link" href="#8.6.4.4.-CosineAnnealingLR%EF%BC%9A-%E4%BD%99%E5%BC%A6%E9%80%80%E7%81%AB%E8%B0%83%E6%95%B4%E5%AD%A6%E4%B9%A0%E7%8E%87"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">CosineAnnealingLR</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.6.4.5.-ReduceLROnPlateau%EF%BC%9A-%E5%BD%93%E6%8C%87%E6%A0%87%E5%81%9C%E6%AD%A2%E6%94%B9%E5%96%84%E6%97%B6%EF%BC%8C%E9%99%8D%E4%BD%8E%E5%AD%A6%E4%B9%A0%E7%8E%87">8.6.4.5. <a id="toc8_6_4_5_"></a><a href="#toc0_">ReduceLROnPlateau </a><a class="anchor-link" href="#8.6.4.5.-ReduceLROnPlateau%EF%BC%9A-%E5%BD%93%E6%8C%87%E6%A0%87%E5%81%9C%E6%AD%A2%E6%94%B9%E5%96%84%E6%97%B6%EF%BC%8C%E9%99%8D%E4%BD%8E%E5%AD%A6%E4%B9%A0%E7%8E%87"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">ReduceLROnPlateau</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'min'</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">train</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.6.4.6.-LambdaLR%EF%BC%9A-%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E5%87%BD%E6%95%B0%E6%9D%A5%E8%B0%83%E6%95%B4%E5%AD%A6%E4%B9%A0%E7%8E%87">8.6.4.6. <a id="toc8_6_4_6_"></a><a href="#toc0_">LambdaLR </a><a class="anchor-link" href="#8.6.4.6.-LambdaLR%EF%BC%9A-%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E5%87%BD%E6%95%B0%E6%9D%A5%E8%B0%83%E6%95%B4%E5%AD%A6%E4%B9%A0%E7%8E%87"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">LambdaLR</span>

<span class="n">lambda1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">epoch</span><span class="p">:</span> <span class="mf">0.65</span> <span class="o">**</span> <span class="n">epoch</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="o">=</span><span class="n">lambda1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.6.4.7.-%E8%87%AA%E5%AE%9A%E4%B9%89">8.6.4.7. <a id="toc8_6_4_7_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.6.4.7.-%E8%87%AA%E5%AE%9A%E4%B9%89"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># torch.optim.lr_scheduler._LRScheduler</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">_LRScheduler</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Help on class _LRScheduler in module torch.optim.lr_scheduler:

class _LRScheduler(LRScheduler)
 |  _LRScheduler(optimizer: torch.optim.optimizer.Optimizer, last_epoch=-1, verbose='deprecated')
 |
 |  # Including _LRScheduler for backwards compatibility
 |  # Subclass instead of assign because we want __name__ of _LRScheduler to be _LRScheduler (assigning would make it LRScheduler).
 |
 |  Method resolution order:
 |      _LRScheduler
 |      LRScheduler
 |      builtins.object
 |
 |  Data and other attributes defined here:
 |
 |  __annotations__ = {}
 |
 |  ----------------------------------------------------------------------
 |  Methods inherited from LRScheduler:
 |
 |  __init__(self, optimizer: torch.optim.optimizer.Optimizer, last_epoch=-1, verbose='deprecated')
 |      Initialize self.  See help(type(self)) for accurate signature.
 |
 |  get_last_lr(self) -&gt; List[float]
 |      Return last computed learning rate by current scheduler.
 |
 |  get_lr(self) -&gt; List[float]
 |
 |  load_state_dict(self, state_dict: Dict[str, Any])
 |      Loads the schedulers state.
 |
 |      Args:
 |          state_dict (dict): scheduler state. Should be an object returned
 |              from a call to :meth:`state_dict`.
 |
 |  print_lr(self, is_verbose: bool, group: Dict[str, Any], lr: float, epoch: Optional[int] = None)
 |      Display the current learning rate.
 |
 |      .. deprecated:: 2.4
 |          ``print_lr()`` is deprecated. Please use ``get_last_lr()`` to access the
 |          learning rate.
 |
 |  state_dict(self)
 |      Returns the state of the scheduler as a :class:`dict`.
 |
 |      It contains an entry for every variable in self.__dict__ which
 |      is not the optimizer.
 |
 |  step(self, epoch: Optional[int] = None)
 |
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from LRScheduler:
 |
 |  __dict__
 |      dictionary for instance variables
 |
 |  __weakref__
 |      list of weak references to the object

</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.7.-%E4%B8%93%E9%A2%98-%E8%AE%AD%E7%BB%83">8.7. <a id="toc8_7_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#8.7.-%E4%B8%93%E9%A2%98-%E8%AE%AD%E7%BB%83"></a></h2><p><img alt="Train step via pure PyTorch" src="./Pytorch_Pictures/PyTorch_graphacial_demo/Train_step_via_pure_PyTorch.jpg"/></p>
<div class="highlight"><pre><span></span><span class="n"></span>
</pre></div>
<div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">():</span>
    <span class="n"></span> <span class="n">Batch</span> <span class="n">Normalization</span> <span class="n"></span> <span class="n">Dropout</span><span class="err"></span>
    <span class="n">BN</span><span class="p">(</span><span class="n">Batch</span> <span class="n">Normalization</span><span class="err"></span><span class="n">Dropout</span><span class="err"></span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span><span class="n"></span><span class="err"></span> 
                        <span class="n">BN</span><span class="err"></span><span class="n">BN</span><span class="err"></span><span class="n"></span><span class="err"></span>
                        <span class="n">Dropout</span><span class="err"></span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span><span class="n"></span><span class="err"></span>

<span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n"></span> <span class="n">Batch</span> <span class="n">Normalization</span> <span class="n"></span> <span class="n">Dropout</span><span class="err"></span>
    <span class="n">BN</span><span class="p">(</span><span class="n">Batch</span> <span class="n">Normalization</span><span class="err"></span><span class="n">Dropout</span><span class="err"></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="err"></span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="n">BN</span><span class="err"></span><span class="n">BN</span><span class="err"></span>
                        <span class="n">Dropout</span><span class="err"></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="n"></span><span class="err"></span><span class="n"></span><span class="err"></span>
                        
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">pass</span>

    <span class="n">train</span><span class="p">()</span> <span class="n">eval</span><span class="p">()</span> <span class="n"></span><span class="err"></span><span class="n">gradient</span><span class="err"></span><span class="n">forward</span>
    <span class="n"></span><span class="err"></span><span class="n">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span><span class="n">autograd</span><span class="err"></span><span class="n">forward</span><span class="err"></span><span class="n"></span><span class="err"></span><span class="n">with</span><span class="err"></span><span class="n">GPU</span><span class="err"></span><span class="n">dropoutBN</span><span class="err"></span>
    <span class="n"></span><span class="err"></span><span class="n">testtorch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span><span class="err"></span><span class="n"></span><span class="err"></span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[75]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>  
<span class="c1"># import torch.nn.functional as F </span>
<span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="n">dbs</span> <span class="o">=</span> <span class="s1">'./Pytorch_datasets/'</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
            <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
            <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># </span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># test_iter = data.DataLoader(dataset=test_dataset) # testbatch</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Failed to download (trying next):
HTTP Error 403: Forbidden

Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz
Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw/train-images-idx3-ubyte.gz
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|| 9912422/9912422 [00:02&lt;00:00, 3659860.80it/s]
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Extracting ./Pytorch_datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Failed to download (trying next):
HTTP Error 403: Forbidden

Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz
Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw/train-labels-idx1-ubyte.gz
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|| 28881/28881 [00:00&lt;00:00, 119645.04it/s]
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Extracting ./Pytorch_datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Failed to download (trying next):
HTTP Error 403: Forbidden

Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz
Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw/t10k-images-idx3-ubyte.gz
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|| 1648877/1648877 [00:01&lt;00:00, 912416.46it/s] 
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Extracting ./Pytorch_datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Failed to download (trying next):
HTTP Error 403: Forbidden

Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz
Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|| 4542/4542 [00:00&lt;00:00, 17224709.56it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Extracting ./Pytorch_datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw

</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[79]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[80]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> 
<span class="kn">import</span> <span class="nn">IPython.display</span> <span class="k">as</span> <span class="nn">display</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">train_steps</span><span class="p">(</span>
        <span class="n">epochs</span><span class="p">,</span> 
        <span class="n">train_dataset</span><span class="p">,</span> 
        <span class="n">train_iter</span><span class="p">,</span> 
        <span class="n">test_dataset</span><span class="p">,</span> 
        <span class="n">net</span><span class="p">,</span> 
        <span class="n">loss_fn</span><span class="p">,</span> 
        <span class="n">opt</span><span class="p">,</span> 
        <span class="n">device</span><span class="p">,</span> 
        <span class="n">train_figure</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
        <span class="n">resume</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
        <span class="n">PATH</span> <span class="o">=</span> <span class="s1">'Pytorch_params/weights'</span>
    <span class="p">):</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">    :</span>
<span class="sd">            epochs = epochs                         # epoch</span>
<span class="sd">            train_dataset = train_dataset           # train</span>
<span class="sd">            train_iter = train_iter                 # batchtrain</span>
<span class="sd">            test_dataset = test_dataset             # test</span>
<span class="sd">            net = net                               # </span>
<span class="sd">            loss_fn = loss_fn                       # </span>
<span class="sd">            opt = opt                               # </span>
<span class="sd">            device = device                         # device GPU/CPU</span>
<span class="sd">            train_figure = False                    # </span>
<span class="sd">            resume = False                          # </span>
<span class="sd">    '''</span>
    <span class="c1"># device</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Runing on </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="c1">## </span>
    <span class="n">train_all_data_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                      <span class="c1"># .to(device)</span>
    <span class="n">train_all_targets_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                <span class="c1"># .to(device)</span>
    <span class="n">test_all_data_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                        <span class="c1"># .to(device)</span>
    <span class="n">test_all_targets_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                  <span class="c1"># .to(device)</span>
    <span class="c1">## </span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                                                          <span class="c1"># .to(device)</span>

    <span class="k">def</span> <span class="nf">dl_plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">epoch_list</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">train_loss_list</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">train_acc_list</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">test_acc_list</span><span class="p">:</span><span class="nb">list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'font.sans-serif'</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="s1">'Times new roman'</span><span class="p">,</span> <span class="s1">'Arial'</span><span class="p">,</span> <span class="s1">'KaiTi'</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">([</span><span class="s1">'ggplot'</span><span class="p">,</span> <span class="s1">'seaborn'</span><span class="p">])</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">))</span>

        <span class="c1"># for y, label in zip([train_loss_list, train_acc_list, test_acc_list], ['train_loss', 'train_acc', 'test_acc']):</span>
        <span class="k">for</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">train_acc_list</span><span class="p">,</span> <span class="n">test_acc_list</span><span class="p">],</span> <span class="p">[</span><span class="s1">'train_acc'</span><span class="p">,</span> <span class="s1">'test_acc'</span><span class="p">]):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_list</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Values'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="c1"># plt.tight_layout()</span>

        <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
        <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># </span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">epoch_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">best_test_acc</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># </span>
    <span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">resume</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">PATH</span><span class="o">+</span><span class="s1">'/last.pt'</span><span class="p">):</span>
            <span class="n">check_point</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="o">+</span><span class="s1">'/last.pt'</span><span class="p">)</span>
            <span class="n">start_epoch</span> <span class="o">=</span> <span class="n">check_point</span><span class="p">[</span><span class="s1">'epoch'</span><span class="p">]</span>
            <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">check_point</span><span class="p">[</span><span class="s1">'model_state_dict'</span><span class="p">])</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">check_point</span><span class="p">[</span><span class="s1">'opt_state_dict'</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">''</span><span class="p">)</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="s1">'start_epoch: '</span><span class="p">,</span> <span class="n">start_epoch</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>                             <span class="c1"># </span>
        <span class="n">epoch_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch_record</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch_record</span>                 <span class="c1"># X, y</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   <span class="c1">## deviceGPU/CPU                    # .to(device)</span>
            <span class="c1"># print(X[0])</span>
            <span class="c1"># print(X[0].dtype)</span>
            <span class="c1"># break</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>                      <span class="c1"># y_hat</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>            <span class="c1"># loss</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>                     <span class="c1"># </span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>                     <span class="c1"># </span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>                          <span class="c1"># </span>

        <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>                              <span class="c1"># </span>
                                                <span class="c1"># net.train()</span>
                                                <span class="c1"># netBNDropouttesttraintest</span>
                                                <span class="c1"># netBNDropoutnet.eval()</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>                   <span class="c1"># withgrad</span>
            <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">),</span> <span class="n">train_all_targets_gpu</span><span class="p">)</span>
            <span class="n">train_loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="c1"># print(train_loss)</span>

            <span class="n">train_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">train_all_targets_gpu</span>
            <span class="n">train_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_acc_cmp</span><span class="p">))</span> 
            <span class="n">train_acc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="c1"># print(train_acc)</span>

            <span class="n">test_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">test_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">test_all_targets_gpu</span>
            <span class="n">test_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_acc_cmp</span><span class="p">))</span>
            <span class="n">test_acc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="c1"># print(test_acc)</span>

            <span class="k">if</span> <span class="n">train_figure</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">dl_plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">epoch_list</span><span class="p">,</span> <span class="n">train_loss_list</span><span class="p">,</span> <span class="n">train_acc_list</span><span class="p">,</span> <span class="n">test_acc_list</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">: train_loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s2">, train_acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s2">, test_acc=</span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="c1"># last.ptbest.pt</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s1">'epoch'</span><span class="p">:</span><span class="n">epoch</span><span class="p">,</span> <span class="s1">'model_state_dict'</span><span class="p">:</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'opt_state_dict'</span><span class="p">:</span><span class="n">opt</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'loss'</span><span class="p">:</span><span class="n">test_acc</span><span class="p">},</span> <span class="n">PATH</span><span class="o">+</span><span class="s1">'/last.pt'</span><span class="p">)</span> 
        <span class="k">if</span> <span class="n">test_acc</span> <span class="o">&gt;</span> <span class="n">best_test_acc</span><span class="p">:</span>
            <span class="n">best_test_acc</span> <span class="o">=</span> <span class="n">test_acc</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s1">'epoch'</span><span class="p">:</span><span class="n">epoch</span><span class="p">,</span> <span class="s1">'model_state_dict'</span><span class="p">:</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'opt_state_dict'</span><span class="p">:</span><span class="n">opt</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'loss'</span><span class="p">:</span><span class="n">test_acc</span><span class="p">},</span> <span class="n">PATH</span><span class="o">+</span><span class="s1">'/best.pt'</span><span class="p">)</span> 

    <span class="n">stop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start</span><span class="si">}</span><span class="s2"> seconds."</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span>
    <span class="c1"># return (epoch_list, train_loss_list, train_acc_list, test_acc_list)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> 
<span class="kn">import</span> <span class="nn">IPython.display</span> <span class="k">as</span> <span class="nn">display</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span>
        <span class="n">epochs</span><span class="p">,</span> 
        <span class="n">train_dataset</span><span class="p">,</span> 
        <span class="n">train_iter</span><span class="p">,</span> 
        <span class="n">test_dataset</span><span class="p">,</span> 
        <span class="n">net</span><span class="p">,</span> 
        <span class="n">loss_fn</span><span class="p">,</span> 
        <span class="n">opt</span><span class="p">,</span> 
        <span class="n">device</span><span class="p">,</span> 
        <span class="n">train_figure</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
        <span class="n">resume</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
        <span class="n">PATH</span> <span class="o">=</span> <span class="s1">'Pytorch_params/weights'</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">    </span>
<span class="sd">    params:</span>
<span class="sd">            epochs = epochs                         # epoch</span>
<span class="sd">            train_dataset = train_dataset           # train</span>
<span class="sd">            train_iter = train_iter                 # batchtrain</span>
<span class="sd">            test_dataset = test_dataset             # test</span>
<span class="sd">            net = net                               # </span>
<span class="sd">            loss_fn = loss_fn                       # </span>
<span class="sd">            opt = opt                               # </span>
<span class="sd">            device = device                         # device GPU/CPU</span>
<span class="sd">            train_figure = False                    # </span>
<span class="sd">            resume = False                          # </span>
<span class="sd">    return:</span>
<span class="sd">            tra_loss, val_loss, val_acc, test_loss, test_acc</span>
<span class="sd">    '''</span>
    <span class="c1"># device</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Runing on </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="c1">## </span>
    <span class="n">train_all_data_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                      <span class="c1"># .to(device)</span>
    <span class="n">train_all_targets_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                <span class="c1"># .to(device)</span>
    <span class="n">test_all_data_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                        <span class="c1"># .to(device)</span>
    <span class="n">test_all_targets_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                  <span class="c1"># .to(device)</span>
    <span class="c1">## </span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                                                          <span class="c1"># .to(device)</span>

    <span class="k">def</span> <span class="nf">dl_plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">epoch_list</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">train_loss_list</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">train_acc_list</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">test_acc_list</span><span class="p">:</span><span class="nb">list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'font.sans-serif'</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="s1">'Times new roman'</span><span class="p">,</span> <span class="s1">'Arial'</span><span class="p">,</span> <span class="s1">'KaiTi'</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">([</span><span class="s1">'ggplot'</span><span class="p">,</span> <span class="s1">'seaborn'</span><span class="p">])</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">))</span>

        <span class="c1"># for y, label in zip([train_loss_list, train_acc_list, test_acc_list], ['train_loss', 'train_acc', 'test_acc']):</span>
        <span class="k">for</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">train_acc_list</span><span class="p">,</span> <span class="n">test_acc_list</span><span class="p">],</span> <span class="p">[</span><span class="s1">'train_acc'</span><span class="p">,</span> <span class="s1">'test_acc'</span><span class="p">]):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_list</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Values'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="c1"># plt.tight_layout()</span>

        <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
        <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># </span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">epoch_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">best_test_acc</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># </span>
    <span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">resume</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">PATH</span><span class="o">+</span><span class="s1">'/last.pt'</span><span class="p">):</span>
            <span class="n">check_point</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="o">+</span><span class="s1">'/last.pt'</span><span class="p">)</span>
            <span class="n">start_epoch</span> <span class="o">=</span> <span class="n">check_point</span><span class="p">[</span><span class="s1">'epoch'</span><span class="p">]</span>
            <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">check_point</span><span class="p">[</span><span class="s1">'model_state_dict'</span><span class="p">])</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">check_point</span><span class="p">[</span><span class="s1">'opt_state_dict'</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">''</span><span class="p">)</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="s1">'start_epoch: '</span><span class="p">,</span> <span class="n">start_epoch</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>                             <span class="c1"># </span>
        <span class="n">epoch_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch_record</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch_record</span>                 <span class="c1"># X, y</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   <span class="c1">## deviceGPU/CPU                    # .to(device)</span>
            <span class="c1"># print(X[0])</span>
            <span class="c1"># print(X[0].dtype)</span>
            <span class="c1"># break</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>                      <span class="c1"># y_hat</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>            <span class="c1"># loss</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>                     <span class="c1"># </span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>                     <span class="c1"># </span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>                          <span class="c1"># </span>

        <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>                              <span class="c1"># </span>
                                                <span class="c1"># net.train()</span>
                                                <span class="c1"># netBNDropouttesttraintest</span>
                                                <span class="c1"># netBNDropoutnet.eval()</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>                   <span class="c1"># withgrad</span>
            <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">),</span> <span class="n">train_all_targets_gpu</span><span class="p">)</span>
            <span class="n">train_loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="c1"># print(train_loss)</span>

            <span class="n">train_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">train_all_targets_gpu</span>
            <span class="n">train_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_acc_cmp</span><span class="p">))</span> 
            <span class="n">train_acc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="c1"># print(train_acc)</span>

            <span class="n">test_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">test_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">test_all_targets_gpu</span>
            <span class="n">test_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_acc_cmp</span><span class="p">))</span>
            <span class="n">test_acc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="c1"># print(test_acc)</span>

            <span class="k">if</span> <span class="n">train_figure</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">dl_plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">epoch_list</span><span class="p">,</span> <span class="n">train_loss_list</span><span class="p">,</span> <span class="n">train_acc_list</span><span class="p">,</span> <span class="n">test_acc_list</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">: train_loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s2">, train_acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s2">, test_acc=</span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="c1"># last.ptbest.pt</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s1">'epoch'</span><span class="p">:</span><span class="n">epoch</span><span class="p">,</span> <span class="s1">'model_state_dict'</span><span class="p">:</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'opt_state_dict'</span><span class="p">:</span><span class="n">opt</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'loss'</span><span class="p">:</span><span class="n">test_acc</span><span class="p">},</span> <span class="n">PATH</span><span class="o">+</span><span class="s1">'/last.pt'</span><span class="p">)</span> 
        <span class="k">if</span> <span class="n">test_acc</span> <span class="o">&gt;</span> <span class="n">best_test_acc</span><span class="p">:</span>
            <span class="n">best_test_acc</span> <span class="o">=</span> <span class="n">test_acc</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s1">'epoch'</span><span class="p">:</span><span class="n">epoch</span><span class="p">,</span> <span class="s1">'model_state_dict'</span><span class="p">:</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'opt_state_dict'</span><span class="p">:</span><span class="n">opt</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'loss'</span><span class="p">:</span><span class="n">test_acc</span><span class="p">},</span> <span class="n">PATH</span><span class="o">+</span><span class="s1">'/best.pt'</span><span class="p">)</span> 

    <span class="n">stop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start</span><span class="si">}</span><span class="s2"> seconds."</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span>
    <span class="c1"># return (epoch_list, train_loss_list, train_acc_list, test_acc_list)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.7.1.-%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83">8.7.1. <a id="toc8_7_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.7.1.-%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[82]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> 
    <span class="n">train_figure</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">resume</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
    <span class="n">PATH</span> <span class="o">=</span> <span class="s1">'./Pytorch_params/weights'</span>
<span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>====================================================================================================
 59.95664095878601 seconds.
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[82]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(1.7594, device='cuda:0'),
 tensor(0.7902, device='cuda:0'),
 tensor(0.8000, device='cuda:0'))</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[83]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">best</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'./Pytorch_params/weights/best.pt'</span><span class="p">)</span>
<span class="n">best</span><span class="p">[</span><span class="s1">'epoch'</span><span class="p">],</span> <span class="n">best</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">],</span> <span class="n">best</span><span class="p">[</span><span class="s1">'model_state_dict'</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/tmp/ipykernel_32820/198423743.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  best = torch.load('./Pytorch_params/weights/best.pt')
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[83]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(9,
 tensor(0.8000, device='cuda:0'),
 OrderedDict([('network.1.weight',
               tensor([[-0.0241, -0.0069,  0.0088,  ..., -0.0267, -0.0129, -0.0065],
                       [ 0.0302, -0.0323,  0.0237,  ..., -0.0168,  0.0240,  0.0341],
                       [-0.0151,  0.0176, -0.0027,  ...,  0.0083, -0.0131,  0.0065],
                       ...,
                       [ 0.0030,  0.0136, -0.0048,  ..., -0.0145, -0.0219, -0.0337],
                       [-0.0136, -0.0261,  0.0065,  ..., -0.0004,  0.0057,  0.0013],
                       [-0.0356, -0.0046, -0.0026,  ..., -0.0298,  0.0247,  0.0137]],
                      device='cuda:0')),
              ('network.1.bias',
               tensor([ 3.9702e-02,  3.4285e-02,  4.3656e-02, -7.5687e-04,  4.5628e-02,
                       -1.5764e-03,  9.1527e-03,  1.2884e-02,  5.1464e-02,  1.3203e-02,
                        3.2777e-02,  2.3281e-02, -7.0645e-07, -2.0750e-02,  1.0967e-02,
                        1.6538e-02, -3.8702e-02,  1.7775e-02,  4.1511e-02,  1.2678e-02,
                        2.1664e-02, -2.0623e-02,  3.2701e-02,  2.3492e-02,  4.9457e-03,
                        3.9780e-02, -1.1985e-02,  4.2158e-02,  5.6506e-02,  2.7593e-02,
                        9.5884e-03,  2.4593e-02,  5.3445e-03,  1.0407e-02, -2.9220e-02,
                       -7.0291e-03,  1.5674e-02, -1.9235e-02,  2.1151e-02,  2.2816e-02,
                        7.4965e-03,  5.0568e-02, -8.6301e-03, -1.1696e-02,  1.7590e-02,
                        5.1232e-02, -1.1965e-02,  3.1024e-02,  3.3625e-02,  1.2786e-02,
                        2.7856e-02,  2.0230e-02,  1.9761e-02,  4.9548e-02,  4.0749e-02,
                        1.2994e-02,  5.2624e-02,  2.0533e-02,  2.9313e-02,  6.8340e-03,
                       -2.8082e-02,  1.5062e-02, -3.0884e-02, -2.3156e-02, -2.2881e-03,
                        2.6252e-03, -3.0055e-02, -1.5311e-02,  3.1937e-02,  3.6528e-02,
                        3.3189e-02, -1.0149e-02,  2.0503e-02, -1.4367e-02,  4.2755e-02,
                       -1.9800e-02, -1.1765e-02,  3.1096e-02,  2.9567e-02, -2.6079e-02,
                        2.4057e-02,  2.8671e-02,  6.5098e-03,  1.6217e-02,  1.6545e-02,
                        1.9598e-02,  3.9184e-02, -1.1046e-02,  6.2070e-03,  3.1246e-02,
                        9.4902e-03,  3.0827e-02, -1.2420e-02, -1.8113e-02, -7.5191e-03,
                       -2.3051e-02,  1.2938e-02, -1.2393e-02, -2.3524e-02, -9.9774e-03,
                        8.9223e-03,  3.3172e-02,  3.3347e-02,  1.9719e-02, -5.4457e-03,
                        1.0521e-02, -2.5926e-03,  3.6220e-03, -8.9649e-03,  3.5096e-03,
                        3.9662e-02,  8.8037e-03,  2.5711e-02, -6.7204e-03, -8.7729e-03,
                        1.3268e-02,  2.2215e-02, -7.2406e-03,  1.6775e-03, -1.3178e-02,
                        2.2741e-02, -1.6813e-02,  6.5540e-03,  4.7898e-02,  1.7329e-02,
                       -1.8237e-02,  2.3492e-02, -2.1715e-02,  3.1797e-02, -2.3865e-03,
                        1.9146e-03,  2.0191e-02,  2.1575e-02, -5.3633e-03,  1.5864e-02,
                        4.8251e-02, -1.8978e-03, -2.8512e-03,  3.3479e-02,  3.3359e-02,
                       -2.1005e-02,  1.0200e-04, -2.5433e-02, -8.3805e-03,  5.2502e-02,
                       -2.7321e-02,  6.5998e-02,  8.3883e-03,  2.5566e-02,  8.6262e-03,
                       -2.2832e-02,  4.9074e-02, -2.7729e-02, -6.6179e-03,  3.1971e-02,
                        4.1276e-02, -2.6954e-02, -9.3661e-03, -6.8694e-03,  1.2666e-02,
                       -1.8432e-02, -3.2942e-02,  3.6010e-02,  1.3340e-02,  1.3230e-02,
                        1.2177e-03, -4.0268e-03,  2.4358e-02, -1.4252e-02,  1.7725e-02,
                        1.4390e-02,  4.5555e-02,  4.3820e-03, -9.9201e-03,  2.5283e-03,
                       -1.3692e-02, -3.6250e-02,  2.1885e-03,  3.5891e-02,  2.4769e-02,
                        9.7989e-03,  4.4549e-02,  1.1250e-02,  2.9513e-04, -8.4876e-03,
                       -1.0764e-02, -5.3896e-03,  3.9276e-02,  3.1027e-02,  1.1406e-02,
                        3.0260e-02,  1.2267e-02,  4.6958e-03,  3.7215e-02,  3.9977e-02,
                        3.3820e-02, -1.0931e-02,  1.0565e-02,  1.1181e-02, -1.3401e-02,
                        3.6825e-02,  4.5035e-02, -2.7077e-02, -2.0625e-02, -1.2974e-02,
                       -2.3754e-02,  3.1041e-02,  4.6583e-02,  5.2671e-02, -1.2074e-02,
                       -1.2163e-02, -2.2311e-02, -1.4121e-02, -2.3022e-02,  1.5178e-02,
                        2.2413e-02,  2.1362e-02, -1.1371e-02, -2.4531e-02,  3.2458e-02,
                        2.1671e-02,  3.3461e-02,  6.0620e-03,  2.3813e-02,  4.7138e-02,
                       -3.1214e-02, -2.6454e-03, -2.5188e-02,  3.4154e-02,  2.0549e-02,
                       -9.4273e-03,  2.9883e-02, -8.0837e-03,  4.4898e-02,  5.3602e-03,
                       -2.3646e-02,  2.8702e-02,  2.7271e-02,  5.5416e-02, -2.3502e-02,
                        1.4266e-02, -4.1066e-02,  3.4123e-02,  2.6651e-02,  3.1687e-02,
                        2.6590e-02, -3.7192e-03,  2.8239e-02,  5.7477e-03, -2.0121e-02,
                        5.4461e-03,  3.0526e-02, -9.5012e-03,  2.7479e-02, -2.8464e-02,
                        4.6071e-02], device='cuda:0')),
              ('network.3.weight',
               tensor([[-0.0505, -0.1163, -0.0902,  ..., -0.0762,  0.0453,  0.0470],
                       [ 0.0724,  0.1765,  0.0936,  ..., -0.0425,  0.0104, -0.0149],
                       [-0.0884, -0.0270,  0.0364,  ..., -0.0410, -0.0254, -0.0206],
                       ...,
                       [-0.0540,  0.0514, -0.1432,  ..., -0.1346, -0.0148,  0.1571],
                       [ 0.0946,  0.0494,  0.0184,  ...,  0.0630,  0.0512, -0.0797],
                       [ 0.0776,  0.0689, -0.0066,  ..., -0.0522,  0.0436, -0.0084]],
                      device='cuda:0')),
              ('network.3.bias',
               tensor([-0.0526,  0.1243, -0.0987,  0.0301,  0.0522, -0.0409,  0.0423,  0.0652,
                       -0.1231,  0.0462], device='cuda:0'))]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[98]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># netparameter</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>   
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>  
    
<span class="n">train_steps</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
            <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
            <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
            <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
            <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
            <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> 
            <span class="n">train_figure</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
            <span class="n">resume</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>====================================================================================================
 70.18707489967346 seconds.
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[98]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(1.7867), tensor(0.7317), tensor(0.7402))</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.7.2.-%E8%87%AA%E5%B7%B1%E6%8E%A2%E7%B4%A2">8.7.2. <a id="toc8_7_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.7.2.-%E8%87%AA%E5%B7%B1%E6%8E%A2%E7%B4%A2"></a></h3><h4 id="8.7.2.1.-lr%E7%9A%84%E5%BD%B1%E5%93%8D">8.7.2.1. <a id="toc8_7_2_1_"></a><a href="#toc0_">lr</a><a class="anchor-link" href="#8.7.2.1.-lr%E7%9A%84%E5%BD%B1%E5%93%8D"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[99]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># lr 0.01 -&gt; 0.5</span>
<span class="c1"># </span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>      
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>   
   
<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> 
    <span class="n">train_figure</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>====================================================================================================
 69.80070853233337 seconds.
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[99]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(1.4991), tensor(0.9673), tensor(0.9614))</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="8.7.2.2.-%E4%B8%8D%E5%90%8C%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%95%88%E7%8E%87">8.7.2.2. <a id="toc8_7_2_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.7.2.2.-%E4%B8%8D%E5%90%8C%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%95%88%E7%8E%87"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[119]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># test_acc92%</span>
<span class="c1"># CNN</span>
<span class="c1"># </span>

<span class="k">class</span> <span class="nc">Net1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net1</span><span class="p">()</span>  
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>   
   
<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> 
    <span class="n">train_figure</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>====================================================================================================
 87.9712917804718 seconds.
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[119]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(1.4962), tensor(0.9704), tensor(0.9643))</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="335.982812pt" height="265.325625pt" viewBox="0 0 335.982812 265.325625" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-04-25T11:13:04.145402</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M -0 265.325625 
L 335.982812 265.325625 
L 335.982812 0 
L -0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 44.782812 228.96 
L 323.782812 228.96 
L 323.782812 7.2 
L 44.782812 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 44.782812 228.96 
L 44.782812 7.2 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_2">
      <defs>
       <path id="m92953bacde" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m92953bacde" x="44.782812" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- 1 -->
      <g transform="translate(42.282812 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-31" d="M 750 3822 
L 1781 4325 
L 1884 4325 
L 1884 747 
Q 1884 391 1914 303 
Q 1944 216 2037 169 
Q 2131 122 2419 116 
L 2419 0 
L 825 0 
L 825 116 
Q 1125 122 1212 167 
Q 1300 213 1334 289 
Q 1369 366 1369 747 
L 1369 3034 
Q 1369 3497 1338 3628 
Q 1316 3728 1258 3775 
Q 1200 3822 1119 3822 
Q 1003 3822 797 3725 
L 750 3822 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-31"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_3">
      <path d="M 75.782813 228.96 
L 75.782813 7.2 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_4">
      <g>
       <use xlink:href="#m92953bacde" x="75.782813" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 2 -->
      <g transform="translate(73.282813 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-32" d="M 2934 816 
L 2638 0 
L 138 0 
L 138 116 
Q 1241 1122 1691 1759 
Q 2141 2397 2141 2925 
Q 2141 3328 1894 3587 
Q 1647 3847 1303 3847 
Q 991 3847 742 3664 
Q 494 3481 375 3128 
L 259 3128 
Q 338 3706 661 4015 
Q 984 4325 1469 4325 
Q 1984 4325 2329 3994 
Q 2675 3663 2675 3213 
Q 2675 2891 2525 2569 
Q 2294 2063 1775 1497 
Q 997 647 803 472 
L 1909 472 
Q 2247 472 2383 497 
Q 2519 522 2628 598 
Q 2738 675 2819 816 
L 2934 816 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-32"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_5">
      <path d="M 106.782813 228.96 
L 106.782813 7.2 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_6">
      <g>
       <use xlink:href="#m92953bacde" x="106.782813" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 3 -->
      <g transform="translate(104.282813 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-33" d="M 325 3431 
Q 506 3859 782 4092 
Q 1059 4325 1472 4325 
Q 1981 4325 2253 3994 
Q 2459 3747 2459 3466 
Q 2459 3003 1878 2509 
Q 2269 2356 2469 2072 
Q 2669 1788 2669 1403 
Q 2669 853 2319 450 
Q 1863 -75 997 -75 
Q 569 -75 414 31 
Q 259 138 259 259 
Q 259 350 332 419 
Q 406 488 509 488 
Q 588 488 669 463 
Q 722 447 909 348 
Q 1097 250 1169 231 
Q 1284 197 1416 197 
Q 1734 197 1970 444 
Q 2206 691 2206 1028 
Q 2206 1275 2097 1509 
Q 2016 1684 1919 1775 
Q 1784 1900 1550 2001 
Q 1316 2103 1072 2103 
L 972 2103 
L 972 2197 
Q 1219 2228 1467 2375 
Q 1716 2522 1828 2728 
Q 1941 2934 1941 3181 
Q 1941 3503 1739 3701 
Q 1538 3900 1238 3900 
Q 753 3900 428 3381 
L 325 3431 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-33"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_7">
      <path d="M 137.782813 228.96 
L 137.782813 7.2 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_8">
      <g>
       <use xlink:href="#m92953bacde" x="137.782813" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 4 -->
      <g transform="translate(135.282813 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-34" d="M 2978 1563 
L 2978 1119 
L 2409 1119 
L 2409 0 
L 1894 0 
L 1894 1119 
L 100 1119 
L 100 1519 
L 2066 4325 
L 2409 4325 
L 2409 1563 
L 2978 1563 
z
M 1894 1563 
L 1894 3666 
L 406 1563 
L 1894 1563 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-34"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_9">
      <path d="M 168.782813 228.96 
L 168.782813 7.2 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_10">
      <g>
       <use xlink:href="#m92953bacde" x="168.782813" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- 5 -->
      <g transform="translate(166.282813 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-35" d="M 2778 4238 
L 2534 3706 
L 1259 3706 
L 981 3138 
Q 1809 3016 2294 2522 
Q 2709 2097 2709 1522 
Q 2709 1188 2573 903 
Q 2438 619 2231 419 
Q 2025 219 1772 97 
Q 1413 -75 1034 -75 
Q 653 -75 479 54 
Q 306 184 306 341 
Q 306 428 378 495 
Q 450 563 559 563 
Q 641 563 702 538 
Q 763 513 909 409 
Q 1144 247 1384 247 
Q 1750 247 2026 523 
Q 2303 800 2303 1197 
Q 2303 1581 2056 1914 
Q 1809 2247 1375 2428 
Q 1034 2569 447 2591 
L 1259 4238 
L 2778 4238 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-35"/>
      </g>
     </g>
    </g>
    <g id="xtick_6">
     <g id="line2d_11">
      <path d="M 199.782813 228.96 
L 199.782813 7.2 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_12">
      <g>
       <use xlink:href="#m92953bacde" x="199.782813" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_6">
      <!-- 6 -->
      <g transform="translate(197.282813 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-36" d="M 2869 4325 
L 2869 4209 
Q 2456 4169 2195 4045 
Q 1934 3922 1679 3669 
Q 1425 3416 1258 3105 
Q 1091 2794 978 2366 
Q 1428 2675 1881 2675 
Q 2316 2675 2634 2325 
Q 2953 1975 2953 1425 
Q 2953 894 2631 456 
Q 2244 -75 1606 -75 
Q 1172 -75 869 213 
Q 275 772 275 1663 
Q 275 2231 503 2743 
Q 731 3256 1154 3653 
Q 1578 4050 1965 4187 
Q 2353 4325 2688 4325 
L 2869 4325 
z
M 925 2138 
Q 869 1716 869 1456 
Q 869 1156 980 804 
Q 1091 453 1309 247 
Q 1469 100 1697 100 
Q 1969 100 2183 356 
Q 2397 613 2397 1088 
Q 2397 1622 2184 2012 
Q 1972 2403 1581 2403 
Q 1463 2403 1327 2353 
Q 1191 2303 925 2138 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-36"/>
      </g>
     </g>
    </g>
    <g id="xtick_7">
     <g id="line2d_13">
      <path d="M 230.782813 228.96 
L 230.782813 7.2 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_14">
      <g>
       <use xlink:href="#m92953bacde" x="230.782813" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 7 -->
      <g transform="translate(228.282813 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-37" d="M 644 4238 
L 2916 4238 
L 2916 4119 
L 1503 -88 
L 1153 -88 
L 2419 3728 
L 1253 3728 
Q 900 3728 750 3644 
Q 488 3500 328 3200 
L 238 3234 
L 644 4238 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-37"/>
      </g>
     </g>
    </g>
    <g id="xtick_8">
     <g id="line2d_15">
      <path d="M 261.782812 228.96 
L 261.782812 7.2 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_16">
      <g>
       <use xlink:href="#m92953bacde" x="261.782812" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 8 -->
      <g transform="translate(259.282812 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-38" d="M 1228 2134 
Q 725 2547 579 2797 
Q 434 3047 434 3316 
Q 434 3728 753 4026 
Q 1072 4325 1600 4325 
Q 2113 4325 2425 4047 
Q 2738 3769 2738 3413 
Q 2738 3175 2569 2928 
Q 2400 2681 1866 2347 
Q 2416 1922 2594 1678 
Q 2831 1359 2831 1006 
Q 2831 559 2490 242 
Q 2150 -75 1597 -75 
Q 994 -75 656 303 
Q 388 606 388 966 
Q 388 1247 577 1523 
Q 766 1800 1228 2134 
z
M 1719 2469 
Q 2094 2806 2194 3001 
Q 2294 3197 2294 3444 
Q 2294 3772 2109 3958 
Q 1925 4144 1606 4144 
Q 1288 4144 1088 3959 
Q 888 3775 888 3528 
Q 888 3366 970 3203 
Q 1053 3041 1206 2894 
L 1719 2469 
z
M 1375 2016 
Q 1116 1797 991 1539 
Q 866 1281 866 981 
Q 866 578 1086 336 
Q 1306 94 1647 94 
Q 1984 94 2187 284 
Q 2391 475 2391 747 
Q 2391 972 2272 1150 
Q 2050 1481 1375 2016 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-38"/>
      </g>
     </g>
    </g>
    <g id="xtick_9">
     <g id="line2d_17">
      <path d="M 292.782812 228.96 
L 292.782812 7.2 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_18">
      <g>
       <use xlink:href="#m92953bacde" x="292.782812" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <!-- 9 -->
      <g transform="translate(290.282812 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-39" d="M 338 -88 
L 338 28 
Q 744 34 1094 217 
Q 1444 400 1770 856 
Q 2097 1313 2225 1859 
Q 1734 1544 1338 1544 
Q 891 1544 572 1889 
Q 253 2234 253 2806 
Q 253 3363 572 3797 
Q 956 4325 1575 4325 
Q 2097 4325 2469 3894 
Q 2925 3359 2925 2575 
Q 2925 1869 2578 1258 
Q 2231 647 1613 244 
Q 1109 -88 516 -88 
L 338 -88 
z
M 2275 2091 
Q 2331 2497 2331 2741 
Q 2331 3044 2228 3395 
Q 2125 3747 1936 3934 
Q 1747 4122 1506 4122 
Q 1228 4122 1018 3872 
Q 809 3622 809 3128 
Q 809 2469 1088 2097 
Q 1291 1828 1588 1828 
Q 1731 1828 1928 1897 
Q 2125 1966 2275 2091 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-39"/>
      </g>
     </g>
    </g>
    <g id="xtick_10">
     <g id="line2d_19">
      <path d="M 323.782812 228.96 
L 323.782812 7.2 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_20">
      <g>
       <use xlink:href="#m92953bacde" x="323.782812" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_10">
      <!-- 10 -->
      <g transform="translate(318.782812 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-30" d="M 231 2094 
Q 231 2819 450 3342 
Q 669 3866 1031 4122 
Q 1313 4325 1613 4325 
Q 2100 4325 2488 3828 
Q 2972 3213 2972 2159 
Q 2972 1422 2759 906 
Q 2547 391 2217 158 
Q 1888 -75 1581 -75 
Q 975 -75 572 641 
Q 231 1244 231 2094 
z
M 844 2016 
Q 844 1141 1059 588 
Q 1238 122 1591 122 
Q 1759 122 1940 273 
Q 2122 425 2216 781 
Q 2359 1319 2359 2297 
Q 2359 3022 2209 3506 
Q 2097 3866 1919 4016 
Q 1791 4119 1609 4119 
Q 1397 4119 1231 3928 
Q 1006 3669 925 3112 
Q 844 2556 844 2016 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-31"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="50"/>
      </g>
     </g>
    </g>
    <g id="text_11">
     <!-- Epoch -->
     <g transform="translate(171.509375 255.986562) scale(0.1 -0.1)">
      <defs>
       <path id="TimesNewRomanPSMT-45" d="M 1338 4006 
L 1338 2331 
L 2269 2331 
Q 2631 2331 2753 2441 
Q 2916 2584 2934 2947 
L 3050 2947 
L 3050 1472 
L 2934 1472 
Q 2891 1781 2847 1869 
Q 2791 1978 2662 2040 
Q 2534 2103 2269 2103 
L 1338 2103 
L 1338 706 
Q 1338 425 1363 364 
Q 1388 303 1450 267 
Q 1513 231 1688 231 
L 2406 231 
Q 2766 231 2928 281 
Q 3091 331 3241 478 
Q 3434 672 3638 1063 
L 3763 1063 
L 3397 0 
L 131 0 
L 131 116 
L 281 116 
Q 431 116 566 188 
Q 666 238 702 338 
Q 738 438 738 747 
L 738 3500 
Q 738 3903 656 3997 
Q 544 4122 281 4122 
L 131 4122 
L 131 4238 
L 3397 4238 
L 3444 3309 
L 3322 3309 
Q 3256 3644 3176 3769 
Q 3097 3894 2941 3959 
Q 2816 4006 2500 4006 
L 1338 4006 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-70" d="M -6 2578 
L 875 2934 
L 994 2934 
L 994 2266 
Q 1216 2644 1439 2795 
Q 1663 2947 1909 2947 
Q 2341 2947 2628 2609 
Q 2981 2197 2981 1534 
Q 2981 794 2556 309 
Q 2206 -88 1675 -88 
Q 1444 -88 1275 -22 
Q 1150 25 994 166 
L 994 -706 
Q 994 -1000 1030 -1079 
Q 1066 -1159 1155 -1206 
Q 1244 -1253 1478 -1253 
L 1478 -1369 
L -22 -1369 
L -22 -1253 
L 56 -1253 
Q 228 -1256 350 -1188 
Q 409 -1153 442 -1076 
Q 475 -1000 475 -688 
L 475 2019 
Q 475 2297 450 2372 
Q 425 2447 370 2484 
Q 316 2522 222 2522 
Q 147 2522 31 2478 
L -6 2578 
z
M 994 2081 
L 994 1013 
Q 994 666 1022 556 
Q 1066 375 1236 237 
Q 1406 100 1666 100 
Q 1978 100 2172 344 
Q 2425 663 2425 1241 
Q 2425 1897 2138 2250 
Q 1938 2494 1663 2494 
Q 1513 2494 1366 2419 
Q 1253 2363 994 2081 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-6f" d="M 1600 2947 
Q 2250 2947 2644 2453 
Q 2978 2031 2978 1484 
Q 2978 1100 2793 706 
Q 2609 313 2286 112 
Q 1963 -88 1566 -88 
Q 919 -88 538 428 
Q 216 863 216 1403 
Q 216 1797 411 2186 
Q 606 2575 925 2761 
Q 1244 2947 1600 2947 
z
M 1503 2744 
Q 1338 2744 1170 2645 
Q 1003 2547 900 2300 
Q 797 2053 797 1666 
Q 797 1041 1045 587 
Q 1294 134 1700 134 
Q 2003 134 2200 384 
Q 2397 634 2397 1244 
Q 2397 2006 2069 2444 
Q 1847 2744 1503 2744 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-63" d="M 2631 1088 
Q 2516 522 2178 217 
Q 1841 -88 1431 -88 
Q 944 -88 581 321 
Q 219 731 219 1428 
Q 219 2103 620 2525 
Q 1022 2947 1584 2947 
Q 2006 2947 2278 2723 
Q 2550 2500 2550 2259 
Q 2550 2141 2473 2067 
Q 2397 1994 2259 1994 
Q 2075 1994 1981 2113 
Q 1928 2178 1911 2362 
Q 1894 2547 1784 2644 
Q 1675 2738 1481 2738 
Q 1169 2738 978 2506 
Q 725 2200 725 1697 
Q 725 1184 976 792 
Q 1228 400 1656 400 
Q 1963 400 2206 609 
Q 2378 753 2541 1131 
L 2631 1088 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-68" d="M 1041 4444 
L 1041 2350 
Q 1388 2731 1591 2839 
Q 1794 2947 1997 2947 
Q 2241 2947 2416 2812 
Q 2591 2678 2675 2391 
Q 2734 2191 2734 1659 
L 2734 647 
Q 2734 375 2778 275 
Q 2809 200 2884 156 
Q 2959 113 3159 113 
L 3159 0 
L 1753 0 
L 1753 113 
L 1819 113 
Q 2019 113 2097 173 
Q 2175 234 2206 353 
Q 2216 403 2216 647 
L 2216 1659 
Q 2216 2128 2167 2275 
Q 2119 2422 2012 2495 
Q 1906 2569 1756 2569 
Q 1603 2569 1437 2487 
Q 1272 2406 1041 2159 
L 1041 647 
Q 1041 353 1073 281 
Q 1106 209 1195 161 
Q 1284 113 1503 113 
L 1503 0 
L 84 0 
L 84 113 
Q 275 113 384 172 
Q 447 203 484 290 
Q 522 378 522 647 
L 522 3238 
Q 522 3728 498 3840 
Q 475 3953 426 3993 
Q 378 4034 297 4034 
Q 231 4034 84 3984 
L 41 4094 
L 897 4444 
L 1041 4444 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#TimesNewRomanPSMT-45"/>
      <use xlink:href="#TimesNewRomanPSMT-70" x="61.083984"/>
      <use xlink:href="#TimesNewRomanPSMT-6f" x="111.083984"/>
      <use xlink:href="#TimesNewRomanPSMT-63" x="161.083984"/>
      <use xlink:href="#TimesNewRomanPSMT-68" x="205.46875"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_21">
      <path d="M 44.782812 228.96 
L 323.782812 228.96 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_22">
      <defs>
       <path id="m2ec95d50d3" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_12">
      <!-- 0.00 -->
      <g transform="translate(20.282812 232.431875) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-2e" d="M 800 606 
Q 947 606 1047 504 
Q 1147 403 1147 259 
Q 1147 116 1045 14 
Q 944 -88 800 -88 
Q 656 -88 554 14 
Q 453 116 453 259 
Q 453 406 554 506 
Q 656 606 800 606 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_23">
      <path d="M 44.782812 217.872 
L 323.782812 217.872 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_24">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="217.872" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_13">
      <!-- 0.05 -->
      <g transform="translate(20.282812 221.343875) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_25">
      <path d="M 44.782812 206.784 
L 323.782812 206.784 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_26">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="206.784" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_14">
      <!-- 0.10 -->
      <g transform="translate(20.282812 210.255875) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-31" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_27">
      <path d="M 44.782812 195.695999 
L 323.782812 195.695999 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_28">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="195.695999" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_15">
      <!-- 0.15 -->
      <g transform="translate(20.282812 199.167874) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-31" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_29">
      <path d="M 44.782812 184.607999 
L 323.782812 184.607999 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_30">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="184.607999" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_16">
      <!-- 0.20 -->
      <g transform="translate(20.282812 188.079874) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-32" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_6">
     <g id="line2d_31">
      <path d="M 44.782812 173.52 
L 323.782812 173.52 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_32">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="173.52" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_17">
      <!-- 0.25 -->
      <g transform="translate(20.282812 176.991875) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-32" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_7">
     <g id="line2d_33">
      <path d="M 44.782812 162.431997 
L 323.782812 162.431997 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_34">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="162.431997" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_18">
      <!-- 0.30 -->
      <g transform="translate(20.282812 165.903872) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-33" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_8">
     <g id="line2d_35">
      <path d="M 44.782812 151.344001 
L 323.782812 151.344001 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_36">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="151.344001" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_19">
      <!-- 0.35 -->
      <g transform="translate(20.282812 154.815876) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-33" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_9">
     <g id="line2d_37">
      <path d="M 44.782812 140.255999 
L 323.782812 140.255999 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_38">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="140.255999" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_20">
      <!-- 0.40 -->
      <g transform="translate(20.282812 143.727874) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-34" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_10">
     <g id="line2d_39">
      <path d="M 44.782812 129.167996 
L 323.782812 129.167996 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_40">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="129.167996" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_21">
      <!-- 0.45 -->
      <g transform="translate(20.282812 132.639871) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-34" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_11">
     <g id="line2d_41">
      <path d="M 44.782812 118.08 
L 323.782812 118.08 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_42">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="118.08" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_22">
      <!-- 0.50 -->
      <g transform="translate(20.282812 121.551875) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_12">
     <g id="line2d_43">
      <path d="M 44.782812 106.991997 
L 323.782812 106.991997 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_44">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="106.991997" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_23">
      <!-- 0.55 -->
      <g transform="translate(20.282812 110.463872) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_13">
     <g id="line2d_45">
      <path d="M 44.782812 95.903995 
L 323.782812 95.903995 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_46">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="95.903995" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_24">
      <!-- 0.60 -->
      <g transform="translate(20.282812 99.37587) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-36" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_14">
     <g id="line2d_47">
      <path d="M 44.782812 84.816005 
L 323.782812 84.816005 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_48">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="84.816005" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_25">
      <!-- 0.65 -->
      <g transform="translate(20.282812 88.28788) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-36" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_15">
     <g id="line2d_49">
      <path d="M 44.782812 73.728003 
L 323.782812 73.728003 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_50">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="73.728003" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_26">
      <!-- 0.70 -->
      <g transform="translate(20.282812 77.199878) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-37" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_16">
     <g id="line2d_51">
      <path d="M 44.782812 62.64 
L 323.782812 62.64 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_52">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="62.64" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_27">
      <!-- 0.75 -->
      <g transform="translate(20.282812 66.111875) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-37" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_17">
     <g id="line2d_53">
      <path d="M 44.782812 51.551997 
L 323.782812 51.551997 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_54">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="51.551997" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_28">
      <!-- 0.80 -->
      <g transform="translate(20.282812 55.023872) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-38" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_18">
     <g id="line2d_55">
      <path d="M 44.782812 40.463995 
L 323.782812 40.463995 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_56">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="40.463995" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_29">
      <!-- 0.85 -->
      <g transform="translate(20.282812 43.93587) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-38" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_19">
     <g id="line2d_57">
      <path d="M 44.782812 29.376005 
L 323.782812 29.376005 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_58">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="29.376005" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_30">
      <!-- 0.90 -->
      <g transform="translate(20.282812 32.84788) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-39" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_20">
     <g id="line2d_59">
      <path d="M 44.782812 18.288003 
L 323.782812 18.288003 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_60">
      <g>
       <use xlink:href="#m2ec95d50d3" x="44.782812" y="18.288003" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_31">
      <!-- 0.95 -->
      <g transform="translate(20.282812 21.759878) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-39" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="text_32">
     <!-- Values -->
     <g transform="translate(14.14375 131.408906) rotate(-90) scale(0.1 -0.1)">
      <defs>
       <path id="TimesNewRomanPSMT-56" d="M 4544 4238 
L 4544 4122 
Q 4319 4081 4203 3978 
Q 4038 3825 3909 3509 
L 2431 -97 
L 2316 -97 
L 728 3556 
Q 606 3838 556 3900 
Q 478 3997 364 4051 
Q 250 4106 56 4122 
L 56 4238 
L 1788 4238 
L 1788 4122 
Q 1494 4094 1406 4022 
Q 1319 3950 1319 3838 
Q 1319 3681 1463 3350 
L 2541 866 
L 3541 3319 
Q 3688 3681 3688 3822 
Q 3688 3913 3597 3995 
Q 3506 4078 3291 4113 
Q 3275 4116 3238 4122 
L 3238 4238 
L 4544 4238 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-61" d="M 1822 413 
Q 1381 72 1269 19 
Q 1100 -59 909 -59 
Q 613 -59 420 144 
Q 228 347 228 678 
Q 228 888 322 1041 
Q 450 1253 767 1440 
Q 1084 1628 1822 1897 
L 1822 2009 
Q 1822 2438 1686 2597 
Q 1550 2756 1291 2756 
Q 1094 2756 978 2650 
Q 859 2544 859 2406 
L 866 2225 
Q 866 2081 792 2003 
Q 719 1925 600 1925 
Q 484 1925 411 2006 
Q 338 2088 338 2228 
Q 338 2497 613 2722 
Q 888 2947 1384 2947 
Q 1766 2947 2009 2819 
Q 2194 2722 2281 2516 
Q 2338 2381 2338 1966 
L 2338 994 
Q 2338 584 2353 492 
Q 2369 400 2405 369 
Q 2441 338 2488 338 
Q 2538 338 2575 359 
Q 2641 400 2828 588 
L 2828 413 
Q 2478 -56 2159 -56 
Q 2006 -56 1915 50 
Q 1825 156 1822 413 
z
M 1822 616 
L 1822 1706 
Q 1350 1519 1213 1441 
Q 966 1303 859 1153 
Q 753 1003 753 825 
Q 753 600 887 451 
Q 1022 303 1197 303 
Q 1434 303 1822 616 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-6c" d="M 1184 4444 
L 1184 647 
Q 1184 378 1223 290 
Q 1263 203 1344 158 
Q 1425 113 1647 113 
L 1647 0 
L 244 0 
L 244 113 
Q 441 113 512 153 
Q 584 194 625 287 
Q 666 381 666 647 
L 666 3247 
Q 666 3731 644 3842 
Q 622 3953 573 3993 
Q 525 4034 450 4034 
Q 369 4034 244 3984 
L 191 4094 
L 1044 4444 
L 1184 4444 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-75" d="M 2709 2863 
L 2709 1128 
Q 2709 631 2732 520 
Q 2756 409 2807 365 
Q 2859 322 2928 322 
Q 3025 322 3147 375 
L 3191 266 
L 2334 -88 
L 2194 -88 
L 2194 519 
Q 1825 119 1631 15 
Q 1438 -88 1222 -88 
Q 981 -88 804 51 
Q 628 191 559 409 
Q 491 628 491 1028 
L 491 2306 
Q 491 2509 447 2587 
Q 403 2666 317 2708 
Q 231 2750 6 2747 
L 6 2863 
L 1009 2863 
L 1009 947 
Q 1009 547 1148 422 
Q 1288 297 1484 297 
Q 1619 297 1789 381 
Q 1959 466 2194 703 
L 2194 2325 
Q 2194 2569 2105 2655 
Q 2016 2741 1734 2747 
L 1734 2863 
L 2709 2863 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-65" d="M 681 1784 
Q 678 1147 991 784 
Q 1303 422 1725 422 
Q 2006 422 2214 576 
Q 2422 731 2563 1106 
L 2659 1044 
Q 2594 616 2278 264 
Q 1963 -88 1488 -88 
Q 972 -88 605 314 
Q 238 716 238 1394 
Q 238 2128 614 2539 
Q 991 2950 1559 2950 
Q 2041 2950 2350 2633 
Q 2659 2316 2659 1784 
L 681 1784 
z
M 681 1966 
L 2006 1966 
Q 1991 2241 1941 2353 
Q 1863 2528 1708 2628 
Q 1553 2728 1384 2728 
Q 1125 2728 920 2526 
Q 716 2325 681 1966 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-73" d="M 2050 2947 
L 2050 1972 
L 1947 1972 
Q 1828 2431 1642 2597 
Q 1456 2763 1169 2763 
Q 950 2763 815 2647 
Q 681 2531 681 2391 
Q 681 2216 781 2091 
Q 878 1963 1175 1819 
L 1631 1597 
Q 2266 1288 2266 781 
Q 2266 391 1970 151 
Q 1675 -88 1309 -88 
Q 1047 -88 709 6 
Q 606 38 541 38 
Q 469 38 428 -44 
L 325 -44 
L 325 978 
L 428 978 
Q 516 541 762 319 
Q 1009 97 1316 97 
Q 1531 97 1667 223 
Q 1803 350 1803 528 
Q 1803 744 1651 891 
Q 1500 1038 1047 1263 
Q 594 1488 453 1669 
Q 313 1847 313 2119 
Q 313 2472 555 2709 
Q 797 2947 1181 2947 
Q 1350 2947 1591 2875 
Q 1750 2828 1803 2828 
Q 1853 2828 1881 2850 
Q 1909 2872 1947 2947 
L 2050 2947 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#TimesNewRomanPSMT-56"/>
      <use xlink:href="#TimesNewRomanPSMT-61" x="61.091797"/>
      <use xlink:href="#TimesNewRomanPSMT-6c" x="105.476562"/>
      <use xlink:href="#TimesNewRomanPSMT-75" x="133.259766"/>
      <use xlink:href="#TimesNewRomanPSMT-65" x="183.259766"/>
      <use xlink:href="#TimesNewRomanPSMT-73" x="227.644531"/>
     </g>
    </g>
   </g>
   <g id="line2d_61">
    <path d="M 44.782812 41.894346 
L 75.782813 24.622945 
L 106.782813 21.26698 
L 137.782813 20.35407 
L 168.782813 18.262122 
L 199.782813 17.020271 
L 230.782813 15.996477 
L 261.782812 14.891379 
L 292.782812 14.248274 
L 323.782812 13.753012 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="line2d_62">
    <path d="M 44.782812 40.707932 
L 75.782813 24.031588 
L 106.782813 21.614399 
L 137.782813 21.126526 
L 168.782813 18.975454 
L 199.782813 18.177117 
L 230.782813 17.134844 
L 261.782812 16.136931 
L 292.782812 15.693403 
L 323.782812 15.116837 
" clip-path="url(#p21d23a3a71)" style="fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="patch_3">
    <path d="M 44.782812 228.96 
L 44.782812 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 323.782812 228.96 
L 323.782812 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 44.782812 228.96 
L 323.782812 228.96 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 44.782812 7.2 
L 323.782812 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="legend_1">
    <g id="patch_7">
     <path d="M 51.782812 223.96 
L 120.425 223.96 
Q 122.425 223.96 122.425 221.96 
L 122.425 194.644375 
Q 122.425 192.644375 120.425 192.644375 
L 51.782812 192.644375 
Q 49.782812 192.644375 49.782812 194.644375 
L 49.782812 221.96 
Q 49.782812 223.96 51.782812 223.96 
z
" style="fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter"/>
    </g>
    <g id="line2d_63">
     <path d="M 53.782812 200.144375 
L 63.782812 200.144375 
L 73.782813 200.144375 
" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
    </g>
    <g id="text_33">
     <!-- train_acc -->
     <g transform="translate(81.782813 203.644375) scale(0.1 -0.1)">
      <defs>
       <path id="TimesNewRomanPSMT-74" d="M 1031 3803 
L 1031 2863 
L 1700 2863 
L 1700 2644 
L 1031 2644 
L 1031 788 
Q 1031 509 1111 412 
Q 1191 316 1316 316 
Q 1419 316 1516 380 
Q 1613 444 1666 569 
L 1788 569 
Q 1678 263 1478 108 
Q 1278 -47 1066 -47 
Q 922 -47 784 33 
Q 647 113 581 261 
Q 516 409 516 719 
L 516 2644 
L 63 2644 
L 63 2747 
Q 234 2816 414 2980 
Q 594 3144 734 3369 
Q 806 3488 934 3803 
L 1031 3803 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-72" d="M 1038 2947 
L 1038 2303 
Q 1397 2947 1775 2947 
Q 1947 2947 2059 2842 
Q 2172 2738 2172 2600 
Q 2172 2478 2090 2393 
Q 2009 2309 1897 2309 
Q 1788 2309 1652 2417 
Q 1516 2525 1450 2525 
Q 1394 2525 1328 2463 
Q 1188 2334 1038 2041 
L 1038 669 
Q 1038 431 1097 309 
Q 1138 225 1241 169 
Q 1344 113 1538 113 
L 1538 0 
L 72 0 
L 72 113 
Q 291 113 397 181 
Q 475 231 506 341 
Q 522 394 522 644 
L 522 1753 
Q 522 2253 501 2348 
Q 481 2444 426 2487 
Q 372 2531 291 2531 
Q 194 2531 72 2484 
L 41 2597 
L 906 2947 
L 1038 2947 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-69" d="M 928 4444 
Q 1059 4444 1151 4351 
Q 1244 4259 1244 4128 
Q 1244 3997 1151 3903 
Q 1059 3809 928 3809 
Q 797 3809 703 3903 
Q 609 3997 609 4128 
Q 609 4259 701 4351 
Q 794 4444 928 4444 
z
M 1188 2947 
L 1188 647 
Q 1188 378 1227 289 
Q 1266 200 1342 156 
Q 1419 113 1622 113 
L 1622 0 
L 231 0 
L 231 113 
Q 441 113 512 153 
Q 584 194 626 287 
Q 669 381 669 647 
L 669 1750 
Q 669 2216 641 2353 
Q 619 2453 572 2492 
Q 525 2531 444 2531 
Q 356 2531 231 2484 
L 188 2597 
L 1050 2947 
L 1188 2947 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-6e" d="M 1034 2341 
Q 1538 2947 1994 2947 
Q 2228 2947 2397 2830 
Q 2566 2713 2666 2444 
Q 2734 2256 2734 1869 
L 2734 647 
Q 2734 375 2778 278 
Q 2813 200 2889 156 
Q 2966 113 3172 113 
L 3172 0 
L 1756 0 
L 1756 113 
L 1816 113 
Q 2016 113 2095 173 
Q 2175 234 2206 353 
Q 2219 400 2219 647 
L 2219 1819 
Q 2219 2209 2117 2386 
Q 2016 2563 1775 2563 
Q 1403 2563 1034 2156 
L 1034 647 
Q 1034 356 1069 288 
Q 1113 197 1189 155 
Q 1266 113 1500 113 
L 1500 0 
L 84 0 
L 84 113 
L 147 113 
Q 366 113 442 223 
Q 519 334 519 647 
L 519 1709 
Q 519 2225 495 2337 
Q 472 2450 423 2490 
Q 375 2531 294 2531 
Q 206 2531 84 2484 
L 38 2597 
L 900 2947 
L 1034 2947 
L 1034 2341 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-5f" d="M 3256 -1381 
L -53 -1381 
L -53 -1119 
L 3256 -1119 
L 3256 -1381 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#TimesNewRomanPSMT-74"/>
      <use xlink:href="#TimesNewRomanPSMT-72" x="27.783203"/>
      <use xlink:href="#TimesNewRomanPSMT-61" x="61.083984"/>
      <use xlink:href="#TimesNewRomanPSMT-69" x="105.46875"/>
      <use xlink:href="#TimesNewRomanPSMT-6e" x="133.251953"/>
      <use xlink:href="#TimesNewRomanPSMT-5f" x="183.251953"/>
      <use xlink:href="#TimesNewRomanPSMT-61" x="233.251953"/>
      <use xlink:href="#TimesNewRomanPSMT-63" x="277.636719"/>
      <use xlink:href="#TimesNewRomanPSMT-63" x="322.021484"/>
     </g>
    </g>
    <g id="line2d_64">
     <path d="M 53.782812 214.302187 
L 63.782812 214.302187 
L 73.782813 214.302187 
" style="fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square"/>
    </g>
    <g id="text_34">
     <!-- test_acc -->
     <g transform="translate(81.782813 217.802187) scale(0.1 -0.1)">
      <use xlink:href="#TimesNewRomanPSMT-74"/>
      <use xlink:href="#TimesNewRomanPSMT-65" x="27.783203"/>
      <use xlink:href="#TimesNewRomanPSMT-73" x="72.167969"/>
      <use xlink:href="#TimesNewRomanPSMT-74" x="111.083984"/>
      <use xlink:href="#TimesNewRomanPSMT-5f" x="138.867188"/>
      <use xlink:href="#TimesNewRomanPSMT-61" x="188.867188"/>
      <use xlink:href="#TimesNewRomanPSMT-63" x="233.251953"/>
      <use xlink:href="#TimesNewRomanPSMT-63" x="277.636719"/>
     </g>
    </g>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="p21d23a3a71">
   <rect x="44.782812" y="7.2" width="279" height="221.76"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[120]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span> 
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span> 


<span class="c1"># </span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># </span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># self.network = nn.Sequential(nn.Flatten(),</span>
        <span class="c1">#                              nn.Linear(28*28, 2**5), nn.ReLU(),</span>
        <span class="c1">#                              nn.Linear(2**5, 10), nn.Softmax())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hidden</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ac</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="c1"># self.ac = nn.Tanh()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hidden</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer5</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ac</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer3</span><span class="p">(</span><span class="n">y</span><span class="p">))))</span>
                   
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer5</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> 
    <span class="n">train_figure</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>====================================================================================================
 210.56247329711914 seconds.
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[120]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor(1.4977), tensor(0.9650), tensor(0.9571))</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="335.982812pt" height="265.325625pt" viewBox="0 0 335.982812 265.325625" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-04-25T11:16:47.537576</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M -0 265.325625 
L 335.982812 265.325625 
L 335.982812 0 
L -0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 44.782812 228.96 
L 323.782812 228.96 
L 323.782812 7.2 
L 44.782812 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 83.265571 228.96 
L 83.265571 7.2 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_2">
      <defs>
       <path id="mc04ace902a" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#mc04ace902a" x="83.265571" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- 5 -->
      <g transform="translate(80.765571 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-35" d="M 2778 4238 
L 2534 3706 
L 1259 3706 
L 981 3138 
Q 1809 3016 2294 2522 
Q 2709 2097 2709 1522 
Q 2709 1188 2573 903 
Q 2438 619 2231 419 
Q 2025 219 1772 97 
Q 1413 -75 1034 -75 
Q 653 -75 479 54 
Q 306 184 306 341 
Q 306 428 378 495 
Q 450 563 559 563 
Q 641 563 702 538 
Q 763 513 909 409 
Q 1144 247 1384 247 
Q 1750 247 2026 523 
Q 2303 800 2303 1197 
Q 2303 1581 2056 1914 
Q 1809 2247 1375 2428 
Q 1034 2569 447 2591 
L 1259 4238 
L 2778 4238 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-35"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_3">
      <path d="M 131.369019 228.96 
L 131.369019 7.2 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_4">
      <g>
       <use xlink:href="#mc04ace902a" x="131.369019" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 10 -->
      <g transform="translate(126.369019 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-31" d="M 750 3822 
L 1781 4325 
L 1884 4325 
L 1884 747 
Q 1884 391 1914 303 
Q 1944 216 2037 169 
Q 2131 122 2419 116 
L 2419 0 
L 825 0 
L 825 116 
Q 1125 122 1212 167 
Q 1300 213 1334 289 
Q 1369 366 1369 747 
L 1369 3034 
Q 1369 3497 1338 3628 
Q 1316 3728 1258 3775 
Q 1200 3822 1119 3822 
Q 1003 3822 797 3725 
L 750 3822 
z
" transform="scale(0.015625)"/>
        <path id="TimesNewRomanPSMT-30" d="M 231 2094 
Q 231 2819 450 3342 
Q 669 3866 1031 4122 
Q 1313 4325 1613 4325 
Q 2100 4325 2488 3828 
Q 2972 3213 2972 2159 
Q 2972 1422 2759 906 
Q 2547 391 2217 158 
Q 1888 -75 1581 -75 
Q 975 -75 572 641 
Q 231 1244 231 2094 
z
M 844 2016 
Q 844 1141 1059 588 
Q 1238 122 1591 122 
Q 1759 122 1940 273 
Q 2122 425 2216 781 
Q 2359 1319 2359 2297 
Q 2359 3022 2209 3506 
Q 2097 3866 1919 4016 
Q 1791 4119 1609 4119 
Q 1397 4119 1231 3928 
Q 1006 3669 925 3112 
Q 844 2556 844 2016 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-31"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="50"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_5">
      <path d="M 179.472468 228.96 
L 179.472468 7.2 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_6">
      <g>
       <use xlink:href="#mc04ace902a" x="179.472468" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 15 -->
      <g transform="translate(174.472468 242.90375) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-31"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="50"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_7">
      <path d="M 227.575916 228.96 
L 227.575916 7.2 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_8">
      <g>
       <use xlink:href="#mc04ace902a" x="227.575916" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 20 -->
      <g transform="translate(222.575916 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-32" d="M 2934 816 
L 2638 0 
L 138 0 
L 138 116 
Q 1241 1122 1691 1759 
Q 2141 2397 2141 2925 
Q 2141 3328 1894 3587 
Q 1647 3847 1303 3847 
Q 991 3847 742 3664 
Q 494 3481 375 3128 
L 259 3128 
Q 338 3706 661 4015 
Q 984 4325 1469 4325 
Q 1984 4325 2329 3994 
Q 2675 3663 2675 3213 
Q 2675 2891 2525 2569 
Q 2294 2063 1775 1497 
Q 997 647 803 472 
L 1909 472 
Q 2247 472 2383 497 
Q 2519 522 2628 598 
Q 2738 675 2819 816 
L 2934 816 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-32"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="50"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_9">
      <path d="M 275.679364 228.96 
L 275.679364 7.2 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_10">
      <g>
       <use xlink:href="#mc04ace902a" x="275.679364" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- 25 -->
      <g transform="translate(270.679364 242.90375) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-32"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="50"/>
      </g>
     </g>
    </g>
    <g id="xtick_6">
     <g id="line2d_11">
      <path d="M 323.782812 228.96 
L 323.782812 7.2 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_12">
      <g>
       <use xlink:href="#mc04ace902a" x="323.782812" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_6">
      <!-- 30 -->
      <g transform="translate(318.782812 242.90375) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-33" d="M 325 3431 
Q 506 3859 782 4092 
Q 1059 4325 1472 4325 
Q 1981 4325 2253 3994 
Q 2459 3747 2459 3466 
Q 2459 3003 1878 2509 
Q 2269 2356 2469 2072 
Q 2669 1788 2669 1403 
Q 2669 853 2319 450 
Q 1863 -75 997 -75 
Q 569 -75 414 31 
Q 259 138 259 259 
Q 259 350 332 419 
Q 406 488 509 488 
Q 588 488 669 463 
Q 722 447 909 348 
Q 1097 250 1169 231 
Q 1284 197 1416 197 
Q 1734 197 1970 444 
Q 2206 691 2206 1028 
Q 2206 1275 2097 1509 
Q 2016 1684 1919 1775 
Q 1784 1900 1550 2001 
Q 1316 2103 1072 2103 
L 972 2103 
L 972 2197 
Q 1219 2228 1467 2375 
Q 1716 2522 1828 2728 
Q 1941 2934 1941 3181 
Q 1941 3503 1739 3701 
Q 1538 3900 1238 3900 
Q 753 3900 428 3381 
L 325 3431 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-33"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="50"/>
      </g>
     </g>
    </g>
    <g id="text_7">
     <!-- Epoch -->
     <g transform="translate(171.509375 255.986562) scale(0.1 -0.1)">
      <defs>
       <path id="TimesNewRomanPSMT-45" d="M 1338 4006 
L 1338 2331 
L 2269 2331 
Q 2631 2331 2753 2441 
Q 2916 2584 2934 2947 
L 3050 2947 
L 3050 1472 
L 2934 1472 
Q 2891 1781 2847 1869 
Q 2791 1978 2662 2040 
Q 2534 2103 2269 2103 
L 1338 2103 
L 1338 706 
Q 1338 425 1363 364 
Q 1388 303 1450 267 
Q 1513 231 1688 231 
L 2406 231 
Q 2766 231 2928 281 
Q 3091 331 3241 478 
Q 3434 672 3638 1063 
L 3763 1063 
L 3397 0 
L 131 0 
L 131 116 
L 281 116 
Q 431 116 566 188 
Q 666 238 702 338 
Q 738 438 738 747 
L 738 3500 
Q 738 3903 656 3997 
Q 544 4122 281 4122 
L 131 4122 
L 131 4238 
L 3397 4238 
L 3444 3309 
L 3322 3309 
Q 3256 3644 3176 3769 
Q 3097 3894 2941 3959 
Q 2816 4006 2500 4006 
L 1338 4006 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-70" d="M -6 2578 
L 875 2934 
L 994 2934 
L 994 2266 
Q 1216 2644 1439 2795 
Q 1663 2947 1909 2947 
Q 2341 2947 2628 2609 
Q 2981 2197 2981 1534 
Q 2981 794 2556 309 
Q 2206 -88 1675 -88 
Q 1444 -88 1275 -22 
Q 1150 25 994 166 
L 994 -706 
Q 994 -1000 1030 -1079 
Q 1066 -1159 1155 -1206 
Q 1244 -1253 1478 -1253 
L 1478 -1369 
L -22 -1369 
L -22 -1253 
L 56 -1253 
Q 228 -1256 350 -1188 
Q 409 -1153 442 -1076 
Q 475 -1000 475 -688 
L 475 2019 
Q 475 2297 450 2372 
Q 425 2447 370 2484 
Q 316 2522 222 2522 
Q 147 2522 31 2478 
L -6 2578 
z
M 994 2081 
L 994 1013 
Q 994 666 1022 556 
Q 1066 375 1236 237 
Q 1406 100 1666 100 
Q 1978 100 2172 344 
Q 2425 663 2425 1241 
Q 2425 1897 2138 2250 
Q 1938 2494 1663 2494 
Q 1513 2494 1366 2419 
Q 1253 2363 994 2081 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-6f" d="M 1600 2947 
Q 2250 2947 2644 2453 
Q 2978 2031 2978 1484 
Q 2978 1100 2793 706 
Q 2609 313 2286 112 
Q 1963 -88 1566 -88 
Q 919 -88 538 428 
Q 216 863 216 1403 
Q 216 1797 411 2186 
Q 606 2575 925 2761 
Q 1244 2947 1600 2947 
z
M 1503 2744 
Q 1338 2744 1170 2645 
Q 1003 2547 900 2300 
Q 797 2053 797 1666 
Q 797 1041 1045 587 
Q 1294 134 1700 134 
Q 2003 134 2200 384 
Q 2397 634 2397 1244 
Q 2397 2006 2069 2444 
Q 1847 2744 1503 2744 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-63" d="M 2631 1088 
Q 2516 522 2178 217 
Q 1841 -88 1431 -88 
Q 944 -88 581 321 
Q 219 731 219 1428 
Q 219 2103 620 2525 
Q 1022 2947 1584 2947 
Q 2006 2947 2278 2723 
Q 2550 2500 2550 2259 
Q 2550 2141 2473 2067 
Q 2397 1994 2259 1994 
Q 2075 1994 1981 2113 
Q 1928 2178 1911 2362 
Q 1894 2547 1784 2644 
Q 1675 2738 1481 2738 
Q 1169 2738 978 2506 
Q 725 2200 725 1697 
Q 725 1184 976 792 
Q 1228 400 1656 400 
Q 1963 400 2206 609 
Q 2378 753 2541 1131 
L 2631 1088 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-68" d="M 1041 4444 
L 1041 2350 
Q 1388 2731 1591 2839 
Q 1794 2947 1997 2947 
Q 2241 2947 2416 2812 
Q 2591 2678 2675 2391 
Q 2734 2191 2734 1659 
L 2734 647 
Q 2734 375 2778 275 
Q 2809 200 2884 156 
Q 2959 113 3159 113 
L 3159 0 
L 1753 0 
L 1753 113 
L 1819 113 
Q 2019 113 2097 173 
Q 2175 234 2206 353 
Q 2216 403 2216 647 
L 2216 1659 
Q 2216 2128 2167 2275 
Q 2119 2422 2012 2495 
Q 1906 2569 1756 2569 
Q 1603 2569 1437 2487 
Q 1272 2406 1041 2159 
L 1041 647 
Q 1041 353 1073 281 
Q 1106 209 1195 161 
Q 1284 113 1503 113 
L 1503 0 
L 84 0 
L 84 113 
Q 275 113 384 172 
Q 447 203 484 290 
Q 522 378 522 647 
L 522 3238 
Q 522 3728 498 3840 
Q 475 3953 426 3993 
Q 378 4034 297 4034 
Q 231 4034 84 3984 
L 41 4094 
L 897 4444 
L 1041 4444 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#TimesNewRomanPSMT-45"/>
      <use xlink:href="#TimesNewRomanPSMT-70" x="61.083984"/>
      <use xlink:href="#TimesNewRomanPSMT-6f" x="111.083984"/>
      <use xlink:href="#TimesNewRomanPSMT-63" x="161.083984"/>
      <use xlink:href="#TimesNewRomanPSMT-68" x="205.46875"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_13">
      <path d="M 44.782812 228.96 
L 323.782812 228.96 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_14">
      <defs>
       <path id="mcd123fd2b1" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="228.96" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 0.00 -->
      <g transform="translate(20.282812 232.431875) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-2e" d="M 800 606 
Q 947 606 1047 504 
Q 1147 403 1147 259 
Q 1147 116 1045 14 
Q 944 -88 800 -88 
Q 656 -88 554 14 
Q 453 116 453 259 
Q 453 406 554 506 
Q 656 606 800 606 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_15">
      <path d="M 44.782812 217.872 
L 323.782812 217.872 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_16">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="217.872" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <!-- 0.05 -->
      <g transform="translate(20.282812 221.343875) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_17">
      <path d="M 44.782812 206.784 
L 323.782812 206.784 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_18">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="206.784" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_10">
      <!-- 0.10 -->
      <g transform="translate(20.282812 210.255875) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-31" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_19">
      <path d="M 44.782812 195.695999 
L 323.782812 195.695999 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_20">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="195.695999" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_11">
      <!-- 0.15 -->
      <g transform="translate(20.282812 199.167874) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-31" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_21">
      <path d="M 44.782812 184.607999 
L 323.782812 184.607999 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_22">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="184.607999" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_12">
      <!-- 0.20 -->
      <g transform="translate(20.282812 188.079874) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-32" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_6">
     <g id="line2d_23">
      <path d="M 44.782812 173.52 
L 323.782812 173.52 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_24">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="173.52" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_13">
      <!-- 0.25 -->
      <g transform="translate(20.282812 176.991875) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-32" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_7">
     <g id="line2d_25">
      <path d="M 44.782812 162.431997 
L 323.782812 162.431997 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_26">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="162.431997" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_14">
      <!-- 0.30 -->
      <g transform="translate(20.282812 165.903872) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-33" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_8">
     <g id="line2d_27">
      <path d="M 44.782812 151.344001 
L 323.782812 151.344001 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_28">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="151.344001" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_15">
      <!-- 0.35 -->
      <g transform="translate(20.282812 154.815876) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-33" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_9">
     <g id="line2d_29">
      <path d="M 44.782812 140.255999 
L 323.782812 140.255999 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_30">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="140.255999" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_16">
      <!-- 0.40 -->
      <g transform="translate(20.282812 143.727874) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-34" d="M 2978 1563 
L 2978 1119 
L 2409 1119 
L 2409 0 
L 1894 0 
L 1894 1119 
L 100 1119 
L 100 1519 
L 2066 4325 
L 2409 4325 
L 2409 1563 
L 2978 1563 
z
M 1894 1563 
L 1894 3666 
L 406 1563 
L 1894 1563 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-34" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_10">
     <g id="line2d_31">
      <path d="M 44.782812 129.167996 
L 323.782812 129.167996 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_32">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="129.167996" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_17">
      <!-- 0.45 -->
      <g transform="translate(20.282812 132.639871) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-34" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_11">
     <g id="line2d_33">
      <path d="M 44.782812 118.08 
L 323.782812 118.08 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_34">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="118.08" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_18">
      <!-- 0.50 -->
      <g transform="translate(20.282812 121.551875) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_12">
     <g id="line2d_35">
      <path d="M 44.782812 106.991997 
L 323.782812 106.991997 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_36">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="106.991997" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_19">
      <!-- 0.55 -->
      <g transform="translate(20.282812 110.463872) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_13">
     <g id="line2d_37">
      <path d="M 44.782812 95.903995 
L 323.782812 95.903995 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_38">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="95.903995" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_20">
      <!-- 0.60 -->
      <g transform="translate(20.282812 99.37587) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-36" d="M 2869 4325 
L 2869 4209 
Q 2456 4169 2195 4045 
Q 1934 3922 1679 3669 
Q 1425 3416 1258 3105 
Q 1091 2794 978 2366 
Q 1428 2675 1881 2675 
Q 2316 2675 2634 2325 
Q 2953 1975 2953 1425 
Q 2953 894 2631 456 
Q 2244 -75 1606 -75 
Q 1172 -75 869 213 
Q 275 772 275 1663 
Q 275 2231 503 2743 
Q 731 3256 1154 3653 
Q 1578 4050 1965 4187 
Q 2353 4325 2688 4325 
L 2869 4325 
z
M 925 2138 
Q 869 1716 869 1456 
Q 869 1156 980 804 
Q 1091 453 1309 247 
Q 1469 100 1697 100 
Q 1969 100 2183 356 
Q 2397 613 2397 1088 
Q 2397 1622 2184 2012 
Q 1972 2403 1581 2403 
Q 1463 2403 1327 2353 
Q 1191 2303 925 2138 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-36" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_14">
     <g id="line2d_39">
      <path d="M 44.782812 84.816005 
L 323.782812 84.816005 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_40">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="84.816005" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_21">
      <!-- 0.65 -->
      <g transform="translate(20.282812 88.28788) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-36" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_15">
     <g id="line2d_41">
      <path d="M 44.782812 73.728003 
L 323.782812 73.728003 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_42">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="73.728003" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_22">
      <!-- 0.70 -->
      <g transform="translate(20.282812 77.199878) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-37" d="M 644 4238 
L 2916 4238 
L 2916 4119 
L 1503 -88 
L 1153 -88 
L 2419 3728 
L 1253 3728 
Q 900 3728 750 3644 
Q 488 3500 328 3200 
L 238 3234 
L 644 4238 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-37" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_16">
     <g id="line2d_43">
      <path d="M 44.782812 62.64 
L 323.782812 62.64 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_44">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="62.64" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_23">
      <!-- 0.75 -->
      <g transform="translate(20.282812 66.111875) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-37" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_17">
     <g id="line2d_45">
      <path d="M 44.782812 51.551997 
L 323.782812 51.551997 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_46">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="51.551997" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_24">
      <!-- 0.80 -->
      <g transform="translate(20.282812 55.023872) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-38" d="M 1228 2134 
Q 725 2547 579 2797 
Q 434 3047 434 3316 
Q 434 3728 753 4026 
Q 1072 4325 1600 4325 
Q 2113 4325 2425 4047 
Q 2738 3769 2738 3413 
Q 2738 3175 2569 2928 
Q 2400 2681 1866 2347 
Q 2416 1922 2594 1678 
Q 2831 1359 2831 1006 
Q 2831 559 2490 242 
Q 2150 -75 1597 -75 
Q 994 -75 656 303 
Q 388 606 388 966 
Q 388 1247 577 1523 
Q 766 1800 1228 2134 
z
M 1719 2469 
Q 2094 2806 2194 3001 
Q 2294 3197 2294 3444 
Q 2294 3772 2109 3958 
Q 1925 4144 1606 4144 
Q 1288 4144 1088 3959 
Q 888 3775 888 3528 
Q 888 3366 970 3203 
Q 1053 3041 1206 2894 
L 1719 2469 
z
M 1375 2016 
Q 1116 1797 991 1539 
Q 866 1281 866 981 
Q 866 578 1086 336 
Q 1306 94 1647 94 
Q 1984 94 2187 284 
Q 2391 475 2391 747 
Q 2391 972 2272 1150 
Q 2050 1481 1375 2016 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-38" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_18">
     <g id="line2d_47">
      <path d="M 44.782812 40.463995 
L 323.782812 40.463995 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_48">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="40.463995" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_25">
      <!-- 0.85 -->
      <g transform="translate(20.282812 43.93587) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-38" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_19">
     <g id="line2d_49">
      <path d="M 44.782812 29.376005 
L 323.782812 29.376005 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_50">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="29.376005" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_26">
      <!-- 0.90 -->
      <g transform="translate(20.282812 32.84788) scale(0.1 -0.1)">
       <defs>
        <path id="TimesNewRomanPSMT-39" d="M 338 -88 
L 338 28 
Q 744 34 1094 217 
Q 1444 400 1770 856 
Q 2097 1313 2225 1859 
Q 1734 1544 1338 1544 
Q 891 1544 572 1889 
Q 253 2234 253 2806 
Q 253 3363 572 3797 
Q 956 4325 1575 4325 
Q 2097 4325 2469 3894 
Q 2925 3359 2925 2575 
Q 2925 1869 2578 1258 
Q 2231 647 1613 244 
Q 1109 -88 516 -88 
L 338 -88 
z
M 2275 2091 
Q 2331 2497 2331 2741 
Q 2331 3044 2228 3395 
Q 2125 3747 1936 3934 
Q 1747 4122 1506 4122 
Q 1228 4122 1018 3872 
Q 809 3622 809 3128 
Q 809 2469 1088 2097 
Q 1291 1828 1588 1828 
Q 1731 1828 1928 1897 
Q 2125 1966 2275 2091 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-39" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-30" x="125"/>
      </g>
     </g>
    </g>
    <g id="ytick_20">
     <g id="line2d_51">
      <path d="M 44.782812 18.288003 
L 323.782812 18.288003 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_52">
      <g>
       <use xlink:href="#mcd123fd2b1" x="44.782812" y="18.288003" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_27">
      <!-- 0.95 -->
      <g transform="translate(20.282812 21.759878) scale(0.1 -0.1)">
       <use xlink:href="#TimesNewRomanPSMT-30"/>
       <use xlink:href="#TimesNewRomanPSMT-2e" x="50"/>
       <use xlink:href="#TimesNewRomanPSMT-39" x="75"/>
       <use xlink:href="#TimesNewRomanPSMT-35" x="125"/>
      </g>
     </g>
    </g>
    <g id="text_28">
     <!-- Values -->
     <g transform="translate(14.14375 131.408906) rotate(-90) scale(0.1 -0.1)">
      <defs>
       <path id="TimesNewRomanPSMT-56" d="M 4544 4238 
L 4544 4122 
Q 4319 4081 4203 3978 
Q 4038 3825 3909 3509 
L 2431 -97 
L 2316 -97 
L 728 3556 
Q 606 3838 556 3900 
Q 478 3997 364 4051 
Q 250 4106 56 4122 
L 56 4238 
L 1788 4238 
L 1788 4122 
Q 1494 4094 1406 4022 
Q 1319 3950 1319 3838 
Q 1319 3681 1463 3350 
L 2541 866 
L 3541 3319 
Q 3688 3681 3688 3822 
Q 3688 3913 3597 3995 
Q 3506 4078 3291 4113 
Q 3275 4116 3238 4122 
L 3238 4238 
L 4544 4238 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-61" d="M 1822 413 
Q 1381 72 1269 19 
Q 1100 -59 909 -59 
Q 613 -59 420 144 
Q 228 347 228 678 
Q 228 888 322 1041 
Q 450 1253 767 1440 
Q 1084 1628 1822 1897 
L 1822 2009 
Q 1822 2438 1686 2597 
Q 1550 2756 1291 2756 
Q 1094 2756 978 2650 
Q 859 2544 859 2406 
L 866 2225 
Q 866 2081 792 2003 
Q 719 1925 600 1925 
Q 484 1925 411 2006 
Q 338 2088 338 2228 
Q 338 2497 613 2722 
Q 888 2947 1384 2947 
Q 1766 2947 2009 2819 
Q 2194 2722 2281 2516 
Q 2338 2381 2338 1966 
L 2338 994 
Q 2338 584 2353 492 
Q 2369 400 2405 369 
Q 2441 338 2488 338 
Q 2538 338 2575 359 
Q 2641 400 2828 588 
L 2828 413 
Q 2478 -56 2159 -56 
Q 2006 -56 1915 50 
Q 1825 156 1822 413 
z
M 1822 616 
L 1822 1706 
Q 1350 1519 1213 1441 
Q 966 1303 859 1153 
Q 753 1003 753 825 
Q 753 600 887 451 
Q 1022 303 1197 303 
Q 1434 303 1822 616 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-6c" d="M 1184 4444 
L 1184 647 
Q 1184 378 1223 290 
Q 1263 203 1344 158 
Q 1425 113 1647 113 
L 1647 0 
L 244 0 
L 244 113 
Q 441 113 512 153 
Q 584 194 625 287 
Q 666 381 666 647 
L 666 3247 
Q 666 3731 644 3842 
Q 622 3953 573 3993 
Q 525 4034 450 4034 
Q 369 4034 244 3984 
L 191 4094 
L 1044 4444 
L 1184 4444 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-75" d="M 2709 2863 
L 2709 1128 
Q 2709 631 2732 520 
Q 2756 409 2807 365 
Q 2859 322 2928 322 
Q 3025 322 3147 375 
L 3191 266 
L 2334 -88 
L 2194 -88 
L 2194 519 
Q 1825 119 1631 15 
Q 1438 -88 1222 -88 
Q 981 -88 804 51 
Q 628 191 559 409 
Q 491 628 491 1028 
L 491 2306 
Q 491 2509 447 2587 
Q 403 2666 317 2708 
Q 231 2750 6 2747 
L 6 2863 
L 1009 2863 
L 1009 947 
Q 1009 547 1148 422 
Q 1288 297 1484 297 
Q 1619 297 1789 381 
Q 1959 466 2194 703 
L 2194 2325 
Q 2194 2569 2105 2655 
Q 2016 2741 1734 2747 
L 1734 2863 
L 2709 2863 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-65" d="M 681 1784 
Q 678 1147 991 784 
Q 1303 422 1725 422 
Q 2006 422 2214 576 
Q 2422 731 2563 1106 
L 2659 1044 
Q 2594 616 2278 264 
Q 1963 -88 1488 -88 
Q 972 -88 605 314 
Q 238 716 238 1394 
Q 238 2128 614 2539 
Q 991 2950 1559 2950 
Q 2041 2950 2350 2633 
Q 2659 2316 2659 1784 
L 681 1784 
z
M 681 1966 
L 2006 1966 
Q 1991 2241 1941 2353 
Q 1863 2528 1708 2628 
Q 1553 2728 1384 2728 
Q 1125 2728 920 2526 
Q 716 2325 681 1966 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-73" d="M 2050 2947 
L 2050 1972 
L 1947 1972 
Q 1828 2431 1642 2597 
Q 1456 2763 1169 2763 
Q 950 2763 815 2647 
Q 681 2531 681 2391 
Q 681 2216 781 2091 
Q 878 1963 1175 1819 
L 1631 1597 
Q 2266 1288 2266 781 
Q 2266 391 1970 151 
Q 1675 -88 1309 -88 
Q 1047 -88 709 6 
Q 606 38 541 38 
Q 469 38 428 -44 
L 325 -44 
L 325 978 
L 428 978 
Q 516 541 762 319 
Q 1009 97 1316 97 
Q 1531 97 1667 223 
Q 1803 350 1803 528 
Q 1803 744 1651 891 
Q 1500 1038 1047 1263 
Q 594 1488 453 1669 
Q 313 1847 313 2119 
Q 313 2472 555 2709 
Q 797 2947 1181 2947 
Q 1350 2947 1591 2875 
Q 1750 2828 1803 2828 
Q 1853 2828 1881 2850 
Q 1909 2872 1947 2947 
L 2050 2947 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#TimesNewRomanPSMT-56"/>
      <use xlink:href="#TimesNewRomanPSMT-61" x="61.091797"/>
      <use xlink:href="#TimesNewRomanPSMT-6c" x="105.476562"/>
      <use xlink:href="#TimesNewRomanPSMT-75" x="133.259766"/>
      <use xlink:href="#TimesNewRomanPSMT-65" x="183.259766"/>
      <use xlink:href="#TimesNewRomanPSMT-73" x="227.644531"/>
     </g>
    </g>
   </g>
   <g id="line2d_53">
    <path d="M 44.782812 27.317327 
L 54.403502 23.913314 
L 64.024192 23.163025 
L 73.644881 21.640267 
L 83.265571 20.716268 
L 92.886261 20.383626 
L 102.50695 19.07895 
L 112.12764 18.720427 
L 121.74833 18.398875 
L 131.369019 17.707722 
L 140.989709 18.288003 
L 150.610399 17.219862 
L 160.231088 16.84286 
L 169.851778 16.813292 
L 179.472468 16.550876 
L 189.093157 16.354987 
L 198.713847 16.84286 
L 208.334537 16.32173 
L 217.955226 16.107362 
L 227.575916 16.151708 
L 237.196606 15.778421 
L 246.817295 16.007567 
L 256.437985 15.815378 
L 266.058675 15.545574 
L 275.679364 15.353372 
L 285.300054 15.368163 
L 294.920744 15.04661 
L 304.541433 15.334893 
L 314.162123 15.212931 
L 323.782812 14.965294 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="line2d_54">
    <path d="M 44.782812 27.114048 
L 54.403502 23.499355 
L 64.024192 23.299778 
L 73.644881 21.547874 
L 83.265571 20.727358 
L 92.886261 21.281757 
L 102.50695 19.951201 
L 112.12764 19.662918 
L 121.74833 19.24157 
L 131.369019 18.642811 
L 140.989709 19.552033 
L 150.610399 18.376708 
L 160.231088 18.044066 
L 169.851778 18.376708 
L 179.472468 18.110592 
L 189.093157 17.511846 
L 198.713847 17.999706 
L 208.334537 17.866655 
L 217.955226 17.711423 
L 227.575916 17.866655 
L 237.196606 17.090498 
L 246.817295 17.711423 
L 256.437985 17.777949 
L 266.058675 17.445307 
L 275.679364 16.735676 
L 285.300054 17.334435 
L 294.920744 16.447393 
L 304.541433 16.868741 
L 314.162123 17.068319 
L 323.782812 16.71351 
" clip-path="url(#pef7e57143d)" style="fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="patch_3">
    <path d="M 44.782812 228.96 
L 44.782812 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 323.782812 228.96 
L 323.782812 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 44.782812 228.96 
L 323.782812 228.96 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 44.782812 7.2 
L 323.782812 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="legend_1">
    <g id="patch_7">
     <path d="M 51.782812 223.96 
L 120.425 223.96 
Q 122.425 223.96 122.425 221.96 
L 122.425 194.644375 
Q 122.425 192.644375 120.425 192.644375 
L 51.782812 192.644375 
Q 49.782812 192.644375 49.782812 194.644375 
L 49.782812 221.96 
Q 49.782812 223.96 51.782812 223.96 
z
" style="fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter"/>
    </g>
    <g id="line2d_55">
     <path d="M 53.782812 200.144375 
L 63.782812 200.144375 
L 73.782813 200.144375 
" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
    </g>
    <g id="text_29">
     <!-- train_acc -->
     <g transform="translate(81.782813 203.644375) scale(0.1 -0.1)">
      <defs>
       <path id="TimesNewRomanPSMT-74" d="M 1031 3803 
L 1031 2863 
L 1700 2863 
L 1700 2644 
L 1031 2644 
L 1031 788 
Q 1031 509 1111 412 
Q 1191 316 1316 316 
Q 1419 316 1516 380 
Q 1613 444 1666 569 
L 1788 569 
Q 1678 263 1478 108 
Q 1278 -47 1066 -47 
Q 922 -47 784 33 
Q 647 113 581 261 
Q 516 409 516 719 
L 516 2644 
L 63 2644 
L 63 2747 
Q 234 2816 414 2980 
Q 594 3144 734 3369 
Q 806 3488 934 3803 
L 1031 3803 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-72" d="M 1038 2947 
L 1038 2303 
Q 1397 2947 1775 2947 
Q 1947 2947 2059 2842 
Q 2172 2738 2172 2600 
Q 2172 2478 2090 2393 
Q 2009 2309 1897 2309 
Q 1788 2309 1652 2417 
Q 1516 2525 1450 2525 
Q 1394 2525 1328 2463 
Q 1188 2334 1038 2041 
L 1038 669 
Q 1038 431 1097 309 
Q 1138 225 1241 169 
Q 1344 113 1538 113 
L 1538 0 
L 72 0 
L 72 113 
Q 291 113 397 181 
Q 475 231 506 341 
Q 522 394 522 644 
L 522 1753 
Q 522 2253 501 2348 
Q 481 2444 426 2487 
Q 372 2531 291 2531 
Q 194 2531 72 2484 
L 41 2597 
L 906 2947 
L 1038 2947 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-69" d="M 928 4444 
Q 1059 4444 1151 4351 
Q 1244 4259 1244 4128 
Q 1244 3997 1151 3903 
Q 1059 3809 928 3809 
Q 797 3809 703 3903 
Q 609 3997 609 4128 
Q 609 4259 701 4351 
Q 794 4444 928 4444 
z
M 1188 2947 
L 1188 647 
Q 1188 378 1227 289 
Q 1266 200 1342 156 
Q 1419 113 1622 113 
L 1622 0 
L 231 0 
L 231 113 
Q 441 113 512 153 
Q 584 194 626 287 
Q 669 381 669 647 
L 669 1750 
Q 669 2216 641 2353 
Q 619 2453 572 2492 
Q 525 2531 444 2531 
Q 356 2531 231 2484 
L 188 2597 
L 1050 2947 
L 1188 2947 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-6e" d="M 1034 2341 
Q 1538 2947 1994 2947 
Q 2228 2947 2397 2830 
Q 2566 2713 2666 2444 
Q 2734 2256 2734 1869 
L 2734 647 
Q 2734 375 2778 278 
Q 2813 200 2889 156 
Q 2966 113 3172 113 
L 3172 0 
L 1756 0 
L 1756 113 
L 1816 113 
Q 2016 113 2095 173 
Q 2175 234 2206 353 
Q 2219 400 2219 647 
L 2219 1819 
Q 2219 2209 2117 2386 
Q 2016 2563 1775 2563 
Q 1403 2563 1034 2156 
L 1034 647 
Q 1034 356 1069 288 
Q 1113 197 1189 155 
Q 1266 113 1500 113 
L 1500 0 
L 84 0 
L 84 113 
L 147 113 
Q 366 113 442 223 
Q 519 334 519 647 
L 519 1709 
Q 519 2225 495 2337 
Q 472 2450 423 2490 
Q 375 2531 294 2531 
Q 206 2531 84 2484 
L 38 2597 
L 900 2947 
L 1034 2947 
L 1034 2341 
z
" transform="scale(0.015625)"/>
       <path id="TimesNewRomanPSMT-5f" d="M 3256 -1381 
L -53 -1381 
L -53 -1119 
L 3256 -1119 
L 3256 -1381 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#TimesNewRomanPSMT-74"/>
      <use xlink:href="#TimesNewRomanPSMT-72" x="27.783203"/>
      <use xlink:href="#TimesNewRomanPSMT-61" x="61.083984"/>
      <use xlink:href="#TimesNewRomanPSMT-69" x="105.46875"/>
      <use xlink:href="#TimesNewRomanPSMT-6e" x="133.251953"/>
      <use xlink:href="#TimesNewRomanPSMT-5f" x="183.251953"/>
      <use xlink:href="#TimesNewRomanPSMT-61" x="233.251953"/>
      <use xlink:href="#TimesNewRomanPSMT-63" x="277.636719"/>
      <use xlink:href="#TimesNewRomanPSMT-63" x="322.021484"/>
     </g>
    </g>
    <g id="line2d_56">
     <path d="M 53.782812 214.302187 
L 63.782812 214.302187 
L 73.782813 214.302187 
" style="fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square"/>
    </g>
    <g id="text_30">
     <!-- test_acc -->
     <g transform="translate(81.782813 217.802187) scale(0.1 -0.1)">
      <use xlink:href="#TimesNewRomanPSMT-74"/>
      <use xlink:href="#TimesNewRomanPSMT-65" x="27.783203"/>
      <use xlink:href="#TimesNewRomanPSMT-73" x="72.167969"/>
      <use xlink:href="#TimesNewRomanPSMT-74" x="111.083984"/>
      <use xlink:href="#TimesNewRomanPSMT-5f" x="138.867188"/>
      <use xlink:href="#TimesNewRomanPSMT-61" x="188.867188"/>
      <use xlink:href="#TimesNewRomanPSMT-63" x="233.251953"/>
      <use xlink:href="#TimesNewRomanPSMT-63" x="277.636719"/>
     </g>
    </g>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="pef7e57143d">
   <rect x="44.782812" y="7.2" width="279" height="221.76"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="8.7.3.-K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81">8.7.3. <a id="toc8_7_3_"></a><a href="#toc0_">K</a><a class="anchor-link" href="#8.7.3.-K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"></a></h3><ul>
<li>K1Test_dataK-1Train_dataKTest_acc</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[90]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_k_fold_data</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="c1"># k1</span>
    <span class="n">fold_size</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">k</span> <span class="c1"># Xk</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'fold_size: '</span><span class="p">,</span> <span class="n">fold_size</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="n">fold_size</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">fold_size</span><span class="p">)</span> <span class="c1">#  ()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="n">X_part</span><span class="p">,</span> <span class="n">y_part</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="n">i</span><span class="p">:</span>
            <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">X_part</span><span class="p">,</span> <span class="n">y_part</span>
        <span class="k">elif</span> <span class="n">X_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X_part</span><span class="p">,</span> <span class="n">y_part</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_part</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_part</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[85]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">negative</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[85]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[ 0,  1,  2],
         [ 3,  4,  5],
         [ 6,  7,  8],
         [ 9, 10, 11],
         [12, 13, 14]]),
 tensor([[  0,  -1,  -2],
         [ -3,  -4,  -5],
         [ -6,  -7,  -8],
         [ -9, -10, -11],
         [-12, -13, -14]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[92]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">get_k_fold_data</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>fold_size:  2
slice(0, 2, None)
slice(2, 4, None)
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[92]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[0, 1, 2],
         [3, 4, 5]]),
 tensor([[ 0, -1, -2],
         [-3, -4, -5]]),
 tensor([[ 6,  7,  8],
         [ 9, 10, 11]]),
 tensor([[ -6,  -7,  -8],
         [ -9, -10, -11]]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.8.-%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B">8.8. <a id="toc8_8_"></a><a href="#toc0_"></a><a class="anchor-link" href="#8.8.-%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"></a></h2><ul>
<li><ul>
<li>figure plt.clf() # figure</li>
<li>figure <code>plt.colse()</code> # figure</li>
<li>axes plt.cla() # axes</li>
</ul>
</li>
<li>plot</li>
<li>jupyterdisplay</li>
<li>yupyterdisplay</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[78]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">dl_plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''jupyter'''</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>                                 <span class="c1"># close figure </span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'epoch'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'loss'</span><span class="p">)</span>

    <span class="c1"># plt.show()                                # </span>
    <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>                        <span class="c1"># jupyter </span>
    <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>             <span class="c1">#  </span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">dl_plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre> 2.1650073528289795 seconds
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[87]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># dl_plot(x, y)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="mi">10</span><span class="si">}</span><span class="s2">: </span><span class="se">\t</span><span class="s2"> train_loss=</span><span class="si">{</span><span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="se">\t</span><span class="s2"> train_acc=</span><span class="si">{</span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
<span class="n">stop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>1/10: 	 train_loss=0.8999999761581421 	 train_acc=0.7833268642425537
2/10: 	 train_loss=1.899999976158142 	 train_acc=0.9463000893592834
3/10: 	 train_loss=2.9000000953674316 	 train_acc=0.23924924433231354
4/10: 	 train_loss=3.9000000953674316 	 train_acc=-0.6877662539482117
5/10: 	 train_loss=4.900000095367432 	 train_acc=-0.9824525713920593
6/10: 	 train_loss=5.900000095367432 	 train_acc=-0.37387657165527344
7/10: 	 train_loss=6.900000095367432 	 train_acc=0.5784398317337036
8/10: 	 train_loss=7.899999618530273 	 train_acc=0.9989413619041443
9/10: 	 train_loss=8.899999618530273 	 train_acc=0.5010212063789368
10/10: 	 train_loss=9.899999618530273 	 train_acc=-0.4575355648994446
 0.0011034011840820312 seconds
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="9.-%E5%9C%A8-GPU-%E4%B8%8A%E8%AE%AD%E7%BB%83">9. <a id="toc9_"></a><a href="#toc0_"> GPU </a><a class="anchor-link" href="#9.-%E5%9C%A8-GPU-%E4%B8%8A%E8%AE%AD%E7%BB%83"></a></h1><ul>
<li>Tensor<code></code>GPU</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1. GPU</td>
<td style="text-align:left">x_gpu = x<code>.to</code>('cuda:0')</td>
</tr>
<tr>
<td style="text-align:left">2. GPU</td>
<td style="text-align:left">net = net<code>.to</code>('cuda:0')</td>
</tr>
</tbody>
</table>
<ul>
<li>CPUGPU</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">GPU</td>
<td style="text-align:left">model.cuda()</td>
<td style="text-align:left">model.<code>to(device)</code></td>
</tr>
<tr>
<td style="text-align:left">GPU</td>
<td style="text-align:left">data.cuda()</td>
<td style="text-align:left">data.<code>to(device)</code></td>
</tr>
<tr>
<td style="text-align:left">GPU</td>
<td style="text-align:left">output=model(data)</td>
<td style="text-align:left">output<code>.detach().cpu().numpy()</code></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">output<code>.detach()</code></td>
<td style="text-align:left">output</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left"><code>.cpu()</code></td>
<td style="text-align:left">GPUCPU</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">.numpy()</td>
<td style="text-align:left">Tensornumpy</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left"><code>.item()</code></td>
<td style="text-align:left">Tensorpython</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="9.1.-%E6%9F%A5%E7%9C%8BGPU%E9%85%8D%E7%BD%AE">9.1. <a id="toc9_1_"></a><a href="#toc0_">GPU</a><a class="anchor-link" href="#9.1.-%E6%9F%A5%E7%9C%8BGPU%E9%85%8D%E7%BD%AE"></a></h2><p><code>torch.cuda</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[91]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="n">device</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[91]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>device(type='cuda', index=0)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[92]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># GPU</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>           
<span class="c1"># True, False</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[92]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[93]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># GPU</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>     
<span class="c1"># 1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[93]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>2</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[94]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># gpu0</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># "Tesla T4"</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[94]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>'NVIDIA A100-SXM4-40GB'</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[95]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
<span class="c1"># 0, 1, 2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[95]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>0</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[96]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">check_device</span><span class="p">():</span>
<span class="w">    </span><span class="sd">'''GPUGPU/'''</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span> <span class="c1"># cuda/GPU</span>
        <span class="n">gpu_num</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="c1"># cuda/GPU</span>
        <span class="k">if</span> <span class="n">gpu_num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">": </span><span class="si">{</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="n">gpu_name</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">gpu_name</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">range</span><span class="p">(</span><span class="n">gpu_num</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">gpu_num</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="n">gpu_name</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">gpu_name</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">range</span><span class="p">(</span><span class="n">gpu_num</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"CPU"</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">None</span> 

<span class="n">check_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>2: ['NVIDIA A100-SXM4-40GB', 'NVIDIA A100-SXM4-40GB']
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># device = [ 'cpu' if not torch.cuda.is_available() else ]</span>
<span class="n">device</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">'cuda:</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">'</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">())]</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="p">[</span><span class="s1">'cpu'</span><span class="p">]</span>
<span class="n">device</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[97]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>['cuda:0', 'cuda:1']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="9.2.-%E5%8D%95%E6%9C%BA%E5%8D%95%E5%8D%A1%EF%BC%88GPU%EF%BC%89">9.2. <a id="toc9_2_"></a><a href="#toc0_">GPU</a><a class="anchor-link" href="#9.2.-%E5%8D%95%E6%9C%BA%E5%8D%95%E5%8D%A1%EF%BC%88GPU%EF%BC%89"></a></h2><p>CPUGPU</p>
<ol>
<li>GPUmodel.cuda()  model.to(device)</li>
<li>GPUdata_gpu = data.cuda()  data_gpu = data.to(device)</li>
<li>GPUoutput = model(data)  output.detach().cpu().numpy()</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda:0'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>

<span class="n">device</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[18]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>device(type='cuda', index=0)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">device</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[19]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[1.],
         [1.]]),
 tensor([[1.],
         [1.]]),
 device(type='cpu'),
 device(type='cpu'))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x1</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">y1</span><span class="o">.</span><span class="n">device</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[20]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[1.],
         [1.]], device='cuda:0'),
 tensor([[1.],
         [1.]], device='cuda:0'),
 device(type='cuda', index=0),
 device(type='cuda', index=0))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="9.3.-%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%EF%BC%88GPU%EF%BC%89">9.3. <a id="toc9_3_"></a><a href="#toc0_">GPU</a><a class="anchor-link" href="#9.3.-%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%EF%BC%88GPU%EF%BC%89"></a></h2><p>PyTorch</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">torch.nn.<code>DataParallel</code>(module=net, device_ids=[0, 1], output_device=[0])</td>
<td style="text-align:left"># </td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">torch.nn.parallel.<code>DistributedDataParallel</code>()</td>
<td style="text-align:left"># </td>
</tr>
</tbody>
</table>
<p>DataParallel (DP)  DistributedDataParallel (DDP) GPU</p>
<ol>
<li><p><strong></strong></p>
<ul>
<li><code>DataParallel</code> GPUGPU</li>
<li><code>DistributedDataParallel</code> GPUGPU</li>
</ul>
</li>
<li><p><strong></strong></p>
<ul>
<li><code>DataParallel</code> GPU</li>
<li><code>DistributedDataParallel</code> NCCLGloo</li>
</ul>
</li>
<li><p><strong></strong></p>
<ul>
<li><code>DataParallel</code>  <code>nn.DataParallel(model)</code> </li>
<li><code>DistributedDataParallel</code> <code>torch.distributed.launch</code> <code>os.environ</code></li>
</ul>
</li>
<li><p><strong></strong></p>
<ul>
<li><code>DataParallel</code> </li>
<li><code>DistributedDataParallel</code> </li>
</ul>
</li>
</ol>
<p> DataParallelDistributedDataParallel </p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="9.3.1.-DP">9.3.1. <a id="toc9_3_1_"></a><a href="#toc0_">DP</a><a class="anchor-link" href="#9.3.1.-DP"></a></h3><ul>
<li><p></p>
</li>
<li><p></p>
</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">device_ids</span><span class="p">,</span> <span class="n">output_device</span><span class="p">)</span>  

<span class="n">Parameters</span>
    <span class="n">module</span> <span class="p">(</span><span class="n">Module</span><span class="p">)</span> <span class="err"></span> <span class="n">module</span> <span class="n">to</span> <span class="n">be</span> <span class="n">parallelized</span>                                                 <span class="c1"># </span>
    <span class="n">device_ids</span> <span class="p">(</span><span class="nb">list</span> <span class="n">of</span> <span class="nb">int</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="err"></span> <span class="n">CUDA</span> <span class="n">devices</span> <span class="p">(</span><span class="n">default</span><span class="p">:</span> <span class="nb">all</span> <span class="n">devices</span><span class="p">)</span>              <span class="c1"># GPU</span>
    <span class="n">output_device</span> <span class="p">(</span><span class="nb">int</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="err"></span> <span class="n">device</span> <span class="n">location</span> <span class="n">of</span> <span class="n">output</span> <span class="p">(</span><span class="n">default</span><span class="p">:</span> <span class="n">device_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>    <span class="c1"># cuda:0</span>
<span class="n">Variables</span>
    <span class="n">module</span> <span class="p">(</span><span class="n">Module</span><span class="p">)</span> <span class="err"></span> <span class="n">the</span> <span class="n">module</span> <span class="n">to</span> <span class="n">be</span> <span class="n">parallelized</span>
</pre></div>
<ul>
<li><p></p>
<ol>
<li><p>: netcuda:[0, 1, 2]X, ycuda:0cuda:1cuda:2</p>
</li>
<li><p>cuda:0GPUcuda:0</p>
<ul>
<li><p>os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"      # import osimport torch</p>
</li>
<li><p>os.environ["CUDA_VISIBLE_DEVICES"] = "2, 3"         # 23GPU2pytorchcuda:0</p>
</li>
</ul>
</li>
</ol>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[103]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span> 
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">data</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">time</span> 

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">dbs</span> <span class="o">=</span> <span class="s1">'./Pytorch_datasets/'</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>

            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
            <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
            <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># </span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>  <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># test_iter = data.DataLoader(dataset=test_dataset) # testbatch</span>

<span class="c1"># </span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
<span class="c1"># </span>
<span class="k">def</span> <span class="nf">train_steps</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">    </span>
<span class="sd">    epochs = epochs                         # epoch</span>
<span class="sd">    train_dataset = train_dataset           # train</span>
<span class="sd">    train_iter = train_iter                 # batchtrain</span>
<span class="sd">    test_dataset = test_dataset             # test</span>
<span class="sd">    net = net                               # </span>
<span class="sd">    loss_fn = loss_fn                       # </span>
<span class="sd">    opt = opt                               # </span>
<span class="sd">    device = device                         # device GPU/CPU</span>
<span class="sd">    '''</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"Runing on </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">train_all_data_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">train_all_targets_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">test_all_data_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">test_all_targets_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
    <span class="c1"># net = nn.DataParallel(module=net, device_ids=[0, 1], output_device=[0]) # GPUnet = nn.DataParallel(module=net)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># </span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_record</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch_record</span>                 <span class="c1"># X, y</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># deviceGPU/CPU</span>
            <span class="c1"># print(X[0])</span>
            <span class="c1"># print(X[0].dtype)</span>
            <span class="c1"># break</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>                     <span class="c1"># </span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>          <span class="c1"># y_hat</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="c1"># loss</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>         <span class="c1"># </span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>              <span class="c1"># </span>

        <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># </span>
                    <span class="c1"># net.train()</span>
                    <span class="c1"># netBNDropouttesttraintest</span>
                    <span class="c1"># netBNDropoutnet.eval()</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># withgrad</span>
            <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">),</span> <span class="n">train_all_targets_gpu</span><span class="p">)</span>
            <span class="c1"># print(train_loss)</span>
            <span class="n">train_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">train_all_targets_gpu</span>
            <span class="n">train_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_acc_cmp</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="c1"># print(train_acc)</span>
            <span class="n">test_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">test_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">test_all_targets_gpu</span>
            <span class="n">test_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_acc_cmp</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="c1"># print(test_acc)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">: train_loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s2">, train_acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s2">, test_acc=</span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">stop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">seconds</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>
    <span class="k">def</span> <span class="nf">convert_seconds</span><span class="p">(</span><span class="n">seconds</span><span class="p">):</span>
        <span class="n">days</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">//</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">)</span>
        <span class="n">hours</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">))</span> <span class="o">//</span> <span class="mi">3600</span>
        <span class="n">minutes</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="mi">3600</span><span class="p">)</span> <span class="o">//</span> <span class="mi">60</span>
        <span class="n">remaining_seconds</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">%</span> <span class="mi">60</span>
        <span class="k">return</span> <span class="n">days</span><span class="p">,</span> <span class="n">hours</span><span class="p">,</span> <span class="n">minutes</span><span class="p">,</span> <span class="n">remaining_seconds</span>
    <span class="n">days</span><span class="p">,</span> <span class="n">hours</span><span class="p">,</span> <span class="n">minutes</span><span class="p">,</span> <span class="n">remaining_seconds</span> <span class="o">=</span> <span class="n">convert_seconds</span><span class="p">(</span><span class="n">seconds</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"Total</span><span class="si">{</span><span class="n">days</span><span class="si">}</span><span class="s2"> d/ </span><span class="si">{</span><span class="n">hours</span><span class="si">}</span><span class="s2"> h/ </span><span class="si">{</span><span class="n">minutes</span><span class="si">}</span><span class="s2"> m/ </span><span class="si">{</span><span class="n">remaining_seconds</span><span class="si">}</span><span class="s2"> s"</span><span class="p">)</span>
    <span class="c1"># return (train_loss, train_acc, test_acc)</span>
    <span class="k">return</span> <span class="kc">None</span>

<span class="c1"># lr 0.01 -&gt; 0.5</span>
<span class="c1"># </span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>  
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>   
<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span> 
<span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================================================================================================== 
 Runing on cuda:0 
 ====================================================================================================
epoch 1/10: train_loss=1.5717055797576904, train_acc=90.85833740234375, test_acc=90.91999816894531
epoch 2/10: train_loss=1.5450035333633423, train_acc=92.63500213623047, test_acc=92.77999877929688
epoch 3/10: train_loss=1.5318394899368286, train_acc=93.75666809082031, test_acc=93.83999633789062
epoch 4/10: train_loss=1.5233505964279175, train_acc=94.5, test_acc=94.18000030517578
epoch 5/10: train_loss=1.5167455673217773, train_acc=95.13500213623047, test_acc=94.83999633789062
epoch 6/10: train_loss=1.5123507976531982, train_acc=95.55833435058594, test_acc=95.25
epoch 7/10: train_loss=1.5058631896972656, train_acc=96.14500427246094, test_acc=95.44000244140625
epoch 8/10: train_loss=1.502568006515503, train_acc=96.41999816894531, test_acc=95.80000305175781
epoch 9/10: train_loss=1.4993404150009155, train_acc=96.69999694824219, test_acc=96.18000030517578
epoch 10/10: train_loss=1.4963492155075073, train_acc=97.02667236328125, test_acc=96.30000305175781
==================================================================================================== 
 Total0.0 d/ 0.0 h/ 1.0 m/ 5.24815821647644 s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="9.3.2.-DDP">9.3.2. <a id="toc9_3_2_"></a><a href="#toc0_">DDP</a><a class="anchor-link" href="#9.3.2.-DDP"></a></h3><div class="highlight"><pre><span></span><span class="m">1</span>.<span class="w"> </span><span class="w"> </span>DataParallel<span class="w"> </span><span class="w"> </span>GPU<span class="w"> </span><span class="w"> </span>distributed<span class="w"> </span>torch<span class="w"> </span><span class="w"> </span>
<span class="w"> </span><span class="w"> </span>n<span class="w"> </span><span class="w"> </span>GPU<span class="w"> </span>
<span class="m">2</span>.<span class="w"> </span>
</pre></div>
<div class="highlight"><pre><span></span><span class="n"></span>
<span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">device_ids</span><span class="p">,</span> <span class="n">output_device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">import</span> <span class="nn">torch.multiprocessing</span> <span class="k">as</span> <span class="nn">mp</span>
<span class="kn">import</span> <span class="nn">os</span> 

<span class="k">def</span> <span class="nf">ddp_setup</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">    Args:</span>
<span class="sd">        rank: unique identifier of each process</span>
<span class="sd">        world_size: Total number of process</span>
<span class="sd">    '''</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"MASTER_ADDR"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"localhost"</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"MASTER_PORT"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"12357"</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">'nccl'</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="9.3.2.1.-%E5%9C%A8colab%E4%B8%8A%E6%B5%8B%E8%AF%95%E5%8F%AF%E7%94%A8">9.3.2.1. <a id="toc9_3_2_1_"></a><a href="#toc0_">colab</a><a class="anchor-link" href="#9.3.2.1.-%E5%9C%A8colab%E4%B8%8A%E6%B5%8B%E8%AF%95%E5%8F%AF%E7%94%A8"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">import</span> <span class="nn">torch.multiprocessing</span> <span class="k">as</span> <span class="nn">mp</span>
<span class="kn">from</span> <span class="nn">torch.multiprocessing</span> <span class="kn">import</span> <span class="n">Process</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># </span>
<span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">local_rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
  
  <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"MASTER_PORT"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"12357"</span>
  <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"MASTER_ADDR"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"localhost"</span>

  <span class="c1"># GPU</span>
  <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">local_rank</span><span class="p">)</span>
  <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">,</span> <span class="n">local_rank</span><span class="p">)</span>

  <span class="c1"># </span>
  <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">'nccl'</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">local_rank</span><span class="p">)</span>

  <span class="c1"># </span>
  <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,))])</span>
  <span class="n">trainset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

  <span class="c1"># DistributedSampler</span>
  <span class="n">train_sampler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">DistributedSampler</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span>
  <span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">)</span>

  <span class="c1"># CNNGPU</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">local_rank</span><span class="p">])</span>

  <span class="c1"># </span>
  <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

  <span class="c1"># </span>
  <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>

  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
      <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
      <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
          <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
          <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

          <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
          <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
          <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

          <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

      <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Local Rank </span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">, Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">, Training Loss: </span><span class="si">{</span><span class="n">running_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">trainloader</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

  <span class="n">dist</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>

<span class="c1"># Process</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
  <span class="c1"># size = torch.cuda.device_count()</span>
  <span class="n">size</span> <span class="o">=</span> <span class="mi">10</span>
  <span class="n">processes</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">world_size</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">))</span>
      <span class="n">p</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
      <span class="n">processes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="9.4.-%E5%A4%9A%E6%9C%BA%E5%A4%9A%E5%8D%A1%EF%BC%88GPU%EF%BC%89--%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83">9.4. <a id="toc9_4_"></a><a href="#toc0_">GPU- </a><a class="anchor-link" href="#9.4.-%E5%A4%9A%E6%9C%BA%E5%A4%9A%E5%8D%A1%EF%BC%88GPU%EF%BC%89--%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83"></a></h2><div class="highlight"><pre><span></span>PyTorch<span class="w">   </span>
<span class="w">    </span><span class="m">1</span>.<span class="w"> </span>torch.nn.parallel.DistributedDataParallel<span class="o">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="10.-%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%8F%82%E6%95%B0%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD">10. <a id="toc10_"></a><a href="#toc0_"></a><a class="anchor-link" href="#10.-%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%8F%82%E6%95%B0%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD"></a></h1><ul>
<li><p>torch.save( ,  )</p>
</li>
<li><p> = torch.load(  )</p>
</li>
<li><p>torch.save<code></code></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="10.1.-%E5%8A%A0%E8%BD%BD%E5%92%8C%E4%BF%9D%E5%AD%98-%E5%BC%A0%E9%87%8F">10.1. <a id="toc10_1_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#10.1.-%E5%8A%A0%E8%BD%BD%E5%92%8C%E4%BF%9D%E5%AD%98-%E5%BC%A0%E9%87%8F"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[40]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[41]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># torch.save()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">'./Pytorch_params/x-file'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[42]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># torch.load()</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'./Pytorch_params/x-file'</span><span class="p">)</span>

<span class="n">x1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[42]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="10.2.-%E5%8A%A0%E8%BD%BD%E5%92%8C%E4%BF%9D%E5%AD%98-%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0">10.2. <a id="toc10_2_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#10.2.-%E5%8A%A0%E8%BD%BD%E5%92%8C%E4%BF%9D%E5%AD%98-%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0"></a></h2><p>      3   </p>
<ol>
<li>saveload</li>
<li></li>
<li></li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[39]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># torch.save()</span>
<span class="c1"># mlp.params</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'./Pytorch_params/mlp.params'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># torch.load()</span>
<span class="c1">#  </span>
<span class="c1"># </span>
<span class="n">net_params</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'./Pytorch_params/mlp.params'</span><span class="p">)</span>
<span class="n">clone</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>

<span class="n">clone</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">net_params</span><span class="p">)</span>
<span class="n">clone</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[40]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>MLP(
  (hidden): Linear(in_features=20, out_features=256, bias=True)
  (output): Linear(in_features=256, out_features=10, bias=True)
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[48]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s1">'epoch'</span><span class="p">:</span> <span class="s1">'10'</span><span class="p">,</span> 
        <span class="s1">'model_state_dict'</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> 
        <span class="c1"># 'opt_state_dict': opt.state_dict(), </span>
        <span class="s1">'loss'</span><span class="p">:</span> <span class="s1">'loss'</span>
    <span class="p">},</span> 
    <span class="s1">'./Pytorch_params/test.pt'</span>
<span class="p">)</span>

<span class="c1"># </span>
<span class="n">check_point</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'./Pytorch_params/test.pt'</span><span class="p">)</span>

<span class="n">check_point</span><span class="p">[</span><span class="s1">'model_state_dict'</span><span class="p">]</span>
<span class="n">check_point</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]</span>
<span class="n">check_point</span><span class="p">[</span><span class="s1">'epoch'</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[48]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>'10'</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="11.-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%B1%BB%E5%9E%8B">11. <a id="toc11_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%B1%BB%E5%9E%8B"></a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11.1.-CNN">11.1. <a id="toc11_1_"></a><a href="#toc0_">CNN</a><a class="anchor-link" href="#11.1.-CNN"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.1.1.-%E6%A6%82%E8%BF%B0">11.1.1. <a id="toc11_1_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.1.1.-%E6%A6%82%E8%BF%B0"></a></h3><p>CBAPD: </p>
<p>FC</p>
<p></p>
<ul>
<li>CNN<ul>
<li>MLP</li>
<li><ul>
<li></li>
<li></li>
</ul>
</li>
<li><ul>
<li> /</li>
<li> </li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.1.2.-%E7%AE%80%E5%8D%95CNN">11.1.2. <a id="toc11_1_2_"></a><a href="#toc0_">CNN</a><a class="anchor-link" href="#11.1.2.-%E7%AE%80%E5%8D%95CNN"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.1.2.1.-%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0">11.1.2.1. <a id="toc11_1_2_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.1.2.1.-%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="11.1.2.1.1.-%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B">11.1.2.1.1. <a id="toc11_1_2_1_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.1.2.1.1.-%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"></a></h5><p><img align="center" alt="" height="300" src="./Pytorch_Pictures/convolution/conv.gif" width="500"/></p>
<ul>
<li><p></p>
</li>
<li><p>(Xh - Kh + 1, Xw - Kw + 1)</p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 

<span class="k">def</span> <span class="nf">cov2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">    convolution ()</span>
<span class="sd">    Args: </span>
<span class="sd">        X (2d): </span>
<span class="sd">        kernel (int): </span>

<span class="sd">    Return: </span>
<span class="sd">        Y: </span>
<span class="sd">    '''</span>

    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">h</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>   <span class="c1"># 0</span>
    <span class="c1"># print(Y)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span><span class="n">j</span> <span class="o">+</span> <span class="n">w</span><span class="p">]</span> <span class="o">*</span> <span class="n">kernel</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>      <span class="c1"># X * kernel </span>
    <span class="k">return</span> <span class="n">Y</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">X</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[14]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">kernel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">kernel</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[15]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0., 1.],
        [2., 3.]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">cov2d</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[16]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[19., 25.],
        [37., 43.]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="11.1.2.1.2.-%E4%BB%8E%E5%A4%B4%E5%8D%B7%E7%A7%AF%E5%B1%82">11.1.2.1.2. <a id="toc11_1_2_1_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.1.2.1.2.-%E4%BB%8E%E5%A4%B4%E5%8D%B7%E7%A7%AF%E5%B1%82"></a></h5><ul>
<li></li>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">Cov2d</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cov2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>                   <span class="c1"># conv2d</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">cov2d1</span> <span class="o">=</span> <span class="n">Cov2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="n">cov2d1</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[19]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 4.2232,  6.6674],
        [11.5557, 13.9999]], grad_fn=&lt;AddBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.1.2.2.-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0">11.1.2.2. <a id="toc11_1_2_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.1.2.2.-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span> 

<span class="n">conv2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
    <span class="n">in_channels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
    <span class="n">out_channels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
    <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> 
    <span class="n">bias</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># nn.Conv2d</span>
<span class="n">conv2d</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[20]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[[[-0.1198, -0.6957],
          [-1.8475, -2.4234]]]], grad_fn=&lt;ConvolutionBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.1.2.3.-%E5%A1%AB%E5%85%85%E5%92%8C%E6%AD%A5%E5%B9%85">11.1.2.3. <a id="toc11_1_2_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.1.2.3.-%E5%A1%AB%E5%85%85%E5%92%8C%E6%AD%A5%E5%B9%85"></a></h4><ul>
<li><p> (padding)</p>
<ul>
<li><p>(Xh - Kh + Ph + 1, Xw - Kw + Pw + 1)</p>
</li>
<li><p>KhKw(1,3,5,7)  ()</p>
<ul>
<li><p>PhKh - 1</p>
</li>
<li><p>PwKw - 1</p>
</li>
</ul>
</li>
<li><p>padding ()</p>
<ul>
<li>padding = (Ph/2, Pw/2)</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[96]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="n">improt</span> <span class="n">nn</span>  

<span class="n">conv2d1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
    <span class="n">in_channels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
    <span class="n">out_channels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
    <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> 
    <span class="n">bias</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
    <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>           <span class="c1"># ((3 - 1)/2, (3 - 1)/2)</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># nn.Conv2d</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">conv2d1</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>

<span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[96]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[0., 1., 2.],
         [3., 4., 5.],
         [6., 7., 8.]]),
 torch.Size([1, 1, 3, 3]),
 tensor([[[[ 0.8745,  0.5668, -1.1526],
           [ 1.3291,  0.4245, -2.8065],
           [-1.7216, -2.1159, -4.1353]]]], grad_fn=&lt;ConvolutionBackward0&gt;),
 torch.Size([1, 1, 3, 3]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li><p> (stride)</p>
<ul>
<li>( (Xh - Kh + Ph + Sh)/Sh, (Xw - Kw + Pw + Sw)/Sw)</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="n">conv2d1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
    <span class="n">in_channels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
    <span class="n">out_channels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
    <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> 
    <span class="n">bias</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
    <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>           <span class="c1"># ((3 - 1)/2, (3 - 1)/2)</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span>                  <span class="c1"># (8 - 3 + 1 + 2 )/2 = 4</span>
<span class="p">)</span>

<span class="c1"># nn.Conv2d</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">conv2d1</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)))</span>

<span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[97]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11., 12., 13., 14., 15.],
         [16., 17., 18., 19., 20., 21., 22., 23.],
         [24., 25., 26., 27., 28., 29., 30., 31.],
         [32., 33., 34., 35., 36., 37., 38., 39.],
         [40., 41., 42., 43., 44., 45., 46., 47.],
         [48., 49., 50., 51., 52., 53., 54., 55.],
         [56., 57., 58., 59., 60., 61., 62., 63.]]),
 torch.Size([1, 1, 8, 8]),
 tensor([[[[ 1.9051,  0.5452,  0.1890, -0.1672],
           [ 7.8690,  5.8516,  7.1474,  8.4432],
           [17.5960, 16.2180, 17.5138, 18.8095],
           [27.3230, 26.5843, 27.8801, 29.1759]]]],
        grad_fn=&lt;ConvolutionBackward0&gt;),
 torch.Size([1, 1, 4, 4]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.1.2.4.-%E5%A4%9A%E8%BE%93%E5%85%A5%E5%92%8C%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93">11.1.2.4. <a id="toc11_1_2_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.1.2.4.-%E5%A4%9A%E8%BE%93%E5%85%A5%E5%92%8C%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[98]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="n">conv2d1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
    <span class="n">in_channels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
    <span class="n">out_channels</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> 
    <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> 
    <span class="n">bias</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
    <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>           <span class="c1"># ((3 - 1)/2, (3 - 1)/2)</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span>                  <span class="c1"># (8 - 3 + 1 + 2 )/2 = 4</span>
<span class="p">)</span>

<span class="c1"># nn.Conv2d</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">conv2d1</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)))</span>

<span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[98]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11., 12., 13., 14., 15.],
         [16., 17., 18., 19., 20., 21., 22., 23.],
         [24., 25., 26., 27., 28., 29., 30., 31.],
         [32., 33., 34., 35., 36., 37., 38., 39.],
         [40., 41., 42., 43., 44., 45., 46., 47.],
         [48., 49., 50., 51., 52., 53., 54., 55.],
         [56., 57., 58., 59., 60., 61., 62., 63.]]),
 torch.Size([1, 1, 8, 8]),
 tensor([[[[  2.4056,   2.1440,   1.8950,   1.6460],
           [  1.5345,  -0.6088,  -0.8895,  -1.1701],
           [ -1.4190,  -2.8542,  -3.1349,  -3.4156],
           [ -4.3725,  -5.0996,  -5.3803,  -5.6610]],
 
          [[ -4.2932,  -2.7050,  -3.2087,  -3.7125],
           [-11.4362,  -6.5766,  -6.9336,  -7.2905],
           [-20.1880,  -9.4324,  -9.7894, -10.1464],
           [-28.9399, -12.2882, -12.6452, -13.0022]],
 
          [[  0.8076,   0.9240,   0.4248,  -0.0743],
           [ -4.4429,  -9.8272, -11.6552, -13.4831],
           [-13.0735, -24.4510, -26.2789, -28.1069],
           [-21.7041, -39.0747, -40.9027, -42.7306]]]],
        grad_fn=&lt;ConvolutionBackward0&gt;),
 torch.Size([1, 3, 4, 4]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.1.2.5.-Pooling-(%E6%B1%87%E8%81%9A%E5%B1%82)">11.1.2.5. <a id="toc11_1_2_5_"></a><a href="#toc0_">Pooling ()</a><a class="anchor-link" href="#11.1.2.5.-Pooling-(%E6%B1%87%E8%81%9A%E5%B1%82)"></a></h4><ul>
<li>pooling</li>
</ul>
<h5 id="11.1.2.5.1.-%E5%B9%B3%E5%9D%87Pooling">11.1.2.5.1. <a id="toc11_1_2_5_1_"></a><a href="#toc0_">Pooling</a><a class="anchor-link" href="#11.1.2.5.1.-%E5%B9%B3%E5%9D%87Pooling"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[82]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span>
    <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> 
    <span class="n">padding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> 
    <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[82]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>AvgPool2d(kernel_size=(2, 2), stride=1, padding=0)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="11.1.2.5.2.-%E6%9C%80%E5%A4%A7Pooling">11.1.2.5.2. <a id="toc11_1_2_5_2_"></a><a href="#toc0_">Pooling</a><a class="anchor-link" href="#11.1.2.5.2.-%E6%9C%80%E5%A4%A7Pooling"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[81]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span>
    <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> 
    <span class="n">padding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> 
    <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[81]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>MaxPool2d(kernel_size=(2, 2), stride=1, padding=0, dilation=1, ceil_mode=False)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.1.3.-LeNet">11.1.3. <a id="toc11_1_3_"></a><a href="#toc0_">LeNet</a><a class="anchor-link" href="#11.1.3.-LeNet"></a></h3><ul>
<li>Yann LeCun</li>
</ul>
<img align="center" alt="" height="300" src="./Pytorch_Pictures/convolution/LeNet.jpg" width="700"/>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[264]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">class</span> <span class="nc">LeNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="c1"># </span>
<span class="n">lenet</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
<span class="c1"># X = torch.rand(size=(1,1,28,28), dtype=torch.float32)</span>
<span class="c1"># X.shape</span>
<span class="n">lenet</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[264]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0.4010, -0.5553,  0.2207,  0.0441, -0.1673,  0.0948, -0.2773,  0.0366,
          0.4789,  0.5569]], grad_fn=&lt;AddmmBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.1.4.-AlexNet">11.1.4. <a id="toc11_1_4_"></a><a href="#toc0_">AlexNet</a><a class="anchor-link" href="#11.1.4.-AlexNet"></a></h3><ul>
<li><p> (ImageNet)  ( supportvectormachines) <strong></strong></p>
</li>
<li><p></p>
</li>
</ul>
<img align="center" alt="" height="700" src="./Pytorch_Pictures/convolution/AlexNet.jpg" width="500"/>
<ul>
<li>LeNet VS AlexNet</li>
</ul>
<img align="center" alt="" height="300" src="./Pytorch_Pictures/convolution/LeNetVSAlexNet.jpg" width="1000"/>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[102]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">AlexNet</span>


<span class="n">alexnet</span> <span class="o">=</span> <span class="n">AlexNet</span><span class="p">()</span>
<span class="n">alexnet</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[102]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.1.5.-VGG">11.1.5. <a id="toc11_1_5_"></a><a href="#toc0_">VGG</a><a class="anchor-link" href="#11.1.5.-VGG"></a></h3><ul>
<li><p></p>
<ul>
<li>Conv2d()</li>
<li>nn.Relu()</li>
<li>nn.MaxPooling()</li>
</ul>
</li>
</ul>
<img align="center" alt="" height="500" src="./Pytorch_Pictures/convolution/VGG.jpg" width="500"/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[121]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">vgg_block</span><span class="p">(</span><span class="n">num_convs</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_convs</span><span class="p">):</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="n">in_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

<span class="n">conv_arch</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> 
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> 
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> 
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span> 
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">vgg</span><span class="p">(</span><span class="n">conv_arch</span><span class="p">):</span>
    <span class="n">conv_blks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">in_channels</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c1"># </span>
    <span class="k">for</span> <span class="p">(</span><span class="n">num_convs</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span> <span class="ow">in</span> <span class="n">conv_arch</span><span class="p">:</span>
        <span class="n">conv_blks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vgg_block</span><span class="p">(</span><span class="n">num_convs</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">))</span>
        <span class="n">in_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
        
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="o">*</span><span class="n">conv_blks</span><span class="p">,</span> 
        <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> 
        <span class="c1"># </span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">out_channels</span><span class="o">*</span><span class="mi">7</span><span class="o">*</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span> 
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
        <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span> 
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span> 
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
        <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span> 
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">vgg</span><span class="p">(</span><span class="n">conv_arch</span><span class="p">)</span>
<span class="n">net</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[121]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Sequential(
  (0): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (1): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (4): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=25088, out_features=4096, bias=True)
  (7): ReLU()
  (8): Dropout(p=0.5, inplace=False)
  (9): Linear(in_features=4096, out_features=4096, bias=True)
  (10): ReLU()
  (11): Dropout(p=0.5, inplace=False)
  (12): Linear(in_features=4096, out_features=10, bias=True)
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>vgg11</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[113]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">vgg11</span>


<span class="n">vgg</span> <span class="o">=</span> <span class="n">vgg11</span><span class="p">()</span>
<span class="n">vgg</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[113]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): ReLU(inplace=True)
    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (14): ReLU(inplace=True)
    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): ReLU(inplace=True)
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (19): ReLU(inplace=True)
    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.1.6.-NiN">11.1.6. <a id="toc11_1_6_"></a><a href="#toc0_">NiN</a><a class="anchor-link" href="#11.1.6.-NiN"></a></h3><ul>
<li>1 x 1</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.1.7.-GoogLeNet">11.1.7. <a id="toc11_1_7_"></a><a href="#toc0_">GoogLeNet</a><a class="anchor-link" href="#11.1.7.-GoogLeNet"></a></h3><ul>
<li><p>2014ImageNetGoogLeNet</p>
</li>
<li><p></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.1.8.-%E6%89%B9%E9%87%8F%E8%A7%84%E8%8C%83%E5%8C%96">11.1.8. <a id="toc11_1_8_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.1.8.-%E6%89%B9%E9%87%8F%E8%A7%84%E8%8C%83%E5%8C%96"></a></h3><ul>
<li>batch normalization</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.1.9.-ResNet">11.1.9. <a id="toc11_1_9_"></a><a href="#toc0_">ResNet</a><a class="anchor-link" href="#11.1.9.-ResNet"></a></h3><div class="highlight"><pre><span></span>CNNResNet
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.1.9.1.-%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0">11.1.9.1. <a id="toc11_1_9_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.1.9.1.-%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[99]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span> 


<span class="k">class</span> <span class="nc">MyResNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[124]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">resnet34</span> 


<span class="n">resnet</span> <span class="o">=</span> <span class="n">resnet34</span><span class="p">()</span>
<span class="n">resnet</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[124]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1000, bias=True)
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11.2.-%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE">11.2. <a id="toc11_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.2.-%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE"></a></h2><h3 id="11.2.1.-%E4%BB%80%E4%B9%88%E6%98%AF%E5%BA%8F%E5%88%97">11.2.1. <a id="toc11_2_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.2.1.-%E4%BB%80%E4%B9%88%E6%98%AF%E5%BA%8F%E5%88%97"></a></h3><p><strong></strong>DNARNN</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.2.2.-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B">11.2.2. <a id="toc11_2_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.2.2.-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"></a></h3><p> (language model) </p>
<p></p>
<ul>
<li>n-gramn</li>
<li>RNNLSTMTransformer</li>
<li>GPTBERT</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.2.3.-%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86">11.2.3. <a id="toc11_2_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.2.3.-%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86"></a></h3><ul>
<li>token//</li>
<li>vocabtokenindice</li>
<li>cropustokenindice</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.2.3.1.-%E4%B8%8B%E8%BD%BD%E3%80%8ATime-machine%E3%80%8B%E5%B9%B6%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE">11.2.3.1. <a id="toc11_2_3_1_"></a><a href="#toc0_">Time machine</a><a class="anchor-link" href="#11.2.3.1.-%E4%B8%8B%E8%BD%BD%E3%80%8ATime-machine%E3%80%8B%E5%B9%B6%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"></a></h4><p>H.G.Well<a href="https://www.gutenberg.org/ebooks/35"></a>
30000

 (<strong></strong>)
</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>


<span class="c1">#@save</span>
<span class="c1"># ../data/timemachine.txt</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">DATA_HUB</span><span class="p">[</span><span class="s1">'time_machine'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">DATA_URL</span> <span class="o">+</span> <span class="s1">'timemachine.txt'</span><span class="p">,</span> <span class="s1">'090b5e7e70c295757f55df93cb0a180b9691891a'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">read_time_machine</span><span class="p">():</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">'time_machine'</span><span class="p">),</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">'[^A-Za-z]+'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>


<span class="n">lines</span> <span class="o">=</span> <span class="n">read_time_machine</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'# : </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># </span>
<span class="nb">print</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre># : 3221
the time machine by h g wells

twinkled and his usually pale face was flushed and animated the
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.2.3.2.-%E8%AF%8D%E5%85%83%E5%8C%96%EF%BC%88Tokenization%EF%BC%89">11.2.3.2. <a id="toc11_2_3_2_"></a><a href="#toc0_">Tokenization</a><a class="anchor-link" href="#11.2.3.2.-%E8%AF%8D%E5%85%83%E5%8C%96%EF%BC%88Tokenization%EF%BC%89"></a></h4><p></p>
<ul>
<li><code></code></li>
<li><code></code></li>
<li><code></code></li>
</ul>
<p></p>
<ul>
<li><code></code>Word-Based Tokenizationword</li>
<li><code></code>Subword Tokenization<ul>
<li>BPEByte Pair Encoding</li>
<li>WordPieceGoogleBERT</li>
<li>UnigramBERT</li>
</ul>
</li>
<li><code></code>Character-Based Tokenizationchar</li>
<li><code></code>Morpheme-Based Tokenization</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># word</span>
<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">token</span><span class="o">=</span><span class="s1">'word'</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="s1">'word'</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">token</span> <span class="o">==</span> <span class="s1">'char'</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">''</span> <span class="o">+</span> <span class="n">token</span><span class="p">)</span>


<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">token</span><span class="o">=</span><span class="s1">'word'</span><span class="p">)</span>
<span class="c1"># tokens = tokenize(lines, token='char')</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">11</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>['the', 'time', 'machine', 'by', 'h', 'g', 'wells']
[]
[]
[]
[]
['i']
[]
[]
['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him']
['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']
['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.2.3.3.-%E8%AF%8D%E8%A1%A8%EF%BC%88Vocabulary%EF%BC%89">11.2.3.3. <a id="toc11_2_3_3_"></a><a href="#toc0_">Vocabulary</a><a class="anchor-link" href="#11.2.3.3.-%E8%AF%8D%E8%A1%A8%EF%BC%88Vocabulary%EF%BC%89"></a></h4><ul>
<li>(token)</li>
<li>token</li>
</ul>
<table>
<thead>
<tr>
<th>token</th>
<th>indice</th>
<th>annotation</th>
</tr>
</thead>
<tbody>
<tr>
<td>unk</td>
<td>0</td>
<td>unknown</td>
</tr>
<tr>
<td>PAD</td>
<td>1</td>
<td>padding</td>
</tr>
<tr>
<td>SOS</td>
<td>2</td>
<td>start of sentence</td>
</tr>
<tr>
<td>EOS</td>
<td>3</td>
<td>end of sentence</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Vocab</span><span class="p">():</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reserved_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">tokens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">reserved_tokens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">reserved_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># </span>
        <span class="n">counter</span> <span class="o">=</span> <span class="n">count_corpus</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>                                                      <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_token_freqs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>       <span class="c1"># </span>
        <span class="c1"># 0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'&lt;unk&gt;'</span><span class="p">]</span> <span class="o">+</span> <span class="n">reserved_tokens</span>                                     <span class="c1">#  ['&lt;unk&gt;', ...]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">)}</span>     <span class="c1">#  {token: idx}</span>
        <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_freqs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">freq</span> <span class="o">&lt;</span> <span class="n">min_freq</span><span class="p">:</span>                                         <span class="c1">#  min_freq</span>
                <span class="k">break</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_to_idx</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>                                 <span class="c1"># </span>
                <span class="bp">self</span><span class="o">.</span><span class="n">token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>           <span class="c1"># </span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_to_idx</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">to_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
<span class="w">        </span><span class="sd">'''</span>
<span class="sd">         &lt;unk&gt;  0</span>
<span class="sd">        </span>
<span class="sd">        '''</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">unk</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="c1"># 0</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="k">return</span> <span class="mi">0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">token_freqs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_freqs</span>


<span class="k">def</span> <span class="nf">count_corpus</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="c1"># tokens1D2D</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
        <span class="c1"># </span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">line</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>


<span class="n">vocab</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'vocab type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'vocab size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'vocab[0:5]:'</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">token_to_idx</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>



<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">11</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"="</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">':'</span><span class="p">,</span> <span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">':'</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>vocab type: &lt;class '__main__.Vocab'&gt;
vocab size: 4580
vocab[0:5]:
[('&lt;unk&gt;', 0), ('the', 1), ('i', 2), ('and', 3), ('of', 4)]
====================================================================================================
: ['the', 'time', 'machine', 'by', 'h', 'g', 'wells']
: [1, 19, 50, 40, 2183, 2184, 400]
====================================================================================================
: ['fire', 'burned', 'brightly', 'and', 'the', 'soft', 'radiance', 'of', 'the', 'incandescent']
: [148, 588, 825, 3, 1, 244, 2187, 4, 1, 2188]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.2.3.4.-%E6%95%B4%E5%90%88%E6%89%80%E6%9C%89%E5%8A%9F%E8%83%BD">11.2.3.4. <a id="toc11_2_3_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.2.3.4.-%E6%95%B4%E5%90%88%E6%89%80%E6%9C%89%E5%8A%9F%E8%83%BD"></a></h4><ul>
<li></li>
<li>token</li>
<li>(token, indice)</li>
<li>tokenindicecorpus</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># char </span>
<span class="k">def</span> <span class="nf">load_corpus_time_machine</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="c1">#  [[], [], [], ...]</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">read_time_machine</span><span class="p">()</span>

    <span class="c1"># </span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="s1">'char'</span><span class="p">)</span>      <span class="c1"># char</span>
    <span class="c1"># tokens = tokenize(lines, token='word')  # word</span>

    <span class="c1"># [(token, indice), (token, indice), ...]</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

    <span class="c1"># </span>
    <span class="c1">#  (corpus) </span>
    <span class="c1"># corpus[indice, indice, indice, ...]</span>
    <span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">line</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">max_tokens</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># max_tokens0corpus</span>
        <span class="n">corpus</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[:</span><span class="n">max_tokens</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">vocab</span>


<span class="n">corpus</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">load_corpus_time_machine</span><span class="p">()</span>

<span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[6]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(170580, 28)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[41]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">corpus</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[41]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[3, 9, 2]</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[42]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">vocab</span><span class="o">.</span><span class="n">to_tokens</span><span class="p">(</span><span class="n">corpus</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[42]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>['t', 'h', 'e', ' ', 't']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.2.3.5.-%E6%96%87%E6%9C%AC%E7%BC%96%E7%A0%81%E4%B8%8E%E5%90%91%E9%87%8F%E5%8C%96">11.2.3.5. <a id="toc11_2_3_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.2.3.5.-%E6%96%87%E6%9C%AC%E7%BC%96%E7%A0%81%E4%B8%8E%E5%90%91%E9%87%8F%E5%8C%96"></a></h4><p>
</p>
<ul>
<li>One-Hot Encoding</li>
<li>Bag-of-Words</li>
<li>TF-IDFTerm Frequency-Inverse Document Frequency</li>
<li>Word Embeddings Word2VecGloVeFastText</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="11.2.3.5.1.-word2vec">11.2.3.5.1. <a id="toc11_2_3_5_1_"></a><a href="#toc0_">word2vec</a><a class="anchor-link" href="#11.2.3.5.1.-word2vec"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.2.4.-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9B%86">11.2.4. <a id="toc11_2_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.2.4.-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9B%86"></a></h3><h4 id="11.2.4.1.-%E9%A1%BA%E5%BA%8F%E9%87%87%E6%A0%B7-(Sequential-Sampling)">11.2.4.1. <a id="toc11_2_4_1_"></a><a href="#toc0_"> (Sequential Sampling)</a><a class="anchor-link" href="#11.2.4.1.-%E9%A1%BA%E5%BA%8F%E9%87%87%E6%A0%B7-(Sequential-Sampling)"></a></h4><ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span> 


<span class="k">def</span> <span class="nf">seq_data_iter_sequential</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="c1"># </span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>   <span class="c1">#  offset 0  num_steps </span>
    <span class="n">num_tokens</span> <span class="o">=</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="o">-</span> <span class="n">offset</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span>  <span class="c1"># </span>
    <span class="n">Xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">corpus</span><span class="p">[</span><span class="n">offset</span><span class="p">:</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">num_tokens</span><span class="p">])</span>  <span class="c1">#  X </span>
    <span class="n">Ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">corpus</span><span class="p">[</span><span class="n">offset</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span> <span class="n">offset</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">num_tokens</span><span class="p">])</span>  <span class="c1">#  Y </span>
    <span class="n">Xs</span><span class="p">,</span> <span class="n">Ys</span> <span class="o">=</span> <span class="n">Xs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">Ys</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># </span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="n">num_steps</span>  <span class="c1"># </span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">*</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">Xs</span><span class="p">[:,</span> <span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">num_steps</span><span class="p">]</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">Ys</span><span class="p">[:,</span> <span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">num_steps</span><span class="p">]</span>
        <span class="k">yield</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="ow">in</span> <span class="n">seq_data_iter_sequential</span><span class="p">(</span><span class="n">corpus</span><span class="o">=</span><span class="n">corpus</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'X: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Y: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>X: 
 tensor([[9, 2, 1, 3, 5],
        [9, 4, 3, 1, 3]])
Y: 
 tensor([[ 2,  1,  3,  5, 13],
        [ 4,  3,  1,  3,  9]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.2.4.2.-%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7-(Random-Sampling)">11.2.4.2. <a id="toc11_2_4_2_"></a><a href="#toc0_"> (Random Sampling)</a><a class="anchor-link" href="#11.2.4.2.-%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7-(Random-Sampling)"></a></h4><ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">random</span> 
<span class="kn">import</span> <span class="nn">torch</span> 


<span class="k">def</span> <span class="nf">seq_data_iter_random</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="c1"># num_steps-1</span>
    <span class="n">corpus</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):]</span>
    <span class="c1"># 1</span>
    <span class="n">num_subseqs</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">num_steps</span>
    <span class="c1"># num_steps</span>
    <span class="n">initial_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_subseqs</span> <span class="o">*</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">))</span>
    <span class="c1"># </span>
    <span class="c1"># </span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">initial_indices</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">data</span><span class="p">(</span><span class="n">pos</span><span class="p">):</span>
        <span class="c1"># posnum_steps</span>
        <span class="k">return</span> <span class="n">corpus</span><span class="p">[</span><span class="n">pos</span><span class="p">:</span> <span class="n">pos</span> <span class="o">+</span> <span class="n">num_steps</span><span class="p">]</span>

    <span class="n">num_batches</span> <span class="o">=</span> <span class="n">num_subseqs</span> <span class="o">//</span> <span class="n">batch_size</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="c1"># initial_indices</span>
        <span class="n">initial_indices_per_batch</span> <span class="o">=</span> <span class="n">initial_indices</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">(</span><span class="n">j</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">initial_indices_per_batch</span><span class="p">]</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">initial_indices_per_batch</span><span class="p">]</span>
        <span class="k">yield</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="ow">in</span> <span class="n">seq_data_iter_random</span><span class="p">(</span><span class="n">corpus</span><span class="o">=</span><span class="n">corpus</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'X: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Y: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>X: 
 tensor([[ 7, 13,  1,  2, 22],
        [ 1, 21, 14,  5, 12]])
Y: 
 tensor([[13,  1,  2, 22,  2],
        [21, 14,  5, 12,  3]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.2.4.3.-%E6%80%BB%E7%BB%93">11.2.4.3. <a id="toc11_2_4_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.2.4.3.-%E6%80%BB%E7%BB%93"></a></h4><table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Non-IID</td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.2.4.4.-%E5%8C%85%E8%A3%85">11.2.4.4. <a id="toc11_2_4_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.2.4.4.-%E5%8C%85%E8%A3%85"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SeqDataLoader</span><span class="p">:</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">use_random_iter</span><span class="p">:</span>
            <span class="c1"># self.data_iter_fn = d2l.seq_data_iter_random</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span> <span class="o">=</span> <span class="n">seq_data_iter_random</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># self.data_iter_fn = d2l.seq_data_iter_sequential</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span> <span class="o">=</span> <span class="n">seq_data_iter_sequential</span>
        <span class="c1"># self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">load_corpus_time_machine</span><span class="p">(</span><span class="n">max_tokens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    </span>
<span class="sd">    """</span>
    <span class="n">data_iter</span> <span class="o">=</span> <span class="n">SeqDataLoader</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">)</span>    
    <span class="k">return</span> <span class="n">data_iter</span><span class="p">,</span> <span class="n">data_iter</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11.3.-RNN">11.3. <a id="toc11_3_"></a><a href="#toc0_">RNN</a><a class="anchor-link" href="#11.3.-RNN"></a></h2><ul>
<li></li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.3.1.-RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86">11.3.1. <a id="toc11_3_1_"></a><a href="#toc0_">RNN-</a><a class="anchor-link" href="#11.3.1.-RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86"></a></h3><ul>
<li><ul>
<li></li>
<li></li>
<li></li>
</ul>
</li>
</ul>
<!-- <img src="./Pytorch_Pictures/RNN//Simple-RNN.jpg" width = "500" height = "300" alt="" align=center /> -->
<p><img alt="Simple-RNN" src="./Pytorch_Pictures/RNN/base-RNN.jpg"/></p>
<p><br/>
$\mathbf{h}_t=\phi(\mathbf{W}_{hh}\mathbf{h}_{t-1}+\mathbf{W}_{hx}\mathbf{x}_{t}+\mathbf{b}_h)$<br/>
<br/>
$\mathbf{o}_t=\phi(\mathbf{W}_\textit{ho}\mathbf{h}_t+\mathbf{b}_o)$</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.1.1.-%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%BB%9C">11.3.1.1. <a id="toc11_3_1_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.3.1.1.-%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%BB%9C"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>


<span class="c1">#     </span>
<span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">num_inputs</span> <span class="o">=</span> <span class="n">num_outputs</span> <span class="o">=</span> <span class="n">vocab_size</span>

    <span class="k">def</span> <span class="nf">normal</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>

    <span class="c1"># </span>
    <span class="n">W_xh</span> <span class="o">=</span> <span class="n">normal</span><span class="p">((</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
    <span class="n">W_hh</span> <span class="o">=</span> <span class="n">normal</span><span class="p">((</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
    <span class="n">b_h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># </span>
    <span class="n">W_hq</span> <span class="o">=</span> <span class="n">normal</span><span class="p">((</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">))</span>
    <span class="n">b_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># </span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">W_xh</span><span class="p">,</span> <span class="n">W_hh</span><span class="p">,</span> <span class="n">b_h</span><span class="p">,</span> <span class="n">W_hq</span><span class="p">,</span> <span class="n">b_q</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">params</span>

<span class="k">def</span> <span class="nf">init_rnn_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>                        <span class="c1"># , (num_layers, batch_size, num_hiddens)num_layers=1num_layers=1</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="p">)</span>

<span class="k">def</span> <span class="nf">rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="c1"># inputs(), (num_steps, batch_size, vocab_size)</span>
    <span class="n">W_xh</span><span class="p">,</span> <span class="n">W_hh</span><span class="p">,</span> <span class="n">b_h</span><span class="p">,</span> <span class="n">W_hq</span><span class="p">,</span> <span class="n">b_q</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">H</span><span class="p">,</span> <span class="o">=</span> <span class="n">state</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># X(batch_size, vocab_size))</span>
    <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>    <span class="c1"># num_stepsX(batch_size, vocab_size),</span>
        <span class="c1"># X: (batch_size, vocab_size)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W_xh</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W_hh</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_h</span><span class="p">)</span>         <span class="c1"># : (batch_size, num_hiddens)</span>
        <span class="c1"># H: (batch_size, num_hiddens)</span>

        <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W_hq</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_q</span>                                         <span class="c1"># : (batch_size, num_outputs) num_outputs=vocab_size</span>
        <span class="c1"># Y: (batch_size, num_outputs/vocab_size)</span>

        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">H</span><span class="p">,)</span>  <span class="c1"># , (num_steps, batch_size, num_outputs)</span>


<span class="k">class</span> <span class="nc">RNNModelScratch</span><span class="p">:</span> <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">get_params</span><span class="p">,</span> <span class="n">init_state</span><span class="p">,</span> <span class="n">forward_fn</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">get_params</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_fn</span> <span class="o">=</span> <span class="n">init_state</span><span class="p">,</span> <span class="n">forward_fn</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># (num_steps, batch_size, vocab_size)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_fn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">begin_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">))</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span>    <span class="c1"># vocab_size=len(vocab) = 28</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[14]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 5]), torch.Size([5, 2]), torch.Size([5, 2, 28]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">RNNModelScratch</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> 
    <span class="n">num_hiddens</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">(),</span> 
    <span class="n">get_params</span><span class="o">=</span><span class="n">get_params</span><span class="p">,</span>
    <span class="n">init_state</span><span class="o">=</span><span class="n">init_rnn_state</span><span class="p">,</span> 
    <span class="n">forward_fn</span><span class="o">=</span><span class="n">rnn</span>
<span class="p">)</span>

<span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">begin_state</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
<span class="n">Y</span><span class="p">,</span> <span class="n">new_state</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()),</span> <span class="n">state</span><span class="p">)</span>

<span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_state</span><span class="p">),</span> <span class="n">new_state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[15]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([10, 28]), 1, torch.Size([2, 512]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.1.2.-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0">11.3.1.2. <a id="toc11_3_1_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.3.1.2.-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[59]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span> 


<span class="k">class</span> <span class="nc">RNNModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rnn_layer</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RNNModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">hidden_size</span>
        <span class="c1"># RNNnum_directions21</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">bidirectional</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">Y</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="c1"># Y(*,)</span>
        <span class="c1"># (*,)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">begin_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">):</span>
            <span class="c1"># nn.GRU</span>
            <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># nn.LSTM</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>


<span class="c1"># </span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">128</span>

<span class="c1"># PyTorch</span>
<span class="n">rnn_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span>
    <span class="n">input_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span>          <span class="c1"># , vocab_size</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span>         <span class="c1"># </span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>                    <span class="c1"># 1</span>
    <span class="n">bidirectional</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>            <span class="c1"># </span>
    <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="c1"># (****)(num_layers, batch_size, num_hiddens)</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>

<span class="c1"># [****]</span>
<span class="c1"># `rnn_layer``Y`</span>
<span class="c1"># </span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)))</span>    <span class="c1"># (num_steps, batch_size, vocab_size)</span>

<span class="n">Y</span><span class="p">,</span> <span class="n">state_new</span> <span class="o">=</span> <span class="n">rnn_layer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
<span class="c1"># Y: (num_steps, batch_size, num_hiddens)</span>
<span class="c1"># state_new: (num_layers, batch_size, num_hiddens)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Y.shape: </span><span class="si">{</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'state_new.shape: </span><span class="si">{</span><span class="n">state_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span><span class="n">rnn_layer</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">net</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Y.shape: torch.Size([5, 2, 128])
state_new.shape: torch.Size([1, 2, 128])
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[59]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>RNNModel(
  (rnn): RNN(28, 128)
  (linear): Linear(in_features=128, out_features=28, bias=True)
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.1.3.-%E8%AE%AD%E7%BB%83%E5%92%8C%E9%A2%84%E6%B5%8B">11.3.1.3. <a id="toc11_3_1_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.3.1.3.-%E8%AE%AD%E7%BB%83%E5%92%8C%E9%A2%84%E6%B5%8B"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.1.4.-warm-up-%E9%A2%84%E7%83%AD%E6%9C%9F">11.3.1.4. <a id="toc11_3_1_4_"></a><a href="#toc0_">warm-up </a><a class="anchor-link" href="#11.3.1.4.-warm-up-%E9%A2%84%E7%83%AD%E6%9C%9F"></a></h4><ul>
<li></li>
<li>num_steps</li>
<li>num_preds</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[61]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="k">def</span> <span class="nf">predict_ch8</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">num_preds</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">"""prefix"""</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">begin_state</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># print(f'prefix: {prefix}')</span>
    <span class="c1"># print(f'prefix[0]: {prefix[0]}')</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">prefix</span><span class="p">[</span><span class="mi">0</span><span class="p">]]]</span>
    <span class="c1"># print(f'outputs: {outputs}')</span>
    <span class="c1"># print(f'outputs[-1]: {outputs[-1]}')</span>

    <span class="n">get_input</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># (batch_size, num_steps)</span>

    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">prefix</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>  <span class="c1"># </span>
        <span class="c1"># print(f'y: {y}')</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">get_input</span><span class="p">(),</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">y</span><span class="p">])</span>
        <span class="c1"># print(f'outputs: {[vocab.idx_to_token[i] for i in outputs]}')</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_preds</span><span class="p">):</span>  <span class="c1"># num_preds</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">get_input</span><span class="p">(),</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">vocab</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>


<span class="c1"># </span>
<span class="n">predict_ch8</span><span class="p">(</span><span class="s1">'time traveller '</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[61]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>'time traveller cccccccccccccccccccccccccccccccccccccccccccccccccc'</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>Gradient Clipping
Gradient ClippingGradient Explosion</li>
</ul>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">clip_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="n">clip_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># </span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip_value</span><span class="p">)</span>
        <span class="c1"># </span>
        <span class="c1"># torch.nn.utils.clip_grad_value_(model.parameters(), clip_value)</span>
    
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>


 <span class="c1"># </span>
<span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[38]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="k">def</span> <span class="nf">grad_clipping</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">params</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">norm</span> <span class="o">&gt;</span> <span class="n">theta</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">[:]</span> <span class="o">*=</span> <span class="n">theta</span> <span class="o">/</span> <span class="n">norm</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[62]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="kn">import</span> <span class="nn">math</span> 


<span class="k">def</span> <span class="nf">train_epoch_ch8</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""8"""</span>
    <span class="n">state</span><span class="p">,</span> <span class="n">timer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Accumulator</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># ,</span>
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">use_random_iter</span><span class="p">:</span>
            <span class="c1"># state</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">begin_state</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="c1"># statenn.GRU</span>
                <span class="n">state</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># statenn.LSTM</span>
                <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
                    <span class="n">s</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">y_hat</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">long</span><span class="p">())</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">updater</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
            <span class="n">updater</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">grad_clipping</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">updater</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">grad_clipping</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="c1"># mean</span>
            <span class="n">updater</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">metric</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">l</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">numel</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>


<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">train_ch8</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span>
              <span class="n">use_random_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""8"""</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">'epoch'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'perplexity'</span><span class="p">,</span>
                            <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">'train'</span><span class="p">],</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">])</span>
    <span class="c1"># </span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="n">updater</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">updater</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">d2l</span><span class="o">.</span><span class="n">sgd</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">prefix</span><span class="p">:</span> <span class="n">predict_ch8</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="c1"># </span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">ppl</span><span class="p">,</span> <span class="n">speed</span> <span class="o">=</span> <span class="n">train_epoch_ch8</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="s1">'time traveller'</span><span class="p">))</span>
            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="n">ppl</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">' </span><span class="si">{</span><span class="n">ppl</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">speed</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1"> / </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="s1">'time traveller'</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="s1">'traveller'</span><span class="p">))</span>

<span class="c1"># </span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">35</span>
<span class="c1"># train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>

<span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mf">0.1</span>
<span class="n">train_ch8</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre> 5.1, 466010.7 / cuda:0
time traveller this and heredin t ioged an alle that merthe in t
travellers on the time traveller and and the proment ano th
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="262.1875pt" height="183.35625pt" viewBox="0 0 262.1875 183.35625" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-12-03T00:33:49.550713</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 183.35625 
L 262.1875 183.35625 
L 262.1875 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 50.14375 145.8 
L 245.44375 145.8 
L 245.44375 7.2 
L 50.14375 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 86.015179 145.8 
L 86.015179 7.2 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_2">
      <defs>
       <path id="m5993261be6" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m5993261be6" x="86.015179" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- 100 -->
      <g transform="translate(76.471429 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_3">
      <path d="M 125.872321 145.8 
L 125.872321 7.2 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_4">
      <g>
       <use xlink:href="#m5993261be6" x="125.872321" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 200 -->
      <g transform="translate(116.328571 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-32"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_5">
      <path d="M 165.729464 145.8 
L 165.729464 7.2 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_6">
      <g>
       <use xlink:href="#m5993261be6" x="165.729464" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 300 -->
      <g transform="translate(156.185714 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-33" d="M 2597 2516 
Q 3050 2419 3304 2112 
Q 3559 1806 3559 1356 
Q 3559 666 3084 287 
Q 2609 -91 1734 -91 
Q 1441 -91 1130 -33 
Q 819 25 488 141 
L 488 750 
Q 750 597 1062 519 
Q 1375 441 1716 441 
Q 2309 441 2620 675 
Q 2931 909 2931 1356 
Q 2931 1769 2642 2001 
Q 2353 2234 1838 2234 
L 1294 2234 
L 1294 2753 
L 1863 2753 
Q 2328 2753 2575 2939 
Q 2822 3125 2822 3475 
Q 2822 3834 2567 4026 
Q 2313 4219 1838 4219 
Q 1578 4219 1281 4162 
Q 984 4106 628 3988 
L 628 4550 
Q 988 4650 1302 4700 
Q 1616 4750 1894 4750 
Q 2613 4750 3031 4423 
Q 3450 4097 3450 3541 
Q 3450 3153 3228 2886 
Q 3006 2619 2597 2516 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-33"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_7">
      <path d="M 205.586607 145.8 
L 205.586607 7.2 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_8">
      <g>
       <use xlink:href="#m5993261be6" x="205.586607" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 400 -->
      <g transform="translate(196.042857 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-34"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_9">
      <path d="M 245.44375 145.8 
L 245.44375 7.2 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_10">
      <g>
       <use xlink:href="#m5993261be6" x="245.44375" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- 500 -->
      <g transform="translate(235.9 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-35"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="text_6">
     <!-- epoch -->
     <g transform="translate(132.565625 174.076563) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-68" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 4863 
L 1159 4863 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-65"/>
      <use xlink:href="#DejaVuSans-70" x="61.523438"/>
      <use xlink:href="#DejaVuSans-6f" x="125"/>
      <use xlink:href="#DejaVuSans-63" x="186.181641"/>
      <use xlink:href="#DejaVuSans-68" x="241.162109"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_11">
      <path d="M 50.14375 140.148239 
L 245.44375 140.148239 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_12">
      <defs>
       <path id="m0540bc9c12" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m0540bc9c12" x="50.14375" y="140.148239" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 5.0 -->
      <g transform="translate(27.240625 143.947458) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-35"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_13">
      <path d="M 50.14375 114.39123 
L 245.44375 114.39123 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_14">
      <g>
       <use xlink:href="#m0540bc9c12" x="50.14375" y="114.39123" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 7.5 -->
      <g transform="translate(27.240625 118.190449) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-37" d="M 525 4666 
L 3525 4666 
L 3525 4397 
L 1831 0 
L 1172 0 
L 2766 4134 
L 525 4134 
L 525 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-37"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-35" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_15">
      <path d="M 50.14375 88.634221 
L 245.44375 88.634221 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_16">
      <g>
       <use xlink:href="#m0540bc9c12" x="50.14375" y="88.634221" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <!-- 10.0 -->
      <g transform="translate(20.878125 92.43344) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-2e" x="127.246094"/>
       <use xlink:href="#DejaVuSans-30" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_17">
      <path d="M 50.14375 62.877212 
L 245.44375 62.877212 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_18">
      <g>
       <use xlink:href="#m0540bc9c12" x="50.14375" y="62.877212" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_10">
      <!-- 12.5 -->
      <g transform="translate(20.878125 66.67643) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-32" x="63.623047"/>
       <use xlink:href="#DejaVuSans-2e" x="127.246094"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_19">
      <path d="M 50.14375 37.120203 
L 245.44375 37.120203 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_20">
      <g>
       <use xlink:href="#m0540bc9c12" x="50.14375" y="37.120203" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_11">
      <!-- 15.0 -->
      <g transform="translate(20.878125 40.919421) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-35" x="63.623047"/>
       <use xlink:href="#DejaVuSans-2e" x="127.246094"/>
       <use xlink:href="#DejaVuSans-30" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_6">
     <g id="line2d_21">
      <path d="M 50.14375 11.363194 
L 245.44375 11.363194 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_22">
      <g>
       <use xlink:href="#m0540bc9c12" x="50.14375" y="11.363194" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_12">
      <!-- 17.5 -->
      <g transform="translate(20.878125 15.162412) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-37" x="63.623047"/>
       <use xlink:href="#DejaVuSans-2e" x="127.246094"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="text_13">
     <!-- perplexity -->
     <g transform="translate(14.798437 101.626563) rotate(-90) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-72" d="M 2631 2963 
Q 2534 3019 2420 3045 
Q 2306 3072 2169 3072 
Q 1681 3072 1420 2755 
Q 1159 2438 1159 1844 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1341 3275 1631 3429 
Q 1922 3584 2338 3584 
Q 2397 3584 2469 3576 
Q 2541 3569 2628 3553 
L 2631 2963 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6c" d="M 603 4863 
L 1178 4863 
L 1178 0 
L 603 0 
L 603 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-78" d="M 3513 3500 
L 2247 1797 
L 3578 0 
L 2900 0 
L 1881 1375 
L 863 0 
L 184 0 
L 1544 1831 
L 300 3500 
L 978 3500 
L 1906 2253 
L 2834 3500 
L 3513 3500 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-69" d="M 603 3500 
L 1178 3500 
L 1178 0 
L 603 0 
L 603 3500 
z
M 603 4863 
L 1178 4863 
L 1178 4134 
L 603 4134 
L 603 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-79" d="M 2059 -325 
Q 1816 -950 1584 -1140 
Q 1353 -1331 966 -1331 
L 506 -1331 
L 506 -850 
L 844 -850 
Q 1081 -850 1212 -737 
Q 1344 -625 1503 -206 
L 1606 56 
L 191 3500 
L 800 3500 
L 1894 763 
L 2988 3500 
L 3597 3500 
L 2059 -325 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-70"/>
      <use xlink:href="#DejaVuSans-65" x="63.476562"/>
      <use xlink:href="#DejaVuSans-72" x="125"/>
      <use xlink:href="#DejaVuSans-70" x="166.113281"/>
      <use xlink:href="#DejaVuSans-6c" x="229.589844"/>
      <use xlink:href="#DejaVuSans-65" x="257.373047"/>
      <use xlink:href="#DejaVuSans-78" x="317.146484"/>
      <use xlink:href="#DejaVuSans-69" x="376.326172"/>
      <use xlink:href="#DejaVuSans-74" x="404.109375"/>
      <use xlink:href="#DejaVuSans-79" x="443.318359"/>
     </g>
    </g>
   </g>
   <g id="line2d_23">
    <path d="M 50.14375 13.5 
L 54.129464 18.0495 
L 58.115179 25.055054 
L 62.100893 34.614152 
L 66.086607 44.831669 
L 70.072321 53.886683 
L 74.058036 62.143667 
L 78.04375 68.08641 
L 82.029464 73.414657 
L 86.015179 77.692842 
L 90.000893 81.345669 
L 93.986607 84.514807 
L 97.972321 87.586178 
L 101.958036 90.270084 
L 105.94375 91.830293 
L 109.929464 94.468642 
L 113.915179 95.582305 
L 117.900893 97.727729 
L 121.886607 99.031206 
L 125.872321 99.759825 
L 129.858036 101.06579 
L 133.84375 103.109254 
L 137.829464 104.094147 
L 141.815179 105.580781 
L 145.800893 106.691054 
L 149.786607 108.249658 
L 153.772321 108.972132 
L 157.758036 110.319303 
L 161.74375 111.569507 
L 165.729464 112.42697 
L 169.715179 114.579692 
L 173.700893 114.949141 
L 177.686607 116.847394 
L 181.672321 118.290438 
L 185.658036 119.484067 
L 189.64375 120.409555 
L 193.629464 121.536275 
L 197.615179 123.061408 
L 201.600893 124.704499 
L 205.586607 125.739535 
L 209.572321 127.99086 
L 213.558036 129.129209 
L 217.54375 130.47843 
L 221.529464 132.243209 
L 225.515179 133.354917 
L 229.500893 134.865151 
L 233.486607 136.13642 
L 237.472321 137.54092 
L 241.458036 138.045549 
L 245.44375 139.5 
" clip-path="url(#pabc858b0f6)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="patch_3">
    <path d="M 50.14375 145.8 
L 50.14375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 245.44375 145.8 
L 245.44375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 50.14375 145.8 
L 245.44375 145.8 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 50.14375 7.2 
L 245.44375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="legend_1">
    <g id="patch_7">
     <path d="M 183.16875 29.878125 
L 238.44375 29.878125 
Q 240.44375 29.878125 240.44375 27.878125 
L 240.44375 14.2 
Q 240.44375 12.2 238.44375 12.2 
L 183.16875 12.2 
Q 181.16875 12.2 181.16875 14.2 
L 181.16875 27.878125 
Q 181.16875 29.878125 183.16875 29.878125 
z
" style="fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter"/>
    </g>
    <g id="line2d_24">
     <path d="M 185.16875 20.298438 
L 195.16875 20.298438 
L 205.16875 20.298438 
" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
    </g>
    <g id="text_14">
     <!-- train -->
     <g transform="translate(213.16875 23.798438) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-61" d="M 2194 1759 
Q 1497 1759 1228 1600 
Q 959 1441 959 1056 
Q 959 750 1161 570 
Q 1363 391 1709 391 
Q 2188 391 2477 730 
Q 2766 1069 2766 1631 
L 2766 1759 
L 2194 1759 
z
M 3341 1997 
L 3341 0 
L 2766 0 
L 2766 531 
Q 2569 213 2275 61 
Q 1981 -91 1556 -91 
Q 1019 -91 701 211 
Q 384 513 384 1019 
Q 384 1609 779 1909 
Q 1175 2209 1959 2209 
L 2766 2209 
L 2766 2266 
Q 2766 2663 2505 2880 
Q 2244 3097 1772 3097 
Q 1472 3097 1187 3025 
Q 903 2953 641 2809 
L 641 3341 
Q 956 3463 1253 3523 
Q 1550 3584 1831 3584 
Q 2591 3584 2966 3190 
Q 3341 2797 3341 1997 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-74"/>
      <use xlink:href="#DejaVuSans-72" x="39.208984"/>
      <use xlink:href="#DejaVuSans-61" x="80.322266"/>
      <use xlink:href="#DejaVuSans-69" x="141.601562"/>
      <use xlink:href="#DejaVuSans-6e" x="169.384766"/>
     </g>
    </g>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="pabc858b0f6">
   <rect x="50.14375" y="7.2" width="195.3" height="138.6"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.1.5.-%E6%B7%B1%E5%B1%82RNN">11.3.1.5. <a id="toc11_3_1_5_"></a><a href="#toc0_">RNN</a><a class="anchor-link" href="#11.3.1.5.-%E6%B7%B1%E5%B1%82RNN"></a></h4><ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[90]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span> 


<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">512</span>


<span class="n">rnn_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span>
    <span class="n">input_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span>            <span class="c1"># </span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span>           <span class="c1"># </span>
    <span class="n">bidirectional</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>     <span class="c1"># </span>
    <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>             <span class="c1"># 1</span>
    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>


<span class="c1"># dir(rnn_layer)      # </span>
<span class="c1"># help(rnn_layer)   # </span>

<span class="c1"># </span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Initial state </span>
<span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
<span class="n">y</span><span class="p">,</span> <span class="n">new_state</span> <span class="o">=</span> <span class="n">rnn_layer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

<span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[90]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 5, 512]), torch.Size([5, 2, 512]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.1.6.-%E5%8F%8C%E5%90%91RNN">11.3.1.6. <a id="toc11_3_1_6_"></a><a href="#toc0_">RNN</a><a class="anchor-link" href="#11.3.1.6.-%E5%8F%8C%E5%90%91RNN"></a></h4><ul>
<li></li>
<li></li>
<li><ul>
<li></li>
<li></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[104]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span> 


<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">1</span>

<span class="n">rnn_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span>
    <span class="n">input_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span>            <span class="c1"># </span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span>           <span class="c1"># </span>
    <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidirectional</span><span class="p">,</span>     <span class="c1"># </span>
    <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>             <span class="c1"># 1 </span>
    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># dir(rnn_layer)      # </span>
<span class="c1"># help(rnn_layer)   # </span>

<span class="c1"># input</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Initial state</span>
<span class="c1"># 2</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_layers</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>

<span class="n">y</span><span class="p">,</span> <span class="n">new_state</span> <span class="o">=</span> <span class="n">rnn_layer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

<span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">new_state</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[104]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 5, 1024]), torch.Size([2, 2, 512]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.3.2.-GRU">11.3.2. <a id="toc11_3_2_"></a><a href="#toc0_">GRU</a><a class="anchor-link" href="#11.3.2.-GRU"></a></h3><ul>
<li>GRULSTM</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.2.1.-%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0">11.3.2.1. <a id="toc11_3_2_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.3.2.1.-%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.2.2.-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0">11.3.2.2. <a id="toc11_3_2_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.3.2.2.-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[122]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1</span>   

<span class="n">gru_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
    <span class="n">input_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> 
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span> 
    <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> 
    <span class="n">bidirectional</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># input     </span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Initial state </span>
<span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>

<span class="n">y</span><span class="p">,</span> <span class="n">new_state</span> <span class="o">=</span> <span class="n">gru_layer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

<span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">new_state</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[122]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 5, 512]), torch.Size([1, 2, 512]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.3.3.-LSTM">11.3.3. <a id="toc11_3_3_"></a><a href="#toc0_">LSTM</a><a class="anchor-link" href="#11.3.3.-LSTM"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.3.1.-%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0">11.3.3.1. <a id="toc11_3_3_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.3.3.1.-%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.3.2.-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0">11.3.3.2. <a id="toc11_3_3_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.3.3.2.-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>


<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1</span>

<span class="n">lstm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
    <span class="n">input_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span>  <span class="c1">#   </span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span> 
    <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> 
    <span class="n">bidirectional</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>


<span class="c1"># input</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Initial state </span>
<span class="c1"># hidden_state  cell_state </span>
<span class="n">hidden_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
<span class="n">cell_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>

<span class="n">y</span><span class="p">,</span> <span class="n">new_state</span> <span class="o">=</span> <span class="n">lstm_layer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden_state</span><span class="p">,</span> <span class="n">cell_state</span><span class="p">))</span>

<span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">new_state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">new_state</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[36]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 5, 512]), torch.Size([1, 2, 512]), torch.Size([1, 2, 512]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.3.4.-Encoder-Decoder%E6%A1%86%E6%9E%B6">11.3.4. <a id="toc11_3_4_"></a><a href="#toc0_">Encoder-Decoder</a><a class="anchor-link" href="#11.3.4.-Encoder-Decoder%E6%A1%86%E6%9E%B6"></a></h3><div class="highlight"><pre><span></span>-Encoder--Decoder-
<span class="w">                       </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.4.1.-Encoder%E9%83%A8%E5%88%86">11.3.4.1. <a id="toc11_3_4_1_"></a><a href="#toc0_">Encoder</a><a class="anchor-link" href="#11.3.4.1.-Encoder%E9%83%A8%E5%88%86"></a></h4><p>Encoder</p>
<div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[231]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""-"""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.4.2.-Decoder%E9%83%A8%E5%88%86">11.3.4.2. <a id="toc11_3_4_2_"></a><a href="#toc0_">Decoder</a><a class="anchor-link" href="#11.3.4.2.-Decoder%E9%83%A8%E5%88%86"></a></h4><p>Decoder</p>
<div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[232]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""-"""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.3.4.3.-Encoder-Decoder%EF%BC%88%E5%90%88%E5%B9%B6%E7%BC%96%E7%A0%81%E5%99%A8%E5%92%8C%E8%A7%A3%E7%A0%81%E5%99%A8%EF%BC%89">11.3.4.3. <a id="toc11_3_4_3_"></a><a href="#toc0_">Encoder-Decoder</a><a class="anchor-link" href="#11.3.4.3.-Encoder-Decoder%EF%BC%88%E5%90%88%E5%B9%B6%E7%BC%96%E7%A0%81%E5%99%A8%E5%92%8C%E8%A7%A3%E7%A0%81%E5%99%A8%EF%BC%89"></a></h4><div class="highlight"><pre><span></span>Encoder-Decoder
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[233]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">EncoderDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""-"""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_X</span><span class="p">,</span> <span class="n">dec_X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">enc_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">enc_X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="n">dec_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_X</span><span class="p">,</span> <span class="n">dec_state</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11.4.-seq2seq-(Sequence-to-sequence-learning)">11.4. <a id="toc11_4_"></a><a href="#toc0_">seq2seq (Sequence to sequence learning)</a><a class="anchor-link" href="#11.4.-seq2seq-(Sequence-to-sequence-learning)"></a></h2><p>Seq2Seq  Google RNNEncoderDecoderAttentionSeq2Seq </p>
<div class="highlight"><pre><span></span>RNN-<span class="o">(</span>Encoder-Decoder<span class="o">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.4.1.-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%9B%86">11.4.1. <a id="toc11_4_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.4.1.-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%9B%86"></a></h3><p></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.4.1.1.-%E4%B8%8B%E8%BD%BD%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E9%9B%86">11.4.1.1. <a id="toc11_4_1_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.4.1.1.-%E4%B8%8B%E8%BD%BD%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E9%9B%86"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[63]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>


<span class="c1">#@save</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">DATA_HUB</span><span class="p">[</span><span class="s1">'fra-eng'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">DATA_URL</span> <span class="o">+</span> <span class="s1">'fra-eng.zip'</span><span class="p">,</span> <span class="s1">'94646ad1522d915e7b0f9296181140edcf86a4f5'</span><span class="p">)</span>

<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">read_data_nmt</span><span class="p">():</span>    
<span class="w">    </span><span class="sd">""""""</span>
    <span class="n">data_dir</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">download_extract</span><span class="p">(</span><span class="s1">'fra-eng'</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'fra.txt'</span><span class="p">),</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">raw_text</span> <span class="o">=</span> <span class="n">read_data_nmt</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">raw_text</span><span class="p">[:</span><span class="mi">75</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Go.	Va !
Hi.	Salut !
Run!	Cours!
Run!	Courez!
Who?	Qui ?
Wow!	a alors!

</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">'''</span>
<span class="sd">nonbreaking</span>
<span class="sd"> space</span>
<span class="sd">'''</span>
<span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">preprocess_nmt</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Preprocess the English-French dataset."""</span>
    <span class="k">def</span> <span class="nf">no_space</span><span class="p">(</span><span class="n">char</span><span class="p">,</span> <span class="n">prev_char</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="s1">',.!?'</span><span class="p">)</span> <span class="ow">and</span> <span class="n">prev_char</span> <span class="o">!=</span> <span class="s1">' '</span>

    <span class="c1"># Replace non-breaking space with space, and convert uppercase letters to</span>
    <span class="c1"># lowercase ones</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'</span><span class="se">\u202f</span><span class="s1">'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'</span><span class="se">\xa0</span><span class="s1">'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="c1"># Insert space between words and punctuation marks</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="s1">' '</span> <span class="o">+</span> <span class="n">char</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">no_space</span><span class="p">(</span><span class="n">char</span><span class="p">,</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span> <span class="k">else</span> <span class="n">char</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">text</span><span class="p">)]</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">preprocess_nmt</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">[:</span><span class="mi">80</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>go .	va !
hi .	salut !
run !	cours !
run !	courez !
who ?	qui ?
wow !	a alors !
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.4.1.2.-%E8%AF%8D%E5%85%83%E5%8C%96">11.4.1.2. <a id="toc11_4_1_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.4.1.2.-%E8%AF%8D%E5%85%83%E5%8C%96"></a></h4><p></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[66]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">'''</span>
<span class="sd">sourcetargetsource[i]</span>
<span class="sd">itarget[i]i</span>
<span class="sd">'''</span>
<span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">tokenize_nmt</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">num_examples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Tokenize the English-French dataset."""</span>
    <span class="n">source</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">num_examples</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="n">num_examples</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">source</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">))</span>
            <span class="n">target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">source</span><span class="p">,</span> <span class="n">target</span>

<span class="n">source</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">tokenize_nmt</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">source</span><span class="p">[:</span><span class="mi">6</span><span class="p">],</span> <span class="n">target</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[66]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>([['go', '.'],
  ['hi', '.'],
  ['run', '!'],
  ['run', '!'],
  ['who', '?'],
  ['wow', '!']],
 [['va', '!'],
  ['salut', '!'],
  ['cours', '!'],
  ['courez', '!'],
  ['qui', '?'],
  ['a', 'alors', '!']])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.4.1.3.-%E8%AF%8D%E8%A1%A8">11.4.1.3. <a id="toc11_4_1_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.4.1.3.-%E8%AF%8D%E8%A1%A8"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[67]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="n">src_vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">reserved_tokens</span><span class="o">=</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">,</span> <span class="s1">'&lt;bos&gt;'</span><span class="p">,</span> <span class="s1">'&lt;eos&gt;'</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>10012
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">src_vocab</span><span class="p">[</span><span class="s1">'unk'</span><span class="p">],</span> <span class="n">src_vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">],</span> <span class="n">src_vocab</span><span class="p">[</span><span class="s1">'&lt;bos&gt;'</span><span class="p">],</span> <span class="n">src_vocab</span><span class="p">[</span><span class="s1">'&lt;eos&gt;'</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[6]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(0, 1, 2, 3)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">src_vocab</span><span class="o">.</span><span class="n">token_to_idx</span>  <span class="c1"># dict</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[7]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>{'&lt;unk&gt;': 0,
 '&lt;pad&gt;': 1,
 '&lt;bos&gt;': 2,
 '&lt;eos&gt;': 3,
 '.': 4,
 'i': 5,
 'you': 6,
 'to': 7,
 'the': 8,
 '?': 9,
 'a': 10,
 'is': 11,
 'tom': 12,
 'that': 13,
 'he': 14,
 'do': 15,
 'of': 16,
 'it': 17,
 'this': 18,
 'in': 19,
 'me': 20,
 'have': 21,
 "don't": 22,
 ',': 23,
 'was': 24,
 'my': 25,
 'are': 26,
 'for': 27,
 'your': 28,
 'what': 29,
 "i'm": 30,
 'we': 31,
 'be': 32,
 'want': 33,
 'she': 34,
 'not': 35,
 'know': 36,
 'like': 37,
 'on': 38,
 'with': 39,
 'can': 40,
 'his': 41,
 'all': 42,
 'did': 43,
 'at': 44,
 "you're": 45,
 'how': 46,
 'go': 47,
 'they': 48,
 'him': 49,
 'think': 50,
 'and': 51,
 "it's": 52,
 'about': 53,
 'time': 54,
 "can't": 55,
 'here': 56,
 'very': 57,
 "didn't": 58,
 'get': 59,
 'there': 60,
 'her': 61,
 'were': 62,
 'as': 63,
 'will': 64,
 'had': 65,
 'if': 66,
 'why': 67,
 'just': 68,
 'up': 69,
 'out': 70,
 'no': 71,
 'has': 72,
 'one': 73,
 'going': 74,
 'would': 75,
 'so': 76,
 'good': 77,
 'need': 78,
 'tell': 79,
 'an': 80,
 'see': 81,
 "i'll": 82,
 'come': 83,
 'when': 84,
 'from': 85,
 'by': 86,
 'really': 87,
 'mary': 88,
 'help': 89,
 'who': 90,
 'please': 91,
 'us': 92,
 "that's": 93,
 'should': 94,
 'could': 95,
 'been': 96,
 "i've": 97,
 'never': 98,
 'more': 99,
 'now': 100,
 'where': 101,
 'take': 102,
 'something': 103,
 'got': 104,
 'too': 105,
 'than': 106,
 'much': 107,
 'make': 108,
 'some': 109,
 "i'd": 110,
 "we're": 111,
 'right': 112,
 'but': 113,
 'work': 114,
 'am': 115,
 'money': 116,
 'any': 117,
 'home': 118,
 'last': 119,
 'thought': 120,
 'say': 121,
 'sure': 122,
 'anything': 123,
 'look': 124,
 'back': 125,
 '!': 126,
 'day': 127,
 "doesn't": 128,
 'give': 129,
 'car': 130,
 'told': 131,
 'talk': 132,
 'people': 133,
 'made': 134,
 'lot': 135,
 'let': 136,
 'way': 137,
 'our': 138,
 'must': 139,
 'many': 140,
 'said': 141,
 "he's": 142,
 'love': 143,
 'long': 144,
 'went': 145,
 'still': 146,
 'feel': 147,
 'only': 148,
 'eat': 149,
 'always': 150,
 'better': 151,
 'happy': 152,
 'doing': 153,
 'today': 154,
 'french': 155,
 'house': 156,
 "isn't": 157,
 "let's": 158,
 'does': 159,
 'new': 160,
 'believe': 161,
 'before': 162,
 'leave': 163,
 "what's": 164,
 'book': 165,
 'again': 166,
 'them': 167,
 'room': 168,
 'job': 169,
 'off': 170,
 'school': 171,
 'night': 172,
 'little': 173,
 'well': 174,
 "won't": 175,
 'may': 176,
 'old': 177,
 'down': 178,
 'wanted': 179,
 'everything': 180,
 'yesterday': 181,
 'alone': 182,
 'happened': 183,
 'tomorrow': 184,
 'father': 185,
 'stay': 186,
 'two': 187,
 'put': 188,
 'left': 189,
 'over': 190,
 'enough': 191,
 'every': 192,
 'asked': 193,
 'three': 194,
 'speak': 195,
 'find': 196,
 'stop': 197,
 'these': 198,
 'saw': 199,
 'man': 200,
 'into': 201,
 'done': 202,
 'try': 203,
 'understand': 204,
 'ask': 205,
 'or': 206,
 'ever': 207,
 'keep': 208,
 'friends': 209,
 'problem': 210,
 'sorry': 211,
 'next': 212,
 'nothing': 213,
 "there's": 214,
 'dog': 215,
 'after': 216,
 'call': 217,
 'buy': 218,
 'hard': 219,
 "you've": 220,
 'hope': 221,
 'busy': 222,
 'read': 223,
 'away': 224,
 'live': 225,
 'friend': 226,
 'wrong': 227,
 'late': 228,
 'first': 229,
 'things': 230,
 'door': 231,
 'hear': 232,
 "tom's": 233,
 'life': 234,
 "they're": 235,
 'thing': 236,
 'other': 237,
 'remember': 238,
 'idea': 239,
 "wasn't": 240,
 'boston': 241,
 'anyone': 242,
 'mother': 243,
 'years': 244,
 'took': 245,
 'gave': 246,
 'without': 247,
 'being': 248,
 'their': 249,
 'everyone': 250,
 "couldn't": 251,
 'mind': 252,
 'came': 253,
 'children': 254,
 'yet': 255,
 'knew': 256,
 'already': 257,
 "you'd": 258,
 'used': 259,
 'name': 260,
 'kind': 261,
 'drink': 262,
 'tired': 263,
 'looking': 264,
 'morning': 265,
 'heard': 266,
 'seen': 267,
 'best': 268,
 'bad': 269,
 "you'll": 270,
 'lost': 271,
 'teacher': 272,
 'found': 273,
 'even': 274,
 'play': 275,
 'water': 276,
 "haven't": 277,
 'same': 278,
 'care': 279,
 'often': 280,
 'week': 281,
 'english': 282,
 "aren't": 283,
 'use': 284,
 'soon': 285,
 'wait': 286,
 'afraid': 287,
 'ready': 288,
 'wish': 289,
 'answer': 290,
 'big': 291,
 'yourself': 292,
 'bed': 293,
 'party': 294,
 'someone': 295,
 'while': 296,
 'few': 297,
 'happen': 298,
 'talking': 299,
 'else': 300,
 'parents': 301,
 'wants': 302,
 'cold': 303,
 'train': 304,
 'myself': 305,
 'open': 306,
 'around': 307,
 'show': 308,
 'might': 309,
 'bought': 310,
 'nice': 311,
 'glad': 312,
 'both': 313,
 'getting': 314,
 'married': 315,
 'another': 316,
 "we'll": 317,
 'place': 318,
 'watch': 319,
 'great': 320,
 'turn': 321,
 'year': 322,
 'true': 323,
 'looks': 324,
 'early': 325,
 'because': 326,
 'such': 327,
 'knows': 328,
 'beautiful': 329,
 'sleep': 330,
 'write': 331,
 'plan': 332,
 'hurt': 333,
 "wouldn't": 334,
 'almost': 335,
 'able': 336,
 "she's": 337,
 'those': 338,
 'walk': 339,
 'once': 340,
 'which': 341,
 'tried': 342,
 'pay': 343,
 'matter': 344,
 'question': 345,
 'food': 346,
 'fun': 347,
 'meet': 348,
 'dinner': 349,
 'days': 350,
 'bus': 351,
 'coffee': 352,
 'brother': 353,
 'letter': 354,
 'truth': 355,
 'met': 356,
 'coming': 357,
 'anymore': 358,
 'everybody': 359,
 'young': 360,
 'meeting': 361,
 'most': 362,
 'person': 363,
 'mine': 364,
 'books': 365,
 "shouldn't": 366,
 'careful': 367,
 'sister': 368,
 'each': 369,
 'own': 370,
 'family': 371,
 'together': 372,
 'hate': 373,
 'felt': 374,
 'seems': 375,
 'tonight': 376,
 'doctor': 377,
 'change': 378,
 'learn': 379,
 'seem': 380,
 'since': 381,
 'likes': 382,
 'study': 383,
 'word': 384,
 'waiting': 385,
 'forget': 386,
 'easy': 387,
 'pretty': 388,
 'died': 389,
 'trying': 390,
 'girl': 391,
 'phone': 392,
 'world': 393,
 'far': 394,
 'gone': 395,
 'working': 396,
 "we've": 397,
 'hand': 398,
 'started': 399,
 'child': 400,
 'accident': 401,
 'station': 402,
 'mean': 403,
 'nobody': 404,
 'finished': 405,
 'longer': 406,
 'difficult': 407,
 'sick': 408,
 'boy': 409,
 'surprised': 410,
 'important': 411,
 'start': 412,
 'rain': 413,
 'looked': 414,
 'quite': 415,
 'lunch': 416,
 'cat': 417,
 'drive': 418,
 'wife': 419,
 'questions': 420,
 'weather': 421,
 'anybody': 422,
 'reading': 423,
 'movie': 424,
 'having': 425,
 'yours': 426,
 'makes': 427,
 'mistake': 428,
 'supposed': 429,
 'thank': 430,
 'office': 431,
 'story': 432,
 'until': 433,
 'ten': 434,
 'run': 435,
 'swim': 436,
 'small': 437,
 'tv': 438,
 'times': 439,
 'close': 440,
 'himself': 441,
 'bit': 442,
 'playing': 443,
 'spend': 444,
 'angry': 445,
 'eyes': 446,
 'trust': 447,
 'stupid': 448,
 'called': 449,
 'ago': 450,
 'guess': 451,
 'advice': 452,
 'japan': 453,
 'hurry': 454,
 'picture': 455,
 'hours': 456,
 '."': 457,
 'broke': 458,
 'music': 459,
 'exactly': 460,
 'says': 461,
 'caught': 462,
 'students': 463,
 'wonder': 464,
 'son': 465,
 'lives': 466,
 'fire': 467,
 'afternoon': 468,
 'window': 469,
 'eating': 470,
 'turned': 471,
 'police': 472,
 'bicycle': 473,
 'thinking': 474,
 'fell': 475,
 'ran': 476,
 'decided': 477,
 'table': 478,
 'fast': 479,
 'usually': 480,
 'probably': 481,
 "who's": 482,
 'minutes': 483,
 'japanese': 484,
 'interested': 485,
 'interesting': 486,
 'trouble': 487,
 'free': 488,
 'hair': 489,
 'arrived': 490,
 'hot': 491,
 'bring': 492,
 "weren't": 493,
 'light': 494,
 'town': 495,
 'homework': 496,
 'advised': 497,
 'worry': 498,
 'number': 499,
 'park': 500,
 'game': 501,
 'under': 502,
 'safe': 503,
 'listen': 504,
 'forgot': 505,
 'stand': 506,
 'enjoy': 507,
 'country': 508,
 'living': 509,
 'news': 510,
 'through': 511,
 'against': 512,
 'appreciate': 513,
 'agree': 514,
 'age': 515,
 'miss': 516,
 'sit': 517,
 'hands': 518,
 'quit': 519,
 'promise': 520,
 'proud': 521,
 'sing': 522,
 'chance': 523,
 'saying': 524,
 'possible': 525,
 'visit': 526,
 'finish': 527,
 'different': 528,
 'maybe': 529,
 'later': 530,
 'high': 531,
 'reason': 532,
 'wine': 533,
 'then': 534,
 'outside': 535,
 'summer': 536,
 'kept': 537,
 'taking': 538,
 'catch': 539,
 'hungry': 540,
 'needs': 541,
 'born': 542,
 'lie': 543,
 'making': 544,
 "should've": 545,
 'cut': 546,
 'business': 547,
 'moment': 548,
 'trip': 549,
 'favorite': 550,
 'dead': 551,
 'end': 552,
 'ok': 553,
 'shoes': 554,
 'older': 555,
 'become': 556,
 'win': 557,
 'tree': 558,
 'behind': 559,
 'five': 560,
 'box': 561,
 'near': 562,
 'works': 563,
 'red': 564,
 'girlfriend': 565,
 'breakfast': 566,
 'die': 567,
 'class': 568,
 'song': 569,
 'tea': 570,
 'eaten': 571,
 'city': 572,
 'dress': 573,
 'student': 574,
 'baby': 575,
 "mary's": 576,
 'rich': 577,
 'needed': 578,
 'guy': 579,
 'face': 580,
 'funny': 581,
 'secret': 582,
 'team': 583,
 'month': 584,
 'company': 585,
 'full': 586,
 'quickly': 587,
 'comes': 588,
 'paid': 589,
 'stayed': 590,
 "where's": 591,
 'crazy': 592,
 'fish': 593,
 'rest': 594,
 'ate': 595,
 'lose': 596,
 'woman': 597,
 'point': 598,
 'watching': 599,
 'tennis': 600,
 'beer': 601,
 'explain': 602,
 'part': 603,
 'invited': 604,
 'serious': 605,
 'cannot': 606,
 'break': 607,
 'large': 608,
 'clothes': 609,
 'daughter': 610,
 'smoking': 611,
 'hotel': 612,
 'kids': 613,
 'key': 614,
 'choice': 615,
 'asleep': 616,
 'hat': 617,
 'feeling': 618,
 'sound': 619,
 'death': 620,
 'cost': 621,
 'somebody': 622,
 'clean': 623,
 'australia': 624,
 'spent': 625,
 'worried': 626,
 'began': 627,
 'words': 628,
 'real': 629,
 'lived': 630,
 'wearing': 631,
 '?"': 632,
 'studying': 633,
 'handle': 634,
 'expensive': 635,
 'sometimes': 636,
 'goes': 637,
 'hour': 638,
 'became': 639,
 'street': 640,
 'touch': 641,
 'hit': 642,
 'milk': 643,
 'river': 644,
 'killed': 645,
 'store': 646,
 'hospital': 647,
 'changed': 648,
 'short': 649,
 'rather': 650,
 'decision': 651,
 'computer': 652,
 'others': 653,
 'telling': 654,
 'drunk': 655,
 'deal': 656,
 'between': 657,
 'paper': 658,
 'hold': 659,
 'lucky': 660,
 'cake': 661,
 'scared': 662,
 'takes': 663,
 'birthday': 664,
 'snow': 665,
 'language': 666,
 'closed': 667,
 'present': 668,
 'helped': 669,
 'dark': 670,
 'minute': 671,
 'stopped': 672,
 'problems': 673,
 'restaurant': 674,
 'sat': 675,
 'monday': 676,
 'speaking': 677,
 'expect': 678,
 'front': 679,
 'whole': 680,
 'quiet': 681,
 'war': 682,
 'mistakes': 683,
 'figured': 684,
 'worked': 685,
 'finally': 686,
 'gets': 687,
 'along': 688,
 'head': 689,
 'report': 690,
 'wrote': 691,
 'happening': 692,
 'dogs': 693,
 'coat': 694,
 'sense': 695,
 'cup': 696,
 'talked': 697,
 'liked': 698,
 'strong': 699,
 'upset': 700,
 'kill': 701,
 'speaks': 702,
 'thanks': 703,
 'missed': 704,
 'forward': 705,
 'strange': 706,
 'expected': 707,
 'check': 708,
 'boss': 709,
 'dream': 710,
 'dangerous': 711,
 'beach': 712,
 'known': 713,
 'health': 714,
 'situation': 715,
 'actually': 716,
 'running': 717,
 'brought': 718,
 'whether': 719,
 'six': 720,
 'its': 721,
 'whatever': 722,
 'dictionary': 723,
 'move': 724,
 'seeing': 725,
 'shut': 726,
 'order': 727,
 'swimming': 728,
 'weekend': 729,
 'tall': 730,
 'men': 731,
 'air': 732,
 'evening': 733,
 'walked': 734,
 'plane': 735,
 'allowed': 736,
 'thirty': 737,
 'loves': 738,
 'case': 739,
 'least': 740,
 'building': 741,
 'broken': 742,
 'list': 743,
 'worth': 744,
 'happens': 745,
 'heart': 746,
 'disappointed': 747,
 'follow': 748,
 'famous': 749,
 'prefer': 750,
 'written': 751,
 'smoke': 752,
 'christmas': 753,
 'perfect': 754,
 'drinking': 755,
 "o'clock": 756,
 'luck': 757,
 'choose': 758,
 'completely': 759,
 'dollars': 760,
 'pain': 761,
 'future': 762,
 'either': 763,
 'mad': 764,
 'seat': 765,
 'crying': 766,
 'dance': 767,
 'second': 768,
 'piano': 769,
 'offer': 770,
 'necessary': 771,
 'fine': 772,
 'half': 773,
 'sent': 774,
 'sunday': 775,
 "hasn't": 776,
 'garden': 777,
 'apologize': 778,
 'rules': 779,
 'road': 780,
 'library': 781,
 'leaving': 782,
 'noise': 783,
 'weight': 784,
 'flowers': 785,
 'wear': 786,
 'opinion': 787,
 'cook': 788,
 'writing': 789,
 'camera': 790,
 'set': 791,
 'taken': 792,
 'glass': 793,
 'learned': 794,
 'address': 795,
 'somewhere': 796,
 'poor': 797,
 'several': 798,
 "it'll": 799,
 'white': 800,
 'danger': 801,
 'attention': 802,
 "he'll": 803,
 'tokyo': 804,
 'floor': 805,
 'save': 806,
 'alive': 807,
 'accept': 808,
 'information': 809,
 'clear': 810,
 'suppose': 811,
 'opened': 812,
 'during': 813,
 'kiss': 814,
 'loved': 815,
 'nervous': 816,
 'grow': 817,
 'girls': 818,
 'waste': 819,
 'showed': 820,
 'join': 821,
 'women': 822,
 'bag': 823,
 'sleeping': 824,
 'listening': 825,
 'less': 826,
 'solve': 827,
 'sad': 828,
 'won': 829,
 'date': 830,
 'shopping': 831,
 'blame': 832,
 'desk': 833,
 'tie': 834,
 'medicine': 835,
 'vacation': 836,
 'pass': 837,
 'college': 838,
 'side': 839,
 'success': 840,
 'teach': 841,
 'keys': 842,
 'arrive': 843,
 'umbrella': 844,
 'fix': 845,
 'sounds': 846,
 'ticket': 847,
 'whose': 848,
 'ship': 849,
 'radio': 850,
 'lying': 851,
 'spoke': 852,
 'smart': 853,
 'means': 854,
 'lawyer': 855,
 'thinks': 856,
 'telephone': 857,
 'abroad': 858,
 'promised': 859,
 'glasses': 860,
 'willing': 861,
 'wake': 862,
 'shot': 863,
 'black': 864,
 'owe': 865,
 'husband': 866,
 'speech': 867,
 'cats': 868,
 'plans': 869,
 'horse': 870,
 'borrow': 871,
 'driving': 872,
 'staying': 873,
 'apple': 874,
 'message': 875,
 'immediately': 876,
 'guitar': 877,
 'piece': 878,
 'discuss': 879,
 'across': 880,
 'excuse': 881,
 'dressed': 882,
 'uncle': 883,
 'pictures': 884,
 'given': 885,
 'fat': 886,
 'guys': 887,
 'waited': 888,
 'prepared': 889,
 'fight': 890,
 'bank': 891,
 'asking': 892,
 'involved': 893,
 'american': 894,
 'lend': 895,
 'carefully': 896,
 'harder': 897,
 'none': 898,
 'boyfriend': 899,
 'concert': 900,
 'sign': 901,
 'boys': 902,
 'ride': 903,
 'traffic': 904,
 'cry': 905,
 'certain': 906,
 'gun': 907,
 'shower': 908,
 'afford': 909,
 'cute': 910,
 'joke': 911,
 'price': 912,
 'couple': 913,
 'inside': 914,
 'easily': 915,
 'arm': 916,
 'lake': 917,
 'novel': 918,
 'shirt': 919,
 'storm': 920,
 'painting': 921,
 'agreed': 922,
 'send': 923,
 'satisfied': 924,
 'worse': 925,
 'regret': 926,
 'america': 927,
 'fired': 928,
 'begin': 929,
 'kid': 930,
 'twice': 931,
 'raining': 932,
 'succeed': 933,
 'travel': 934,
 'fault': 935,
 "how's": 936,
 'count': 937,
 'correct': 938,
 'act': 939,
 "they'll": 940,
 'passed': 941,
 'chair': 942,
 "we'd": 943,
 'difference': 944,
 'ice': 945,
 'test': 946,
 'empty': 947,
 'honest': 948,
 'laugh': 949,
 'meat': 950,
 'movies': 951,
 'television': 952,
 'four': 953,
 'pen': 954,
 'earlier': 955,
 'hardly': 956,
 'impossible': 957,
 'held': 958,
 'color': 959,
 'figure': 960,
 'ahead': 961,
 'wonderful': 962,
 'blue': 963,
 'enjoyed': 964,
 'winter': 965,
 'likely': 966,
 'machine': 967,
 'carry': 968,
 'warm': 969,
 'refused': 970,
 'fall': 971,
 'line': 972,
 'bill': 973,
 'played': 974,
 'decide': 975,
 'kissed': 976,
 'terrible': 977,
 'animals': 978,
 'younger': 979,
 'herself': 980,
 'mountain': 981,
 'bother': 982,
 'laughed': 983,
 'slept': 984,
 'walking': 985,
 'ideas': 986,
 'past': 987,
 'heavy': 988,
 'shop': 989,
 'anywhere': 990,
 'foreign': 991,
 'sooner': 992,
 'liar': 993,
 'cooking': 994,
 'injured': 995,
 'leaves': 996,
 'newspaper': 997,
 'pick': 998,
 'smell': 999,
 ...}</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">src_vocab</span><span class="o">.</span><span class="n">idx_to_token</span>  <span class="c1"># list</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[8]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>['&lt;unk&gt;',
 '&lt;pad&gt;',
 '&lt;bos&gt;',
 '&lt;eos&gt;',
 '.',
 'i',
 'you',
 'to',
 'the',
 '?',
 'a',
 'is',
 'tom',
 'that',
 'he',
 'do',
 'of',
 'it',
 'this',
 'in',
 'me',
 'have',
 "don't",
 ',',
 'was',
 'my',
 'are',
 'for',
 'your',
 'what',
 "i'm",
 'we',
 'be',
 'want',
 'she',
 'not',
 'know',
 'like',
 'on',
 'with',
 'can',
 'his',
 'all',
 'did',
 'at',
 "you're",
 'how',
 'go',
 'they',
 'him',
 'think',
 'and',
 "it's",
 'about',
 'time',
 "can't",
 'here',
 'very',
 "didn't",
 'get',
 'there',
 'her',
 'were',
 'as',
 'will',
 'had',
 'if',
 'why',
 'just',
 'up',
 'out',
 'no',
 'has',
 'one',
 'going',
 'would',
 'so',
 'good',
 'need',
 'tell',
 'an',
 'see',
 "i'll",
 'come',
 'when',
 'from',
 'by',
 'really',
 'mary',
 'help',
 'who',
 'please',
 'us',
 "that's",
 'should',
 'could',
 'been',
 "i've",
 'never',
 'more',
 'now',
 'where',
 'take',
 'something',
 'got',
 'too',
 'than',
 'much',
 'make',
 'some',
 "i'd",
 "we're",
 'right',
 'but',
 'work',
 'am',
 'money',
 'any',
 'home',
 'last',
 'thought',
 'say',
 'sure',
 'anything',
 'look',
 'back',
 '!',
 'day',
 "doesn't",
 'give',
 'car',
 'told',
 'talk',
 'people',
 'made',
 'lot',
 'let',
 'way',
 'our',
 'must',
 'many',
 'said',
 "he's",
 'love',
 'long',
 'went',
 'still',
 'feel',
 'only',
 'eat',
 'always',
 'better',
 'happy',
 'doing',
 'today',
 'french',
 'house',
 "isn't",
 "let's",
 'does',
 'new',
 'believe',
 'before',
 'leave',
 "what's",
 'book',
 'again',
 'them',
 'room',
 'job',
 'off',
 'school',
 'night',
 'little',
 'well',
 "won't",
 'may',
 'old',
 'down',
 'wanted',
 'everything',
 'yesterday',
 'alone',
 'happened',
 'tomorrow',
 'father',
 'stay',
 'two',
 'put',
 'left',
 'over',
 'enough',
 'every',
 'asked',
 'three',
 'speak',
 'find',
 'stop',
 'these',
 'saw',
 'man',
 'into',
 'done',
 'try',
 'understand',
 'ask',
 'or',
 'ever',
 'keep',
 'friends',
 'problem',
 'sorry',
 'next',
 'nothing',
 "there's",
 'dog',
 'after',
 'call',
 'buy',
 'hard',
 "you've",
 'hope',
 'busy',
 'read',
 'away',
 'live',
 'friend',
 'wrong',
 'late',
 'first',
 'things',
 'door',
 'hear',
 "tom's",
 'life',
 "they're",
 'thing',
 'other',
 'remember',
 'idea',
 "wasn't",
 'boston',
 'anyone',
 'mother',
 'years',
 'took',
 'gave',
 'without',
 'being',
 'their',
 'everyone',
 "couldn't",
 'mind',
 'came',
 'children',
 'yet',
 'knew',
 'already',
 "you'd",
 'used',
 'name',
 'kind',
 'drink',
 'tired',
 'looking',
 'morning',
 'heard',
 'seen',
 'best',
 'bad',
 "you'll",
 'lost',
 'teacher',
 'found',
 'even',
 'play',
 'water',
 "haven't",
 'same',
 'care',
 'often',
 'week',
 'english',
 "aren't",
 'use',
 'soon',
 'wait',
 'afraid',
 'ready',
 'wish',
 'answer',
 'big',
 'yourself',
 'bed',
 'party',
 'someone',
 'while',
 'few',
 'happen',
 'talking',
 'else',
 'parents',
 'wants',
 'cold',
 'train',
 'myself',
 'open',
 'around',
 'show',
 'might',
 'bought',
 'nice',
 'glad',
 'both',
 'getting',
 'married',
 'another',
 "we'll",
 'place',
 'watch',
 'great',
 'turn',
 'year',
 'true',
 'looks',
 'early',
 'because',
 'such',
 'knows',
 'beautiful',
 'sleep',
 'write',
 'plan',
 'hurt',
 "wouldn't",
 'almost',
 'able',
 "she's",
 'those',
 'walk',
 'once',
 'which',
 'tried',
 'pay',
 'matter',
 'question',
 'food',
 'fun',
 'meet',
 'dinner',
 'days',
 'bus',
 'coffee',
 'brother',
 'letter',
 'truth',
 'met',
 'coming',
 'anymore',
 'everybody',
 'young',
 'meeting',
 'most',
 'person',
 'mine',
 'books',
 "shouldn't",
 'careful',
 'sister',
 'each',
 'own',
 'family',
 'together',
 'hate',
 'felt',
 'seems',
 'tonight',
 'doctor',
 'change',
 'learn',
 'seem',
 'since',
 'likes',
 'study',
 'word',
 'waiting',
 'forget',
 'easy',
 'pretty',
 'died',
 'trying',
 'girl',
 'phone',
 'world',
 'far',
 'gone',
 'working',
 "we've",
 'hand',
 'started',
 'child',
 'accident',
 'station',
 'mean',
 'nobody',
 'finished',
 'longer',
 'difficult',
 'sick',
 'boy',
 'surprised',
 'important',
 'start',
 'rain',
 'looked',
 'quite',
 'lunch',
 'cat',
 'drive',
 'wife',
 'questions',
 'weather',
 'anybody',
 'reading',
 'movie',
 'having',
 'yours',
 'makes',
 'mistake',
 'supposed',
 'thank',
 'office',
 'story',
 'until',
 'ten',
 'run',
 'swim',
 'small',
 'tv',
 'times',
 'close',
 'himself',
 'bit',
 'playing',
 'spend',
 'angry',
 'eyes',
 'trust',
 'stupid',
 'called',
 'ago',
 'guess',
 'advice',
 'japan',
 'hurry',
 'picture',
 'hours',
 '."',
 'broke',
 'music',
 'exactly',
 'says',
 'caught',
 'students',
 'wonder',
 'son',
 'lives',
 'fire',
 'afternoon',
 'window',
 'eating',
 'turned',
 'police',
 'bicycle',
 'thinking',
 'fell',
 'ran',
 'decided',
 'table',
 'fast',
 'usually',
 'probably',
 "who's",
 'minutes',
 'japanese',
 'interested',
 'interesting',
 'trouble',
 'free',
 'hair',
 'arrived',
 'hot',
 'bring',
 "weren't",
 'light',
 'town',
 'homework',
 'advised',
 'worry',
 'number',
 'park',
 'game',
 'under',
 'safe',
 'listen',
 'forgot',
 'stand',
 'enjoy',
 'country',
 'living',
 'news',
 'through',
 'against',
 'appreciate',
 'agree',
 'age',
 'miss',
 'sit',
 'hands',
 'quit',
 'promise',
 'proud',
 'sing',
 'chance',
 'saying',
 'possible',
 'visit',
 'finish',
 'different',
 'maybe',
 'later',
 'high',
 'reason',
 'wine',
 'then',
 'outside',
 'summer',
 'kept',
 'taking',
 'catch',
 'hungry',
 'needs',
 'born',
 'lie',
 'making',
 "should've",
 'cut',
 'business',
 'moment',
 'trip',
 'favorite',
 'dead',
 'end',
 'ok',
 'shoes',
 'older',
 'become',
 'win',
 'tree',
 'behind',
 'five',
 'box',
 'near',
 'works',
 'red',
 'girlfriend',
 'breakfast',
 'die',
 'class',
 'song',
 'tea',
 'eaten',
 'city',
 'dress',
 'student',
 'baby',
 "mary's",
 'rich',
 'needed',
 'guy',
 'face',
 'funny',
 'secret',
 'team',
 'month',
 'company',
 'full',
 'quickly',
 'comes',
 'paid',
 'stayed',
 "where's",
 'crazy',
 'fish',
 'rest',
 'ate',
 'lose',
 'woman',
 'point',
 'watching',
 'tennis',
 'beer',
 'explain',
 'part',
 'invited',
 'serious',
 'cannot',
 'break',
 'large',
 'clothes',
 'daughter',
 'smoking',
 'hotel',
 'kids',
 'key',
 'choice',
 'asleep',
 'hat',
 'feeling',
 'sound',
 'death',
 'cost',
 'somebody',
 'clean',
 'australia',
 'spent',
 'worried',
 'began',
 'words',
 'real',
 'lived',
 'wearing',
 '?"',
 'studying',
 'handle',
 'expensive',
 'sometimes',
 'goes',
 'hour',
 'became',
 'street',
 'touch',
 'hit',
 'milk',
 'river',
 'killed',
 'store',
 'hospital',
 'changed',
 'short',
 'rather',
 'decision',
 'computer',
 'others',
 'telling',
 'drunk',
 'deal',
 'between',
 'paper',
 'hold',
 'lucky',
 'cake',
 'scared',
 'takes',
 'birthday',
 'snow',
 'language',
 'closed',
 'present',
 'helped',
 'dark',
 'minute',
 'stopped',
 'problems',
 'restaurant',
 'sat',
 'monday',
 'speaking',
 'expect',
 'front',
 'whole',
 'quiet',
 'war',
 'mistakes',
 'figured',
 'worked',
 'finally',
 'gets',
 'along',
 'head',
 'report',
 'wrote',
 'happening',
 'dogs',
 'coat',
 'sense',
 'cup',
 'talked',
 'liked',
 'strong',
 'upset',
 'kill',
 'speaks',
 'thanks',
 'missed',
 'forward',
 'strange',
 'expected',
 'check',
 'boss',
 'dream',
 'dangerous',
 'beach',
 'known',
 'health',
 'situation',
 'actually',
 'running',
 'brought',
 'whether',
 'six',
 'its',
 'whatever',
 'dictionary',
 'move',
 'seeing',
 'shut',
 'order',
 'swimming',
 'weekend',
 'tall',
 'men',
 'air',
 'evening',
 'walked',
 'plane',
 'allowed',
 'thirty',
 'loves',
 'case',
 'least',
 'building',
 'broken',
 'list',
 'worth',
 'happens',
 'heart',
 'disappointed',
 'follow',
 'famous',
 'prefer',
 'written',
 'smoke',
 'christmas',
 'perfect',
 'drinking',
 "o'clock",
 'luck',
 'choose',
 'completely',
 'dollars',
 'pain',
 'future',
 'either',
 'mad',
 'seat',
 'crying',
 'dance',
 'second',
 'piano',
 'offer',
 'necessary',
 'fine',
 'half',
 'sent',
 'sunday',
 "hasn't",
 'garden',
 'apologize',
 'rules',
 'road',
 'library',
 'leaving',
 'noise',
 'weight',
 'flowers',
 'wear',
 'opinion',
 'cook',
 'writing',
 'camera',
 'set',
 'taken',
 'glass',
 'learned',
 'address',
 'somewhere',
 'poor',
 'several',
 "it'll",
 'white',
 'danger',
 'attention',
 "he'll",
 'tokyo',
 'floor',
 'save',
 'alive',
 'accept',
 'information',
 'clear',
 'suppose',
 'opened',
 'during',
 'kiss',
 'loved',
 'nervous',
 'grow',
 'girls',
 'waste',
 'showed',
 'join',
 'women',
 'bag',
 'sleeping',
 'listening',
 'less',
 'solve',
 'sad',
 'won',
 'date',
 'shopping',
 'blame',
 'desk',
 'tie',
 'medicine',
 'vacation',
 'pass',
 'college',
 'side',
 'success',
 'teach',
 'keys',
 'arrive',
 'umbrella',
 'fix',
 'sounds',
 'ticket',
 'whose',
 'ship',
 'radio',
 'lying',
 'spoke',
 'smart',
 'means',
 'lawyer',
 'thinks',
 'telephone',
 'abroad',
 'promised',
 'glasses',
 'willing',
 'wake',
 'shot',
 'black',
 'owe',
 'husband',
 'speech',
 'cats',
 'plans',
 'horse',
 'borrow',
 'driving',
 'staying',
 'apple',
 'message',
 'immediately',
 'guitar',
 'piece',
 'discuss',
 'across',
 'excuse',
 'dressed',
 'uncle',
 'pictures',
 'given',
 'fat',
 'guys',
 'waited',
 'prepared',
 'fight',
 'bank',
 'asking',
 'involved',
 'american',
 'lend',
 'carefully',
 'harder',
 'none',
 'boyfriend',
 'concert',
 'sign',
 'boys',
 'ride',
 'traffic',
 'cry',
 'certain',
 'gun',
 'shower',
 'afford',
 'cute',
 'joke',
 'price',
 'couple',
 'inside',
 'easily',
 'arm',
 'lake',
 'novel',
 'shirt',
 'storm',
 'painting',
 'agreed',
 'send',
 'satisfied',
 'worse',
 'regret',
 'america',
 'fired',
 'begin',
 'kid',
 'twice',
 'raining',
 'succeed',
 'travel',
 'fault',
 "how's",
 'count',
 'correct',
 'act',
 "they'll",
 'passed',
 'chair',
 "we'd",
 'difference',
 'ice',
 'test',
 'empty',
 'honest',
 'laugh',
 'meat',
 'movies',
 'television',
 'four',
 'pen',
 'earlier',
 'hardly',
 'impossible',
 'held',
 'color',
 'figure',
 'ahead',
 'wonderful',
 'blue',
 'enjoyed',
 'winter',
 'likely',
 'machine',
 'carry',
 'warm',
 'refused',
 'fall',
 'line',
 'bill',
 'played',
 'decide',
 'kissed',
 'terrible',
 'animals',
 'younger',
 'herself',
 'mountain',
 'bother',
 'laughed',
 'slept',
 'walking',
 'ideas',
 'past',
 'heavy',
 'shop',
 'anywhere',
 'foreign',
 'sooner',
 'liar',
 'cooking',
 'injured',
 'leaves',
 'newspaper',
 'pick',
 'smell',
 ...]</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.4.1.4.-%E6%88%AA%E6%96%AD%E5%92%8C%E5%A1%AB%E5%85%85">11.4.1.4. <a id="toc11_4_1_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.4.1.4.-%E6%88%AA%E6%96%AD%E5%92%8C%E5%A1%AB%E5%85%85"></a></h4><p>truncationpadding</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[68]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">truncate_pad</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">padding_token</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Truncate or pad sequences."""</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">num_steps</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">line</span><span class="p">[:</span><span class="n">num_steps</span><span class="p">]</span>                                 <span class="c1"># Truncate</span>
    <span class="k">return</span> <span class="n">line</span> <span class="o">+</span> <span class="p">[</span><span class="n">padding_token</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_steps</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">))</span>     <span class="c1"># Pad</span>

<span class="n">truncate_pad</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">[</span><span class="n">source</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="mi">10</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span>      <span class="c1"># return list</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[68]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[47, 4, 1, 1, 1, 1, 1, 1, 1, 1]</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[69]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">'''</span>
<span class="sd">&lt;eos&gt;</span>
<span class="sd"></span>
<span class="sd">&lt;eos&gt;</span>
<span class="sd"></span>
<span class="sd">'''</span>
<span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">build_array_nmt</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Transform text sequences of machine translation into minibatches."""</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span> <span class="o">+</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="s1">'&lt;eos&gt;'</span><span class="p">]]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>
    <span class="n">array</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">truncate_pad</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">])</span>
    <span class="c1">#  &lt;pad&gt; </span>
    <span class="c1"># array != vocab['&lt;pad&gt;']</span>
    <span class="c1"># d2l.astype(..., d2l.int32)1  0</span>
    <span class="c1"># d2l.reduce_sum(..., 1)</span>
    <span class="n">valid_len</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">array</span> <span class="o">!=</span> <span class="n">vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">array</span><span class="p">,</span> <span class="n">valid_len</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">src_vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[11]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>1</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.4.1.5.-%E9%9B%86%E5%90%88">11.4.1.5. <a id="toc11_4_1_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.4.1.5.-%E9%9B%86%E5%90%88"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[70]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>


<span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">load_data_nmt</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">num_examples</span><span class="o">=</span><span class="mi">600</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Return the iterator and the vocabularies of the translation dataset."""</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">preprocess_nmt</span><span class="p">(</span><span class="n">read_data_nmt</span><span class="p">())</span>
    <span class="n">source</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">tokenize_nmt</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">)</span>

    <span class="n">src_vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">reserved_tokens</span><span class="o">=</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">,</span> <span class="s1">'&lt;bos&gt;'</span><span class="p">,</span> <span class="s1">'&lt;eos&gt;'</span><span class="p">])</span>
    <span class="n">tgt_vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">reserved_tokens</span><span class="o">=</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">,</span> <span class="s1">'&lt;bos&gt;'</span><span class="p">,</span> <span class="s1">'&lt;eos&gt;'</span><span class="p">])</span>

    <span class="n">src_array</span><span class="p">,</span> <span class="n">src_valid_len</span> <span class="o">=</span> <span class="n">build_array_nmt</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
    <span class="n">tgt_array</span><span class="p">,</span> <span class="n">tgt_valid_len</span> <span class="o">=</span> <span class="n">build_array_nmt</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
    
    <span class="c1"># </span>
    <span class="n">data_arrays</span> <span class="o">=</span> <span class="p">(</span><span class="n">src_array</span><span class="p">,</span> <span class="n">src_valid_len</span><span class="p">,</span> <span class="n">tgt_array</span><span class="p">,</span> <span class="n">tgt_valid_len</span><span class="p">)</span>      
    <span class="n">data_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_array</span><span class="p">(</span><span class="n">data_arrays</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data_iter</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span>

<span class="c1">#@tab all</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span> <span class="o">=</span> <span class="n">load_data_nmt</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">X_valid_len</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Y_valid_len</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'X:'</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'valid lengths for X:'</span><span class="p">,</span> <span class="n">X_valid_len</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Y:'</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'valid lengths for Y:'</span><span class="p">,</span> <span class="n">Y_valid_len</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>X: tensor([[162,   9,   4,   3,   1,   1,   1,   1],
        [ 24, 160,   4,   3,   1,   1,   1,   1]], dtype=torch.int32)
valid lengths for X: tensor([4, 4])
Y: tensor([[171,   5,   3,   1,   1,   1,   1,   1],
        [ 13,  36,   0,   4,   3,   1,   1,   1]], dtype=torch.int32)
valid lengths for Y: tensor([3, 5])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">src_vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">],</span> <span class="n">tgt_vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">]</span>  <span class="c1"># 1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[14]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(1, 1)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.4.2.-%E7%BC%96%E7%A0%81%E5%99%A8-%E8%A7%A3%E7%A0%81%E5%99%A8%E6%9E%B6%E6%9E%84">11.4.2. <a id="toc11_4_2_"></a><a href="#toc0_">-</a><a class="anchor-link" href="#11.4.2.-%E7%BC%96%E7%A0%81%E5%99%A8-%E8%A7%A3%E7%A0%81%E5%99%A8%E6%9E%B6%E6%9E%84"></a></h3><p><br/>
</p>
<ul>
<li>encoder</li>
<li>decoder</li>
</ul>
<p>Theyarewatching.Ilsregordent.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[71]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">'''</span>
<span class="sd"></span>
<span class="sd">'''</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""-"""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[72]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">'''</span>
<span class="sd"></span>
<span class="sd">'''</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""-"""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">'''init_stateenc_outputs'''</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[73]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">'''</span>
<span class="sd">-</span>
<span class="sd">'''</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="k">class</span> <span class="nc">EncoderDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""-"""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span> 

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_X</span><span class="p">,</span> <span class="n">dec_X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">enc_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">enc_X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="n">dec_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_X</span><span class="p">,</span> <span class="n">dec_state</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.4.3.-%E5%BA%8F%E5%88%97%E5%88%B0%E5%BA%8F%E5%88%97%E5%AD%A6%E4%B9%A0">11.4.3. <a id="toc11_4_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.4.3.-%E5%BA%8F%E5%88%97%E5%88%B0%E5%BA%8F%E5%88%97%E5%AD%A6%E4%B9%A0"></a></h3><p>sequencetosequenceseq2seq.</p>
<p><img alt="" src="./Pytorch_Pictures/seq2seq/seq2seq_learning.jpg"/></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[74]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">import</span> <span class="nn">torch</span>


<span class="k">class</span> <span class="nc">Seq2SeqEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''''''</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="c1"># X (batch_size, num_steps, embed_size)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># (num_layers, batch_size, num_hiddens)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 0</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># output:(num_steps, batch_size, num_hiddens)</span>
        <span class="c1"># state:(num_layers, batch_size, num_hiddens)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>
        
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

<span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[74]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([7, 4, 16]), torch.Size([2, 4, 16]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[75]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">import</span> <span class="nn">torch</span> 


<span class="k">class</span> <span class="nc">Seq2SeqDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''''''</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">embed_size</span><span class="o">+</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">enc_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># 'X'(batch_size, num_steps, embed_size)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># contextXnum_steps</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Xcontext</span>
        <span class="n">X_and_context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># </span>
        <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X_and_context</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># output:(batch_size, num_steps, vocab_size)</span>
        <span class="c1"># state:(num_layers, batch_size, num_hiddens)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>

<span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqDecoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

<span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

<span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[75]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.4.4.-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0">11.4.4. <a id="toc11_4_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.4.4.-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.4.4.1.-%E6%8E%A9%E7%A0%81">11.4.4.1. <a id="toc11_4_4_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.4.4.1.-%E6%8E%A9%E7%A0%81"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[21]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([1, 2]),
 tensor([[1],
         [2]]),
 tensor([[1, 2]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># tokenize</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[</span>
  <span class="p">[</span><span class="s1">'a'</span><span class="p">,</span> <span class="s1">'b'</span><span class="p">,</span> <span class="s1">'c'</span><span class="p">,</span> <span class="s1">'pad'</span><span class="p">,</span> <span class="s1">'pad'</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">'d'</span><span class="p">,</span> <span class="s1">'e'</span><span class="p">,</span> <span class="s1">'f'</span><span class="p">,</span> <span class="s1">'g'</span><span class="p">,</span> <span class="s1">'h'</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'j'</span><span class="p">,</span> <span class="s1">'pad'</span><span class="p">,</span> <span class="s1">'pad'</span><span class="p">,</span> <span class="s1">'pad'</span><span class="p">]</span>
<span class="p">]</span>

<span class="c1"># corpus</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># mask</span>
<span class="n">mask</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
    <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span>
    <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
<span class="p">]</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

<span class="c1"># ~</span>
<span class="n">X</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

<span class="n">X</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[22]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 1,  2,  3, -1, -1],
        [ 4,  5,  6,  7,  8],
        [ 9, 10, -1, -1, -1]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sequence_mask</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_len</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">    /</span>
<span class="sd">    '''</span>
    <span class="n">maxlen</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># </span>
    <span class="c1"># [None, :]  [:, None]</span>
    <span class="c1"># &lt; valid_len[:, None] valid_len  True Falsevalid_len </span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&lt;</span> <span class="n">valid_len</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="c1"># </span>
    <span class="c1"># ~mask</span>
    <span class="n">X</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span> 
    <span class="k">return</span> <span class="n">X</span> 

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'X: </span><span class="si">{</span><span class="n">X</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">sequence_mask</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_len</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>X: tensor([[1, 2, 3],
        [4, 5, 6]])
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[23]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1, 0, 0],
        [4, 5, 0]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'X: </span><span class="si">{</span><span class="n">X</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">sequence_mask</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_len</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>X: tensor([[[1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.]],

        [[1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.]]])
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[24]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[[ 1.,  1.,  1.,  1.],
         [-1., -1., -1., -1.],
         [-1., -1., -1., -1.]],

        [[ 1.,  1.,  1.,  1.],
         [ 1.,  1.,  1.,  1.],
         [-1., -1., -1., -1.]]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.4.4.2.-%E5%B8%A6%E6%8E%A9%E7%A0%81%E7%9A%84softmax%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1">11.4.4.2. <a id="toc11_4_4_2_"></a><a href="#toc0_">softmax</a><a class="anchor-link" href="#11.4.4.2.-%E5%B8%A6%E6%8E%A9%E7%A0%81%E7%9A%84softmax%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1"></a></h4><p>softmax10</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">MaskedSoftmaxCELoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""The softmax cross-entropy loss with masks."""</span>
    <span class="c1"># `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)</span>
    <span class="c1"># `label` shape: (`batch_size`, `num_steps`)</span>
    <span class="c1"># `valid_len` shape: (`batch_size`,)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">valid_len</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">sequence_mask</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">valid_len</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="o">=</span><span class="s1">'none'</span>
        <span class="n">unweighted_loss</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MaskedSoftmaxCELoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">label</span><span class="p">)</span>
        <span class="c1">#  (00)   </span>
        <span class="n">weighted_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">unweighted_loss</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">weighted_loss</span>
    

<span class="n">loss</span> <span class="o">=</span> <span class="n">MaskedSoftmaxCELoss</span><span class="p">()</span>

<span class="n">loss</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[25]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([2.3026, 1.1513, 0.0000])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.4.5.-%E8%AE%AD%E7%BB%83">11.4.5. <a id="toc11_4_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.4.5.-%E8%AE%AD%E7%BB%83"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">train_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">data_iter</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Train a model for sequence to sequence."""</span>
    <span class="k">def</span> <span class="nf">xavier_init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>                       <span class="c1">#  nn.Linear xavier_uniform_ </span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">_flat_weights_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">"weight"</span> <span class="ow">in</span> <span class="n">param</span><span class="p">:</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">param</span><span class="p">])</span>   <span class="c1"># GRUXavier</span>
    <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">xavier_init_weights</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">MaskedSoftmaxCELoss</span><span class="p">()</span>                                    <span class="c1"># Softmax MaskedSoftmaxCELoss</span>
    <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">'epoch'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'loss'</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">timer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
        <span class="n">metric</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Accumulator</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Sum of training loss, no. of tokens</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">X_valid_len</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Y_valid_len</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
            <span class="c1">#  &lt;bos&gt;Teacher Forcing</span>
            <span class="n">bos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">tgt_vocab</span><span class="p">[</span><span class="s1">'&lt;bos&gt;'</span><span class="p">]]</span> <span class="o">*</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">dec_input</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">bos</span><span class="p">,</span> <span class="n">Y</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Teacher forcing</span>
            <span class="n">Y_hat</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">,</span> <span class="n">X_valid_len</span><span class="p">)</span>
            <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Y_valid_len</span><span class="p">)</span>
            <span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># Make the loss scalar for `backward`</span>
            <span class="n">d2l</span><span class="o">.</span><span class="n">grad_clipping</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">num_tokens</span> <span class="o">=</span> <span class="n">Y_valid_len</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">metric</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">num_tokens</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'loss </span><span class="si">{</span><span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1"> '</span>
          <span class="sa">f</span><span class="s1">'tokens/sec on </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    

<span class="c1">#@tab all</span>
<span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>

<span class="n">train_iter</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_nmt</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqDecoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tgt_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">EncoderDecoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>
<span class="n">train_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>loss 0.019, 10476.8 tokens/sec on cuda:0
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="262.1875pt" height="183.35625pt" viewBox="0 0 262.1875 183.35625" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-12-02T09:45:48.629190</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 183.35625 
L 262.1875 183.35625 
L 262.1875 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 50.14375 145.8 
L 245.44375 145.8 
L 245.44375 7.2 
L 50.14375 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 86.015179 145.8 
L 86.015179 7.2 
" clip-path="url(#p0d17079d2c)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_2">
      <defs>
       <path id="me51cabeb02" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#me51cabeb02" x="86.015179" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- 100 -->
      <g transform="translate(76.471429 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_3">
      <path d="M 125.872321 145.8 
L 125.872321 7.2 
" clip-path="url(#p0d17079d2c)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_4">
      <g>
       <use xlink:href="#me51cabeb02" x="125.872321" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 200 -->
      <g transform="translate(116.328571 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-32"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_5">
      <path d="M 165.729464 145.8 
L 165.729464 7.2 
" clip-path="url(#p0d17079d2c)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_6">
      <g>
       <use xlink:href="#me51cabeb02" x="165.729464" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 300 -->
      <g transform="translate(156.185714 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-33" d="M 2597 2516 
Q 3050 2419 3304 2112 
Q 3559 1806 3559 1356 
Q 3559 666 3084 287 
Q 2609 -91 1734 -91 
Q 1441 -91 1130 -33 
Q 819 25 488 141 
L 488 750 
Q 750 597 1062 519 
Q 1375 441 1716 441 
Q 2309 441 2620 675 
Q 2931 909 2931 1356 
Q 2931 1769 2642 2001 
Q 2353 2234 1838 2234 
L 1294 2234 
L 1294 2753 
L 1863 2753 
Q 2328 2753 2575 2939 
Q 2822 3125 2822 3475 
Q 2822 3834 2567 4026 
Q 2313 4219 1838 4219 
Q 1578 4219 1281 4162 
Q 984 4106 628 3988 
L 628 4550 
Q 988 4650 1302 4700 
Q 1616 4750 1894 4750 
Q 2613 4750 3031 4423 
Q 3450 4097 3450 3541 
Q 3450 3153 3228 2886 
Q 3006 2619 2597 2516 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-33"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_7">
      <path d="M 205.586607 145.8 
L 205.586607 7.2 
" clip-path="url(#p0d17079d2c)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_8">
      <g>
       <use xlink:href="#me51cabeb02" x="205.586607" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 400 -->
      <g transform="translate(196.042857 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-34"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_9">
      <path d="M 245.44375 145.8 
L 245.44375 7.2 
" clip-path="url(#p0d17079d2c)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_10">
      <g>
       <use xlink:href="#me51cabeb02" x="245.44375" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- 500 -->
      <g transform="translate(235.9 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-35"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="text_6">
     <!-- epoch -->
     <g transform="translate(132.565625 174.076563) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-68" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 4863 
L 1159 4863 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-65"/>
      <use xlink:href="#DejaVuSans-70" x="61.523438"/>
      <use xlink:href="#DejaVuSans-6f" x="125"/>
      <use xlink:href="#DejaVuSans-63" x="186.181641"/>
      <use xlink:href="#DejaVuSans-68" x="241.162109"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_11">
      <path d="M 50.14375 118.916228 
L 245.44375 118.916228 
" clip-path="url(#p0d17079d2c)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_12">
      <defs>
       <path id="m7147314362" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m7147314362" x="50.14375" y="118.916228" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 0.05 -->
      <g transform="translate(20.878125 122.715447) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_13">
      <path d="M 50.14375 86.460336 
L 245.44375 86.460336 
" clip-path="url(#p0d17079d2c)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_14">
      <g>
       <use xlink:href="#m7147314362" x="50.14375" y="86.460336" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 0.10 -->
      <g transform="translate(20.878125 90.259555) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-31" x="95.410156"/>
       <use xlink:href="#DejaVuSans-30" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_15">
      <path d="M 50.14375 54.004445 
L 245.44375 54.004445 
" clip-path="url(#p0d17079d2c)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_16">
      <g>
       <use xlink:href="#m7147314362" x="50.14375" y="54.004445" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <!-- 0.15 -->
      <g transform="translate(20.878125 57.803664) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-31" x="95.410156"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_17">
      <path d="M 50.14375 21.548554 
L 245.44375 21.548554 
" clip-path="url(#p0d17079d2c)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_18">
      <g>
       <use xlink:href="#m7147314362" x="50.14375" y="21.548554" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_10">
      <!-- 0.20 -->
      <g transform="translate(20.878125 25.347772) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-32" x="95.410156"/>
       <use xlink:href="#DejaVuSans-30" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="text_11">
     <!-- loss -->
     <g transform="translate(14.798437 86.157813) rotate(-90) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-6c" d="M 603 4863 
L 1178 4863 
L 1178 0 
L 603 0 
L 603 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-6c"/>
      <use xlink:href="#DejaVuSans-6f" x="27.783203"/>
      <use xlink:href="#DejaVuSans-73" x="88.964844"/>
      <use xlink:href="#DejaVuSans-73" x="141.064453"/>
     </g>
    </g>
   </g>
   <g id="line2d_19">
    <path d="M 50.14375 13.5 
L 54.129464 60.759704 
L 58.115179 88.900059 
L 62.100893 104.610788 
L 66.086607 114.577292 
L 70.072321 121.591538 
L 74.058036 126.024379 
L 78.04375 128.990386 
L 82.029464 131.900228 
L 86.015179 133.251352 
L 90.000893 134.627342 
L 93.986607 134.896579 
L 97.972321 136.284714 
L 101.958036 136.701588 
L 105.94375 136.810646 
L 109.929464 137.605009 
L 113.915179 137.348236 
L 117.900893 137.901734 
L 121.886607 137.900854 
L 125.872321 138.502985 
L 129.858036 138.198777 
L 133.84375 138.475473 
L 137.829464 138.725984 
L 141.815179 138.216267 
L 145.800893 138.661288 
L 149.786607 138.444164 
L 153.772321 139.111636 
L 157.758036 139.023949 
L 161.74375 139.096383 
L 165.729464 138.859261 
L 169.715179 138.905553 
L 173.700893 138.831175 
L 177.686607 139.053486 
L 181.672321 139.171477 
L 185.658036 139.019357 
L 189.64375 139.055613 
L 193.629464 139.371301 
L 197.615179 139.324127 
L 201.600893 139.5 
L 205.586607 139.313784 
L 209.572321 139.1003 
L 213.558036 139.432662 
L 217.54375 139.206029 
L 221.529464 139.259822 
L 225.515179 139.368179 
L 229.500893 139.24858 
L 233.486607 139.150105 
L 237.472321 139.087948 
L 241.458036 139.395646 
L 245.44375 139.302084 
" clip-path="url(#p0d17079d2c)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="patch_3">
    <path d="M 50.14375 145.8 
L 50.14375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 245.44375 145.8 
L 245.44375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 50.14375 145.8 
L 245.44375 145.8 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 50.14375 7.2 
L 245.44375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="p0d17079d2c">
   <rect x="50.14375" y="7.2" width="195.3" height="138.6"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.4.6.-%E9%A2%84%E6%B5%8B">11.4.6. <a id="toc11_4_6_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.4.6.-%E9%A2%84%E6%B5%8B"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[27]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">predict_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">src_sentence</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">save_attention_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Predict for sequence to sequence."""</span>
    <span class="c1"># Set `net` to eval mode for inference</span>
    <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">src_tokens</span> <span class="o">=</span> <span class="n">src_vocab</span><span class="p">[</span><span class="n">src_sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="n">src_vocab</span><span class="p">[</span><span class="s1">'&lt;eos&gt;'</span><span class="p">]]</span>
    <span class="n">enc_valid_len</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">src_tokens</span><span class="p">)],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">src_tokens</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">truncate_pad</span><span class="p">(</span><span class="n">src_tokens</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span>
    <span class="c1"># Add the batch axis</span>
    <span class="n">enc_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">src_tokens</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">enc_outputs</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">enc_X</span><span class="p">,</span> <span class="n">enc_valid_len</span><span class="p">)</span>
    <span class="n">dec_state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_len</span><span class="p">)</span>
    <span class="c1"># Add the batch axis</span>
    <span class="n">dec_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">tgt_vocab</span><span class="p">[</span><span class="s1">'&lt;bos&gt;'</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">output_seq</span><span class="p">,</span> <span class="n">attention_weight_seq</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
        <span class="n">Y</span><span class="p">,</span> <span class="n">dec_state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_X</span><span class="p">,</span> <span class="n">dec_state</span><span class="p">)</span>
        <span class="c1"># We use the token with the highest prediction likelihood as the input</span>
        <span class="c1"># of the decoder at the next time step</span>
        <span class="n">dec_X</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">dec_X</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="c1"># Save attention weights (to be covered later)</span>
        <span class="k">if</span> <span class="n">save_attention_weights</span><span class="p">:</span>
            <span class="n">attention_weight_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">)</span>
        <span class="c1"># Once the end-of-sequence token is predicted, the generation of the</span>
        <span class="c1"># output sequence is complete</span>
        <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="n">tgt_vocab</span><span class="p">[</span><span class="s1">'&lt;eos&gt;'</span><span class="p">]:</span>
            <span class="k">break</span>
        <span class="n">output_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tgt_vocab</span><span class="o">.</span><span class="n">to_tokens</span><span class="p">(</span><span class="n">output_seq</span><span class="p">)),</span> <span class="n">attention_weight_seq</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="k">def</span> <span class="nf">bleu</span><span class="p">(</span><span class="n">pred_seq</span><span class="p">,</span> <span class="n">label_seq</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">"""Compute the BLEU."""</span>
    <span class="n">pred_tokens</span><span class="p">,</span> <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">pred_seq</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">),</span> <span class="n">label_seq</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span>
    <span class="n">len_pred</span><span class="p">,</span> <span class="n">len_label</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">len_label</span> <span class="o">/</span> <span class="n">len_pred</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">num_matches</span><span class="p">,</span> <span class="n">label_subs</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">len_label</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">label_subs</span><span class="p">[</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">n</span><span class="p">])]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">len_pred</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">label_subs</span><span class="p">[</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">n</span><span class="p">])]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">num_matches</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">label_subs</span><span class="p">[</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">n</span><span class="p">])]</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="n">score</span> <span class="o">*=</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">num_matches</span> <span class="o">/</span> <span class="p">(</span><span class="n">len_pred</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">score</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">collections</span>


<span class="c1">#@tab all</span>
<span class="n">engs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'go .'</span><span class="p">,</span> <span class="s2">"i lost ."</span><span class="p">,</span> <span class="s1">'he</span><span class="se">\'</span><span class="s1">s calm .'</span><span class="p">,</span> <span class="s1">'i</span><span class="se">\'</span><span class="s1">m home .'</span><span class="p">]</span>
<span class="n">fras</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'va !'</span><span class="p">,</span> <span class="s1">'j</span><span class="se">\'</span><span class="s1">ai perdu .'</span><span class="p">,</span> <span class="s1">'il est calme .'</span><span class="p">,</span> <span class="s1">'je suis chez moi .'</span><span class="p">]</span>
<span class="k">for</span> <span class="n">eng</span><span class="p">,</span> <span class="n">fra</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">):</span>
    <span class="n">translation</span><span class="p">,</span> <span class="n">attention_weight_seq</span> <span class="o">=</span> <span class="n">predict_seq2seq</span><span class="p">(</span>
        <span class="n">net</span><span class="p">,</span> <span class="n">eng</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">eng</span><span class="si">}</span><span class="s1"> =&gt; </span><span class="si">{</span><span class="n">translation</span><span class="si">}</span><span class="s1">, bleu </span><span class="si">{</span><span class="n">bleu</span><span class="p">(</span><span class="n">translation</span><span class="p">,</span><span class="w"> </span><span class="n">fra</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>go . =&gt; va , &lt;unk&gt; !, bleu 0.000
i lost . =&gt; j'ai perdu ., bleu 1.000
he's calm . =&gt; il est occup &lt;unk&gt; ., bleu 0.548
i'm home . =&gt; je suis chez chez chez chez chez chez chez chez, bleu 0.376
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11.5.-Attention">11.5. <a id="toc11_5_"></a><a href="#toc0_">Attention</a><a class="anchor-link" href="#11.5.-Attention"></a></h2><ul>
<li><p>Google<a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a></p>
</li>
<li><p></p>
<ol>
<li><p>CNNRNN-&gt;-</p>
</li>
<li><p>AttentionAttention</p>
<p>Query:<br/>
Key:  <br/>
Value:  </p>
</li>
</ol>
</li>
<li><p><code>querykeyvalue</code></p>
</li>
</ul>
<p><img align="center" alt="" height="300" src="./Pytorch_Pictures/Attention//Attention_principle.jpg" width="700"/></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.5.1.-%E9%9D%9E%E5%8F%82%E6%95%B0%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%B1%87%E8%81%9A%EF%BC%88Attention-Pooling%EF%BC%89-%E8%AE%A1%E7%AE%97q%E5%92%8Ck%E7%9B%B8%E4%BC%BC%E5%BA%A6">11.5.1. <a id="toc11_5_1_"></a><a href="#toc0_">Attention Pooling-qk</a><a class="anchor-link" href="#11.5.1.-%E9%9D%9E%E5%8F%82%E6%95%B0%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%B1%87%E8%81%9A%EF%BC%88Attention-Pooling%EF%BC%89-%E8%AE%A1%E7%AE%97q%E5%92%8Ck%E7%9B%B8%E4%BC%BC%E5%BA%A6"></a></h3><p></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[53]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># f(x) = </span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.5.2.-%E5%8F%82%E6%95%B0%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%B1%87%E8%81%9A%EF%BC%88Attention-Pooling%EF%BC%89-%E8%AE%A1%E7%AE%97q%E5%92%8Ck%E7%9B%B8%E4%BC%BC%E5%BA%A6">11.5.2. <a id="toc11_5_2_"></a><a href="#toc0_">Attention Pooling-qk</a><a class="anchor-link" href="#11.5.2.-%E5%8F%82%E6%95%B0%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%B1%87%E8%81%9A%EF%BC%88Attention-Pooling%EF%BC%89-%E8%AE%A1%E7%AE%97q%E5%92%8Ck%E7%9B%B8%E4%BC%BC%E5%BA%A6"></a></h3><p>w</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># f(x) = </span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.5.3.-%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%88%86%E6%95%B0%E5%87%BD%E6%95%B0-%E8%AE%A1%E7%AE%97q%E5%92%8Ck%E7%9B%B8%E4%BC%BC%E5%BA%A6">11.5.3. <a id="toc11_5_3_"></a><a href="#toc0_">-qk</a><a class="anchor-link" href="#11.5.3.-%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%88%86%E6%95%B0%E5%87%BD%E6%95%B0-%E8%AE%A1%E7%AE%97q%E5%92%8Ck%E7%9B%B8%E4%BC%BC%E5%BA%A6"></a></h3><p><img align="center" alt="" height="300" src="./Pytorch_Pictures/Attention/Attention_score.jpg" width="500"/></p>
<p></p>
<ul>
<li><code>AttentionSourceValueQueryKeyValue</code></li>
<li><code></code><code>Query</code><code>Key</code><code> ()</code></li>
<li><code>softmax</code> ()<code></code> (<code></code>querykey)</li>
<li>value<code></code><code></code></li>
</ul>
<p></p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">$a(q, k)$</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">$softmax( a(q, k) )$</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">$softmax( a(q, k) ) * v$</td>
</tr>
</tbody>
</table>
<p></p>
<ul>
<li> (Additive Attention)</li>
<li> (Scaled Dot-Product Attention)</li>
<li> (Multiplicative Attention)</li>
<li> (Location-based Attention)</li>
<li> (Linear Attention)</li>
<li> (Adaptive Attention)</li>
<li> (Sparse Attention)</li>
</ul>
<p>:</p>
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.5.3.1.-%E5%8A%A0%E6%80%A7%E6%B3%A8%E6%84%8F%E5%8A%9B-(Additive-Attention)-%E8%AE%A1%E7%AE%97q%E3%80%81k%E7%9B%B8%E4%BC%BC%E5%BA%A6">11.5.3.1. <a id="toc11_5_3_1_"></a><a href="#toc0_"> (Additive Attention)-qk</a><a class="anchor-link" href="#11.5.3.1.-%E5%8A%A0%E6%80%A7%E6%B3%A8%E6%84%8F%E5%8A%9B-(Additive-Attention)-%E8%AE%A1%E7%AE%97q%E3%80%81k%E7%9B%B8%E4%BC%BC%E5%BA%A6"></a></h4><p> Bahdanau  2014 
:</p>
<ul>
<li>querykey</li>
<li> tanh</li>
<li></li>
<li> softmax </li>
</ul>
<p>$\mathrm{score}(q,k)=v^T\cdot\mathrm{tanh}(W_qq+W_kk)$$W_q$$W_k$$v$<br/>

</p>
<ul>
<li></li>
<li></li>
</ul>
<p></p>
<ul>
<li></li>
</ul>
<hr/>
<p></p>
<ul>
<li><code></code><code></code><code></code><code></code><code></code></li>
<li>$a(\mathbf{q},\mathbf{k})=\mathbf{w}_v^\top\tanh(\mathbf{W}_q\mathbf{q}+\mathbf{W}_k\mathbf{k})\in\mathbb{R}$</li>
<li>$\mathbf{q}\in\mathbb{R}^q\text{ }\mathbf{k}\in\mathbb{R}^k,$</li>
<li>$\mathbf{W}_q\in\mathbb{R}^{h\times q}\mathrm{}\mathbf{W}_k\in\mathbb{R}^{h\times k}\text{ }\mathbf{w}_v\in\mathbb{R}^h$, <code></code><code>h</code></li>
<li><code></code></li>
</ul>
<p><img alt="No description has been provided for this image" height="600" src="./Pytorch_Pictures/Attention/Additive_attention.jpg" width="800"/></p>
<ul>
<li>:</li>
</ul>
<div class="highlight"><pre><span></span><span class="c1"># summary </span>
    <span class="c1"># Input:</span>
            <span class="c1"># queries:                  (batch_size, num_query, query_size)</span>
            <span class="c1"># keys:                     (batch_size, k_v_pair_num, key_size)</span>
            <span class="c1"># values:                   (batch_size, k_v_pair_num, value_size)</span>
            <span class="c1"># query_size, key_size, value_size </span>
    <span class="c1"># Output:                           (batch_size, num_query, value_size)</span>
</pre></div>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>-<ul>
<li> (masked) Dropout</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[60]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>


<span class="k">def</span> <span class="nf">sequence_mask</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_len</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    /</span>
<span class="sd">    </span>
<span class="sd">    :</span>
<span class="sd">        X:  (batch_size, seq_len, ...)</span>
<span class="sd">        valid_len:  (batch_size,)</span>
<span class="sd">        value: 0</span>
<span class="sd">        </span>
<span class="sd">    :</span>
<span class="sd">        X</span>
<span class="sd">        </span>
<span class="sd">    :</span>
<span class="sd">        1. maxlen</span>
<span class="sd">        2. :</span>
<span class="sd">           - torch.arange[0,1,...,maxlen-1]</span>
<span class="sd">           - [None,:]batch(1,maxlen) </span>
<span class="sd">           - valid_len[:,None](batch_size,)(batch_size,1)</span>
<span class="sd">           - (batch_size,maxlen)</span>
<span class="sd">        3. ~mask()value</span>
<span class="sd">    """</span>
    <span class="c1"># </span>
    <span class="n">maxlen</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># : (batch_size, maxlen)</span>
    <span class="c1"># True,False</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">((</span><span class="n">maxlen</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&lt;</span> <span class="n">valid_len</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    
    <span class="c1"># (~mask)value</span>
    <span class="n">X</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">masked_softmax</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    softmax     </span>
<span class="sd">    :</span>
<span class="sd">        X: 3D, shape(batch_size, seq_len, feature_dim)</span>
<span class="sd">        valid_lens: 1D2D,</span>
<span class="sd">            - 1Dshape(batch_size,),batch</span>
<span class="sd">            - 2Dshape(batch_size, seq_len),</span>
<span class="sd">    :</span>
<span class="sd">        masked softmax,shapeX</span>
<span class="sd">    """</span>
    <span class="c1"># valid_lens,softmax</span>
    <span class="k">if</span> <span class="n">valid_lens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># valid_lens1D,2D</span>
        <span class="k">if</span> <span class="n">valid_lens</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">valid_lens</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># 2D,1D</span>
            <span class="n">valid_lens</span> <span class="o">=</span> <span class="n">valid_lens</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            
        <span class="c1"># sequence_mask</span>
        <span class="c1"># X2D:(batch_size * seq_len, feature_dim)</span>
        <span class="c1"># (-1e6),softmax0</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">sequence_mask</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">valid_lens</span><span class="p">,</span> <span class="n">value</span><span class="o">=-</span><span class="mf">1e6</span><span class="p">)</span>
        <span class="c1"># softmax</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>


<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">AdditiveAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AdditiveAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">key_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>         <span class="c1"># (key_size, num_hiddens)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">query_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>       <span class="c1"># (query_size, num_hiddens)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>                <span class="c1"># (num_hiddens, 1)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span><span class="p">(</span><span class="n">queries</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>
        <span class="c1"># queries:              (batch_size, num_query, num_hiddens)</span>
        <span class="c1"># keys:                 (batch_size, k_v_pair_num, num_hiddens)</span>
        <span class="c1"># </span>
        <span class="c1"># queries       (batch_sizenum_query        1        num_hiddens)</span>
        <span class="c1"># key           (batch_size    1    k_v_pair_num  num_hiddens)</span>
        <span class="c1">#   (batch_size, num_query, 1, num_hiddens) + (batch_size, 1, k_v_pair_num, num_hiddens) = (batch_size, num_query, k_v_pair_num, num_hiddens)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">keys</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="c1"># features(batch_size, num_query, k_v_pair_num, num_hiddens)</span>
        
        <span class="c1"># self.w_v: (num_hiddens, 1)</span>
        <span class="c1"># scores(batch_sizenum_queryk_v_pair_num, 1)</span>
        <span class="c1"># squeeze(-1)</span>
        <span class="c1"># scores(batch_sizenum_queryk_v_pair_num)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># </span>
        <span class="c1"># masked_softmax, valid_lens</span>
        <span class="c1"># attention_weights(batch_size, num_query, k_v_pair_num)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">masked_softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>

        <span class="c1"># values(batch_sizek_v_pair_numvalue_size)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">),</span> <span class="n">values</span><span class="p">)</span>
    

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">num_query</span><span class="p">,</span> <span class="n">query_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span>
<span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">key_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">value_size</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1">#  (batch_size, num_query, query_size)</span>
<span class="n">queries</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_query</span><span class="p">,</span> <span class="n">query_size</span><span class="p">))</span>
<span class="c1">#  (batch_size, k_v_pair_num, key_size)</span>
<span class="n">keys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">key_size</span><span class="p">))</span>
<span class="c1">#  (batch_size, k_v_pair_num, value_size)</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">value_size</span><span class="p">))</span>

<span class="c1"># batch (batch_size,)</span>
<span class="n">valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>   <span class="c1"># batch</span>

<span class="n">attention</span> <span class="o">=</span> <span class="n">AdditiveAttention</span><span class="p">(</span><span class="n">key_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">query_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">attention</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">attention</span><span class="p">(</span><span class="n">queries</span><span class="o">=</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="o">=</span><span class="n">valid_lens</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># summary </span>
    <span class="c1"># Input:</span>
            <span class="c1"># queries:                  (batch_size, num_query, query_size)</span>
            <span class="c1"># keys:                     (batch_size, k_v_pair_num,  key_size)</span>
            <span class="c1"># values:                   (batch_size, k_v_pair_num, value_size)</span>
    <span class="c1"># Output:                           (batch_size, num_query, value_size)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[60]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 1, 4])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>() -<ul>
<li>Dropout</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 


<span class="c1">########################################################</span>
<span class="c1"># </span>
<span class="c1">########################################################</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">num_query</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">query_size</span> <span class="o">=</span> <span class="mi">20</span>             <span class="c1"># query</span>

<span class="n">num_key</span> <span class="o">=</span> <span class="mi">10</span>                <span class="c1"># </span>
<span class="n">key_size</span> <span class="o">=</span> <span class="mi">2</span>                <span class="c1"># key</span>

<span class="n">num_value</span> <span class="o">=</span> <span class="n">num_key</span>         <span class="c1"># </span>
<span class="n">value_size</span> <span class="o">=</span> <span class="mi">4</span>              <span class="c1"># value</span>

<span class="n">queries</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_query</span><span class="p">,</span> <span class="n">query_size</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'queries size: '</span><span class="p">,</span> <span class="n">queries</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="c1"># batch_size, num_query, query_size</span>
<span class="c1"># 2, 1, 20</span>

<span class="n">keys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_key</span><span class="p">,</span> <span class="n">key_size</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'keys size: '</span><span class="p">,</span> <span class="n">keys</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="c1"># batch_size, kv_pair_num, key_size</span>
<span class="c1"># 2, 10, 2</span>

<span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_value</span><span class="p">,</span> <span class="n">value_size</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'values size: '</span><span class="p">,</span> <span class="n">values</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="c1"># batch_size, kv_pair_num, value_size</span>
<span class="c1"># 2, 10, 4</span>

<span class="c1">########################################################</span>
<span class="c1">#  (W)</span>
<span class="c1">########################################################</span>

<span class="c1">## value_size</span>
<span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">value_size</span>
<span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">W_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">query_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>     <span class="c1"># 20 , 4</span>
<span class="n">W_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">key_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>       <span class="c1"># 2, 4</span>
<span class="n">w_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>              <span class="c1"># 4, 1</span>

<span class="n">Q</span> <span class="o">=</span> <span class="n">W_q</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>                    <span class="c1"># (batch_sizenum_hidden) 3</span>
<span class="c1"># 2, 1, 20 * 20, 4 = 2, 1, 4</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">Q</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>                  <span class="c1"># (batch_size1num_hidden)   () 4</span>
<span class="c1"># 2, 1, (1), 4                        # </span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Q size: '</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="n">K</span> <span class="o">=</span> <span class="n">W_k</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>                       <span class="c1"># (batch_sizenum_hiddens)   3</span>
<span class="c1"># 2, 10, 2 * 2, 4 = 2, 10, 4</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                  <span class="c1"># (batch_size1num_hiddens)  () 4</span>
<span class="c1"># 2, (1), 10, 4                       # </span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'K size: '</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>


<span class="n">features</span> <span class="o">=</span> <span class="n">Q</span> <span class="o">+</span> <span class="n">K</span>                    <span class="c1">#     ()                                  (2,1,(1),4) + (2,(1),10,4) = (2,1,10,4)</span>
<span class="c1"># 2, 1, 10, 4                       # (batch_sizenum_hiddens)    (2,1,(10),4)+ (2,(1),10,4) = (2,1,10,4)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'features size: '</span><span class="p">,</span> <span class="n">features</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="c1"># 2, 1, 10, 4</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'features size (tanh): '</span><span class="p">,</span> <span class="n">features</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">w_v</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>              <span class="c1">#     (2,1,10,4) @ (    4,1) = (2,1,10,1)</span>
                                    <span class="c1">#                      (2,1,10,4) @ (2,1,4,1) = (2,1,10,1)</span>
<span class="c1"># 2, 1, 10, 1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'scores size: '</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># w_v</span>
<span class="c1"># scores(batch_size-)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> 
<span class="c1"># 2, 1, 10</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'scores size squeeze: '</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="n">attention_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># 2, 1, 10</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'attention_weights: '</span><span class="p">,</span> <span class="n">attention_weights</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="c1"># attention_weights</span>

<span class="n">attention</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>    <span class="c1"># (2,1,10) @ (  10,4) = (2,1,4)</span>
                                                    <span class="c1"># (2,1,10) @ (2,10,4) = (2,1,4) </span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'attention: '</span><span class="p">,</span> <span class="n">attention</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="c1"># batch_size, num_query, value_size</span>
<span class="c1"># 2, 1, 4</span>

<span class="c1"># summary </span>
    <span class="c1"># Input:</span>
            <span class="c1"># queries:                  (batch_size, num_query, query_size)</span>
            <span class="c1"># keys:                     (batch_size, k_v_pair_num,  key_size)</span>
            <span class="c1"># values:                   (batch_size, k_v_pair_num, value_size)</span>
    <span class="c1"># Output:                           (batch_size, num_query, value_size)</span>


<span class="c1"># dropout</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>     <span class="c1"># 0.1</span>
<span class="n">attention_weights_droputed</span> <span class="o">=</span> <span class="n">dropout</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">)</span>
<span class="c1"># attention_weights_droputed.shape = 2, 1, 10    dropoutattention_weights</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'attention_wights_droputed size: '</span><span class="p">,</span> <span class="n">attention_weights_droputed</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="n">attention_droputed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">attention_weights_droputed</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="n">attention_droputed</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>queries size:  torch.Size([2, 1, 20])
keys size:  torch.Size([2, 10, 2])
values size:  torch.Size([2, 10, 4])
Q size:  torch.Size([2, 1, 1, 4])
K size:  torch.Size([2, 1, 10, 4])
features size:  torch.Size([2, 1, 10, 4])
features size (tanh):  torch.Size([2, 1, 10, 4])
scores size:  torch.Size([2, 1, 10, 1])
scores size squeeze:  torch.Size([2, 1, 10])
attention_weights:  torch.Size([2, 1, 10])
attention:  torch.Size([2, 1, 4])
attention_wights_droputed size:  torch.Size([2, 1, 10])
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[26]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 1, 4])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># attention_weights(batch_size, num_query, k_v_pair_num)</span>
<span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[28]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[[0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
          0.0000, 0.0000]],

        [[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000,
          0.0000, 0.0000]]], grad_fn=&lt;SoftmaxBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> 
<span class="kn">import</span> <span class="nn">torch</span> 


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="c1"># plt.figure(figsize=(3, 3))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">'batch </span><span class="si">{</span><span class="n">batch</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'k-v pair'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'query'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[43]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># attention_weights(batch_size, num_query, k_v_pair_num)</span>
<span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[43]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[[0.1014, 0.0847, 0.0880, 0.1066, 0.0995, 0.1215, 0.0694, 0.0967,
          0.1058, 0.1264]],

        [[0.0989, 0.0811, 0.0944, 0.0861, 0.0983, 0.1055, 0.1241, 0.0852,
          0.1245, 0.1018]]], grad_fn=&lt;SoftmaxBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[44]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>   


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">'batch </span><span class="si">{</span><span class="n">batch</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'k-v pair'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'query'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.5.3.2.-%E7%BC%A9%E6%94%BE%E7%82%B9%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B-(Scaled-Dot-Product-Attention)-%E8%AE%A1%E7%AE%97q%E3%80%81k%E7%9B%B8%E4%BC%BC%E5%BA%A6">11.5.3.2. <a id="toc11_5_3_2_"></a><a href="#toc0_"> (Scaled Dot-Product Attention)-qk</a><a class="anchor-link" href="#11.5.3.2.-%E7%BC%A9%E6%94%BE%E7%82%B9%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B-(Scaled-Dot-Product-Attention)-%E8%AE%A1%E7%AE%97q%E3%80%81k%E7%9B%B8%E4%BC%BC%E5%BA%A6"></a></h4><p> Vaswani  2017  Transformer 
</p>
<ul>
<li></li>
<li></li>
<li> softmax </li>
</ul>
<p>$\mathrm{Attention}(Q,K,V)=\mathrm{softmax} (\frac{QK^T}{\sqrt{d_k}}) V$, $d_k$</p>
<p></p>
<ul>
<li></li>
<li></li>
</ul>
<p></p>
<ul>
<li></li>
</ul>
<hr/>
<ul>
<li>qk<code></code><code>d</code></li>
<li>$a(\mathbf{q},\mathbf{k})=\mathbf{q}^\top\mathbf{k}/\sqrt{d}$</li>
<li>$\mathrm{softmax}\left(\frac{\mathrm{QK}^\top}{\sqrt{d}}\right)\mathbf{V}\in\mathbb{R}^{n\times v}$</li>
<li>$\text{}\mathbf{Q}\in\mathbb{R}^{n\times d}\text{}\mathbf{K}\in\mathbb{R}^{m\times d}\text{ }\mathbf{V}\in\mathbb{R}^{m\times v}$</li>
<li><code></code></li>
</ul>
<p><img align="center" alt="" height="300" src="./Pytorch_Pictures/Attention/scale-dot-product.png" width="300"/></p>
<ul>
<li></li>
</ul>
<div class="highlight"><pre><span></span><span class="c1"># summary </span>
    <span class="c1"># Input:</span>
            <span class="c1"># queries:                  (batch_size, num_query, query_size)</span>
            <span class="c1"># keys:                     (batch_size, k_v_pair_num,  key_size)</span>
            <span class="c1"># values:                   (batch_size, k_v_pair_num, value_size)</span>
            <span class="c1"># query_size, key_sizevalue_size</span>
    <span class="c1"># Output:                           (batch_size, num_query, value_size)</span>
</pre></div>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>PyTorch<br/>
query_size = key_size = value_size</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[45]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_query</span><span class="p">,</span> <span class="n">query_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">key_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">value_size</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">queries</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_query</span><span class="p">,</span> <span class="n">query_size</span><span class="p">))</span>
<span class="n">keys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">key_size</span><span class="p">))</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">value_size</span><span class="p">))</span>

<span class="c1"># num_heads = 1</span>
<span class="n">att</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">embed_dim</span><span class="o">=</span><span class="n">value_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">out</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">att</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>

<span class="n">out</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[45]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 1, 4])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>-<ul>
<li> (masked) Dropout</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[50]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 

<span class="kn">import</span> <span class="nn">math</span>


<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">DotProductAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DotProductAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="c1"># queries(batch_sized)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">query_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span> 
        <span class="c1"># keys(batch_sized)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">key_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="c1"># values(batch_size)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span><span class="p">(</span><span class="n">queries</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span><span class="p">(</span><span class="n">keys</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
        <span class="c1"># queries: (batch_size, num_query, num_hiddens)</span>
        <span class="c1"># keys: (batch_size, k_v_pair_num, num_hiddens)</span>
        <span class="c1"># values: (batch_size, k_v_pair_num, value_size)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># transpose_b=Truekeys</span>
        <span class="c1"># (batch_size, num_query, num_hiddens) @ (batch_size, num_hiddens, k_v_pair_num) = (batch_size, num_query, k_v_pair_num)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

        <span class="c1"># valid_lens:(batch_size)(batch_size)</span>
        <span class="c1"># masked_softmax</span>
        <span class="c1"># attention_weights(batch_size, num_query, k_v_pair_num)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">masked_softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>

        <span class="c1"># (batch_size, num_query, k_v_pair_num) @ (batch_size, k_v_pair_num, value_size) = (batch_size, num_query, value_size)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">),</span> <span class="n">values</span><span class="p">)</span>
    
    
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_query</span><span class="p">,</span> <span class="n">query_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">key_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">value_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">queries</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_query</span><span class="p">,</span> <span class="n">query_size</span><span class="p">))</span>
<span class="n">keys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">key_size</span><span class="p">))</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">value_size</span><span class="p">))</span>

<span class="n">attention</span> <span class="o">=</span> <span class="n">DotProductAttention</span><span class="p">(</span><span class="n">query_size</span><span class="o">=</span><span class="n">query_size</span><span class="p">,</span> <span class="n">key_size</span><span class="o">=</span><span class="n">key_size</span><span class="p">,</span> <span class="n">value_size</span><span class="o">=</span><span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
<span class="n">attention</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">attention</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[50]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 1, 8])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>() <ul>
<li>Dropout</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[52]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="c1">#   </span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">num_query</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">query_size</span> <span class="o">=</span> <span class="mi">4</span>             <span class="c1"># queryd</span>

<span class="n">num_key</span> <span class="o">=</span> <span class="mi">10</span>                    <span class="c1"># m</span>
<span class="n">key_size</span> <span class="o">=</span> <span class="mi">4</span>                <span class="c1"># keyd</span>

<span class="n">num_value</span> <span class="o">=</span> <span class="n">num_key</span>             <span class="c1"># m</span>
<span class="n">value_size</span> <span class="o">=</span> <span class="mi">4</span>              <span class="c1"># valuev</span>

<span class="n">queries</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_query</span><span class="p">,</span> <span class="n">query_size</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'queries size: '</span><span class="p">,</span> <span class="n">queries</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="c1"># (batch_size, num_query, query_size)</span>
<span class="c1"># (2, 1, 20)</span>

<span class="n">keys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_key</span><span class="p">,</span> <span class="n">key_size</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'keys size: '</span><span class="p">,</span> <span class="n">keys</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="c1"># (batch_size, num_key, key_size)</span>
<span class="c1"># (2, 10, 20)</span>

<span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_value</span><span class="p">,</span> <span class="n">value_size</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'values size: '</span><span class="p">,</span> <span class="n">values</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="c1"># (batch_size, num_value, value_size)</span>
<span class="c1"># (2, 10, 4)</span>

<span class="n">features</span> <span class="o">=</span> <span class="p">(</span><span class="n">queries</span> <span class="o">@</span> <span class="n">keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> 
<span class="c1"># features = torch.bmm(queries, keys.transpose(1, 2))               # </span>
<span class="c1"># (2, 1, 20) @ (2, 20, 10) = (2, 1, 10)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'features size: </span><span class="si">{</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">features</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">queries</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
<span class="c1"># (2, 1, 10)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'scores size: </span><span class="si">{</span><span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="n">attention_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># (2, 1, 10) /  = (2, 1, 10)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'attention_weights size: </span><span class="si">{</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="n">attention</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="c1"># (2, 1, 4)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'attention size: </span><span class="si">{</span><span class="n">attention</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># summary </span>
    <span class="c1"># Input:</span>
            <span class="c1"># queries:                  (batch_size, num_query, query_size)</span>
            <span class="c1"># keys:                     (batch_size, k_v_pair_num,  key_size)</span>
            <span class="c1"># values:                   (batch_size, k_v_pair_num, value_size)</span>
    <span class="c1"># Output:                           (batch_size, num_query, value_size)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>queries size:  torch.Size([2, 1, 4])
keys size:  torch.Size([2, 10, 4])
values size:  torch.Size([2, 10, 4])
features size: torch.Size([2, 1, 10])
scores size: torch.Size([2, 1, 10])
attention_weights size: torch.Size([2, 1, 10])
attention size: torch.Size([2, 1, 4])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.5.4.-%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-q%E3%80%81k%E5%92%8Cv%E7%9B%B8%E5%90%8C">11.5.4. <a id="toc11_5_4_"></a><a href="#toc0_">-qkv</a><a class="anchor-link" href="#11.5.4.-%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-q%E3%80%81k%E5%92%8Cv%E7%9B%B8%E5%90%8C"></a></h3><p><code>X</code><code>W_q</code><code>W_k</code><code>W_v</code><code>Q</code><code>K</code><code>V</code> <code>/</code>Xqkv <code></code> </p>
<ul>
<li></li>
</ul>
<div class="highlight"><pre><span></span><span class="c1"># self-attention:                       queries = keys = values</span>
    <span class="c1"># Input:</span>
            <span class="c1"># queries:                  (batch_size, num_query, query_size)</span>
            <span class="c1"># keys:                     (batch_size, k_v_pair_num,  key_size)</span>
            <span class="c1"># values:                   (batch_size, k_v_pair_num, value_size)</span>
    <span class="c1"># Output:                           (batch_size, num_query, value_size)</span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[61]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">data</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">time</span> 


<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>


<span class="c1"># </span>
<span class="n">dbs</span> <span class="o">=</span> <span class="s1">'./Pytorch_datasets/'</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>

            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
            <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
            <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># </span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>  <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># test_iter = data.DataLoader(dataset=test_dataset) # testbatch</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[66]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 1:CNN</span>
<span class="k">class</span> <span class="nc">CNNMNISTModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
<span class="c1"># 2:Additive attention</span>
<span class="k">class</span> <span class="nc">SelfAttentionMNISTModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attention_type</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># </span>
        <span class="k">if</span> <span class="n">attention_type</span> <span class="o">==</span> <span class="s1">'add'</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">AdditiveAttention</span><span class="p">(</span><span class="n">query_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">key_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">attention_type</span> <span class="o">==</span> <span class="s1">'dot'</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">DotProductAttention</span><span class="p">(</span><span class="n">query_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">key_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">value_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Invalid attention type: </span><span class="si">{</span><span class="n">attention_type</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        
        <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># dim=1query(1, 768)</span>
        <span class="c1"># qkv</span>
        <span class="c1"># , (batch_size, num_query, value_size)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">queries</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># dim=1768</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
    

<span class="c1"># </span>
<span class="k">def</span> <span class="nf">train_steps</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">    </span>
<span class="sd">    epochs = epochs                         # epoch</span>
<span class="sd">    train_dataset = train_dataset           # train</span>
<span class="sd">    train_iter = train_iter                 # batchtrain</span>
<span class="sd">    test_dataset = test_dataset             # test</span>
<span class="sd">    net = net                               # </span>
<span class="sd">    loss_fn = loss_fn                       # </span>
<span class="sd">    opt = opt                               # </span>
<span class="sd">    device = device                         # device GPU/CPU</span>
<span class="sd">    '''</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"Runing on </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">train_all_data_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">train_all_targets_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">test_all_data_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">test_all_targets_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
    <span class="c1"># net = nn.DataParallel(module=net, device_ids=[0, 1], output_device=[0]) # GPUnet = nn.DataParallel(module=net)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># </span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_record</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch_record</span>                 <span class="c1"># X, y</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># deviceGPU/CPU      </span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>                     <span class="c1"># </span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>          <span class="c1"># y_hat</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="c1"># loss</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>         <span class="c1"># </span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>              <span class="c1"># </span>
        <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> 
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># withgrad</span>
            <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">),</span> <span class="n">train_all_targets_gpu</span><span class="p">)</span>
            <span class="c1"># print(train_loss)</span>
            <span class="n">train_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">train_all_targets_gpu</span>
            <span class="n">train_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_acc_cmp</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="c1"># print(train_acc)</span>
            <span class="n">test_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">test_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">test_all_targets_gpu</span>
            <span class="n">test_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_acc_cmp</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="c1"># print(test_acc)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">: train_loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s2">, train_acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s2">, test_acc=</span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">stop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">seconds</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>
    <span class="k">def</span> <span class="nf">convert_seconds</span><span class="p">(</span><span class="n">seconds</span><span class="p">):</span>
        <span class="n">days</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">//</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">)</span>
        <span class="n">hours</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">))</span> <span class="o">//</span> <span class="mi">3600</span>
        <span class="n">minutes</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="mi">3600</span><span class="p">)</span> <span class="o">//</span> <span class="mi">60</span>
        <span class="n">remaining_seconds</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">%</span> <span class="mi">60</span>
        <span class="k">return</span> <span class="n">days</span><span class="p">,</span> <span class="n">hours</span><span class="p">,</span> <span class="n">minutes</span><span class="p">,</span> <span class="n">remaining_seconds</span>
    <span class="n">days</span><span class="p">,</span> <span class="n">hours</span><span class="p">,</span> <span class="n">minutes</span><span class="p">,</span> <span class="n">remaining_seconds</span> <span class="o">=</span> <span class="n">convert_seconds</span><span class="p">(</span><span class="n">seconds</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"Total</span><span class="si">{</span><span class="n">days</span><span class="si">}</span><span class="s2"> d/ </span><span class="si">{</span><span class="n">hours</span><span class="si">}</span><span class="s2"> h/ </span><span class="si">{</span><span class="n">minutes</span><span class="si">}</span><span class="s2"> m/ </span><span class="si">{</span><span class="n">remaining_seconds</span><span class="si">}</span><span class="s2"> s"</span><span class="p">)</span>
    <span class="c1"># return (train_loss, train_acc, test_acc)</span>
    <span class="k">return</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[68]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># CNN</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">CNNMNISTModel</span><span class="p">()</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  

<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span> 
<span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================================================================================================== 
 Runing on cuda:0 
 ====================================================================================================
epoch 1/10: train_loss=1.6279242038726807, train_acc=84.27833557128906, test_acc=84.61000061035156
epoch 2/10: train_loss=1.5473763942718506, train_acc=92.55500030517578, test_acc=92.8499984741211
epoch 3/10: train_loss=1.5314202308654785, train_acc=93.88166809082031, test_acc=93.72999572753906
epoch 4/10: train_loss=1.5217000246047974, train_acc=94.71333312988281, test_acc=94.57999420166016
epoch 5/10: train_loss=1.5153697729110718, train_acc=95.24000549316406, test_acc=94.8699951171875
epoch 6/10: train_loss=1.5102185010910034, train_acc=95.73332977294922, test_acc=95.25
epoch 7/10: train_loss=1.5050678253173828, train_acc=96.20166778564453, test_acc=95.58999633789062
epoch 8/10: train_loss=1.5006235837936401, train_acc=96.61000061035156, test_acc=96.16999816894531
epoch 9/10: train_loss=1.4976444244384766, train_acc=96.913330078125, test_acc=96.23999786376953
epoch 10/10: train_loss=1.4948958158493042, train_acc=97.20166778564453, test_acc=96.48999786376953
==================================================================================================== 
 Total0.0 d/ 0.0 h/ 1.0 m/ 4.458106756210327 s
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># AdditiveAttention</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">SelfAttentionMNISTModel</span><span class="p">(</span><span class="n">attention_type</span><span class="o">=</span><span class="s1">'add'</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  

<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span> 
<span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================================================================================================== 
 Runing on cuda:0 
 ====================================================================================================
epoch 1/10: train_loss=0.16107121109962463, train_acc=95.36499786376953, test_acc=95.27999877929688
epoch 2/10: train_loss=0.09944581240415573, train_acc=97.13999938964844, test_acc=96.66999816894531
epoch 3/10: train_loss=0.07719363272190094, train_acc=97.74166870117188, test_acc=97.13999938964844
epoch 4/10: train_loss=0.06208990514278412, train_acc=98.1866683959961, test_acc=97.41999816894531
epoch 5/10: train_loss=0.0564107820391655, train_acc=98.36666870117188, test_acc=97.27999877929688
epoch 6/10: train_loss=0.04126492142677307, train_acc=98.84166717529297, test_acc=97.50999450683594
epoch 7/10: train_loss=0.038705650717020035, train_acc=98.92666625976562, test_acc=97.78999328613281
epoch 8/10: train_loss=0.02942928485572338, train_acc=99.23999786376953, test_acc=97.97999572753906
epoch 9/10: train_loss=0.035614024847745895, train_acc=98.95833587646484, test_acc=97.66999816894531
epoch 10/10: train_loss=0.02169625461101532, train_acc=99.49166870117188, test_acc=97.89999389648438
==================================================================================================== 
 Total0.0 d/ 0.0 h/ 1.0 m/ 9.748560905456543 s
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[65]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># DotProductAttention</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">SelfAttentionMNISTModel</span><span class="p">(</span><span class="n">attention_type</span><span class="o">=</span><span class="s1">'dot'</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  

<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span> 
<span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================================================================================================== 
 Runing on cuda:0 
 ====================================================================================================
epoch 1/10: train_loss=0.19046252965927124, train_acc=94.09833526611328, test_acc=93.47999572753906
epoch 2/10: train_loss=0.07349269837141037, train_acc=97.84166717529297, test_acc=97.37999725341797
epoch 3/10: train_loss=0.05895423889160156, train_acc=98.16999816894531, test_acc=97.55999755859375
epoch 4/10: train_loss=0.04070112481713295, train_acc=98.75333404541016, test_acc=97.93999481201172
epoch 5/10: train_loss=0.039311956614255905, train_acc=98.73999786376953, test_acc=97.57999420166016
epoch 6/10: train_loss=0.039534058421850204, train_acc=98.73833465576172, test_acc=97.30999755859375
epoch 7/10: train_loss=0.022449102252721786, train_acc=99.34666442871094, test_acc=97.89999389648438
epoch 8/10: train_loss=0.029125791043043137, train_acc=99.05000305175781, test_acc=97.68999481201172
epoch 9/10: train_loss=0.037722766399383545, train_acc=98.71666717529297, test_acc=97.25999450683594
epoch 10/10: train_loss=0.020519915968179703, train_acc=99.30333709716797, test_acc=97.3499984741211
==================================================================================================== 
 Total0.0 d/ 0.0 h/ 1.0 m/ 9.772022008895874 s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.5.5.-%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-h%E4%B8%AAq%E3%80%81k%E5%92%8Cv%E5%AF%B9">11.5.5. <a id="toc11_5_5_"></a><a href="#toc0_">-hqkv</a><a class="anchor-link" href="#11.5.5.-%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-h%E4%B8%AAq%E3%80%81k%E5%92%8Cv%E5%AF%B9"></a></h3><p>Q, K, Vhhattentionhattentionattentionsattentionheadhhead</p>
<p><img align="center" alt="" height="350" src="./Pytorch_Pictures/Attention/multi_head.jpg" width="300"/></p>
<p><code></code>d</p>
<div class="highlight"><pre><span></span><span class="c1"># summary </span>
    <span class="c1"># Input:</span>
            <span class="c1"># queries:                  (batch_size, num_query, query_size)</span>
            <span class="c1"># keys:                     (batch_size, k_v_pair_num,  key_size)</span>
            <span class="c1"># values:                   (batch_size, k_v_pair_num, value_size)</span>
    <span class="c1"># Output:                           (batch_size, num_query, value_size)</span>

<span class="c1">#  transpose_input()</span>
<span class="c1">#  transpose_output()</span>
<span class="c1">#  self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=exitBias)   # concathead ()</span>
</pre></div>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li><br/>
query_size = key_size = value_size = d<br/>
nn.MultiheadAttention(embed_dim=value_size, num_heads=num_heads, batch_first=True)</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="c1"># </span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">query_num</span><span class="p">,</span> <span class="n">query_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">key_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">value_size</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># </span>
<span class="n">multihead_attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">embed_dim</span><span class="o">=</span><span class="n">value_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1">#  query_size = key_size = value_size = d</span>

<span class="c1"># </span>
<span class="c1">#  (, , )</span>
<span class="n">query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">query_num</span><span class="p">,</span> <span class="n">query_size</span><span class="p">)</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">key_size</span><span class="p">)</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">value_size</span><span class="p">)</span>

<span class="c1"># </span>
<span class="c1"># mask = torch.zeros(batch_size, seq_length, seq_length).type(torch.bool)</span>

<span class="c1"># </span>
<span class="c1">#  mask </span>
<span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">multihead_attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">":"</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># : (batch_size, query_num, value_size)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">":"</span><span class="p">,</span> <span class="n">attention_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># : (batch_size, num_query, k_v_pair_num)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>: torch.Size([2, 1, 4])
: torch.Size([2, 1, 10])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>- ()<ul>
<li>Dropout</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[165]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>  
<span class="kn">import</span> <span class="nn">math</span> 


<span class="c1"># </span>
<span class="k">class</span> <span class="nc">AdditiveAttentionForMultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># queries, keys = self.W_q(queries), self.W_k(keys)</span>
        <span class="c1"># queries:              (batch_size, num_query, num_hiddens)</span>
        <span class="c1"># keys:                 (batch_size, k_v_pair_num, num_hiddens)</span>
        <span class="c1"># </span>
        <span class="c1"># queries       (batch_sizenum_query        1        num_hiddens)</span>
        <span class="c1"># key           (batch_size    1    k_v_pair_num  num_hiddens)</span>
        <span class="c1">#   (batch_size, num_query, 1, num_hiddens) + (batch_size, 1, k_v_pair_num, num_hiddens) = (batch_size, num_query, k_v_pair_num, num_hiddens)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">keys</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="c1"># features(batch_size, num_query, k_v_pair_num, num_hiddens)</span>
        
        <span class="c1"># self.w_v: (num_hiddens, 1)</span>
        <span class="c1"># scores(batch_sizenum_queryk_v_pair_num, 1)</span>
        <span class="c1"># squeeze(-1)</span>
        <span class="c1"># scores(batch_sizenum_queryk_v_pair_num)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># </span>
        <span class="c1"># masked_softmax, valid_lens</span>
        <span class="c1"># attention_weights(batch_size, num_query, k_v_pair_num)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">masked_softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>

        <span class="c1"># values(batch_sizek_v_pair_numvalue_size)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">),</span> <span class="n">values</span><span class="p">)</span>

<span class="c1"># </span>
<span class="k">class</span> <span class="nc">DotProductAttentionForMultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># queries, keys, values = self.W_q(queries), self.W_k(keys), self.w_v(values)</span>
        <span class="c1"># queries: (batch_size, num_query, num_hiddens)</span>
        <span class="c1"># keys: (batch_size, k_v_pair_num, num_hiddens)</span>
        <span class="c1"># values: (batch_size, k_v_pair_num, value_size)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># transpose_b=Truekeys</span>
        <span class="c1"># (batch_size, num_query, num_hiddens) @ (batch_size, num_hiddens, k_v_pair_num) = (batch_size, num_query, k_v_pair_num)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

        <span class="c1"># valid_lens:(batch_size)(batch_size)</span>
        <span class="c1"># masked_softmax</span>
        <span class="c1"># attention_weights(batch_size, num_query, k_v_pair_num)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">masked_softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>

        <span class="c1"># (batch_size, num_query, k_v_pair_num) @ (batch_size, k_v_pair_num, value_size) = (batch_size, num_query, value_size)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">),</span> <span class="n">values</span><span class="p">)</span>

<span class="c1"># </span>
<span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">attention_type</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">query_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">key_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_hiddens</span> <span class="o">%</span> <span class="n">num_heads</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># raise ValueError(f'num_hiddens must be divisible by num_heads, but got num_hiddens={num_hiddens} and num_heads={num_heads}')</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'num_hiddensnum_headsnum_hiddens=</span><span class="si">{</span><span class="n">num_hiddens</span><span class="si">}</span><span class="s1">num_heads=</span><span class="si">{</span><span class="n">num_heads</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        
        <span class="c1"># </span>
        <span class="k">if</span> <span class="n">attention_type</span> <span class="o">==</span> <span class="s1">'add'</span><span class="p">:</span>
            <span class="c1"># self.attention = AdditiveAttention(query_size=query_size, key_size=key_size, num_hiddens=num_hiddens, dropout=dropout)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">AdditiveAttentionForMultiHeadAttention</span><span class="p">(</span><span class="n">num_hiddens</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">num_hiddens</span><span class="o">/</span><span class="n">num_heads</span><span class="p">),</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">attention_type</span> <span class="o">==</span> <span class="s1">'dot'</span><span class="p">:</span>
            <span class="c1"># self.attention = DotProductAttention(query_size=query_size, key_size=key_size, value_size=value_size, num_hiddens=num_hiddens, dropout=dropout)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">DotProductAttentionForMultiHeadAttention</span><span class="p">(</span><span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Invalid attention type: </span><span class="si">{</span><span class="n">attention_type</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>        

        <span class="c1"># concathead ()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_o</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>   

    <span class="k">def</span> <span class="nf">transpose_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
<span class="w">        </span><span class="sd">""""""</span>
        <span class="c1"># X:(batch_sizenum_hiddens)</span>
        <span class="c1"># X:(batch_size`num_heads`num_hiddens/num_heads)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># X:(batch_size`num_heads`num_hiddens/num_heads)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>                                                                   <span class="c1">#  (multi heads)</span>

        <span class="c1"># :(batch_size*`num_heads`,num_hiddens/num_heads)</span>
        <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">transpose_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""transpose_qkv"""</span>
        <span class="c1"># X:(batch_size*`num_heads`,num_hiddens/num_heads)</span>
        <span class="c1"># X:(batch_size,`num_heads``,num_hiddens/num_heads)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

        <span class="c1"># X:(batch_size,`num_heads`,num_hiddens/num_heads)                                        # </span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

        <span class="c1"># X:(batch_size,num_hiddens)</span>
        <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># queries: (batch_size, num_query, query_size)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>
        <span class="c1"># queries: (batch_size, num_query, num_hiddens)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_input</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
        <span class="c1"># queries: (batch_size*num_heads, num_query, num_hiddens/num_heads)</span>

        <span class="c1"># keys: (batch_size, k_v_pair_num, key_size)    </span>
        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>
        <span class="c1"># keys: (batch_size, k_v_pair_num, num_hiddens)</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_input</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
        <span class="c1"># keys: (batch_size*num_heads, k_v_pair_num, num_hiddens/num_heads)</span>

        <span class="c1"># values: (batch_size, k_v_pair_num, value_size)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_v</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>    
        <span class="c1"># values: (batch_size, k_v_pair_num, num_hiddens)     </span>
        <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_input</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
        <span class="c1"># values: (batch_size*num_heads, k_v_pair_num, num_hiddens/num_heads)</span>

        <span class="k">if</span> <span class="n">valid_lens</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># 0num_heads</span>
            <span class="c1"># </span>
            <span class="n">valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">valid_lens</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># output:(batch_size*num_headsnum_querynum_hiddens/num_heads)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">queries</span><span class="o">=</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="o">=</span><span class="n">valid_lens</span><span class="p">)</span>

        <span class="c1"># output_concat:(batch_sizenum_querynum_hiddens) </span>
        <span class="n">output_concat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_output</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_o</span><span class="p">(</span><span class="n">output_concat</span><span class="p">)</span>


<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">num_query</span><span class="p">,</span> <span class="n">query_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">key_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">value_size</span> <span class="o">=</span> <span class="mi">4</span> 
<span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># </span>
<span class="n">multiHeadAttention</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span>
    <span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span><span class="p">,</span> 
    <span class="n">query_size</span> <span class="o">=</span> <span class="n">query_size</span><span class="p">,</span> 
    <span class="n">key_size</span> <span class="o">=</span> <span class="n">key_size</span><span class="p">,</span> 
    <span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span> 
    <span class="n">value_size</span> <span class="o">=</span> <span class="n">value_size</span><span class="p">,</span>
    <span class="n">attention_type</span><span class="o">=</span><span class="s1">'add'</span>
<span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">multiHeadAttention</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_query</span><span class="p">,</span> <span class="n">query_size</span><span class="p">));</span> <span class="nb">print</span><span class="p">(</span><span class="s1">'raw queries size: '</span><span class="p">,</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">key_size</span><span class="p">));</span> <span class="nb">print</span><span class="p">(</span><span class="s1">'raw keys size: '</span><span class="p">,</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">k_v_pair_num</span><span class="p">,</span> <span class="n">value_size</span><span class="p">));</span> <span class="nb">print</span><span class="p">(</span><span class="s1">'raw values size: '</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">attention_values</span> <span class="o">=</span> <span class="n">multiHeadAttention</span><span class="p">(</span><span class="n">queries</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="n">key</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">value</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">'attention_values size: '</span><span class="p">,</span> <span class="n">attention_values</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>MultiHeadAttention(
  (W_q): Linear(in_features=4, out_features=128, bias=True)
  (W_k): Linear(in_features=4, out_features=128, bias=True)
  (W_v): Linear(in_features=4, out_features=128, bias=True)
  (attention): AdditiveAttentionForMultiHeadAttention(
    (dropout): Dropout(p=False, inplace=False)
    (w_v): Linear(in_features=64, out_features=1, bias=True)
  )
  (W_o): Linear(in_features=128, out_features=128, bias=True)
)
raw queries size:  torch.Size([2, 1, 4])
raw keys size:  torch.Size([2, 10, 4])
raw values size:  torch.Size([2, 10, 4])
attention_values size:  torch.Size([2, 1, 128])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li><ul>
<li>Dropout</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[136]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>  
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">data</span>

<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="kn">import</span> <span class="nn">time</span> 


<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>


<span class="c1"># </span>
<span class="n">dbs</span> <span class="o">=</span> <span class="s1">'./Pytorch_datasets/'</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>

            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
            <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
            <span class="c1">#  torchvision.transforms.Normalize((0.1307,), (0.3081,))</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># </span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>  <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># test_iter = data.DataLoader(dataset=test_dataset) # testbatch</span>

  
<span class="c1"># 4</span>
<span class="k">class</span> <span class="nc">MultiHeadAttentionMNISTModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">attention_type</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> 
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">128</span>
        <span class="c1">#  from PyTorch</span>
        <span class="c1"># self.attention = nn.MultiheadAttention(embed_dim=num_hiddens, num_heads=num_heads, batch_first=True)</span>

        <span class="c1">#  from </span>
        <span class="k">if</span> <span class="n">attention_type</span> <span class="o">==</span> <span class="s1">'add'</span><span class="p">:</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span>
                <span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span><span class="p">,</span> 
                <span class="n">query_size</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span> 
                <span class="n">key_size</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span> 
                <span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span> 
                <span class="n">value_size</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span>
                <span class="n">attention_type</span><span class="o">=</span><span class="s1">'add'</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">attention_type</span> <span class="o">==</span> <span class="s1">'dot'</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span>
                <span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span><span class="p">,</span> 
                <span class="n">query_size</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span> 
                <span class="n">key_size</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span> 
                <span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span> 
                <span class="n">value_size</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span>
                <span class="n">attention_type</span><span class="o">=</span><span class="s1">'dot'</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Invalid attention type: </span><span class="si">{</span><span class="n">attention_type</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">queries</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># x, weights = self.attention(query=x, key=x, value=x)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="c1"># </span>
<span class="k">def</span> <span class="nf">train_steps</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">    </span>
<span class="sd">    epochs = epochs                         # epoch</span>
<span class="sd">    train_dataset = train_dataset           # train</span>
<span class="sd">    train_iter = train_iter                 # batchtrain</span>
<span class="sd">    test_dataset = test_dataset             # test</span>
<span class="sd">    net = net                               # </span>
<span class="sd">    loss_fn = loss_fn                       # </span>
<span class="sd">    opt = opt                               # </span>
<span class="sd">    device = device                         # device GPU/CPU</span>
<span class="sd">    '''</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"Runing on </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">train_all_data_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">train_all_targets_gpu</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">test_all_data_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">test_all_targets_gpu</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># </span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_record</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch_record</span>                 <span class="c1"># X, y</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># deviceGPU/CPU</span>
            <span class="c1"># print(X[0])</span>
            <span class="c1"># print(X[0].dtype)</span>
            <span class="c1"># break</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>                     <span class="c1"># </span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>          <span class="c1"># y_hat</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="c1"># loss</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>         <span class="c1"># </span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>              <span class="c1"># </span>

        <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># </span>
                    <span class="c1"># net.train()</span>
                    <span class="c1"># netBNDropouttesttraintest</span>
                    <span class="c1"># netBNDropoutnet.eval()</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># withgrad</span>
            <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">),</span> <span class="n">train_all_targets_gpu</span><span class="p">)</span>
            <span class="c1"># print(train_loss)</span>
            <span class="n">train_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">train_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">train_all_targets_gpu</span>
            <span class="n">train_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_acc_cmp</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="c1"># print(train_acc)</span>
            <span class="n">test_acc_cmp</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">test_all_data_gpu</span><span class="o">/</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">test_all_targets_gpu</span>
            <span class="n">test_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_acc_cmp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_acc_cmp</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="c1"># print(test_acc)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">: train_loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s2">, train_acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s2">, test_acc=</span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">stop</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">seconds</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>
    <span class="k">def</span> <span class="nf">convert_seconds</span><span class="p">(</span><span class="n">seconds</span><span class="p">):</span>
        <span class="n">days</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">//</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">)</span>
        <span class="n">hours</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="p">(</span><span class="mi">24</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">))</span> <span class="o">//</span> <span class="mi">3600</span>
        <span class="n">minutes</span> <span class="o">=</span> <span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="mi">3600</span><span class="p">)</span> <span class="o">//</span> <span class="mi">60</span>
        <span class="n">remaining_seconds</span> <span class="o">=</span> <span class="n">seconds</span> <span class="o">%</span> <span class="mi">60</span>
        <span class="k">return</span> <span class="n">days</span><span class="p">,</span> <span class="n">hours</span><span class="p">,</span> <span class="n">minutes</span><span class="p">,</span> <span class="n">remaining_seconds</span>
    <span class="n">days</span><span class="p">,</span> <span class="n">hours</span><span class="p">,</span> <span class="n">minutes</span><span class="p">,</span> <span class="n">remaining_seconds</span> <span class="o">=</span> <span class="n">convert_seconds</span><span class="p">(</span><span class="n">seconds</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"Total</span><span class="si">{</span><span class="n">days</span><span class="si">}</span><span class="s2"> d/ </span><span class="si">{</span><span class="n">hours</span><span class="si">}</span><span class="s2"> h/ </span><span class="si">{</span><span class="n">minutes</span><span class="si">}</span><span class="s2"> m/ </span><span class="si">{</span><span class="n">remaining_seconds</span><span class="si">}</span><span class="s2"> s"</span><span class="p">)</span>
    <span class="c1"># return (train_loss, train_acc, test_acc)</span>
    <span class="k">return</span> <span class="kc">None</span>

<span class="c1"># lr 0.01 -&gt; 0.5</span>
<span class="c1"># </span>
<span class="n">net</span> <span class="o">=</span> <span class="n">MultiHeadAttentionMNISTModel</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">attention_type</span><span class="o">=</span><span class="s1">'add'</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>   
<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span> 
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================================================================================================== 
 Runing on cuda:0 
 ====================================================================================================
epoch 1/10: train_loss=0.14009088277816772, train_acc=95.65833282470703, test_acc=95.5199966430664
epoch 2/10: train_loss=0.13370926678180695, train_acc=95.71333312988281, test_acc=95.25
epoch 3/10: train_loss=0.07562894374132156, train_acc=97.73333740234375, test_acc=96.81999969482422
epoch 4/10: train_loss=0.07592946290969849, train_acc=97.53833770751953, test_acc=96.45999908447266
epoch 5/10: train_loss=0.05741669610142708, train_acc=98.17500305175781, test_acc=97.05999755859375
epoch 6/10: train_loss=0.04960254952311516, train_acc=98.39666748046875, test_acc=96.97000122070312
epoch 7/10: train_loss=0.03714532405138016, train_acc=98.79833221435547, test_acc=97.29000091552734
epoch 8/10: train_loss=0.03278254717588425, train_acc=98.93167114257812, test_acc=97.3499984741211
epoch 9/10: train_loss=0.03205224871635437, train_acc=98.96833038330078, test_acc=97.3499984741211
epoch 10/10: train_loss=0.024361353367567062, train_acc=99.23333740234375, test_acc=97.27999877929688
==================================================================================================== 
 Total0.0 d/ 0.0 h/ 4.0 m/ 35.818323850631714 s
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[138]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">MultiHeadAttentionMNISTModel</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">attention_type</span><span class="o">=</span><span class="s1">'dot'</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>   
<span class="n">train_steps</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
    <span class="n">train_iter</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
    <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>                        
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
    <span class="n">opt</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
    <span class="n">device</span><span class="o">=</span><span class="n">device</span> 
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================================================================================================== 
 Runing on cuda:0 
 ====================================================================================================
epoch 1/10: train_loss=1.7988883256912231, train_acc=63.3800048828125, test_acc=64.43000030517578
epoch 2/10: train_loss=0.7157629132270813, train_acc=79.63999938964844, test_acc=80.43999481201172
epoch 3/10: train_loss=0.5111636519432068, train_acc=85.36166381835938, test_acc=85.54999542236328
epoch 4/10: train_loss=0.42976391315460205, train_acc=87.88166809082031, test_acc=87.88999938964844
epoch 5/10: train_loss=0.38460060954093933, train_acc=89.12166595458984, test_acc=89.12999725341797
epoch 6/10: train_loss=0.3557939827442169, train_acc=89.91500091552734, test_acc=89.97000122070312
epoch 7/10: train_loss=0.33672431111335754, train_acc=90.47000122070312, test_acc=90.56999969482422
epoch 8/10: train_loss=0.3150826394557953, train_acc=91.03833770751953, test_acc=91.04000091552734
epoch 9/10: train_loss=0.29902029037475586, train_acc=91.41333770751953, test_acc=91.48999786376953
epoch 10/10: train_loss=0.2822543978691101, train_acc=91.91999816894531, test_acc=92.04999542236328
==================================================================================================== 
 Total0.0 d/ 0.0 h/ 4.0 m/ 59.04266595840454 s
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[141]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torchview</span> <span class="kn">import</span> <span class="n">draw_graph</span>


<span class="n">model_graph</span> <span class="o">=</span> <span class="n">draw_graph</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">MultiHeadAttentionMNISTModel</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">attention_type</span><span class="o">=</span><span class="s1">'dot'</span><span class="p">),</span> 
    <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">"cuda:0"</span>
<span class="p">)</span>
<span class="n">model_graph</span><span class="o">.</span><span class="n">visual_graph</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[141]:</div>
<div class="jp-RenderedSVG jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 12.0.0 (20240803.0821)
 -->
<!-- Title: model Pages: 1 -->
<svg width="431pt" height="1318pt"
 viewBox="0.00 0.00 430.75 1318.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(0.768513 0.768513) rotate(0) translate(4 1711)">
<title>model</title>
<polygon fill="white" stroke="none" points="-4,4 -4,-1711 556.5,-1711 556.5,4 -4,4"/>
<!-- 0 -->
<g id="node1" class="node">
<title>0</title>
<polygon fill="lightyellow" stroke="none" points="343.38,-1707 208.62,-1707 208.62,-1671.5 343.38,-1671.5 343.38,-1707"/>
<polygon fill="none" stroke="black" points="208.62,-1671.5 208.62,-1707 277.88,-1707 277.88,-1671.5 208.62,-1671.5"/>
<text text-anchor="start" x="213.62" y="-1692.5" font-family="Linux libertine" font-size="10.00">input&#45;tensor</text>
<text text-anchor="start" x="224.88" y="-1679.75" font-family="Linux libertine" font-size="10.00">depth:0</text>
<polygon fill="none" stroke="black" points="277.88,-1671.5 277.88,-1707 343.38,-1707 343.38,-1671.5 277.88,-1671.5"/>
<text text-anchor="start" x="282.88" y="-1686.12" font-family="Linux libertine" font-size="10.00">(64, 28, 28)</text>
</g>
<!-- 1 -->
<g id="node2" class="node">
<title>1</title>
<polygon fill="#c1ffc1" stroke="none" points="356.5,-1635.5 195.5,-1635.5 195.5,-1591.5 356.5,-1591.5 356.5,-1635.5"/>
<polygon fill="none" stroke="black" points="195.5,-1591.5 195.5,-1635.5 241.5,-1635.5 241.5,-1591.5 195.5,-1591.5"/>
<text text-anchor="start" x="201.25" y="-1616.75" font-family="Linux libertine" font-size="10.00">Flatten</text>
<text text-anchor="start" x="200.12" y="-1604" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="241.5,-1613.5 241.5,-1635.5 288.5,-1635.5 288.5,-1613.5 241.5,-1613.5"/>
<text text-anchor="start" x="251.12" y="-1621" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="288.5,-1613.5 288.5,-1635.5 356.5,-1635.5 356.5,-1613.5 288.5,-1613.5"/>
<text text-anchor="start" x="293.25" y="-1621" font-family="Linux libertine" font-size="10.00">(64, 28, 28) </text>
<polygon fill="none" stroke="black" points="241.5,-1591.5 241.5,-1613.5 288.5,-1613.5 288.5,-1591.5 241.5,-1591.5"/>
<text text-anchor="start" x="246.25" y="-1599" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="288.5,-1591.5 288.5,-1613.5 356.5,-1613.5 356.5,-1591.5 288.5,-1591.5"/>
<text text-anchor="start" x="299.25" y="-1599" font-family="Linux libertine" font-size="10.00">(64, 784) </text>
</g>
<!-- 0&#45;&gt;1 -->
<g id="edge1" class="edge">
<title>0&#45;&gt;1</title>
<path fill="none" stroke="black" d="M276,-1671.51C276,-1664.15 276,-1655.24 276,-1646.68"/>
<polygon fill="black" stroke="black" points="279.5,-1646.9 276,-1636.9 272.5,-1646.9 279.5,-1646.9"/>
</g>
<!-- 2 -->
<g id="node3" class="node">
<title>2</title>
<polygon fill="#c1ffc1" stroke="none" points="350.5,-1555.5 201.5,-1555.5 201.5,-1511.5 350.5,-1511.5 350.5,-1555.5"/>
<polygon fill="none" stroke="black" points="201.5,-1511.5 201.5,-1555.5 247.5,-1555.5 247.5,-1511.5 201.5,-1511.5"/>
<text text-anchor="start" x="209.5" y="-1536.75" font-family="Linux libertine" font-size="10.00">Linear</text>
<text text-anchor="start" x="206.12" y="-1524" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="247.5,-1533.5 247.5,-1555.5 294.5,-1555.5 294.5,-1533.5 247.5,-1533.5"/>
<text text-anchor="start" x="257.12" y="-1541" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="294.5,-1533.5 294.5,-1555.5 350.5,-1555.5 350.5,-1533.5 294.5,-1533.5"/>
<text text-anchor="start" x="299.25" y="-1541" font-family="Linux libertine" font-size="10.00">(64, 784) </text>
<polygon fill="none" stroke="black" points="247.5,-1511.5 247.5,-1533.5 294.5,-1533.5 294.5,-1511.5 247.5,-1511.5"/>
<text text-anchor="start" x="252.25" y="-1519" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="294.5,-1511.5 294.5,-1533.5 350.5,-1533.5 350.5,-1511.5 294.5,-1511.5"/>
<text text-anchor="start" x="299.25" y="-1519" font-family="Linux libertine" font-size="10.00">(64, 128) </text>
</g>
<!-- 1&#45;&gt;2 -->
<g id="edge2" class="edge">
<title>1&#45;&gt;2</title>
<path fill="none" stroke="black" d="M276,-1591.6C276,-1583.99 276,-1575.2 276,-1566.84"/>
<polygon fill="black" stroke="black" points="279.5,-1566.97 276,-1556.97 272.5,-1566.97 279.5,-1566.97"/>
</g>
<!-- 3 -->
<g id="node4" class="node">
<title>3</title>
<polygon fill="#c1ffc1" stroke="none" points="350.5,-1475.5 201.5,-1475.5 201.5,-1431.5 350.5,-1431.5 350.5,-1475.5"/>
<polygon fill="none" stroke="black" points="201.5,-1431.5 201.5,-1475.5 247.5,-1475.5 247.5,-1431.5 201.5,-1431.5"/>
<text text-anchor="start" x="211.75" y="-1456.75" font-family="Linux libertine" font-size="10.00">ReLU</text>
<text text-anchor="start" x="206.12" y="-1444" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="247.5,-1453.5 247.5,-1475.5 294.5,-1475.5 294.5,-1453.5 247.5,-1453.5"/>
<text text-anchor="start" x="257.12" y="-1461" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="294.5,-1453.5 294.5,-1475.5 350.5,-1475.5 350.5,-1453.5 294.5,-1453.5"/>
<text text-anchor="start" x="299.25" y="-1461" font-family="Linux libertine" font-size="10.00">(64, 128) </text>
<polygon fill="none" stroke="black" points="247.5,-1431.5 247.5,-1453.5 294.5,-1453.5 294.5,-1431.5 247.5,-1431.5"/>
<text text-anchor="start" x="252.25" y="-1439" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="294.5,-1431.5 294.5,-1453.5 350.5,-1453.5 350.5,-1431.5 294.5,-1431.5"/>
<text text-anchor="start" x="299.25" y="-1439" font-family="Linux libertine" font-size="10.00">(64, 128) </text>
</g>
<!-- 2&#45;&gt;3 -->
<g id="edge3" class="edge">
<title>2&#45;&gt;3</title>
<path fill="none" stroke="black" d="M276,-1511.6C276,-1503.99 276,-1495.2 276,-1486.84"/>
<polygon fill="black" stroke="black" points="279.5,-1486.97 276,-1476.97 272.5,-1486.97 279.5,-1486.97"/>
</g>
<!-- 4 -->
<g id="node5" class="node">
<title>4</title>
<polygon fill="aliceblue" stroke="none" points="364.5,-1395.5 187.5,-1395.5 187.5,-1351.5 364.5,-1351.5 364.5,-1395.5"/>
<polygon fill="none" stroke="black" points="187.5,-1351.5 187.5,-1395.5 249.5,-1395.5 249.5,-1351.5 187.5,-1351.5"/>
<text text-anchor="start" x="192.25" y="-1376.75" font-family="Linux libertine" font-size="10.00">unsqueeze</text>
<text text-anchor="start" x="200.12" y="-1364" font-family="Linux libertine" font-size="10.00">depth:1</text>
<polygon fill="none" stroke="black" points="249.5,-1373.5 249.5,-1395.5 296.5,-1395.5 296.5,-1373.5 249.5,-1373.5"/>
<text text-anchor="start" x="259.12" y="-1381" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="296.5,-1373.5 296.5,-1395.5 364.5,-1395.5 364.5,-1373.5 296.5,-1373.5"/>
<text text-anchor="start" x="307.25" y="-1381" font-family="Linux libertine" font-size="10.00">(64, 128) </text>
<polygon fill="none" stroke="black" points="249.5,-1351.5 249.5,-1373.5 296.5,-1373.5 296.5,-1351.5 249.5,-1351.5"/>
<text text-anchor="start" x="254.25" y="-1359" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="296.5,-1351.5 296.5,-1373.5 364.5,-1373.5 364.5,-1351.5 296.5,-1351.5"/>
<text text-anchor="start" x="301.25" y="-1359" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
</g>
<!-- 3&#45;&gt;4 -->
<g id="edge4" class="edge">
<title>3&#45;&gt;4</title>
<path fill="none" stroke="black" d="M276,-1431.6C276,-1423.99 276,-1415.2 276,-1406.84"/>
<polygon fill="black" stroke="black" points="279.5,-1406.97 276,-1396.97 272.5,-1406.97 279.5,-1406.97"/>
</g>
<!-- 5 -->
<g id="node6" class="node">
<title>5</title>
<polygon fill="#c1ffc1" stroke="none" points="356.5,-1315.5 195.5,-1315.5 195.5,-1271.5 356.5,-1271.5 356.5,-1315.5"/>
<polygon fill="none" stroke="black" points="195.5,-1271.5 195.5,-1315.5 241.5,-1315.5 241.5,-1271.5 195.5,-1271.5"/>
<text text-anchor="start" x="203.5" y="-1296.75" font-family="Linux libertine" font-size="10.00">Linear</text>
<text text-anchor="start" x="200.12" y="-1284" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="241.5,-1293.5 241.5,-1315.5 288.5,-1315.5 288.5,-1293.5 241.5,-1293.5"/>
<text text-anchor="start" x="251.12" y="-1301" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="288.5,-1293.5 288.5,-1315.5 356.5,-1315.5 356.5,-1293.5 288.5,-1293.5"/>
<text text-anchor="start" x="293.25" y="-1301" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
<polygon fill="none" stroke="black" points="241.5,-1271.5 241.5,-1293.5 288.5,-1293.5 288.5,-1271.5 241.5,-1271.5"/>
<text text-anchor="start" x="246.25" y="-1279" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="288.5,-1271.5 288.5,-1293.5 356.5,-1293.5 356.5,-1271.5 288.5,-1271.5"/>
<text text-anchor="start" x="293.25" y="-1279" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
</g>
<!-- 4&#45;&gt;5 -->
<g id="edge5" class="edge">
<title>4&#45;&gt;5</title>
<path fill="none" stroke="black" d="M276,-1351.6C276,-1343.99 276,-1335.2 276,-1326.84"/>
<polygon fill="black" stroke="black" points="279.5,-1326.97 276,-1316.97 272.5,-1326.97 279.5,-1326.97"/>
</g>
<!-- 9 -->
<g id="node10" class="node">
<title>9</title>
<polygon fill="#c1ffc1" stroke="none" points="539.5,-1315.5 378.5,-1315.5 378.5,-1271.5 539.5,-1271.5 539.5,-1315.5"/>
<polygon fill="none" stroke="black" points="378.5,-1271.5 378.5,-1315.5 424.5,-1315.5 424.5,-1271.5 378.5,-1271.5"/>
<text text-anchor="start" x="386.5" y="-1296.75" font-family="Linux libertine" font-size="10.00">Linear</text>
<text text-anchor="start" x="383.12" y="-1284" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="424.5,-1293.5 424.5,-1315.5 471.5,-1315.5 471.5,-1293.5 424.5,-1293.5"/>
<text text-anchor="start" x="434.12" y="-1301" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="471.5,-1293.5 471.5,-1315.5 539.5,-1315.5 539.5,-1293.5 471.5,-1293.5"/>
<text text-anchor="start" x="476.25" y="-1301" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
<polygon fill="none" stroke="black" points="424.5,-1271.5 424.5,-1293.5 471.5,-1293.5 471.5,-1271.5 424.5,-1271.5"/>
<text text-anchor="start" x="429.25" y="-1279" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="471.5,-1271.5 471.5,-1293.5 539.5,-1293.5 539.5,-1271.5 471.5,-1271.5"/>
<text text-anchor="start" x="476.25" y="-1279" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
</g>
<!-- 4&#45;&gt;9 -->
<g id="edge6" class="edge">
<title>4&#45;&gt;9</title>
<path fill="none" stroke="black" d="M325.04,-1351.6C347.91,-1341.85 375.33,-1330.16 399.39,-1319.91"/>
<polygon fill="black" stroke="black" points="400.6,-1323.19 408.43,-1316.05 397.86,-1316.76 400.6,-1323.19"/>
</g>
<!-- 13 -->
<g id="node14" class="node">
<title>13</title>
<polygon fill="#c1ffc1" stroke="none" points="173.5,-1315.5 12.5,-1315.5 12.5,-1271.5 173.5,-1271.5 173.5,-1315.5"/>
<polygon fill="none" stroke="black" points="12.5,-1271.5 12.5,-1315.5 58.5,-1315.5 58.5,-1271.5 12.5,-1271.5"/>
<text text-anchor="start" x="20.5" y="-1296.75" font-family="Linux libertine" font-size="10.00">Linear</text>
<text text-anchor="start" x="17.12" y="-1284" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="58.5,-1293.5 58.5,-1315.5 105.5,-1315.5 105.5,-1293.5 58.5,-1293.5"/>
<text text-anchor="start" x="68.12" y="-1301" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="105.5,-1293.5 105.5,-1315.5 173.5,-1315.5 173.5,-1293.5 105.5,-1293.5"/>
<text text-anchor="start" x="110.25" y="-1301" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
<polygon fill="none" stroke="black" points="58.5,-1271.5 58.5,-1293.5 105.5,-1293.5 105.5,-1271.5 58.5,-1271.5"/>
<text text-anchor="start" x="63.25" y="-1279" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="105.5,-1271.5 105.5,-1293.5 173.5,-1293.5 173.5,-1271.5 105.5,-1271.5"/>
<text text-anchor="start" x="110.25" y="-1279" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
</g>
<!-- 4&#45;&gt;13 -->
<g id="edge7" class="edge">
<title>4&#45;&gt;13</title>
<path fill="none" stroke="black" d="M226.96,-1351.6C204.09,-1341.85 176.67,-1330.16 152.61,-1319.91"/>
<polygon fill="black" stroke="black" points="154.14,-1316.76 143.57,-1316.05 151.4,-1323.19 154.14,-1316.76"/>
</g>
<!-- 6 -->
<g id="node7" class="node">
<title>6</title>
<polygon fill="aliceblue" stroke="none" points="361,-1235.5 191,-1235.5 191,-1191.5 361,-1191.5 361,-1235.5"/>
<polygon fill="none" stroke="black" points="191,-1191.5 191,-1235.5 240,-1235.5 240,-1191.5 191,-1191.5"/>
<text text-anchor="start" x="196" y="-1216.75" font-family="Linux libertine" font-size="10.00">reshape</text>
<text text-anchor="start" x="197.12" y="-1204" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="240,-1213.5 240,-1235.5 287,-1235.5 287,-1213.5 240,-1213.5"/>
<text text-anchor="start" x="249.62" y="-1221" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="287,-1213.5 287,-1235.5 361,-1235.5 361,-1213.5 287,-1213.5"/>
<text text-anchor="start" x="294.75" y="-1221" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
<polygon fill="none" stroke="black" points="240,-1191.5 240,-1213.5 287,-1213.5 287,-1191.5 240,-1191.5"/>
<text text-anchor="start" x="244.75" y="-1199" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="287,-1191.5 287,-1213.5 361,-1213.5 361,-1191.5 287,-1191.5"/>
<text text-anchor="start" x="291.75" y="-1199" font-family="Linux libertine" font-size="10.00">(64, 1, 2, 64) </text>
</g>
<!-- 5&#45;&gt;6 -->
<g id="edge8" class="edge">
<title>5&#45;&gt;6</title>
<path fill="none" stroke="black" d="M276,-1271.6C276,-1263.99 276,-1255.2 276,-1246.84"/>
<polygon fill="black" stroke="black" points="279.5,-1246.97 276,-1236.97 272.5,-1246.97 279.5,-1246.97"/>
</g>
<!-- 7 -->
<g id="node8" class="node">
<title>7</title>
<polygon fill="aliceblue" stroke="none" points="362,-1155.5 190,-1155.5 190,-1111.5 362,-1111.5 362,-1155.5"/>
<polygon fill="none" stroke="black" points="190,-1111.5 190,-1155.5 241,-1155.5 241,-1111.5 190,-1111.5"/>
<text text-anchor="start" x="194.88" y="-1136.75" font-family="Linux libertine" font-size="10.00">permute</text>
<text text-anchor="start" x="197.12" y="-1124" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="241,-1133.5 241,-1155.5 288,-1155.5 288,-1133.5 241,-1133.5"/>
<text text-anchor="start" x="250.62" y="-1141" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="288,-1133.5 288,-1155.5 362,-1155.5 362,-1133.5 288,-1133.5"/>
<text text-anchor="start" x="292.75" y="-1141" font-family="Linux libertine" font-size="10.00">(64, 1, 2, 64) </text>
<polygon fill="none" stroke="black" points="241,-1111.5 241,-1133.5 288,-1133.5 288,-1111.5 241,-1111.5"/>
<text text-anchor="start" x="245.75" y="-1119" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="288,-1111.5 288,-1133.5 362,-1133.5 362,-1111.5 288,-1111.5"/>
<text text-anchor="start" x="292.75" y="-1119" font-family="Linux libertine" font-size="10.00">(64, 2, 1, 64) </text>
</g>
<!-- 6&#45;&gt;7 -->
<g id="edge9" class="edge">
<title>6&#45;&gt;7</title>
<path fill="none" stroke="black" d="M276,-1191.6C276,-1183.99 276,-1175.2 276,-1166.84"/>
<polygon fill="black" stroke="black" points="279.5,-1166.97 276,-1156.97 272.5,-1166.97 279.5,-1166.97"/>
</g>
<!-- 8 -->
<g id="node9" class="node">
<title>8</title>
<polygon fill="aliceblue" stroke="none" points="361,-995.5 191,-995.5 191,-951.5 361,-951.5 361,-995.5"/>
<polygon fill="none" stroke="black" points="191,-951.5 191,-995.5 240,-995.5 240,-951.5 191,-951.5"/>
<text text-anchor="start" x="196" y="-976.75" font-family="Linux libertine" font-size="10.00">reshape</text>
<text text-anchor="start" x="197.12" y="-964" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="240,-973.5 240,-995.5 287,-995.5 287,-973.5 240,-973.5"/>
<text text-anchor="start" x="249.62" y="-981" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="287,-973.5 287,-995.5 361,-995.5 361,-973.5 287,-973.5"/>
<text text-anchor="start" x="291.75" y="-981" font-family="Linux libertine" font-size="10.00">(64, 2, 1, 64) </text>
<polygon fill="none" stroke="black" points="240,-951.5 240,-973.5 287,-973.5 287,-951.5 240,-951.5"/>
<text text-anchor="start" x="244.75" y="-959" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="287,-951.5 287,-973.5 361,-973.5 361,-951.5 287,-951.5"/>
<text text-anchor="start" x="294.75" y="-959" font-family="Linux libertine" font-size="10.00">(128, 1, 64) </text>
</g>
<!-- 7&#45;&gt;8 -->
<g id="edge10" class="edge">
<title>7&#45;&gt;8</title>
<path fill="none" stroke="black" d="M276,-1111.52C276,-1084.57 276,-1037.56 276,-1006.23"/>
<polygon fill="black" stroke="black" points="279.5,-1006.58 276,-996.58 272.5,-1006.58 279.5,-1006.58"/>
</g>
<!-- 18 -->
<g id="node19" class="node">
<title>18</title>
<polygon fill="aliceblue" stroke="none" points="412.5,-915.5 189.5,-915.5 189.5,-871.5 412.5,-871.5 412.5,-915.5"/>
<polygon fill="none" stroke="black" points="189.5,-871.5 189.5,-915.5 235.5,-915.5 235.5,-871.5 189.5,-871.5"/>
<text text-anchor="start" x="199.75" y="-896.75" font-family="Linux libertine" font-size="10.00">bmm</text>
<text text-anchor="start" x="194.12" y="-884" font-family="Linux libertine" font-size="10.00">depth:3</text>
<polygon fill="none" stroke="black" points="235.5,-893.5 235.5,-915.5 282.5,-915.5 282.5,-893.5 235.5,-893.5"/>
<text text-anchor="start" x="245.12" y="-901" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="282.5,-893.5 282.5,-915.5 412.5,-915.5 412.5,-893.5 282.5,-893.5"/>
<text text-anchor="start" x="287.5" y="-901" font-family="Linux libertine" font-size="10.00">(128, 1, 64), (128, 64, 1) </text>
<polygon fill="none" stroke="black" points="235.5,-871.5 235.5,-893.5 282.5,-893.5 282.5,-871.5 235.5,-871.5"/>
<text text-anchor="start" x="240.25" y="-879" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="282.5,-871.5 282.5,-893.5 412.5,-893.5 412.5,-871.5 282.5,-871.5"/>
<text text-anchor="start" x="321.25" y="-879" font-family="Linux libertine" font-size="10.00">(128, 1, 1) </text>
</g>
<!-- 8&#45;&gt;18 -->
<g id="edge17" class="edge">
<title>8&#45;&gt;18</title>
<path fill="none" stroke="black" d="M282.7,-951.6C285.19,-943.82 288.08,-934.8 290.82,-926.26"/>
<polygon fill="black" stroke="black" points="294.1,-927.49 293.82,-916.9 287.43,-925.36 294.1,-927.49"/>
</g>
<!-- 10 -->
<g id="node11" class="node">
<title>10</title>
<polygon fill="aliceblue" stroke="none" points="550,-1235.5 380,-1235.5 380,-1191.5 550,-1191.5 550,-1235.5"/>
<polygon fill="none" stroke="black" points="380,-1191.5 380,-1235.5 429,-1235.5 429,-1191.5 380,-1191.5"/>
<text text-anchor="start" x="385" y="-1216.75" font-family="Linux libertine" font-size="10.00">reshape</text>
<text text-anchor="start" x="386.12" y="-1204" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="429,-1213.5 429,-1235.5 476,-1235.5 476,-1213.5 429,-1213.5"/>
<text text-anchor="start" x="438.62" y="-1221" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="476,-1213.5 476,-1235.5 550,-1235.5 550,-1213.5 476,-1213.5"/>
<text text-anchor="start" x="483.75" y="-1221" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
<polygon fill="none" stroke="black" points="429,-1191.5 429,-1213.5 476,-1213.5 476,-1191.5 429,-1191.5"/>
<text text-anchor="start" x="433.75" y="-1199" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="476,-1191.5 476,-1213.5 550,-1213.5 550,-1191.5 476,-1191.5"/>
<text text-anchor="start" x="480.75" y="-1199" font-family="Linux libertine" font-size="10.00">(64, 1, 2, 64) </text>
</g>
<!-- 9&#45;&gt;10 -->
<g id="edge11" class="edge">
<title>9&#45;&gt;10</title>
<path fill="none" stroke="black" d="M460.61,-1271.6C461.19,-1263.99 461.87,-1255.2 462.51,-1246.84"/>
<polygon fill="black" stroke="black" points="465.99,-1247.21 463.27,-1236.97 459.01,-1246.67 465.99,-1247.21"/>
</g>
<!-- 11 -->
<g id="node12" class="node">
<title>11</title>
<polygon fill="aliceblue" stroke="none" points="552,-1155.5 380,-1155.5 380,-1111.5 552,-1111.5 552,-1155.5"/>
<polygon fill="none" stroke="black" points="380,-1111.5 380,-1155.5 431,-1155.5 431,-1111.5 380,-1111.5"/>
<text text-anchor="start" x="384.88" y="-1136.75" font-family="Linux libertine" font-size="10.00">permute</text>
<text text-anchor="start" x="387.12" y="-1124" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="431,-1133.5 431,-1155.5 478,-1155.5 478,-1133.5 431,-1133.5"/>
<text text-anchor="start" x="440.62" y="-1141" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="478,-1133.5 478,-1155.5 552,-1155.5 552,-1133.5 478,-1133.5"/>
<text text-anchor="start" x="482.75" y="-1141" font-family="Linux libertine" font-size="10.00">(64, 1, 2, 64) </text>
<polygon fill="none" stroke="black" points="431,-1111.5 431,-1133.5 478,-1133.5 478,-1111.5 431,-1111.5"/>
<text text-anchor="start" x="435.75" y="-1119" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="478,-1111.5 478,-1133.5 552,-1133.5 552,-1111.5 478,-1111.5"/>
<text text-anchor="start" x="482.75" y="-1119" font-family="Linux libertine" font-size="10.00">(64, 2, 1, 64) </text>
</g>
<!-- 10&#45;&gt;11 -->
<g id="edge12" class="edge">
<title>10&#45;&gt;11</title>
<path fill="none" stroke="black" d="M465.27,-1191.6C465.37,-1183.99 465.48,-1175.2 465.59,-1166.84"/>
<polygon fill="black" stroke="black" points="469.08,-1167.02 465.71,-1156.97 462.08,-1166.93 469.08,-1167.02"/>
</g>
<!-- 12 -->
<g id="node13" class="node">
<title>12</title>
<polygon fill="aliceblue" stroke="none" points="551,-1075.5 381,-1075.5 381,-1031.5 551,-1031.5 551,-1075.5"/>
<polygon fill="none" stroke="black" points="381,-1031.5 381,-1075.5 430,-1075.5 430,-1031.5 381,-1031.5"/>
<text text-anchor="start" x="386" y="-1056.75" font-family="Linux libertine" font-size="10.00">reshape</text>
<text text-anchor="start" x="387.12" y="-1044" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="430,-1053.5 430,-1075.5 477,-1075.5 477,-1053.5 430,-1053.5"/>
<text text-anchor="start" x="439.62" y="-1061" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="477,-1053.5 477,-1075.5 551,-1075.5 551,-1053.5 477,-1053.5"/>
<text text-anchor="start" x="481.75" y="-1061" font-family="Linux libertine" font-size="10.00">(64, 2, 1, 64) </text>
<polygon fill="none" stroke="black" points="430,-1031.5 430,-1053.5 477,-1053.5 477,-1031.5 430,-1031.5"/>
<text text-anchor="start" x="434.75" y="-1039" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="477,-1031.5 477,-1053.5 551,-1053.5 551,-1031.5 477,-1031.5"/>
<text text-anchor="start" x="484.75" y="-1039" font-family="Linux libertine" font-size="10.00">(128, 1, 64) </text>
</g>
<!-- 11&#45;&gt;12 -->
<g id="edge13" class="edge">
<title>11&#45;&gt;12</title>
<path fill="none" stroke="black" d="M466,-1111.6C466,-1103.99 466,-1095.2 466,-1086.84"/>
<polygon fill="black" stroke="black" points="469.5,-1086.97 466,-1076.97 462.5,-1086.97 469.5,-1086.97"/>
</g>
<!-- 17 -->
<g id="node18" class="node">
<title>17</title>
<polygon fill="aliceblue" stroke="none" points="552.5,-995.5 379.5,-995.5 379.5,-951.5 552.5,-951.5 552.5,-995.5"/>
<polygon fill="none" stroke="black" points="379.5,-951.5 379.5,-995.5 437.5,-995.5 437.5,-951.5 379.5,-951.5"/>
<text text-anchor="start" x="384.5" y="-976.75" font-family="Linux libertine" font-size="10.00">transpose</text>
<text text-anchor="start" x="390.12" y="-964" font-family="Linux libertine" font-size="10.00">depth:3</text>
<polygon fill="none" stroke="black" points="437.5,-973.5 437.5,-995.5 484.5,-995.5 484.5,-973.5 437.5,-973.5"/>
<text text-anchor="start" x="447.12" y="-981" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="484.5,-973.5 484.5,-995.5 552.5,-995.5 552.5,-973.5 484.5,-973.5"/>
<text text-anchor="start" x="489.25" y="-981" font-family="Linux libertine" font-size="10.00">(128, 1, 64) </text>
<polygon fill="none" stroke="black" points="437.5,-951.5 437.5,-973.5 484.5,-973.5 484.5,-951.5 437.5,-951.5"/>
<text text-anchor="start" x="442.25" y="-959" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="484.5,-951.5 484.5,-973.5 552.5,-973.5 552.5,-951.5 484.5,-951.5"/>
<text text-anchor="start" x="489.25" y="-959" font-family="Linux libertine" font-size="10.00">(128, 64, 1) </text>
</g>
<!-- 12&#45;&gt;17 -->
<g id="edge18" class="edge">
<title>12&#45;&gt;17</title>
<path fill="none" stroke="black" d="M466,-1031.6C466,-1023.99 466,-1015.2 466,-1006.84"/>
<polygon fill="black" stroke="black" points="469.5,-1006.97 466,-996.97 462.5,-1006.97 469.5,-1006.97"/>
</g>
<!-- 14 -->
<g id="node15" class="node">
<title>14</title>
<polygon fill="aliceblue" stroke="none" points="172,-1235.5 2,-1235.5 2,-1191.5 172,-1191.5 172,-1235.5"/>
<polygon fill="none" stroke="black" points="2,-1191.5 2,-1235.5 51,-1235.5 51,-1191.5 2,-1191.5"/>
<text text-anchor="start" x="7" y="-1216.75" font-family="Linux libertine" font-size="10.00">reshape</text>
<text text-anchor="start" x="8.12" y="-1204" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="51,-1213.5 51,-1235.5 98,-1235.5 98,-1213.5 51,-1213.5"/>
<text text-anchor="start" x="60.62" y="-1221" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="98,-1213.5 98,-1235.5 172,-1235.5 172,-1213.5 98,-1213.5"/>
<text text-anchor="start" x="105.75" y="-1221" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
<polygon fill="none" stroke="black" points="51,-1191.5 51,-1213.5 98,-1213.5 98,-1191.5 51,-1191.5"/>
<text text-anchor="start" x="55.75" y="-1199" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="98,-1191.5 98,-1213.5 172,-1213.5 172,-1191.5 98,-1191.5"/>
<text text-anchor="start" x="102.75" y="-1199" font-family="Linux libertine" font-size="10.00">(64, 1, 2, 64) </text>
</g>
<!-- 13&#45;&gt;14 -->
<g id="edge14" class="edge">
<title>13&#45;&gt;14</title>
<path fill="none" stroke="black" d="M91.39,-1271.6C90.81,-1263.99 90.13,-1255.2 89.49,-1246.84"/>
<polygon fill="black" stroke="black" points="92.99,-1246.67 88.73,-1236.97 86.01,-1247.21 92.99,-1246.67"/>
</g>
<!-- 15 -->
<g id="node16" class="node">
<title>15</title>
<polygon fill="aliceblue" stroke="none" points="172,-1155.5 0,-1155.5 0,-1111.5 172,-1111.5 172,-1155.5"/>
<polygon fill="none" stroke="black" points="0,-1111.5 0,-1155.5 51,-1155.5 51,-1111.5 0,-1111.5"/>
<text text-anchor="start" x="4.88" y="-1136.75" font-family="Linux libertine" font-size="10.00">permute</text>
<text text-anchor="start" x="7.12" y="-1124" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="51,-1133.5 51,-1155.5 98,-1155.5 98,-1133.5 51,-1133.5"/>
<text text-anchor="start" x="60.62" y="-1141" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="98,-1133.5 98,-1155.5 172,-1155.5 172,-1133.5 98,-1133.5"/>
<text text-anchor="start" x="102.75" y="-1141" font-family="Linux libertine" font-size="10.00">(64, 1, 2, 64) </text>
<polygon fill="none" stroke="black" points="51,-1111.5 51,-1133.5 98,-1133.5 98,-1111.5 51,-1111.5"/>
<text text-anchor="start" x="55.75" y="-1119" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="98,-1111.5 98,-1133.5 172,-1133.5 172,-1111.5 98,-1111.5"/>
<text text-anchor="start" x="102.75" y="-1119" font-family="Linux libertine" font-size="10.00">(64, 2, 1, 64) </text>
</g>
<!-- 14&#45;&gt;15 -->
<g id="edge15" class="edge">
<title>14&#45;&gt;15</title>
<path fill="none" stroke="black" d="M86.73,-1191.6C86.63,-1183.99 86.52,-1175.2 86.41,-1166.84"/>
<polygon fill="black" stroke="black" points="89.92,-1166.93 86.29,-1156.97 82.92,-1167.02 89.92,-1166.93"/>
</g>
<!-- 16 -->
<g id="node17" class="node">
<title>16</title>
<polygon fill="aliceblue" stroke="none" points="171,-915.5 1,-915.5 1,-871.5 171,-871.5 171,-915.5"/>
<polygon fill="none" stroke="black" points="1,-871.5 1,-915.5 50,-915.5 50,-871.5 1,-871.5"/>
<text text-anchor="start" x="6" y="-896.75" font-family="Linux libertine" font-size="10.00">reshape</text>
<text text-anchor="start" x="7.12" y="-884" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="50,-893.5 50,-915.5 97,-915.5 97,-893.5 50,-893.5"/>
<text text-anchor="start" x="59.62" y="-901" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="97,-893.5 97,-915.5 171,-915.5 171,-893.5 97,-893.5"/>
<text text-anchor="start" x="101.75" y="-901" font-family="Linux libertine" font-size="10.00">(64, 2, 1, 64) </text>
<polygon fill="none" stroke="black" points="50,-871.5 50,-893.5 97,-893.5 97,-871.5 50,-871.5"/>
<text text-anchor="start" x="54.75" y="-879" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="97,-871.5 97,-893.5 171,-893.5 171,-871.5 97,-871.5"/>
<text text-anchor="start" x="104.75" y="-879" font-family="Linux libertine" font-size="10.00">(128, 1, 64) </text>
</g>
<!-- 15&#45;&gt;16 -->
<g id="edge16" class="edge">
<title>15&#45;&gt;16</title>
<path fill="none" stroke="black" d="M86,-1111.8C86,-1070.21 86,-976.29 86,-926.65"/>
<polygon fill="black" stroke="black" points="89.5,-926.84 86,-916.84 82.5,-926.84 89.5,-926.84"/>
</g>
<!-- 22 -->
<g id="node23" class="node">
<title>22</title>
<polygon fill="aliceblue" stroke="none" points="301.5,-595.5 84.5,-595.5 84.5,-551.5 301.5,-551.5 301.5,-595.5"/>
<polygon fill="none" stroke="black" points="84.5,-551.5 84.5,-595.5 130.5,-595.5 130.5,-551.5 84.5,-551.5"/>
<text text-anchor="start" x="94.75" y="-576.75" font-family="Linux libertine" font-size="10.00">bmm</text>
<text text-anchor="start" x="89.12" y="-564" font-family="Linux libertine" font-size="10.00">depth:3</text>
<polygon fill="none" stroke="black" points="130.5,-573.5 130.5,-595.5 177.5,-595.5 177.5,-573.5 130.5,-573.5"/>
<text text-anchor="start" x="140.12" y="-581" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="177.5,-573.5 177.5,-595.5 301.5,-595.5 301.5,-573.5 177.5,-573.5"/>
<text text-anchor="start" x="182.5" y="-581" font-family="Linux libertine" font-size="10.00">(128, 1, 1), (128, 1, 64) </text>
<polygon fill="none" stroke="black" points="130.5,-551.5 130.5,-573.5 177.5,-573.5 177.5,-551.5 130.5,-551.5"/>
<text text-anchor="start" x="135.25" y="-559" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="177.5,-551.5 177.5,-573.5 301.5,-573.5 301.5,-551.5 177.5,-551.5"/>
<text text-anchor="start" x="210.25" y="-559" font-family="Linux libertine" font-size="10.00">(128, 1, 64) </text>
</g>
<!-- 16&#45;&gt;22 -->
<g id="edge19" class="edge">
<title>16&#45;&gt;22</title>
<path fill="none" stroke="black" d="M93.02,-871.64C111.31,-817.28 160.51,-671.04 182.33,-606.2"/>
<polygon fill="black" stroke="black" points="185.6,-607.47 185.47,-596.88 178.96,-605.24 185.6,-607.47"/>
</g>
<!-- 17&#45;&gt;18 -->
<g id="edge20" class="edge">
<title>17&#45;&gt;18</title>
<path fill="none" stroke="black" d="M421.78,-951.6C401.44,-941.98 377.1,-930.48 355.62,-920.32"/>
<polygon fill="black" stroke="black" points="357.24,-917.22 346.71,-916.11 354.25,-923.55 357.24,-917.22"/>
</g>
<!-- 19 -->
<g id="node20" class="node">
<title>19</title>
<polygon fill="aliceblue" stroke="none" points="371.5,-835.5 216.5,-835.5 216.5,-791.5 371.5,-791.5 371.5,-835.5"/>
<polygon fill="none" stroke="black" points="216.5,-791.5 216.5,-835.5 262.5,-835.5 262.5,-791.5 216.5,-791.5"/>
<text text-anchor="start" x="232" y="-816.75" font-family="Linux libertine" font-size="10.00">div</text>
<text text-anchor="start" x="221.12" y="-804" font-family="Linux libertine" font-size="10.00">depth:3</text>
<polygon fill="none" stroke="black" points="262.5,-813.5 262.5,-835.5 309.5,-835.5 309.5,-813.5 262.5,-813.5"/>
<text text-anchor="start" x="272.12" y="-821" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="309.5,-813.5 309.5,-835.5 371.5,-835.5 371.5,-813.5 309.5,-813.5"/>
<text text-anchor="start" x="314.25" y="-821" font-family="Linux libertine" font-size="10.00">(128, 1, 1) </text>
<polygon fill="none" stroke="black" points="262.5,-791.5 262.5,-813.5 309.5,-813.5 309.5,-791.5 262.5,-791.5"/>
<text text-anchor="start" x="267.25" y="-799" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="309.5,-791.5 309.5,-813.5 371.5,-813.5 371.5,-791.5 309.5,-791.5"/>
<text text-anchor="start" x="314.25" y="-799" font-family="Linux libertine" font-size="10.00">(128, 1, 1) </text>
</g>
<!-- 18&#45;&gt;19 -->
<g id="edge21" class="edge">
<title>18&#45;&gt;19</title>
<path fill="none" stroke="black" d="M299.12,-871.6C298.44,-863.99 297.65,-855.2 296.9,-846.84"/>
<polygon fill="black" stroke="black" points="300.4,-846.61 296.02,-836.97 293.42,-847.24 300.4,-846.61"/>
</g>
<!-- 20 -->
<g id="node21" class="node">
<title>20</title>
<polygon fill="aliceblue" stroke="none" points="366,-755.5 208,-755.5 208,-711.5 366,-711.5 366,-755.5"/>
<polygon fill="none" stroke="black" points="208,-711.5 208,-755.5 257,-755.5 257,-711.5 208,-711.5"/>
<text text-anchor="start" x="212.62" y="-736.75" font-family="Linux libertine" font-size="10.00">softmax</text>
<text text-anchor="start" x="214.12" y="-724" font-family="Linux libertine" font-size="10.00">depth:3</text>
<polygon fill="none" stroke="black" points="257,-733.5 257,-755.5 304,-755.5 304,-733.5 257,-733.5"/>
<text text-anchor="start" x="266.62" y="-741" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="304,-733.5 304,-755.5 366,-755.5 366,-733.5 304,-733.5"/>
<text text-anchor="start" x="308.75" y="-741" font-family="Linux libertine" font-size="10.00">(128, 1, 1) </text>
<polygon fill="none" stroke="black" points="257,-711.5 257,-733.5 304,-733.5 304,-711.5 257,-711.5"/>
<text text-anchor="start" x="261.75" y="-719" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="304,-711.5 304,-733.5 366,-733.5 366,-711.5 304,-711.5"/>
<text text-anchor="start" x="308.75" y="-719" font-family="Linux libertine" font-size="10.00">(128, 1, 1) </text>
</g>
<!-- 19&#45;&gt;20 -->
<g id="edge22" class="edge">
<title>19&#45;&gt;20</title>
<path fill="none" stroke="black" d="M292.12,-791.6C291.44,-783.99 290.65,-775.2 289.9,-766.84"/>
<polygon fill="black" stroke="black" points="293.4,-766.61 289.02,-756.97 286.42,-767.24 293.4,-766.61"/>
</g>
<!-- 21 -->
<g id="node22" class="node">
<title>21</title>
<polygon fill="#c1ffc1" stroke="none" points="353,-675.5 195,-675.5 195,-631.5 353,-631.5 353,-675.5"/>
<polygon fill="none" stroke="black" points="195,-631.5 195,-675.5 244,-675.5 244,-631.5 195,-631.5"/>
<text text-anchor="start" x="200" y="-656.75" font-family="Linux libertine" font-size="10.00">Dropout</text>
<text text-anchor="start" x="201.12" y="-644" font-family="Linux libertine" font-size="10.00">depth:3</text>
<polygon fill="none" stroke="black" points="244,-653.5 244,-675.5 291,-675.5 291,-653.5 244,-653.5"/>
<text text-anchor="start" x="253.62" y="-661" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="291,-653.5 291,-675.5 353,-675.5 353,-653.5 291,-653.5"/>
<text text-anchor="start" x="295.75" y="-661" font-family="Linux libertine" font-size="10.00">(128, 1, 1) </text>
<polygon fill="none" stroke="black" points="244,-631.5 244,-653.5 291,-653.5 291,-631.5 244,-631.5"/>
<text text-anchor="start" x="248.75" y="-639" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="291,-631.5 291,-653.5 353,-653.5 353,-631.5 291,-631.5"/>
<text text-anchor="start" x="295.75" y="-639" font-family="Linux libertine" font-size="10.00">(128, 1, 1) </text>
</g>
<!-- 20&#45;&gt;21 -->
<g id="edge23" class="edge">
<title>20&#45;&gt;21</title>
<path fill="none" stroke="black" d="M283.52,-711.6C282.23,-703.9 280.75,-695 279.34,-686.55"/>
<polygon fill="black" stroke="black" points="282.84,-686.24 277.74,-676.95 275.93,-687.39 282.84,-686.24"/>
</g>
<!-- 21&#45;&gt;22 -->
<g id="edge24" class="edge">
<title>21&#45;&gt;22</title>
<path fill="none" stroke="black" d="M252.29,-631.6C243.3,-622.94 232.73,-612.76 223.02,-603.41"/>
<polygon fill="black" stroke="black" points="225.49,-600.93 215.86,-596.51 220.63,-605.97 225.49,-600.93"/>
</g>
<!-- 23 -->
<g id="node24" class="node">
<title>23</title>
<polygon fill="aliceblue" stroke="none" points="278,-515.5 108,-515.5 108,-471.5 278,-471.5 278,-515.5"/>
<polygon fill="none" stroke="black" points="108,-471.5 108,-515.5 157,-515.5 157,-471.5 108,-471.5"/>
<text text-anchor="start" x="113" y="-496.75" font-family="Linux libertine" font-size="10.00">reshape</text>
<text text-anchor="start" x="114.12" y="-484" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="157,-493.5 157,-515.5 204,-515.5 204,-493.5 157,-493.5"/>
<text text-anchor="start" x="166.62" y="-501" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="204,-493.5 204,-515.5 278,-515.5 278,-493.5 204,-493.5"/>
<text text-anchor="start" x="211.75" y="-501" font-family="Linux libertine" font-size="10.00">(128, 1, 64) </text>
<polygon fill="none" stroke="black" points="157,-471.5 157,-493.5 204,-493.5 204,-471.5 157,-471.5"/>
<text text-anchor="start" x="161.75" y="-479" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="204,-471.5 204,-493.5 278,-493.5 278,-471.5 204,-471.5"/>
<text text-anchor="start" x="208.75" y="-479" font-family="Linux libertine" font-size="10.00">(64, 2, 1, 64) </text>
</g>
<!-- 22&#45;&gt;23 -->
<g id="edge25" class="edge">
<title>22&#45;&gt;23</title>
<path fill="none" stroke="black" d="M193,-551.6C193,-543.99 193,-535.2 193,-526.84"/>
<polygon fill="black" stroke="black" points="196.5,-526.97 193,-516.97 189.5,-526.97 196.5,-526.97"/>
</g>
<!-- 24 -->
<g id="node25" class="node">
<title>24</title>
<polygon fill="aliceblue" stroke="none" points="279,-435.5 107,-435.5 107,-391.5 279,-391.5 279,-435.5"/>
<polygon fill="none" stroke="black" points="107,-391.5 107,-435.5 158,-435.5 158,-391.5 107,-391.5"/>
<text text-anchor="start" x="111.88" y="-416.75" font-family="Linux libertine" font-size="10.00">permute</text>
<text text-anchor="start" x="114.12" y="-404" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="158,-413.5 158,-435.5 205,-435.5 205,-413.5 158,-413.5"/>
<text text-anchor="start" x="167.62" y="-421" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="205,-413.5 205,-435.5 279,-435.5 279,-413.5 205,-413.5"/>
<text text-anchor="start" x="209.75" y="-421" font-family="Linux libertine" font-size="10.00">(64, 2, 1, 64) </text>
<polygon fill="none" stroke="black" points="158,-391.5 158,-413.5 205,-413.5 205,-391.5 158,-391.5"/>
<text text-anchor="start" x="162.75" y="-399" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="205,-391.5 205,-413.5 279,-413.5 279,-391.5 205,-391.5"/>
<text text-anchor="start" x="209.75" y="-399" font-family="Linux libertine" font-size="10.00">(64, 1, 2, 64) </text>
</g>
<!-- 23&#45;&gt;24 -->
<g id="edge26" class="edge">
<title>23&#45;&gt;24</title>
<path fill="none" stroke="black" d="M193,-471.6C193,-463.99 193,-455.2 193,-446.84"/>
<polygon fill="black" stroke="black" points="196.5,-446.97 193,-436.97 189.5,-446.97 196.5,-446.97"/>
</g>
<!-- 25 -->
<g id="node26" class="node">
<title>25</title>
<polygon fill="aliceblue" stroke="none" points="278,-355.5 108,-355.5 108,-311.5 278,-311.5 278,-355.5"/>
<polygon fill="none" stroke="black" points="108,-311.5 108,-355.5 157,-355.5 157,-311.5 108,-311.5"/>
<text text-anchor="start" x="113" y="-336.75" font-family="Linux libertine" font-size="10.00">reshape</text>
<text text-anchor="start" x="114.12" y="-324" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="157,-333.5 157,-355.5 204,-355.5 204,-333.5 157,-333.5"/>
<text text-anchor="start" x="166.62" y="-341" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="204,-333.5 204,-355.5 278,-355.5 278,-333.5 204,-333.5"/>
<text text-anchor="start" x="208.75" y="-341" font-family="Linux libertine" font-size="10.00">(64, 1, 2, 64) </text>
<polygon fill="none" stroke="black" points="157,-311.5 157,-333.5 204,-333.5 204,-311.5 157,-311.5"/>
<text text-anchor="start" x="161.75" y="-319" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="204,-311.5 204,-333.5 278,-333.5 278,-311.5 204,-311.5"/>
<text text-anchor="start" x="211.75" y="-319" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
</g>
<!-- 24&#45;&gt;25 -->
<g id="edge27" class="edge">
<title>24&#45;&gt;25</title>
<path fill="none" stroke="black" d="M193,-391.6C193,-383.99 193,-375.2 193,-366.84"/>
<polygon fill="black" stroke="black" points="196.5,-366.97 193,-356.97 189.5,-366.97 196.5,-366.97"/>
</g>
<!-- 26 -->
<g id="node27" class="node">
<title>26</title>
<polygon fill="#c1ffc1" stroke="none" points="273.5,-275.5 112.5,-275.5 112.5,-231.5 273.5,-231.5 273.5,-275.5"/>
<polygon fill="none" stroke="black" points="112.5,-231.5 112.5,-275.5 158.5,-275.5 158.5,-231.5 112.5,-231.5"/>
<text text-anchor="start" x="120.5" y="-256.75" font-family="Linux libertine" font-size="10.00">Linear</text>
<text text-anchor="start" x="117.12" y="-244" font-family="Linux libertine" font-size="10.00">depth:2</text>
<polygon fill="none" stroke="black" points="158.5,-253.5 158.5,-275.5 205.5,-275.5 205.5,-253.5 158.5,-253.5"/>
<text text-anchor="start" x="168.12" y="-261" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="205.5,-253.5 205.5,-275.5 273.5,-275.5 273.5,-253.5 205.5,-253.5"/>
<text text-anchor="start" x="210.25" y="-261" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
<polygon fill="none" stroke="black" points="158.5,-231.5 158.5,-253.5 205.5,-253.5 205.5,-231.5 158.5,-231.5"/>
<text text-anchor="start" x="163.25" y="-239" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="205.5,-231.5 205.5,-253.5 273.5,-253.5 273.5,-231.5 205.5,-231.5"/>
<text text-anchor="start" x="210.25" y="-239" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
</g>
<!-- 25&#45;&gt;26 -->
<g id="edge28" class="edge">
<title>25&#45;&gt;26</title>
<path fill="none" stroke="black" d="M193,-311.6C193,-303.99 193,-295.2 193,-286.84"/>
<polygon fill="black" stroke="black" points="196.5,-286.97 193,-276.97 189.5,-286.97 196.5,-286.97"/>
</g>
<!-- 27 -->
<g id="node28" class="node">
<title>27</title>
<polygon fill="aliceblue" stroke="none" points="275.5,-195.5 110.5,-195.5 110.5,-151.5 275.5,-151.5 275.5,-195.5"/>
<polygon fill="none" stroke="black" points="110.5,-151.5 110.5,-195.5 160.5,-195.5 160.5,-151.5 110.5,-151.5"/>
<text text-anchor="start" x="115.25" y="-176.75" font-family="Linux libertine" font-size="10.00">squeeze</text>
<text text-anchor="start" x="117.12" y="-164" font-family="Linux libertine" font-size="10.00">depth:1</text>
<polygon fill="none" stroke="black" points="160.5,-173.5 160.5,-195.5 207.5,-195.5 207.5,-173.5 160.5,-173.5"/>
<text text-anchor="start" x="170.12" y="-181" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="207.5,-173.5 207.5,-195.5 275.5,-195.5 275.5,-173.5 207.5,-173.5"/>
<text text-anchor="start" x="212.25" y="-181" font-family="Linux libertine" font-size="10.00">(64, 1, 128) </text>
<polygon fill="none" stroke="black" points="160.5,-151.5 160.5,-173.5 207.5,-173.5 207.5,-151.5 160.5,-151.5"/>
<text text-anchor="start" x="165.25" y="-159" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="207.5,-151.5 207.5,-173.5 275.5,-173.5 275.5,-151.5 207.5,-151.5"/>
<text text-anchor="start" x="218.25" y="-159" font-family="Linux libertine" font-size="10.00">(64, 128) </text>
</g>
<!-- 26&#45;&gt;27 -->
<g id="edge29" class="edge">
<title>26&#45;&gt;27</title>
<path fill="none" stroke="black" d="M193,-231.6C193,-223.99 193,-215.2 193,-206.84"/>
<polygon fill="black" stroke="black" points="196.5,-206.97 193,-196.97 189.5,-206.97 196.5,-206.97"/>
</g>
<!-- 28 -->
<g id="node29" class="node">
<title>28</title>
<polygon fill="#c1ffc1" stroke="none" points="267.5,-115.5 118.5,-115.5 118.5,-71.5 267.5,-71.5 267.5,-115.5"/>
<polygon fill="none" stroke="black" points="118.5,-71.5 118.5,-115.5 164.5,-115.5 164.5,-71.5 118.5,-71.5"/>
<text text-anchor="start" x="126.5" y="-96.75" font-family="Linux libertine" font-size="10.00">Linear</text>
<text text-anchor="start" x="123.12" y="-84" font-family="Linux libertine" font-size="10.00">depth:1</text>
<polygon fill="none" stroke="black" points="164.5,-93.5 164.5,-115.5 211.5,-115.5 211.5,-93.5 164.5,-93.5"/>
<text text-anchor="start" x="174.12" y="-101" font-family="Linux libertine" font-size="10.00">input:</text>
<polygon fill="none" stroke="black" points="211.5,-93.5 211.5,-115.5 267.5,-115.5 267.5,-93.5 211.5,-93.5"/>
<text text-anchor="start" x="216.25" y="-101" font-family="Linux libertine" font-size="10.00">(64, 128) </text>
<polygon fill="none" stroke="black" points="164.5,-71.5 164.5,-93.5 211.5,-93.5 211.5,-71.5 164.5,-71.5"/>
<text text-anchor="start" x="169.25" y="-79" font-family="Linux libertine" font-size="10.00">output: </text>
<polygon fill="none" stroke="black" points="211.5,-71.5 211.5,-93.5 267.5,-93.5 267.5,-71.5 211.5,-71.5"/>
<text text-anchor="start" x="219.25" y="-79" font-family="Linux libertine" font-size="10.00">(64, 10) </text>
</g>
<!-- 27&#45;&gt;28 -->
<g id="edge30" class="edge">
<title>27&#45;&gt;28</title>
<path fill="none" stroke="black" d="M193,-151.6C193,-143.99 193,-135.2 193,-126.84"/>
<polygon fill="black" stroke="black" points="196.5,-126.97 193,-116.97 189.5,-126.97 196.5,-126.97"/>
</g>
<!-- 29 -->
<g id="node30" class="node">
<title>29</title>
<polygon fill="lightyellow" stroke="none" points="254.75,-35.5 131.25,-35.5 131.25,0 254.75,0 254.75,-35.5"/>
<polygon fill="none" stroke="black" points="131.25,0 131.25,-35.5 207.25,-35.5 207.25,0 131.25,0"/>
<text text-anchor="start" x="136.25" y="-21" font-family="Linux libertine" font-size="10.00">output&#45;tensor</text>
<text text-anchor="start" x="150.88" y="-8.25" font-family="Linux libertine" font-size="10.00">depth:0</text>
<polygon fill="none" stroke="black" points="207.25,0 207.25,-35.5 254.75,-35.5 254.75,0 207.25,0"/>
<text text-anchor="start" x="212.25" y="-14.62" font-family="Linux libertine" font-size="10.00">(64, 10)</text>
</g>
<!-- 28&#45;&gt;29 -->
<g id="edge31" class="edge">
<title>28&#45;&gt;29</title>
<path fill="none" stroke="black" d="M193,-71.56C193,-63.78 193,-54.83 193,-46.53"/>
<polygon fill="black" stroke="black" points="196.5,-46.56 193,-36.56 189.5,-46.56 196.5,-46.56"/>
</g>
</g>
</svg>
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.5.6.-attention-seq2seq">11.5.6. <a id="toc11_5_6_"></a><a href="#toc0_">attention-seq2seq</a><a class="anchor-link" href="#11.5.6.-attention-seq2seq"></a></h3><ul>
<li><p>attentionSeq2Seq</p>
</li>
<li><p>AttentionSeq2Seq</p>
</li>
</ul>
<p><img alt="attention_seq2seq" src="./Pytorch_Pictures/Attention/seq2seq_attention.jpg"/></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[142]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">AttentionDecoder</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Decoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""The base attention-based decoder interface."""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AttentionDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">attention_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[150]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="k">class</span> <span class="nc">Seq2SeqAttentionDecoder</span><span class="p">(</span><span class="n">AttentionDecoder</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Seq2SeqAttentionDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">AdditiveAttention</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embed_size</span> <span class="o">+</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="c1"># Shape of `outputs`: (`num_steps`, `batch_size`, `num_hiddens`).</span>
        <span class="c1"># Shape of `hidden_state[0]`: (`num_layers`, `batch_size`,</span>
        <span class="c1"># `num_hiddens`)</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden_state</span> <span class="o">=</span> <span class="n">enc_outputs</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">hidden_state</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Shape of `enc_outputs`: (`batch_size`, `num_steps`, `num_hiddens`).</span>
        <span class="c1"># Shape of `hidden_state[0]`: (`num_layers`, `batch_size`,</span>
        <span class="c1"># `num_hiddens`)</span>
        <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">hidden_state</span><span class="p">,</span> <span class="n">enc_valid_lens</span> <span class="o">=</span> <span class="n">state</span>
        <span class="c1"># Shape of the output `X`: (`num_steps`, `batch_size`, `embed_size`)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
            <span class="c1"># querykeyvalue</span>
            <span class="c1"># Shape of `query`: (`batch_size`, 1, `num_hiddens`)</span>
            <span class="n">query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">hidden_state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Shape of `context`: (`batch_size`, 1, `num_hiddens`)</span>
            <span class="n">context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">)</span>

            <span class="c1"># Concatenate on the feature dimension</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">context</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Reshape `x` as (1, `batch_size`, `embed_size` + `num_hiddens`)</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">hidden_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">hidden_state</span><span class="p">)</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">)</span>
        <span class="c1"># After fully-connected layer transformation, shape of `outputs`:</span>
        <span class="c1"># (`num_steps`, `batch_size`, `vocab_size`)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">[</span><span class="n">enc_outputs</span><span class="p">,</span> <span class="n">hidden_state</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">]</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">attention_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span>
    

<span class="c1">#@tab pytorch</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                             <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqAttentionDecoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                                  <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>  <span class="c1"># (`batch_size`, `num_steps`)</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">),</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[150]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([4, 7, 10]), 3, torch.Size([4, 7, 16]), 2, torch.Size([4, 16]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[145]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>

<span class="n">train_iter</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_nmt</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqAttentionDecoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tgt_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">EncoderDecoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>loss 0.020, 4265.2 tokens/sec on cuda:0
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="262.1875pt" height="183.35625pt" viewBox="0 0 262.1875 183.35625" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-12-02T18:42:16.311496</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 183.35625 
L 262.1875 183.35625 
L 262.1875 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 50.14375 145.8 
L 245.44375 145.8 
L 245.44375 7.2 
L 50.14375 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 82.69375 145.8 
L 82.69375 7.2 
" clip-path="url(#pa6ca4ffa78)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_2">
      <defs>
       <path id="m5d0dda3006" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m5d0dda3006" x="82.69375" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- 50 -->
      <g transform="translate(76.33125 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-35"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_3">
      <path d="M 123.38125 145.8 
L 123.38125 7.2 
" clip-path="url(#pa6ca4ffa78)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_4">
      <g>
       <use xlink:href="#m5d0dda3006" x="123.38125" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 100 -->
      <g transform="translate(113.8375 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_5">
      <path d="M 164.06875 145.8 
L 164.06875 7.2 
" clip-path="url(#pa6ca4ffa78)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_6">
      <g>
       <use xlink:href="#m5d0dda3006" x="164.06875" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 150 -->
      <g transform="translate(154.525 160.398438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-35" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_7">
      <path d="M 204.75625 145.8 
L 204.75625 7.2 
" clip-path="url(#pa6ca4ffa78)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_8">
      <g>
       <use xlink:href="#m5d0dda3006" x="204.75625" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 200 -->
      <g transform="translate(195.2125 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-32"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_9">
      <path d="M 245.44375 145.8 
L 245.44375 7.2 
" clip-path="url(#pa6ca4ffa78)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_10">
      <g>
       <use xlink:href="#m5d0dda3006" x="245.44375" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- 250 -->
      <g transform="translate(235.9 160.398438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
       <use xlink:href="#DejaVuSans-35" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="text_6">
     <!-- epoch -->
     <g transform="translate(132.565625 174.076563) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-68" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 4863 
L 1159 4863 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-65"/>
      <use xlink:href="#DejaVuSans-70" x="61.523438"/>
      <use xlink:href="#DejaVuSans-6f" x="125"/>
      <use xlink:href="#DejaVuSans-63" x="186.181641"/>
      <use xlink:href="#DejaVuSans-68" x="241.162109"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_11">
      <path d="M 50.14375 119.493627 
L 245.44375 119.493627 
" clip-path="url(#pa6ca4ffa78)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_12">
      <defs>
       <path id="m449f6fe0b9" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m449f6fe0b9" x="50.14375" y="119.493627" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 0.05 -->
      <g transform="translate(20.878125 123.292845) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_13">
      <path d="M 50.14375 86.198172 
L 245.44375 86.198172 
" clip-path="url(#pa6ca4ffa78)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_14">
      <g>
       <use xlink:href="#m449f6fe0b9" x="50.14375" y="86.198172" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 0.10 -->
      <g transform="translate(20.878125 89.99739) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-31" x="95.410156"/>
       <use xlink:href="#DejaVuSans-30" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_15">
      <path d="M 50.14375 52.902717 
L 245.44375 52.902717 
" clip-path="url(#pa6ca4ffa78)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_16">
      <g>
       <use xlink:href="#m449f6fe0b9" x="50.14375" y="52.902717" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <!-- 0.15 -->
      <g transform="translate(20.878125 56.701936) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-31" x="95.410156"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_17">
      <path d="M 50.14375 19.607262 
L 245.44375 19.607262 
" clip-path="url(#pa6ca4ffa78)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_18">
      <g>
       <use xlink:href="#m449f6fe0b9" x="50.14375" y="19.607262" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_10">
      <!-- 0.20 -->
      <g transform="translate(20.878125 23.406481) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-32" x="95.410156"/>
       <use xlink:href="#DejaVuSans-30" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="text_11">
     <!-- loss -->
     <g transform="translate(14.798437 86.157813) rotate(-90) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-6c" d="M 603 4863 
L 1178 4863 
L 1178 0 
L 603 0 
L 603 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-6c"/>
      <use xlink:href="#DejaVuSans-6f" x="27.783203"/>
      <use xlink:href="#DejaVuSans-73" x="88.964844"/>
      <use xlink:href="#DejaVuSans-73" x="141.064453"/>
     </g>
    </g>
   </g>
   <g id="line2d_19">
    <path d="M 50.14375 13.5 
L 58.28125 57.493393 
L 66.41875 81.703355 
L 74.55625 97.599021 
L 82.69375 109.18852 
L 90.83125 116.745293 
L 98.96875 122.591125 
L 107.10625 126.080522 
L 115.24375 129.162657 
L 123.38125 130.373424 
L 131.51875 132.863883 
L 139.65625 134.596077 
L 147.79375 135.719012 
L 155.93125 136.05223 
L 164.06875 136.698517 
L 172.20625 137.220684 
L 180.34375 137.706105 
L 188.48125 138.343086 
L 196.61875 138.608395 
L 204.75625 138.328986 
L 212.89375 138.661723 
L 221.03125 139.11157 
L 229.16875 139.029937 
L 237.30625 139.067785 
L 245.44375 139.5 
" clip-path="url(#pa6ca4ffa78)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="patch_3">
    <path d="M 50.14375 145.8 
L 50.14375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 245.44375 145.8 
L 245.44375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 50.14375 145.8 
L 245.44375 145.8 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 50.14375 7.2 
L 245.44375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="pa6ca4ffa78">
   <rect x="50.14375" y="7.2" width="195.3" height="138.6"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[146]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="n">engs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'go .'</span><span class="p">,</span> <span class="s2">"i lost ."</span><span class="p">,</span> <span class="s1">'he</span><span class="se">\'</span><span class="s1">s calm .'</span><span class="p">,</span> <span class="s1">'i</span><span class="se">\'</span><span class="s1">m home .'</span><span class="p">]</span>
<span class="n">fras</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'va !'</span><span class="p">,</span> <span class="s1">'j</span><span class="se">\'</span><span class="s1">ai perdu .'</span><span class="p">,</span> <span class="s1">'il est calme .'</span><span class="p">,</span> <span class="s1">'je suis chez moi .'</span><span class="p">]</span>

<span class="k">for</span> <span class="n">eng</span><span class="p">,</span> <span class="n">fra</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">):</span>
    <span class="n">translation</span><span class="p">,</span> <span class="n">dec_attention_weight_seq</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">predict_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">eng</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">eng</span><span class="si">}</span><span class="s1"> =&gt; </span><span class="si">{</span><span class="n">translation</span><span class="si">}</span><span class="s1">, '</span><span class="p">,</span> <span class="sa">f</span><span class="s1">'bleu </span><span class="si">{</span><span class="n">d2l</span><span class="o">.</span><span class="n">bleu</span><span class="p">(</span><span class="n">translation</span><span class="p">,</span><span class="w"> </span><span class="n">fra</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>go . =&gt; va !,  bleu 1.000
i lost . =&gt; j'ai perdu .,  bleu 1.000
he's calm . =&gt; il est .,  bleu 0.603
i'm home . =&gt; je suis chez moi .,  bleu 1.000
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[147]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="n">attention_weights</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">step</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">dec_attention_weight_seq</span><span class="p">],</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[149]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="c1"># Plus one to include the end-of-sequence token</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">show_heatmaps</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">engs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">'Key posistions'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'Query posistions'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="174.23925pt" height="183.35625pt" viewBox="0 0 174.23925 183.35625" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-12-02T18:42:52.691201</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 183.35625 
L 174.23925 183.35625 
L 174.23925 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 34.240625 145.8 
L 126.640625 145.8 
L 126.640625 7.2 
L 34.240625 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g clip-path="url(#pd9fcc2b972)">
    <image xlink:href="data:image/png;base64,
iVBORw0KGgoAAAANSUhEUgAAAIEAAADBCAYAAADo+NM8AAACGElEQVR4nO3cMUpYURRF0f3FgAYRrJyCOBpn4ZDS2griHCwsIqRMiKTR2iKFQtDE/x3GTbHWBM4rNrd8y/XR8dagsx+3k/O1rrP7Vev76PzO6Dr/BREgAkRAIiARkAhIBCQCEgGJgERAIiARkAhIBCQCEgGJgERAIiARkAhIBCQCEgGJgERAIiARkAioln83l6P/E4x7/DX9gvr7NjrvEiACREAiIBGQCEgEJAISAYmAREAiIBGQCEgEJAISAYmAREAiIBGQCEgEJAISAYmAREAiIBGQCEgEVMt5B6P/E3x5+j45X5/2ZverttkvIlwCRIAISAQkAhIBiYBEQCIgEZAISAQkAhIBiYBEQCIgEZAISAQkAhIBiYBEQCIgEZAISAQkAhIBiYBEQLWsL79Hf0hY7+8m59uuLkb3q3p9HZ13CRABIiARkAhIBCQCEgGJgERAIiARkAhIBCQCEgGJgERAIiARkAhIBCQCEgGJgERAIiARkAhIBCQCqt1lWWZf8PBzdn9/f3a/6vBwdN4lQASIgERAIiARkAhIBCQCEgGJgERAIiARkAhIBCQCEgGJgERAIiARkAhIBCQCEgGJgERAIiARkAiodrc/z6MP2L59Hd1fTk5H96v6fDA67xIgAkRAIiARkAhIBCQCEgGJgERAIiARkAhIBCQCEgGJgERAIiARkAhIBCQCEgGJgERAIiARkAhIBFQfuEYospAHpKAAAAAASUVORK5CYII=" id="imagea8b49d973f" transform="scale(1 -1) translate(0 -138.96)" x="34.240625" y="-6.84" width="92.88" height="138.96"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <defs>
       <path id="m37293d4268" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m37293d4268" x="45.790625" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- 0 -->
      <g transform="translate(42.609375 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <g>
       <use xlink:href="#m37293d4268" x="91.990625" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 2 -->
      <g transform="translate(88.809375 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="text_3">
     <!-- Key posistions -->
     <g transform="translate(44.772656 174.076563) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-4b" d="M 628 4666 
L 1259 4666 
L 1259 2694 
L 3353 4666 
L 4166 4666 
L 1850 2491 
L 4331 0 
L 3500 0 
L 1259 2247 
L 1259 0 
L 628 0 
L 628 4666 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-79" d="M 2059 -325 
Q 1816 -950 1584 -1140 
Q 1353 -1331 966 -1331 
L 506 -1331 
L 506 -850 
L 844 -850 
Q 1081 -850 1212 -737 
Q 1344 -625 1503 -206 
L 1606 56 
L 191 3500 
L 800 3500 
L 1894 763 
L 2988 3500 
L 3597 3500 
L 2059 -325 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-20" transform="scale(0.015625)"/>
       <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-69" d="M 603 3500 
L 1178 3500 
L 1178 0 
L 603 0 
L 603 3500 
z
M 603 4863 
L 1178 4863 
L 1178 4134 
L 603 4134 
L 603 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-4b"/>
      <use xlink:href="#DejaVuSans-65" x="60.576172"/>
      <use xlink:href="#DejaVuSans-79" x="122.099609"/>
      <use xlink:href="#DejaVuSans-20" x="181.279297"/>
      <use xlink:href="#DejaVuSans-70" x="213.066406"/>
      <use xlink:href="#DejaVuSans-6f" x="276.542969"/>
      <use xlink:href="#DejaVuSans-73" x="337.724609"/>
      <use xlink:href="#DejaVuSans-69" x="389.824219"/>
      <use xlink:href="#DejaVuSans-73" x="417.607422"/>
      <use xlink:href="#DejaVuSans-74" x="469.707031"/>
      <use xlink:href="#DejaVuSans-69" x="508.916016"/>
      <use xlink:href="#DejaVuSans-6f" x="536.699219"/>
      <use xlink:href="#DejaVuSans-6e" x="597.880859"/>
      <use xlink:href="#DejaVuSans-73" x="661.259766"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_3">
      <defs>
       <path id="ma9411aca92" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#ma9411aca92" x="34.240625" y="18.75" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 0 -->
      <g transform="translate(20.878125 22.549219) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_4">
      <g>
       <use xlink:href="#ma9411aca92" x="34.240625" y="41.85" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- 1 -->
      <g transform="translate(20.878125 45.649219) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-31"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_5">
      <g>
       <use xlink:href="#ma9411aca92" x="34.240625" y="64.95" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_6">
      <!-- 2 -->
      <g transform="translate(20.878125 68.749219) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_6">
      <g>
       <use xlink:href="#ma9411aca92" x="34.240625" y="88.05" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 3 -->
      <g transform="translate(20.878125 91.849219) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-33" d="M 2597 2516 
Q 3050 2419 3304 2112 
Q 3559 1806 3559 1356 
Q 3559 666 3084 287 
Q 2609 -91 1734 -91 
Q 1441 -91 1130 -33 
Q 819 25 488 141 
L 488 750 
Q 750 597 1062 519 
Q 1375 441 1716 441 
Q 2309 441 2620 675 
Q 2931 909 2931 1356 
Q 2931 1769 2642 2001 
Q 2353 2234 1838 2234 
L 1294 2234 
L 1294 2753 
L 1863 2753 
Q 2328 2753 2575 2939 
Q 2822 3125 2822 3475 
Q 2822 3834 2567 4026 
Q 2313 4219 1838 4219 
Q 1578 4219 1281 4162 
Q 984 4106 628 3988 
L 628 4550 
Q 988 4650 1302 4700 
Q 1616 4750 1894 4750 
Q 2613 4750 3031 4423 
Q 3450 4097 3450 3541 
Q 3450 3153 3228 2886 
Q 3006 2619 2597 2516 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-33"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_7">
      <g>
       <use xlink:href="#ma9411aca92" x="34.240625" y="111.15" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 4 -->
      <g transform="translate(20.878125 114.949219) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
    <g id="ytick_6">
     <g id="line2d_8">
      <g>
       <use xlink:href="#ma9411aca92" x="34.240625" y="134.25" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <!-- 5 -->
      <g transform="translate(20.878125 138.049219) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-35"/>
      </g>
     </g>
    </g>
    <g id="text_10">
     <!-- Query posistions -->
     <g transform="translate(14.798438 118.299219) rotate(-90) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-51" d="M 2522 4238 
Q 1834 4238 1429 3725 
Q 1025 3213 1025 2328 
Q 1025 1447 1429 934 
Q 1834 422 2522 422 
Q 3209 422 3611 934 
Q 4013 1447 4013 2328 
Q 4013 3213 3611 3725 
Q 3209 4238 2522 4238 
z
M 3406 84 
L 4238 -825 
L 3475 -825 
L 2784 -78 
Q 2681 -84 2626 -87 
Q 2572 -91 2522 -91 
Q 1538 -91 948 567 
Q 359 1225 359 2328 
Q 359 3434 948 4092 
Q 1538 4750 2522 4750 
Q 3503 4750 4090 4092 
Q 4678 3434 4678 2328 
Q 4678 1516 4351 937 
Q 4025 359 3406 84 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-75" d="M 544 1381 
L 544 3500 
L 1119 3500 
L 1119 1403 
Q 1119 906 1312 657 
Q 1506 409 1894 409 
Q 2359 409 2629 706 
Q 2900 1003 2900 1516 
L 2900 3500 
L 3475 3500 
L 3475 0 
L 2900 0 
L 2900 538 
Q 2691 219 2414 64 
Q 2138 -91 1772 -91 
Q 1169 -91 856 284 
Q 544 659 544 1381 
z
M 1991 3584 
L 1991 3584 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-72" d="M 2631 2963 
Q 2534 3019 2420 3045 
Q 2306 3072 2169 3072 
Q 1681 3072 1420 2755 
Q 1159 2438 1159 1844 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1341 3275 1631 3429 
Q 1922 3584 2338 3584 
Q 2397 3584 2469 3576 
Q 2541 3569 2628 3553 
L 2631 2963 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-51"/>
      <use xlink:href="#DejaVuSans-75" x="78.710938"/>
      <use xlink:href="#DejaVuSans-65" x="142.089844"/>
      <use xlink:href="#DejaVuSans-72" x="203.613281"/>
      <use xlink:href="#DejaVuSans-79" x="244.726562"/>
      <use xlink:href="#DejaVuSans-20" x="303.90625"/>
      <use xlink:href="#DejaVuSans-70" x="335.693359"/>
      <use xlink:href="#DejaVuSans-6f" x="399.169922"/>
      <use xlink:href="#DejaVuSans-73" x="460.351562"/>
      <use xlink:href="#DejaVuSans-69" x="512.451172"/>
      <use xlink:href="#DejaVuSans-73" x="540.234375"/>
      <use xlink:href="#DejaVuSans-74" x="592.333984"/>
      <use xlink:href="#DejaVuSans-69" x="631.542969"/>
      <use xlink:href="#DejaVuSans-6f" x="659.326172"/>
      <use xlink:href="#DejaVuSans-6e" x="720.507812"/>
      <use xlink:href="#DejaVuSans-73" x="783.886719"/>
     </g>
    </g>
   </g>
   <g id="patch_3">
    <path d="M 34.240625 145.8 
L 34.240625 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 126.640625 145.8 
L 126.640625 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 34.240625 145.8 
L 126.640625 145.8 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 34.240625 7.2 
L 126.640625 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
  <g id="axes_2">
   <g id="patch_7">
    <path d="M 133.615625 118.08 
L 137.773625 118.08 
L 137.773625 34.92 
L 133.615625 34.92 
z
" style="fill: #ffffff"/>
   </g>
   <image xlink:href="data:image/png;base64,
iVBORw0KGgoAAAANSUhEUgAAAAUAAABzCAYAAABQFMg5AAAAxklEQVR4nLWVOw7DMAxDWcD3v2qXTok+3eNngIHhjARF0pLsfPr3bT2+oconpqEuF6xJcskEo2am747h/Ui2UdyuOx4zXaaSjPxyBCl8++W+e8SWJoN2Q9LeECz3R/ximn6XKDwb4X6Spl2+2E/baDM8dwnvEYZHTQCLNJHpG3XCa9MnjOyGFEUqeqgRDCy3NdM2yjigSTkRLPpNIDj3XRqJzBnTKKERaRJz0wiZqDlv0ooJc9MIYt575ci8DmjiMS+8Ha7RHygaEE7sVIc4AAAAAElFTkSuQmCC" id="imageb356374225" transform="scale(1 -1) translate(0 -82.8)" x="133.92" y="-34.56" width="3.6" height="82.8"/>
   <g id="matplotlib.axis_3"/>
   <g id="matplotlib.axis_4">
    <g id="ytick_7">
     <g id="line2d_9">
      <defs>
       <path id="m849fa82681" d="M 0 0 
L 3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m849fa82681" x="137.773625" y="94.748407" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_11">
      <!-- 0.25 -->
      <g transform="translate(144.773625 98.547626) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-32" x="95.410156"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_8">
     <g id="line2d_10">
      <g>
       <use xlink:href="#m849fa82681" x="137.773625" y="69.770005" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_12">
      <!-- 0.50 -->
      <g transform="translate(144.773625 73.569223) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-35" x="95.410156"/>
       <use xlink:href="#DejaVuSans-30" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_9">
     <g id="line2d_11">
      <g>
       <use xlink:href="#m849fa82681" x="137.773625" y="44.791602" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_13">
      <!-- 0.75 -->
      <g transform="translate(144.773625 48.590821) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-37" d="M 525 4666 
L 3525 4666 
L 3525 4397 
L 1831 0 
L 1172 0 
L 2766 4134 
L 525 4134 
L 525 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-37" x="95.410156"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
   </g>
   <g id="LineCollection_1"/>
   <g id="patch_8">
    <path d="M 133.615625 118.08 
L 135.694625 118.08 
L 137.773625 118.08 
L 137.773625 34.92 
L 135.694625 34.92 
L 133.615625 34.92 
L 133.615625 118.08 
z
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="pd9fcc2b972">
   <rect x="34.240625" y="7.2" width="92.4" height="138.6"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11.6.-Transformer">11.6. <a id="toc11_6_"></a><a href="#toc0_">Transformer</a><a class="anchor-link" href="#11.6.-Transformer"></a></h2><p>TransformerVaswani2017Attention is All You NeedTransformerSelf-Attention</p>
<div class="highlight"><pre><span></span><span class="n">Encoder</span><span class="o">-</span><span class="n">Decoder</span><span class="err"></span>
<span class="mf">1.</span><span class="n"></span><span class="err"></span>
<span class="mf">2.</span><span class="n"></span><span class="err"></span>
<span class="mf">3.</span><span class="n">Encoder</span><span class="o">-</span><span class="n">Decoder</span><span class="err"></span>
</pre></div>
<p><img alt="Transformer" src="./Pytorch_Pictures/Transformer/Transformer.jpg"/></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.6.1.-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0">11.6.1. <a id="toc11_6_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.6.1.-%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[151]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="n">trans</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Transformer</span><span class="p">(</span>
    <span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> 
    <span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> 
    <span class="n">num_encoder_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> 
    <span class="n">num_decoder_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> 
    <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> 
    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>


<span class="c1"># </span>
<span class="n">src</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>  <span class="c1"># (, , )</span>
<span class="n">tgt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>  <span class="c1"># (, , )</span>

<span class="c1"># </span>
<span class="n">output</span> <span class="o">=</span> <span class="n">trans</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">":"</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># : (, , )</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>: torch.Size([2, 32, 512])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[154]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>

<span class="c1">#  GPU</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># </span>
<span class="n">nhead</span> <span class="o">=</span> <span class="mi">2</span>      <span class="c1"># </span>
<span class="n">num_encoder_layers</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># </span>
<span class="n">dim_feedforward</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># </span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.1</span>          <span class="c1"># Dropout </span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># </span>
<span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PositionalEncoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">))</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">))</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">'pe'</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">#  Transformer </span>
<span class="k">class</span> <span class="nc">TransformerModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">num_encoder_layers</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">=</span> <span class="s1">'Transformer'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>  <span class="c1">#  d_model </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoder</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">num_encoder_layers</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: (batch_size, 1, 28, 28)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1">#  channels  (batch_size, 28, 28)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1">#  (28, batch_size, 28)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># </span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1">#  MNIST </span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
<span class="n">val_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">val_size</span><span class="p">])</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#  GPU</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TransformerModel</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">num_encoder_layers</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="c1"># </span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1">#  GPU</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># </span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1">#  GPU</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">, Validation Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1, Loss: 0.30776989459991455, Validation Accuracy: 90.23%
Epoch 2, Loss: 0.23195476830005646, Validation Accuracy: 93.50%
Epoch 3, Loss: 0.2852802872657776, Validation Accuracy: 94.38%
Epoch 4, Loss: 0.15702208876609802, Validation Accuracy: 95.27%
Epoch 5, Loss: 0.3195101320743561, Validation Accuracy: 95.14%
Epoch 6, Loss: 0.11443279683589935, Validation Accuracy: 95.71%
Epoch 7, Loss: 0.10062020272016525, Validation Accuracy: 95.70%
Epoch 8, Loss: 0.09283831715583801, Validation Accuracy: 95.38%
Epoch 9, Loss: 0.20097430050373077, Validation Accuracy: 95.95%
Epoch 10, Loss: 0.13262364268302917, Validation Accuracy: 95.33%
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.6.2.-%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81">11.6.2. <a id="toc11_6_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.6.2.-%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"></a></h3><p></p>
<ul>
<li>Transformer [A, B, C]  [C, B, A] Transformer</li>
</ul>
<p></p>
<ul>
<li></li>
</ul>
<p></p>
<ul>
<li>Absolute Positional EncodingGooglesincosX</li>
<li>Relative Positional Encoding</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.6.2.1.-%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81">11.6.2.1. <a id="toc11_6_2_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.6.2.1.-%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"></a></h4><p>$\begin{aligned}&amp;\text{ }L,\text{  }d,\text{  }pos\text{  }i\text{ }\\&amp;PE(pos,i)\text{,:}\\&amp;PE(pos,2i)=\sin\left(\frac{pos}{10000\frac{2i}{d}}\right)\\&amp;PE(pos,2i+1)=\cos\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)\\&amp;\bullet\quad pos:\text{ }\\&amp;\bullet\quad i:\text{ }\\&amp;\bullet\quad d:\quad\text{}\end{aligned}$</p>
<p> =4embedding=4</p>
<table>
<thead>
<tr>
<th>Position</th>
<th>PE(pos, 0) (sin)</th>
<th>PE(pos, 1) (cos)</th>
<th>PE(pos, 2) (sin)</th>
<th>PE(pos, 3) (cos)</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0.8415</td>
<td>0.5403</td>
<td>0.00999</td>
<td>0.99995</td>
</tr>
<tr>
<td>2</td>
<td>0.9093</td>
<td>-0.4161</td>
<td>0.01998</td>
<td>0.9998</td>
</tr>
<tr>
<td>3</td>
<td>0.1411</td>
<td>-0.98999</td>
<td>0.02997</td>
<td>0.99955</td>
</tr>
</tbody>
</table>
<p>Transformerembedding</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[240]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span> 


<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PositionalEncoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="c1"># P</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>                 <span class="c1"># (1, max_len, num_hiddens)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="mi">0</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>                  <span class="c1"># On the same device</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="c1"># </span>
<span class="n">encoding_dim</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">60</span>
<span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">encoding_dim</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">pos_encoding</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pos_encoding</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">encoding_dim</span><span class="p">)))</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">pos_encoding</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span>

<span class="c1"># Draw a plot picture</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_steps</span><span class="p">),</span> <span class="n">P</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">6</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'col 6'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_steps</span><span class="p">),</span> <span class="n">P</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">6</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'col 7'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_steps</span><span class="p">),</span> <span class="n">P</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">6</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'col 8'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_steps</span><span class="p">),</span> <span class="n">P</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">6</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'col 9'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Row (position)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[240]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>&lt;matplotlib.legend.Legend at 0x7fad56e2b0e0&gt;</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="380.482812pt" height="183.35625pt" viewBox="0 0 380.482812 183.35625" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-12-02T20:42:03.380674</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M -0 183.35625 
L 380.482812 183.35625 
L 380.482812 0 
L -0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 38.482813 145.8 
L 373.282813 145.8 
L 373.282813 7.2 
L 38.482813 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <defs>
       <path id="m8db258bff5" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m8db258bff5" x="53.700994" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- 0 -->
      <g transform="translate(50.519744 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <g>
       <use xlink:href="#m8db258bff5" x="105.288051" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 10 -->
      <g transform="translate(98.925551 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_3">
      <g>
       <use xlink:href="#m8db258bff5" x="156.875108" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 20 -->
      <g transform="translate(150.512608 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-32"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_4">
      <g>
       <use xlink:href="#m8db258bff5" x="208.462165" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 30 -->
      <g transform="translate(202.099665 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-33" d="M 2597 2516 
Q 3050 2419 3304 2112 
Q 3559 1806 3559 1356 
Q 3559 666 3084 287 
Q 2609 -91 1734 -91 
Q 1441 -91 1130 -33 
Q 819 25 488 141 
L 488 750 
Q 750 597 1062 519 
Q 1375 441 1716 441 
Q 2309 441 2620 675 
Q 2931 909 2931 1356 
Q 2931 1769 2642 2001 
Q 2353 2234 1838 2234 
L 1294 2234 
L 1294 2753 
L 1863 2753 
Q 2328 2753 2575 2939 
Q 2822 3125 2822 3475 
Q 2822 3834 2567 4026 
Q 2313 4219 1838 4219 
Q 1578 4219 1281 4162 
Q 984 4106 628 3988 
L 628 4550 
Q 988 4650 1302 4700 
Q 1616 4750 1894 4750 
Q 2613 4750 3031 4423 
Q 3450 4097 3450 3541 
Q 3450 3153 3228 2886 
Q 3006 2619 2597 2516 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-33"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_5">
      <g>
       <use xlink:href="#m8db258bff5" x="260.049222" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- 40 -->
      <g transform="translate(253.686722 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-34"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="xtick_6">
     <g id="line2d_6">
      <g>
       <use xlink:href="#m8db258bff5" x="311.636279" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_6">
      <!-- 50 -->
      <g transform="translate(305.273779 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-35"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="xtick_7">
     <g id="line2d_7">
      <g>
       <use xlink:href="#m8db258bff5" x="363.223336" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 60 -->
      <g transform="translate(356.860836 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-36" d="M 2113 2584 
Q 1688 2584 1439 2293 
Q 1191 2003 1191 1497 
Q 1191 994 1439 701 
Q 1688 409 2113 409 
Q 2538 409 2786 701 
Q 3034 994 3034 1497 
Q 3034 2003 2786 2293 
Q 2538 2584 2113 2584 
z
M 3366 4563 
L 3366 3988 
Q 3128 4100 2886 4159 
Q 2644 4219 2406 4219 
Q 1781 4219 1451 3797 
Q 1122 3375 1075 2522 
Q 1259 2794 1537 2939 
Q 1816 3084 2150 3084 
Q 2853 3084 3261 2657 
Q 3669 2231 3669 1497 
Q 3669 778 3244 343 
Q 2819 -91 2113 -91 
Q 1303 -91 875 529 
Q 447 1150 447 2328 
Q 447 3434 972 4092 
Q 1497 4750 2381 4750 
Q 2619 4750 2861 4703 
Q 3103 4656 3366 4563 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-36"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="text_8">
     <!-- Row (position) -->
     <g transform="translate(170.189844 174.076563) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-52" d="M 2841 2188 
Q 3044 2119 3236 1894 
Q 3428 1669 3622 1275 
L 4263 0 
L 3584 0 
L 2988 1197 
Q 2756 1666 2539 1819 
Q 2322 1972 1947 1972 
L 1259 1972 
L 1259 0 
L 628 0 
L 628 4666 
L 2053 4666 
Q 2853 4666 3247 4331 
Q 3641 3997 3641 3322 
Q 3641 2881 3436 2590 
Q 3231 2300 2841 2188 
z
M 1259 4147 
L 1259 2491 
L 2053 2491 
Q 2509 2491 2742 2702 
Q 2975 2913 2975 3322 
Q 2975 3731 2742 3939 
Q 2509 4147 2053 4147 
L 1259 4147 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-77" d="M 269 3500 
L 844 3500 
L 1563 769 
L 2278 3500 
L 2956 3500 
L 3675 769 
L 4391 3500 
L 4966 3500 
L 4050 0 
L 3372 0 
L 2619 2869 
L 1863 0 
L 1184 0 
L 269 3500 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-20" transform="scale(0.015625)"/>
       <path id="DejaVuSans-28" d="M 1984 4856 
Q 1566 4138 1362 3434 
Q 1159 2731 1159 2009 
Q 1159 1288 1364 580 
Q 1569 -128 1984 -844 
L 1484 -844 
Q 1016 -109 783 600 
Q 550 1309 550 2009 
Q 550 2706 781 3412 
Q 1013 4119 1484 4856 
L 1984 4856 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-69" d="M 603 3500 
L 1178 3500 
L 1178 0 
L 603 0 
L 603 3500 
z
M 603 4863 
L 1178 4863 
L 1178 4134 
L 603 4134 
L 603 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-29" d="M 513 4856 
L 1013 4856 
Q 1481 4119 1714 3412 
Q 1947 2706 1947 2009 
Q 1947 1309 1714 600 
Q 1481 -109 1013 -844 
L 513 -844 
Q 928 -128 1133 580 
Q 1338 1288 1338 2009 
Q 1338 2731 1133 3434 
Q 928 4138 513 4856 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-52"/>
      <use xlink:href="#DejaVuSans-6f" x="64.982422"/>
      <use xlink:href="#DejaVuSans-77" x="126.164062"/>
      <use xlink:href="#DejaVuSans-20" x="207.951172"/>
      <use xlink:href="#DejaVuSans-28" x="239.738281"/>
      <use xlink:href="#DejaVuSans-70" x="278.751953"/>
      <use xlink:href="#DejaVuSans-6f" x="342.228516"/>
      <use xlink:href="#DejaVuSans-73" x="403.410156"/>
      <use xlink:href="#DejaVuSans-69" x="455.509766"/>
      <use xlink:href="#DejaVuSans-74" x="483.292969"/>
      <use xlink:href="#DejaVuSans-69" x="522.501953"/>
      <use xlink:href="#DejaVuSans-6f" x="550.285156"/>
      <use xlink:href="#DejaVuSans-6e" x="611.466797"/>
      <use xlink:href="#DejaVuSans-29" x="674.845703"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_8">
      <defs>
       <path id="m981bd613b2" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m981bd613b2" x="38.482813" y="139.5" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <!-- −1.0 -->
      <g transform="translate(7.2 143.299219) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-31" x="83.789062"/>
       <use xlink:href="#DejaVuSans-2e" x="147.412109"/>
       <use xlink:href="#DejaVuSans-30" x="179.199219"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_9">
      <g>
       <use xlink:href="#m981bd613b2" x="38.482813" y="108" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_10">
      <!-- −0.5 -->
      <g transform="translate(7.2 111.799219) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-30" x="83.789062"/>
       <use xlink:href="#DejaVuSans-2e" x="147.412109"/>
       <use xlink:href="#DejaVuSans-35" x="179.199219"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_10">
      <g>
       <use xlink:href="#m981bd613b2" x="38.482813" y="76.5" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_11">
      <!-- 0.0 -->
      <g transform="translate(15.579688 80.299219) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_11">
      <g>
       <use xlink:href="#m981bd613b2" x="38.482813" y="45" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_12">
      <!-- 0.5 -->
      <g transform="translate(15.579688 48.799219) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-35" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_12">
      <g>
       <use xlink:href="#m981bd613b2" x="38.482813" y="13.5" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_13">
      <!-- 1.0 -->
      <g transform="translate(15.579688 17.299219) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
      </g>
     </g>
    </g>
   </g>
   <g id="line2d_13">
    <path d="M 53.700994 76.5 
L 58.8597 65.355792 
L 64.018406 54.563068 
L 69.177111 44.462222 
L 74.335817 35.371837 
L 79.494523 27.578612 
L 84.653229 21.328343 
L 89.811934 16.818165 
L 94.97064 14.190325 
L 100.129346 13.527701 
L 105.288051 14.851191 
L 110.446757 18.119061 
L 115.605463 23.22824 
L 120.764168 30.017578 
L 125.922874 38.272962 
L 131.08158 47.733995 
L 136.240286 58.102294 
L 141.398991 69.050862 
L 146.557697 80.234358 
L 151.716403 91.300088 
L 156.875108 101.899017 
L 162.033814 111.696885 
L 167.19252 120.384648 
L 172.351225 127.688311 
L 177.509931 133.377536 
L 182.668637 137.272851 
L 187.827343 139.251424 
L 192.986048 139.250846 
L 198.144754 137.271135 
L 203.30346 133.37473 
L 208.462165 127.684526 
L 213.620871 120.379992 
L 218.779577 111.691504 
L 223.938282 101.893063 
L 229.096988 91.293765 
L 234.255694 80.227879 
L 239.4144 69.044417 
L 244.573105 58.096071 
L 249.731811 47.728208 
L 254.890517 38.267791 
L 260.049222 30.0132 
L 265.207928 23.224759 
L 270.366634 18.116616 
L 275.525339 14.849854 
L 280.684045 13.52751 
L 285.842751 14.191283 
L 291.001457 16.820238 
L 296.160162 21.331467 
L 301.318868 27.582724 
L 306.477574 35.376772 
L 311.636279 44.467828 
L 316.794985 54.569164 
L 321.953691 65.362187 
L 327.112396 76.50649 
L 332.271102 87.650589 
L 337.429808 98.443004 
L 342.588514 108.543399 
L 347.747219 117.633104 
L 352.905925 125.425496 
L 358.064631 131.6748 
" clip-path="url(#p662531076e)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="line2d_14">
    <path d="M 53.700994 13.5 
L 58.8597 14.493496 
L 64.018406 17.442644 
L 69.177111 22.254439 
L 74.335817 28.77711 
L 79.494523 36.804942 
L 84.653229 46.084737 
L 89.811934 56.323816 
L 94.97064 67.199234 
L 100.129346 78.368 
L 105.288051 89.477851 
L 110.446757 100.178386 
L 115.605463 110.132123 
L 120.764168 119.025106 
L 125.922874 126.576875 
L 131.08158 132.549237 
L 136.240286 136.753833 
L 141.398991 139.058056 
L 146.557697 139.389225 
L 151.716403 137.736898 
L 156.875108 134.153187 
L 162.033814 128.751119 
L 167.19252 121.701079 
L 172.351225 113.225425 
L 177.509931 103.591439 
L 182.668637 93.103029 
L 187.827343 82.090967 
L 192.986048 70.902569 
L 198.144754 59.890681 
L 203.30346 49.402673 
L 208.462165 39.769302 
L 213.620871 31.2944 
L 218.779577 24.245258 
L 223.938282 18.844191 
L 229.096988 15.261578 
L 234.255694 13.610392 
L 239.4144 13.94271 
L 244.573105 16.248067 
L 249.731811 20.453733 
L 254.890517 26.427072 
L 260.049222 33.979686 
L 265.207928 42.87339 
L 270.366634 52.827643 
L 275.525339 63.528508 
L 280.684045 74.638487 
L 285.842751 85.807178 
L 291.001457 96.682325 
L 296.160162 106.920933 
L 301.318868 116.200123 
L 306.477574 124.227145 
L 311.636279 130.748869 
L 316.794985 135.55962 
L 321.953691 138.507653 
L 327.112396 139.5 
L 332.271102 138.505359 
L 337.429808 135.555099 
L 342.588514 130.742238 
L 347.747219 124.218628 
L 352.905925 116.19 
L 358.064631 106.909564 
" clip-path="url(#p662531076e)" style="fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="line2d_15">
    <path d="M 53.700994 76.5 
L 58.8597 70.210494 
L 64.018406 63.983832 
L 69.177111 57.882226 
L 74.335817 51.966643 
L 79.494523 46.29619 
L 84.653229 40.927523 
L 89.811934 35.914287 
L 94.97064 31.306567 
L 100.129346 27.150408 
L 105.288051 23.48733 
L 110.446757 20.353934 
L 115.605463 17.781538 
L 120.764168 15.795834 
L 125.922874 14.416667 
L 131.08158 13.657815 
L 136.240286 13.526864 
L 141.398991 14.025116 
L 146.557697 15.147599 
L 151.716403 16.883094 
L 156.875108 19.214263 
L 162.033814 22.117806 
L 167.19252 25.56473 
L 172.351225 29.520569 
L 177.509931 33.945826 
L 182.668637 38.796257 
L 187.827343 44.023409 
L 192.986048 49.57507 
L 198.144754 55.395743 
L 203.30346 61.427298 
L 208.462165 67.60944 
L 213.620871 73.880412 
L 218.779577 80.177574 
L 223.938282 86.437976 
L 229.096988 92.599096 
L 234.255694 98.599343 
L 239.4144 104.378782 
L 244.573105 109.879679 
L 249.731811 115.047043 
L 254.890517 119.829274 
L 260.049222 124.178557 
L 265.207928 128.051455 
L 270.366634 131.409266 
L 275.525339 134.218458 
L 280.684045 136.450932 
L 285.842751 138.084398 
L 291.001457 139.102531 
L 296.160162 139.495163 
L 301.318868 139.258367 
L 306.477574 138.394512 
L 311.636279 136.91223 
L 316.794985 134.826329 
L 321.953691 132.157649 
L 327.112396 128.932843 
L 332.271102 125.18416 
L 337.429808 120.949039 
L 342.588514 116.269803 
L 347.747219 111.193199 
L 352.905925 105.769927 
L 358.064631 100.054224 
" clip-path="url(#p662531076e)" style="fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="line2d_16">
    <path d="M 53.700994 13.5 
L 58.8597 13.814737 
L 64.018406 14.755804 
L 69.177111 16.3138 
L 74.335817 18.473158 
L 79.494523 21.212299 
L 84.653229 24.503856 
L 89.811934 28.314941 
L 94.97064 32.607477 
L 100.129346 37.338571 
L 105.288051 42.460953 
L 110.446757 47.923445 
L 115.605463 53.671465 
L 120.764168 59.647571 
L 125.922874 65.792069 
L 131.08158 72.043557 
L 136.240286 78.339571 
L 141.398991 84.617206 
L 146.557697 90.813729 
L 151.716403 96.867241 
L 156.875108 102.717251 
L 162.033814 108.3053 
L 167.19252 113.575573 
L 172.351225 118.475387 
L 177.509931 122.955809 
L 182.668637 126.972046 
L 187.827343 130.483989 
L 192.986048 133.456546 
L 198.144754 135.860008 
L 203.30346 137.670365 
L 208.462165 138.869527 
L 213.620871 139.445514 
L 218.779577 139.392571 
L 223.938282 138.711228 
L 229.096988 137.408286 
L 234.255694 135.496771 
L 239.4144 132.995782 
L 244.573105 129.9303 
L 249.731811 126.330969 
L 254.890517 122.233731 
L 260.049222 117.679547 
L 265.207928 112.713914 
L 270.366634 107.386442 
L 275.525339 101.750337 
L 280.684045 95.861965 
L 285.842751 89.780136 
L 291.001457 83.565615 
L 296.160162 77.280498 
L 301.318868 70.987552 
L 306.477574 64.749714 
L 311.636279 58.629281 
L 316.794985 52.687407 
L 321.953691 46.983461 
L 327.112396 41.574405 
L 332.271102 36.514343 
L 337.429808 31.853804 
L 342.588514 27.639354 
L 347.747219 23.913101 
L 352.905925 20.712264 
L 358.064631 18.068855 
" clip-path="url(#p662531076e)" style="fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="patch_3">
    <path d="M 38.482813 145.8 
L 38.482813 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 373.282813 145.8 
L 373.282813 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 38.482813 145.8 
L 373.282812 145.8 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 38.482813 7.2 
L 373.282812 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="legend_1">
    <g id="patch_7">
     <path d="M 45.482813 140.8 
L 101.41875 140.8 
Q 103.41875 140.8 103.41875 138.8 
L 103.41875 81.0875 
Q 103.41875 79.0875 101.41875 79.0875 
L 45.482813 79.0875 
Q 43.482813 79.0875 43.482813 81.0875 
L 43.482813 138.8 
Q 43.482813 140.8 45.482813 140.8 
z
" style="fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter"/>
    </g>
    <g id="line2d_17">
     <path d="M 47.482813 87.185938 
L 57.482813 87.185938 
L 67.482812 87.185938 
" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
    </g>
    <g id="text_14">
     <!-- col 6 -->
     <g transform="translate(75.482812 90.685938) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6c" d="M 603 4863 
L 1178 4863 
L 1178 0 
L 603 0 
L 603 4863 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-63"/>
      <use xlink:href="#DejaVuSans-6f" x="54.980469"/>
      <use xlink:href="#DejaVuSans-6c" x="116.162109"/>
      <use xlink:href="#DejaVuSans-20" x="143.945312"/>
      <use xlink:href="#DejaVuSans-36" x="175.732422"/>
     </g>
    </g>
    <g id="line2d_18">
     <path d="M 47.482813 101.864063 
L 57.482813 101.864063 
L 67.482812 101.864063 
" style="fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square"/>
    </g>
    <g id="text_15">
     <!-- col 7 -->
     <g transform="translate(75.482812 105.364063) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-37" d="M 525 4666 
L 3525 4666 
L 3525 4397 
L 1831 0 
L 1172 0 
L 2766 4134 
L 525 4134 
L 525 4666 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-63"/>
      <use xlink:href="#DejaVuSans-6f" x="54.980469"/>
      <use xlink:href="#DejaVuSans-6c" x="116.162109"/>
      <use xlink:href="#DejaVuSans-20" x="143.945312"/>
      <use xlink:href="#DejaVuSans-37" x="175.732422"/>
     </g>
    </g>
    <g id="line2d_19">
     <path d="M 47.482813 116.542188 
L 57.482813 116.542188 
L 67.482812 116.542188 
" style="fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square"/>
    </g>
    <g id="text_16">
     <!-- col 8 -->
     <g transform="translate(75.482812 120.042188) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-38" d="M 2034 2216 
Q 1584 2216 1326 1975 
Q 1069 1734 1069 1313 
Q 1069 891 1326 650 
Q 1584 409 2034 409 
Q 2484 409 2743 651 
Q 3003 894 3003 1313 
Q 3003 1734 2745 1975 
Q 2488 2216 2034 2216 
z
M 1403 2484 
Q 997 2584 770 2862 
Q 544 3141 544 3541 
Q 544 4100 942 4425 
Q 1341 4750 2034 4750 
Q 2731 4750 3128 4425 
Q 3525 4100 3525 3541 
Q 3525 3141 3298 2862 
Q 3072 2584 2669 2484 
Q 3125 2378 3379 2068 
Q 3634 1759 3634 1313 
Q 3634 634 3220 271 
Q 2806 -91 2034 -91 
Q 1263 -91 848 271 
Q 434 634 434 1313 
Q 434 1759 690 2068 
Q 947 2378 1403 2484 
z
M 1172 3481 
Q 1172 3119 1398 2916 
Q 1625 2713 2034 2713 
Q 2441 2713 2670 2916 
Q 2900 3119 2900 3481 
Q 2900 3844 2670 4047 
Q 2441 4250 2034 4250 
Q 1625 4250 1398 4047 
Q 1172 3844 1172 3481 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-63"/>
      <use xlink:href="#DejaVuSans-6f" x="54.980469"/>
      <use xlink:href="#DejaVuSans-6c" x="116.162109"/>
      <use xlink:href="#DejaVuSans-20" x="143.945312"/>
      <use xlink:href="#DejaVuSans-38" x="175.732422"/>
     </g>
    </g>
    <g id="line2d_20">
     <path d="M 47.482813 131.220313 
L 57.482813 131.220313 
L 67.482812 131.220313 
" style="fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square"/>
    </g>
    <g id="text_17">
     <!-- col 9 -->
     <g transform="translate(75.482812 134.720313) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-39" d="M 703 97 
L 703 672 
Q 941 559 1184 500 
Q 1428 441 1663 441 
Q 2288 441 2617 861 
Q 2947 1281 2994 2138 
Q 2813 1869 2534 1725 
Q 2256 1581 1919 1581 
Q 1219 1581 811 2004 
Q 403 2428 403 3163 
Q 403 3881 828 4315 
Q 1253 4750 1959 4750 
Q 2769 4750 3195 4129 
Q 3622 3509 3622 2328 
Q 3622 1225 3098 567 
Q 2575 -91 1691 -91 
Q 1453 -91 1209 -44 
Q 966 3 703 97 
z
M 1959 2075 
Q 2384 2075 2632 2365 
Q 2881 2656 2881 3163 
Q 2881 3666 2632 3958 
Q 2384 4250 1959 4250 
Q 1534 4250 1286 3958 
Q 1038 3666 1038 3163 
Q 1038 2656 1286 2365 
Q 1534 2075 1959 2075 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-63"/>
      <use xlink:href="#DejaVuSans-6f" x="54.980469"/>
      <use xlink:href="#DejaVuSans-6c" x="116.162109"/>
      <use xlink:href="#DejaVuSans-20" x="143.945312"/>
      <use xlink:href="#DejaVuSans-39" x="175.732422"/>
     </g>
    </g>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="p662531076e">
   <rect x="38.482813" y="7.2" width="334.8" height="138.6"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.6.2.2.-%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81">11.6.2.2. <a id="toc11_6_2_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.6.2.2.-%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"></a></h4><p>Relative Positional Encoding   </p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[170]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="k">class</span> <span class="nc">RelativePositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RelativePositionalEncoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="n">max_len</span>

        <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relative_positions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">max_len</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>
                <span class="n">relative_position</span> <span class="o">=</span> <span class="n">i</span> <span class="o">-</span> <span class="n">j</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">relative_positions</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_relative_position_encoding</span><span class="p">(</span><span class="n">relative_position</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_relative_position_encoding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">relative_position</span><span class="p">):</span>
        <span class="c1"># </span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
            <span class="n">encoding</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">relative_position</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">))))</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">:</span>
                <span class="n">encoding</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">relative_position</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">))))</span>
        <span class="k">return</span> <span class="n">encoding</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">relative_positions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relative_positions</span><span class="p">[:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span> <span class="o">+</span> <span class="n">relative_positions</span>


<span class="c1"># </span>
<span class="n">encoding_dim</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">60</span>
<span class="n">relative_pos_encoding</span> <span class="o">=</span> <span class="n">RelativePositionalEncoding</span><span class="p">(</span><span class="n">encoding_dim</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
<span class="n">relative_pos_encoding</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">encoding_dim</span><span class="p">))</span>
<span class="n">X_encoded</span> <span class="o">=</span> <span class="n">relative_pos_encoding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_encoded</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># : torch.Size([1, 60, 32])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([60, 60, 32])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.6.3.-%E5%9F%BA%E4%BA%8E%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C">11.6.3. <a id="toc11_6_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.6.3.-%E5%9F%BA%E4%BA%8E%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[241]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">PositionWiseFFN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_outputs</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PositionWiseFFN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_outputs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>


<span class="c1"># </span>
<span class="n">ffn</span> <span class="o">=</span> <span class="n">PositionWiseFFN</span><span class="p">(</span><span class="n">ffn_num_input</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">ffn_num_outputs</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">ffn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">ffn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[241]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([3, 8])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.6.4.-%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%B1%82%E8%A7%84%E8%8C%83%E5%8C%96">11.6.4. <a id="toc11_6_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.6.4.-%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%B1%82%E8%A7%84%E8%8C%83%E5%8C%96"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[242]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>


<span class="c1"># </span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># X</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'layer norm:'</span><span class="p">,</span> <span class="n">ln</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">batch norm:'</span><span class="p">,</span> <span class="n">bn</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>layer norm: tensor([[-1.0000,  1.0000],
        [-1.0000,  1.0000]], grad_fn=&lt;NativeLayerNormBackward0&gt;) 
batch norm: tensor([[-1.0000, -1.0000],
        [ 1.0000,  1.0000]], grad_fn=&lt;NativeBatchNormBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[243]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">AddNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""""""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AddNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">+</span> <span class="n">X</span><span class="p">)</span>


<span class="c1"># </span>
<span class="n">add_norm</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">add_norm</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">add_norm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[243]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 3, 4])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.6.5.-%E7%BC%96%E7%A0%81%E5%99%A8">11.6.5. <a id="toc11_6_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.6.5.-%E7%BC%96%E7%A0%81%E5%99%A8"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[249]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>


<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">EncoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Transformer"""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># From d2l</span>
        <span class="c1"># self.attention = d2l.MultiHeadAttention(</span>
        <span class="c1">#     key_size, query_size, value_size, num_hiddens, num_heads, dropout,</span>
        <span class="c1">#     use_bias)</span>

        <span class="c1"># From </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span>
            <span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span><span class="p">,</span> 
            <span class="n">query_size</span> <span class="o">=</span> <span class="n">query_size</span><span class="p">,</span> 
            <span class="n">key_size</span> <span class="o">=</span> <span class="n">key_size</span><span class="p">,</span> 
            <span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span> 
            <span class="n">value_size</span> <span class="o">=</span> <span class="n">value_size</span><span class="p">,</span>
            <span class="n">attention_type</span><span class="o">=</span><span class="s1">'dot'</span><span class="p">,</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">norm_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">PositionWiseFFN</span><span class="p">(</span><span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">norm_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span>


<span class="c1"># </span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">24</span><span class="p">))</span>
<span class="n">encoder_blk</span> <span class="o">=</span> <span class="n">EncoderBlock</span><span class="p">(</span><span class="n">key_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">query_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">value_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">norm_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">24</span><span class="p">],</span> <span class="n">ffn_num_input</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">encoder_blk</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">encoder_blk</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[249]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 100, 24])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[247]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Transformer"""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">"block"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">EncoderBlock</span><span class="p">(</span><span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="c1"># -11</span>
        <span class="c1"># </span>
        <span class="c1"># </span>
        <span class="c1"># X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">blk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">blk</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="c1"># self.attention_weights[i] = blk.attention.attention.attention_weights_numpy</span>
        <span class="k">return</span> <span class="n">X</span>


<span class="c1"># </span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">TransformerEncoder</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
    <span class="n">key_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> 
    <span class="n">query_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> 
    <span class="n">value_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> 
    <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> 
    <span class="n">norm_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">24</span><span class="p">],</span> 
    <span class="n">ffn_num_input</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> 
    <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> 
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> 
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">encoder</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[247]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 100, 24])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.6.6.-%E8%A7%A3%E7%A0%81%E5%99%A8">11.6.6. <a id="toc11_6_6_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.6.6.-%E8%A7%A3%E7%A0%81%E5%99%A8"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[252]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="k">class</span> <span class="nc">DecoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># The `i`-th block in the decoder</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DecoderBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">i</span> <span class="o">=</span> <span class="n">i</span>
        <span class="c1"># self.attention1 = d2l.MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention1</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span>
            <span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span><span class="p">,</span> 
            <span class="n">query_size</span> <span class="o">=</span> <span class="n">query_size</span><span class="p">,</span> 
            <span class="n">key_size</span> <span class="o">=</span> <span class="n">key_size</span><span class="p">,</span> 
            <span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span> 
            <span class="n">value_size</span> <span class="o">=</span> <span class="n">value_size</span><span class="p">,</span>
            <span class="n">attention_type</span><span class="o">=</span><span class="s1">'dot'</span><span class="p">,</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="p">)</span>   
        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">norm_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="c1"># self.attention2 = d2l.MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention2</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span>
            <span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span><span class="p">,</span> 
            <span class="n">query_size</span> <span class="o">=</span> <span class="n">query_size</span><span class="p">,</span> 
            <span class="n">key_size</span> <span class="o">=</span> <span class="n">key_size</span><span class="p">,</span> 
            <span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span><span class="p">,</span> 
            <span class="n">value_size</span> <span class="o">=</span> <span class="n">value_size</span><span class="p">,</span>
            <span class="n">attention_type</span><span class="o">=</span><span class="s1">'dot'</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">norm_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">PositionWiseFFN</span><span class="p">(</span><span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm3</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">norm_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># During training, all the tokens of any output sequence are processed</span>
        <span class="c1"># at the same time, so `state[2][self.i]` is `None` as initialized.</span>
        <span class="c1"># When decoding any output sequence token by token during prediction,</span>
        <span class="c1"># `state[2][self.i]` contains representations of the decoded output at</span>
        <span class="c1"># the `i`-th block up to the current time step</span>
        <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">key_values</span> <span class="o">=</span> <span class="n">X</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">key_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">i</span><span class="p">],</span> <span class="n">X</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">key_values</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
            <span class="c1"># Shape of `dec_valid_lens`: (`batch_size`, `num_steps`), where</span>
            <span class="c1"># every row is [1, 2, ..., `num_steps`]</span>
            <span class="n">dec_valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dec_valid_lens</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Self-attention</span>
        <span class="n">X2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">key_values</span><span class="p">,</span> <span class="n">key_values</span><span class="p">,</span> <span class="n">dec_valid_lens</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X2</span><span class="p">)</span>
        <span class="c1"># Encoder-decoder attention. Shape of `enc_outputs`:</span>
        <span class="c1"># (`batch_size`, `num_steps`, `num_hiddens`)</span>
        <span class="n">Y2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention2</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">)</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Y2</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm3</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">Z</span><span class="p">)),</span> <span class="n">state</span>
    

<span class="c1"># </span>
<span class="n">decoder_blk</span> <span class="o">=</span> <span class="n">DecoderBlock</span><span class="p">(</span><span class="n">key_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">query_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">value_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">norm_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">24</span><span class="p">],</span> <span class="n">ffn_num_input</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">decoder_blk</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">24</span><span class="p">))</span>
<span class="n">state</span> <span class="o">=</span> <span class="p">[</span><span class="n">encoder_blk</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">),</span> <span class="n">valid_lens</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]]</span>
<span class="n">decoder_blk</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[252]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 100, 24])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[254]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">"block"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">DecoderBlock</span><span class="p">(</span><span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span> <span class="o">=</span> <span class="p">[[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">2</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">blk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">):</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">blk</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
            <span class="c1"># Decoder self-attention weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">attention1</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span>
            <span class="c1"># Encoder-decoder attention weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">attention2</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">state</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">attention_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span>
    

<span class="c1"># </span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">TransformerDecoder</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
    <span class="n">key_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> 
    <span class="n">query_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> 
    <span class="n">value_size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> 
    <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> 
    <span class="n">norm_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">24</span><span class="p">],</span> 
    <span class="n">ffn_num_input</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> 
    <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> 
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> 
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[254]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>TransformerDecoder(
  (embedding): Embedding(200, 24)
  (pos_encoding): PositionalEncoding(
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (blks): Sequential(
    (block0): DecoderBlock(
      (attention1): MultiHeadAttention(
        (W_q): Linear(in_features=24, out_features=24, bias=True)
        (W_k): Linear(in_features=24, out_features=24, bias=True)
        (W_v): Linear(in_features=24, out_features=24, bias=True)
        (attention): DotProductAttentionForMultiHeadAttention(
          (dropout): Dropout(p=0.5, inplace=False)
        )
        (W_o): Linear(in_features=24, out_features=24, bias=True)
      )
      (addnorm1): AddNorm(
        (dropout): Dropout(p=0.5, inplace=False)
        (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)
      )
      (attention2): MultiHeadAttention(
        (W_q): Linear(in_features=24, out_features=24, bias=True)
        (W_k): Linear(in_features=24, out_features=24, bias=True)
        (W_v): Linear(in_features=24, out_features=24, bias=True)
        (attention): DotProductAttentionForMultiHeadAttention(
          (dropout): Dropout(p=False, inplace=False)
        )
        (W_o): Linear(in_features=24, out_features=24, bias=True)
      )
      (addnorm2): AddNorm(
        (dropout): Dropout(p=0.5, inplace=False)
        (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)
      )
      (ffn): PositionWiseFFN(
        (dense1): Linear(in_features=24, out_features=48, bias=True)
        (relu): ReLU()
        (dense2): Linear(in_features=48, out_features=24, bias=True)
      )
      (addnorm3): AddNorm(
        (dropout): Dropout(p=0.5, inplace=False)
        (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)
      )
    )
    (block1): DecoderBlock(
      (attention1): MultiHeadAttention(
        (W_q): Linear(in_features=24, out_features=24, bias=True)
        (W_k): Linear(in_features=24, out_features=24, bias=True)
        (W_v): Linear(in_features=24, out_features=24, bias=True)
        (attention): DotProductAttentionForMultiHeadAttention(
          (dropout): Dropout(p=0.5, inplace=False)
        )
        (W_o): Linear(in_features=24, out_features=24, bias=True)
      )
      (addnorm1): AddNorm(
        (dropout): Dropout(p=0.5, inplace=False)
        (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)
      )
      (attention2): MultiHeadAttention(
        (W_q): Linear(in_features=24, out_features=24, bias=True)
        (W_k): Linear(in_features=24, out_features=24, bias=True)
        (W_v): Linear(in_features=24, out_features=24, bias=True)
        (attention): DotProductAttentionForMultiHeadAttention(
          (dropout): Dropout(p=False, inplace=False)
        )
        (W_o): Linear(in_features=24, out_features=24, bias=True)
      )
      (addnorm2): AddNorm(
        (dropout): Dropout(p=0.5, inplace=False)
        (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)
      )
      (ffn): PositionWiseFFN(
        (dense1): Linear(in_features=24, out_features=48, bias=True)
        (relu): ReLU()
        (dense2): Linear(in_features=48, out_features=24, bias=True)
      )
      (addnorm3): AddNorm(
        (dropout): Dropout(p=0.5, inplace=False)
        (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (dense): Linear(in_features=24, out_features=200, bias=True)
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.6.7.-%E5%9F%BA%E4%BA%8ETransformer%E7%9A%84Seq2Seq%E7%BD%91%E7%BB%9C">11.6.7. <a id="toc11_6_7_"></a><a href="#toc0_">TransformerSeq2Seq</a><a class="anchor-link" href="#11.6.7.-%E5%9F%BA%E4%BA%8ETransformer%E7%9A%84Seq2Seq%E7%BD%91%E7%BB%9C"></a></h3><div class="highlight"><pre><span></span>TransformerSeq2Seq
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[255]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>
<span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span>
<span class="n">norm_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">32</span><span class="p">]</span>

<span class="n">train_iter</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_nmt</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">TransformerEncoder</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">),</span> 
    <span class="n">key_size</span><span class="o">=</span><span class="n">key_size</span><span class="p">,</span> 
    <span class="n">query_size</span><span class="o">=</span><span class="n">query_size</span><span class="p">,</span> 
    <span class="n">value_size</span><span class="o">=</span><span class="n">value_size</span><span class="p">,</span> 
    <span class="n">num_hiddens</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span> 
    <span class="n">norm_shape</span><span class="o">=</span><span class="n">norm_shape</span><span class="p">,</span> 
    <span class="n">ffn_num_input</span><span class="o">=</span><span class="n">ffn_num_input</span><span class="p">,</span> 
    <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="n">ffn_num_hiddens</span><span class="p">,</span> 
    <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> 
    <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
<span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">TransformerDecoder</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">tgt_vocab</span><span class="p">),</span> 
    <span class="n">key_size</span><span class="o">=</span><span class="n">key_size</span><span class="p">,</span> 
    <span class="n">query_size</span><span class="o">=</span><span class="n">query_size</span><span class="p">,</span> 
    <span class="n">value_size</span><span class="o">=</span><span class="n">value_size</span><span class="p">,</span> 
    <span class="n">num_hiddens</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span> 
    <span class="n">norm_shape</span><span class="o">=</span><span class="n">norm_shape</span><span class="p">,</span> 
    <span class="n">ffn_num_input</span><span class="o">=</span><span class="n">ffn_num_input</span><span class="p">,</span> 
    <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="n">ffn_num_hiddens</span><span class="p">,</span> 
    <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> 
    <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
<span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">EncoderDecoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>loss 0.028, 4143.0 tokens/sec on cuda:0
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="262.1875pt" height="183.35625pt" viewBox="0 0 262.1875 183.35625" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-12-02T20:47:07.953374</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 183.35625 
L 262.1875 183.35625 
L 262.1875 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 50.14375 145.8 
L 245.44375 145.8 
L 245.44375 7.2 
L 50.14375 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 91.259539 145.8 
L 91.259539 7.2 
" clip-path="url(#pe141f96e72)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_2">
      <defs>
       <path id="mb4ad1e9095" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#mb4ad1e9095" x="91.259539" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- 50 -->
      <g transform="translate(84.897039 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-35"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_3">
      <path d="M 142.654276 145.8 
L 142.654276 7.2 
" clip-path="url(#pe141f96e72)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_4">
      <g>
       <use xlink:href="#mb4ad1e9095" x="142.654276" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 100 -->
      <g transform="translate(133.110526 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_5">
      <path d="M 194.049013 145.8 
L 194.049013 7.2 
" clip-path="url(#pe141f96e72)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_6">
      <g>
       <use xlink:href="#mb4ad1e9095" x="194.049013" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 150 -->
      <g transform="translate(184.505263 160.398438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-35" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_7">
      <path d="M 245.44375 145.8 
L 245.44375 7.2 
" clip-path="url(#pe141f96e72)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_8">
      <g>
       <use xlink:href="#mb4ad1e9095" x="245.44375" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 200 -->
      <g transform="translate(235.9 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-32"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="text_5">
     <!-- epoch -->
     <g transform="translate(132.565625 174.076563) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-68" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 4863 
L 1159 4863 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-65"/>
      <use xlink:href="#DejaVuSans-70" x="61.523438"/>
      <use xlink:href="#DejaVuSans-6f" x="125"/>
      <use xlink:href="#DejaVuSans-63" x="186.181641"/>
      <use xlink:href="#DejaVuSans-68" x="241.162109"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_9">
      <path d="M 50.14375 121.414771 
L 245.44375 121.414771 
" clip-path="url(#pe141f96e72)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_10">
      <defs>
       <path id="me5f1c462a9" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#me5f1c462a9" x="50.14375" y="121.414771" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_6">
      <!-- 0.05 -->
      <g transform="translate(20.878125 125.21399) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_11">
      <path d="M 50.14375 80.797703 
L 245.44375 80.797703 
" clip-path="url(#pe141f96e72)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_12">
      <g>
       <use xlink:href="#me5f1c462a9" x="50.14375" y="80.797703" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 0.10 -->
      <g transform="translate(20.878125 84.596922) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-31" x="95.410156"/>
       <use xlink:href="#DejaVuSans-30" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_13">
      <path d="M 50.14375 40.180635 
L 245.44375 40.180635 
" clip-path="url(#pe141f96e72)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_14">
      <g>
       <use xlink:href="#me5f1c462a9" x="50.14375" y="40.180635" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 0.15 -->
      <g transform="translate(20.878125 43.979854) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-31" x="95.410156"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="text_9">
     <!-- loss -->
     <g transform="translate(14.798437 86.157813) rotate(-90) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-6c" d="M 603 4863 
L 1178 4863 
L 1178 0 
L 603 0 
L 603 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-6c"/>
      <use xlink:href="#DejaVuSans-6f" x="27.783203"/>
      <use xlink:href="#DejaVuSans-73" x="88.964844"/>
      <use xlink:href="#DejaVuSans-73" x="141.064453"/>
     </g>
    </g>
   </g>
   <g id="line2d_15">
    <path d="M 50.14375 13.5 
L 60.422697 59.339173 
L 70.701645 90.318185 
L 80.980592 106.129822 
L 91.259539 114.875161 
L 101.538487 121.97627 
L 111.817434 127.074954 
L 122.096382 128.672284 
L 132.375329 132.465432 
L 142.654276 132.222605 
L 152.933224 133.164896 
L 163.212171 133.930388 
L 173.491118 135.341382 
L 183.770066 135.455867 
L 194.049013 135.868095 
L 204.327961 137.149005 
L 214.606908 137.616142 
L 224.885855 138.320687 
L 235.164803 138.95383 
L 245.44375 139.5 
" clip-path="url(#pe141f96e72)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="patch_3">
    <path d="M 50.14375 145.8 
L 50.14375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 245.44375 145.8 
L 245.44375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 50.14375 145.8 
L 245.44375 145.8 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 50.14375 7.2 
L 245.44375 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="pe141f96e72">
   <rect x="50.14375" y="7.2" width="195.3" height="138.6"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[257]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="n">engs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'go .'</span><span class="p">,</span> <span class="s2">"i lost ."</span><span class="p">,</span> <span class="s1">'he</span><span class="se">\'</span><span class="s1">s calm .'</span><span class="p">,</span> <span class="s1">'i</span><span class="se">\'</span><span class="s1">m home .'</span><span class="p">]</span>
<span class="n">fras</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'va !'</span><span class="p">,</span> <span class="s1">'j</span><span class="se">\'</span><span class="s1">ai perdu .'</span><span class="p">,</span> <span class="s1">'il est calme .'</span><span class="p">,</span> <span class="s1">'je suis chez moi .'</span><span class="p">]</span>

<span class="k">for</span> <span class="n">eng</span><span class="p">,</span> <span class="n">fra</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">):</span>
    <span class="n">translation</span><span class="p">,</span> <span class="n">dec_attention_weight_seq</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">predict_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">eng</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">eng</span><span class="si">}</span><span class="s1"> =&gt; </span><span class="si">{</span><span class="n">translation</span><span class="si">}</span><span class="s1">, '</span><span class="p">,</span>
          <span class="sa">f</span><span class="s1">'bleu </span><span class="si">{</span><span class="n">d2l</span><span class="o">.</span><span class="n">bleu</span><span class="p">(</span><span class="n">translation</span><span class="p">,</span><span class="w"> </span><span class="n">fra</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>go . =&gt; va !,  bleu 1.000
i lost . =&gt; j'ai perdu .,  bleu 1.000
he's calm . =&gt; il est calme .,  bleu 1.000
i'm home . =&gt; je suis chez moi .,  bleu 1.000
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11.7.-BERT">11.7. <a id="toc11_7_"></a><a href="#toc0_">BERT</a><a class="anchor-link" href="#11.7.-BERT"></a></h2><p>BERTBidirectional Encoder Representations from TransformersTransformerGoogle2018BERTTransformerBERTMasked Language ModelNext Sentence Prediction</p>
<ul>
<li><p>Encoder</p>
</li>
<li><p>Base1276812110M</p>
</li>
<li><p>Large24102416340M</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.7.1.-BERT-encode-block">11.7.1. <a id="toc11_7_1_"></a><a href="#toc0_">BERT encode block</a><a class="anchor-link" href="#11.7.1.-BERT-encode-block"></a></h3><p><img alt="BERT" src="./Pytorch_Pictures/BERT/BERT.jpg"/></p>
<ol>
<li>tokenization</li>
<li> '<cls>'  '<sep>'</sep></cls></li>
<li></li>
<li>IDvocabID</li>
<li></li>
<li> BERT </li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">get_tokens_and_segments</span><span class="p">(</span><span class="n">tokens_a</span><span class="p">,</span> <span class="n">tokens_b</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Get tokens of the BERT input sequence and their segment IDs.</span>
<span class="sd">    Args:</span>
<span class="sd">        tokens_a: List[str] </span>
<span class="sd">        tokens_b: List[str] </span>
<span class="sd">    Returns:</span>
<span class="sd">        tokens: List[str] '&lt;cls&gt;''&lt;sep&gt;'</span>
<span class="sd">        segments: List[int] 01</span>
<span class="sd">    """</span>
    <span class="c1"># classification (cls) and separator (sep) tokens are added</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'&lt;cls&gt;'</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokens_a</span> <span class="o">+</span> <span class="p">[</span><span class="s1">'&lt;sep&gt;'</span><span class="p">]</span>
    <span class="c1"># 0 and 1 are marking segment A and B, respectively</span>
    <span class="n">segments</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens_a</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tokens_b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tokens</span> <span class="o">+=</span> <span class="n">tokens_b</span> <span class="o">+</span> <span class="p">[</span><span class="s1">'&lt;sep&gt;'</span><span class="p">]</span>
        <span class="n">segments</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens_b</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">segments</span>


<span class="c1"># </span>
<span class="n">tokens_a</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'You'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'the'</span><span class="p">,</span> <span class="s1">'best'</span><span class="p">]</span>
<span class="n">tokens_b</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'You'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'the'</span><span class="p">,</span> <span class="s1">'worst'</span><span class="p">]</span>

<span class="n">tokens</span><span class="p">,</span> <span class="n">segments</span> <span class="o">=</span> <span class="n">get_tokens_and_segments</span><span class="p">(</span><span class="n">tokens_a</span><span class="p">,</span> <span class="n">tokens_b</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'segments: </span><span class="si">{</span><span class="n">segments</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tokens: ['&lt;cls&gt;', 'You', 'are', 'the', 'best', '&lt;sep&gt;', 'You', 'are', 'the', 'worst', '&lt;sep&gt;']
segments: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>


<span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">BERTEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""BERT encoder."""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">key_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">query_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">value_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BERTEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">segment_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="c1"># TransformerEncoderEncoderBlock</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">EncoderBlock</span><span class="p">(</span><span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
        <span class="c1"># In BERT, positional embeddings are learnable, thus we create a</span>
        <span class="c1"># parameter of positional embeddings that are long enough</span>
        <span class="c1"># nn.Parameter, (1, max_len, num_hiddens)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">):</span>
        <span class="c1"># Shape of `X` remains unchanged in the following code snippet:</span>
        <span class="c1"># (batch size, max sequence length, `num_hiddens`)</span>
        <span class="c1"># </span>
        <span class="c1"># (batch_size, seq_len, num_hiddens) + (batch_size, seq_len, num_hiddens) = (batch_size, seq_len, num_hiddens)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">segment_embedding</span><span class="p">(</span><span class="n">segments</span><span class="p">)</span>
        <span class="c1"># </span>
        <span class="c1"># (batch_size, seq_len, num_hiddens) + (1, seq_len, num_hiddens) = (batch_size, seq_len, num_hiddens)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_embedding</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span>
        <span class="k">for</span> <span class="n">blk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">blk</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>
        <span class="c1"># X: (batch_size, seq_len, num_hiddens)</span>
        <span class="k">return</span> <span class="n">X</span>
    

<span class="c1"># </span>
<span class="c1">#@tab pytorch</span>
<span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">768</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="p">[</span><span class="mi">768</span><span class="p">],</span> <span class="mi">768</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.2</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">BERTEncoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>

<span class="c1">#@tab pytorch</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">8</span>

<span class="n">tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">))</span>
<span class="n">segments</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="n">encoded_X</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> 
<span class="c1"># encoded_X: (batch_size, seq_len, num_hiddens)</span>

<span class="c1"># tokens.shape, segments.shape, encoded_X.shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'tokens.shape: </span><span class="si">{</span><span class="n">tokens</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'segments.shape: </span><span class="si">{</span><span class="n">segments</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'encoded_X.shape: </span><span class="si">{</span><span class="n">encoded_X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tokens.shape: torch.Size([2, 8])
segments.shape: torch.Size([2, 8])
encoded_X.shape: torch.Size([2, 8, 768])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.7.2.-Masked-Language-Modeling">11.7.2. <a id="toc11_7_2_"></a><a href="#toc0_">Masked Language Modeling</a><a class="anchor-link" href="#11.7.2.-Masked-Language-Modeling"></a></h3><p>MaskLM MLP BERT </p>
<ul>
<li></li>
<li><mask></mask></li>
<li></li>
<li><code>BERTEncoder&lt;mask&gt;, mlm_positionsMLP</code></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">import</span> <span class="nn">torch</span> 


<span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">MaskLM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""The masked language model task of BERT."""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MaskLM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span> <span class="c1">#  (batch_size, num_pred_positions, vocab_size)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">pred_positions</span><span class="p">):</span>
        <span class="c1"># pred_positions: (batch_size, num_pred_positions)</span>
        <span class="n">num_pred_positions</span> <span class="o">=</span> <span class="n">pred_positions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># ,  (batch_size * num_pred_positions), e.g., torch.tensor([1, 5, 2, 6, 1, 5])</span>
        <span class="n">pred_positions</span> <span class="o">=</span> <span class="n">pred_positions</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># </span>
        <span class="c1">## X: (batch_size, seq_len, num_hiddens)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1">## batch_size            </span>
        <span class="n">batch_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span> 
        <span class="c1">## Suppose that `batch_size` = 2, `num_pred_positions` = 3, then `batch_idx` is `torch.tensor([0, 0, 0, 1, 1, 1])`</span>
        <span class="n">batch_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">batch_idx</span><span class="p">,</span> <span class="n">num_pred_positions</span><span class="p">)</span>

        <span class="c1"># batch_idxpred_positionsX</span>
        <span class="c1">## masked_X: (batch_size * num_pred_positions, num_hiddens), encoded_X[[0, 0, 0, 1, 1, 1], [1, 5, 2, 6, 1, 5]]</span>
        <span class="n">masked_X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">,</span> <span class="n">pred_positions</span><span class="p">]</span>
        <span class="c1">## masked_X: (batch_size, num_pred_positions, num_hiddens)</span>
        <span class="n">masked_X</span> <span class="o">=</span> <span class="n">masked_X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_pred_positions</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1">## (batch_size, num_pred_positions, vocab_size)</span>
        <span class="n">mlm_Y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">masked_X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mlm_Y_hat</span>
    

<span class="c1"># </span>
<span class="c1">#@tab pytorch</span>
<span class="n">mlm</span> <span class="o">=</span> <span class="n">MaskLM</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>

<span class="n">mlm_positions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>    <span class="c1"># (batch_size, num_pred_positions)</span>

<span class="c1"># encoded_X: (batch_size, seq_len, num_hiddens)</span>
<span class="c1"># mlm_positions: (batch_size, num_pred_positions)</span>
<span class="c1"># mlm_Y_hat: (batch_size, num_pred_positions, vocab_size)</span>
<span class="n">mlm_Y_hat</span> <span class="o">=</span> <span class="n">mlm</span><span class="p">(</span><span class="n">encoded_X</span><span class="p">,</span> <span class="n">mlm_positions</span><span class="p">)</span>               

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'encoded_X.shape: </span><span class="si">{</span><span class="n">encoded_X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'mlm_positions.shape: </span><span class="si">{</span><span class="n">mlm_positions</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'mlm_Y_hat.shape: </span><span class="si">{</span><span class="n">mlm_Y_hat</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>encoded_X.shape: torch.Size([2, 8, 768])
mlm_positions.shape: torch.Size([2, 3])
mlm_Y_hat.shape: torch.Size([2, 3, 10000])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="n">mlm_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">]])</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">'none'</span><span class="p">)</span>

<span class="n">mlm_l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">mlm_Y_hat</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)),</span> <span class="n">mlm_Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

<span class="n">mlm_l</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[4]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([6])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.7.3.-Next-Sentence-Prediction">11.7.3. <a id="toc11_7_3_"></a><a href="#toc0_">Next Sentence Prediction</a><a class="anchor-link" href="#11.7.3.-Next-Sentence-Prediction"></a></h3><p>NextSentencePred  BERT  BERT  Masked Language ModelingMLM NSP  NSP </p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">NextSentencePred</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""The next sentence prediction task of BERT."""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NextSentencePred</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># `X` shape: (batch size, `num_hiddens`)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    

<span class="c1"># </span>
<span class="c1"># PyTorch by default won't flatten the tensor as seen in mxnet where, if flatten=True, all but the first axis of input data are collapsed together</span>
<span class="c1">## encoded_X: (batch_size, seq_len, num_hiddens)</span>
<span class="c1">## flattened_encoded_X: (batch_size, seq_len * num_hiddens)</span>
<span class="n">encoded_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">encoded_X</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># input_shape for NSP: (batch size, `num_hiddens`)</span>
<span class="n">nsp</span> <span class="o">=</span> <span class="n">NextSentencePred</span><span class="p">(</span><span class="n">encoded_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># encoded_X: (batch_size, seq_len * num_hiddens)</span>
<span class="c1"># nsp_Y_hat: (batch_size, 2)</span>
<span class="n">nsp_Y_hat</span> <span class="o">=</span> <span class="n">nsp</span><span class="p">(</span><span class="n">encoded_X</span><span class="p">)</span> 

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'encoded_X.shape: </span><span class="si">{</span><span class="n">encoded_X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'nsp_Y_hat.shape: </span><span class="si">{</span><span class="n">nsp_Y_hat</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>encoded_X.shape: torch.Size([2, 6144])
nsp_Y_hat.shape: torch.Size([2, 2])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="n">nsp_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">nsp_l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">nsp_Y_hat</span><span class="p">,</span> <span class="n">nsp_y</span><span class="p">)</span>

<span class="n">nsp_l</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[6]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.7.4.-BERT%E6%A8%A1%E5%9E%8B">11.7.4. <a id="toc11_7_4_"></a><a href="#toc0_">BERT</a><a class="anchor-link" href="#11.7.4.-BERT%E6%A8%A1%E5%9E%8B"></a></h3><p><img alt="BERT" src="./Pytorch_Pictures/BERT/BERT_model.jpg"/></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">BERTModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""The BERT model."""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">key_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">query_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">value_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">hid_in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">mlm_in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">nsp_in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BERTModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">BERTEncoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">key_size</span><span class="o">=</span><span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="o">=</span><span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="o">=</span><span class="n">value_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hid_in_features</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlm</span> <span class="o">=</span> <span class="n">MaskLM</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">mlm_in_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nsp</span> <span class="o">=</span> <span class="n">NextSentencePred</span><span class="p">(</span><span class="n">nsp_in_features</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="n">valid_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pred_positions</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># tokens: (batch_size, seq_len)</span>
        <span class="c1"># segments: (batch_size, seq_len)</span>
        <span class="c1"># valid_lens: (batch_size,)</span>
        <span class="c1"># pred_positions: (batch_size, num_pred_positions)</span>
        <span class="c1"># encoded_X: (batch_size, seq_len, num_hiddens)</span>
        <span class="n">encoded_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">pred_positions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># mlm_Y_hat: (batch_size, num_pred_positions, vocab_size)</span>
            <span class="n">mlm_Y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlm</span><span class="p">(</span><span class="n">encoded_X</span><span class="p">,</span> <span class="n">pred_positions</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mlm_Y_hat</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># The hidden layer of the MLP classifier for next sentence prediction. 0 is the index of the '&lt;cls&gt;' token</span>
        <span class="n">nsp_Y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nsp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">encoded_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]))</span>
        <span class="c1"># encoded_X: (batch_size, seq_len, num_hiddens)</span>
        <span class="c1"># mlm_Y_hat: (batch_size, num_pred_positions, vocab_size)</span>
        <span class="c1"># nsp_Y_hat: (batch_size, 2)</span>
        <span class="k">return</span> <span class="n">encoded_X</span><span class="p">,</span> <span class="n">mlm_Y_hat</span><span class="p">,</span> <span class="n">nsp_Y_hat</span>
    

<span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.7.5.-Datasets-for-Pre-training">11.7.5. <a id="toc11_7_5_"></a><a href="#toc0_">Datasets for Pre-training</a><a class="anchor-link" href="#11.7.5.-Datasets-for-Pre-training"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 
<span class="kn">import</span> <span class="nn">os</span> 
<span class="kn">import</span> <span class="nn">random</span>


<span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">DATA_HUB</span><span class="p">[</span><span class="s1">'wikitext-2'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s1">'https://s3.amazonaws.com/research.metamind.io/wikitext/'</span>
    <span class="s1">'wikitext-2-v1.zip'</span><span class="p">,</span> <span class="s1">'3c914d17d80b1459be871a5039ac23e752a53cbe'</span><span class="p">)</span>

<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">_read_wiki</span><span class="p">(</span><span class="n">data_dir</span><span class="p">):</span>
    <span class="c1"># file_name = os.path.join(data_dir, 'wiki.train.tokens')</span>
    <span class="c1"># with open(file_name, 'r') as f:</span>
    <span class="c1">#     lines = f.readlines()</span>
    <span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'train-00000-of-00001.parquet'</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="c1"># </span>
    <span class="n">paragraphs</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' . '</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' . '</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">paragraphs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">paragraphs</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.7.5.1.-%E7%94%9F%E6%88%90%E4%B8%8B%E4%B8%80%E5%8F%A5%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%95%B0%E6%8D%AE">11.7.5.1. <a id="toc11_7_5_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.7.5.1.-%E7%94%9F%E6%88%90%E4%B8%8B%E4%B8%80%E5%8F%A5%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%95%B0%E6%8D%AE"></a></h4><p> BERTNSP</p>
<p> _get_next_sentence </p>
<ul>
<li>50% next_sentence  sentence  is_next=True</li>
<li>50% next_sentence  is_next=False
</li>
</ul>
<p> _get_nsp_data_from_paragraph </p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">_get_next_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">next_sentence</span><span class="p">,</span> <span class="n">paragraphs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        sentence: </span>
<span class="sd">        next_sentence: </span>
<span class="sd">        paragraphs: </span>
<span class="sd">    Returns:</span>
<span class="sd">        sentence: </span>
<span class="sd">        next_sentence: </span>
<span class="sd">        is_next: </span>
<span class="sd">    '''</span>
    <span class="c1"># 1.  random.random()  [0,1)  0.5 is_next  True</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">is_next</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1">#  paragraphs  next_sentence</span>
        <span class="c1">##  is_next  False next_sentence  sentence </span>
        <span class="c1"># paragraphs</span>
        <span class="n">next_sentence</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">paragraphs</span><span class="p">))</span>
        <span class="n">is_next</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">next_sentence</span><span class="p">,</span> <span class="n">is_next</span>


<span class="c1"># </span>
<span class="n">paragraphs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[[</span><span class="s2">"1A"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"1B"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"1C"</span><span class="p">]],</span>
    <span class="p">[[</span><span class="s2">"2A"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"2B"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"2C"</span><span class="p">]],</span>
    <span class="p">[[</span><span class="s2">"3A"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"3B"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"3C"</span><span class="p">]]</span>
<span class="p">]</span>
<span class="n">sentence</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"1A"</span><span class="p">]</span>
<span class="n">next_sentence</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"1B"</span><span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">_get_next_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">next_sentence</span><span class="p">,</span> <span class="n">paragraphs</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>(['1A'], ['1A'], False)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">_get_nsp_data_from_paragraph</span><span class="p">(</span><span class="n">paragraph</span><span class="p">,</span> <span class="n">paragraphs</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">max_len</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''' </span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        paragraph: , </span>
<span class="sd">        paragraphs: , </span>
<span class="sd">        vocab: , </span>
<span class="sd">        max_len: ,  &lt;cls&gt;  &lt;sep&gt;</span>
<span class="sd">    Returns:</span>
<span class="sd">        nsp_data_from_paragraph: </span>
<span class="sd">    '''</span>
    <span class="n">nsp_data_from_paragraph</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># </span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">paragraph</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">tokens_a</span><span class="p">,</span> <span class="n">tokens_b</span><span class="p">,</span> <span class="n">is_next</span> <span class="o">=</span> <span class="n">_get_next_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="o">=</span><span class="n">paragraph</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">next_sentence</span><span class="o">=</span><span class="n">paragraph</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">paragraphs</span><span class="o">=</span><span class="n">paragraphs</span><span class="p">)</span>
        <span class="c1"># 1'&lt;cls&gt;'2'&lt;sep&gt;'</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens_a</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens_b</span><span class="p">)</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">&gt;</span> <span class="n">max_len</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">tokens</span><span class="p">,</span> <span class="n">segments</span> <span class="o">=</span> <span class="n">get_tokens_and_segments</span><span class="p">(</span><span class="n">tokens_a</span><span class="p">,</span> <span class="n">tokens_b</span><span class="p">)</span>
        <span class="n">nsp_data_from_paragraph</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tokens</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="n">is_next</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">nsp_data_from_paragraph</span>


<span class="c1"># </span>
<span class="n">paragraphs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[[</span><span class="s2">"1A"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"1B"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"1C"</span><span class="p">]],</span>
    <span class="p">[[</span><span class="s2">"2A"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"2B"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"2C"</span><span class="p">]],</span>
    <span class="p">[[</span><span class="s2">"3A"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"3B"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"3C"</span><span class="p">]]</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">_get_nsp_data_from_paragraph</span><span class="p">(</span><span class="n">paragraph</span><span class="o">=</span><span class="n">paragraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">paragraphs</span><span class="o">=</span><span class="n">paragraphs</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'nsp_data_from_paragraph: </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>nsp_data_from_paragraph: [(['&lt;cls&gt;', '1A', '&lt;sep&gt;', '1B', '&lt;sep&gt;'], [0, 0, 0, 1, 1], True), (['&lt;cls&gt;', '1B', '&lt;sep&gt;', '1C', '&lt;sep&gt;'], [0, 0, 0, 1, 1], True)]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.7.5.2.-%E7%94%9F%E6%88%90%E9%81%AE%E8%94%BD%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%95%B0%E6%8D%AE">11.7.5.2. <a id="toc11_7_5_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.7.5.2.-%E7%94%9F%E6%88%90%E9%81%AE%E8%94%BD%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%95%B0%E6%8D%AE"></a></h4><p> _replace_mlm_tokens Masked Language Model, MLM <mask> BERT<br/>
 _replace_mlm_tokens MLMBERT</mask></p>
<ul>
<li>80%  <mask></mask></li>
<li>10% </li>
<li>10% </li>
</ul>
<p></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[148]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">_replace_mlm_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">candidate_pred_positions</span><span class="p">,</span> <span class="n">num_mlm_preds</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''' </span>
<span class="sd">    &lt;mask&gt;</span>
<span class="sd">    Args:</span>
<span class="sd">        tokens :list: </span>
<span class="sd">        candidate_pred_positions :list: </span>
<span class="sd">        num_mlm_preds :int: </span>
<span class="sd">        vocab :Vocab: idx_to_token</span>
<span class="sd">    Returns:</span>
<span class="sd">        mlm_input_tokens: </span>
<span class="sd">        pred_positions_and_labels: </span>
<span class="sd">    '''</span>
    <span class="c1"># </span>
    <span class="n">mlm_input_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
    <span class="c1"># </span>
    <span class="n">pred_positions_and_labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># 15%</span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">candidate_pred_positions</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">mlm_pred_position</span> <span class="ow">in</span> <span class="n">candidate_pred_positions</span><span class="p">:</span>
        <span class="c1"># num_mlm_preds</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_positions_and_labels</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">num_mlm_preds</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">masked_token</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># 80%&lt;mask&gt;</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.8</span><span class="p">:</span>
            <span class="n">masked_token</span> <span class="o">=</span> <span class="s1">'&lt;mask&gt;'</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># 10%</span>
            <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">masked_token</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="n">mlm_pred_position</span><span class="p">]</span>
            <span class="c1"># 10%</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">masked_token</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">)</span>
        <span class="c1"># : </span>
        <span class="n">mlm_input_tokens</span><span class="p">[</span><span class="n">mlm_pred_position</span><span class="p">]</span> <span class="o">=</span> <span class="n">masked_token</span>
        <span class="c1">#    </span>
        <span class="n">pred_positions_and_labels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">mlm_pred_position</span><span class="p">,</span> <span class="n">tokens</span><span class="p">[</span><span class="n">mlm_pred_position</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">mlm_input_tokens</span><span class="p">,</span> <span class="n">pred_positions_and_labels</span>


<span class="c1"># </span>
<span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'&lt;cls&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">'&lt;sep&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">'&lt;sep&gt;'</span><span class="p">]</span>
<span class="c1"># 1234</span>
<span class="n">candidate_pred_positions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="c1"># </span>
<span class="n">num_mlm_preds</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">_replace_mlm_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="o">=</span><span class="n">tokens</span><span class="p">,</span> <span class="n">candidate_pred_positions</span><span class="o">=</span><span class="n">candidate_pred_positions</span><span class="p">,</span> <span class="n">num_mlm_preds</span><span class="o">=</span><span class="n">num_mlm_preds</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'tokens: </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'mlm_input_tokens: </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'pred_positions_and_labels: </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tokens: 	 ['&lt;cls&gt;', '', '', '', '', '', '', '', '&lt;sep&gt;', '', '', '', '', '&lt;sep&gt;']
mlm_input_tokens: 	 ['&lt;cls&gt;', '&lt;mask&gt;', '', '&lt;mask&gt;', '&lt;unk&gt;', '', '', '', '&lt;sep&gt;', '', '', '', '', '&lt;sep&gt;']
pred_positions_and_labels: 	 [(1, ''), (3, ''), (4, '')]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>15%<ul>
<li>15%80%<code>&lt;mask&gt;</code></li>
<li>10%<code></code></li>
<li>10%<code></code></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[162]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">_get_mlm_data_from_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''' </span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        tokens :list: </span>
<span class="sd">        vocab :Vocab: idx_to_token</span>
<span class="sd">    Returns:</span>
<span class="sd">        vocab[mlm_input_tokens]</span>
<span class="sd">        pred_positions</span>
<span class="sd">        vocab[mlm_pred_labels]</span>
<span class="sd">    '''</span>
    <span class="c1"># </span>
    <span class="n">candidate_pred_positions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># </span>
    <span class="c1">## tokens</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
        <span class="c1"># </span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'&lt;cls&gt;'</span><span class="p">,</span> <span class="s1">'&lt;sep&gt;'</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="n">candidate_pred_positions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="c1"># 15%</span>
    <span class="n">num_mlm_preds</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.15</span><span class="p">))</span>
    <span class="c1"># </span>
    <span class="n">mlm_input_tokens</span><span class="p">,</span> <span class="n">pred_positions_and_labels</span> <span class="o">=</span> <span class="n">_replace_mlm_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">candidate_pred_positions</span><span class="p">,</span> <span class="n">num_mlm_preds</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>
    <span class="c1"># ,</span>
    <span class="n">pred_positions_and_labels</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pred_positions_and_labels</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1"># </span>
    <span class="c1">## pred_positions</span>
    <span class="n">pred_positions</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pred_positions_and_labels</span><span class="p">]</span>
    <span class="c1">## mlm_pred_labels</span>
    <span class="n">mlm_pred_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pred_positions_and_labels</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">vocab</span><span class="p">[</span><span class="n">mlm_input_tokens</span><span class="p">],</span> <span class="n">pred_positions</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="n">mlm_pred_labels</span><span class="p">]</span>


<span class="c1"># </span>
<span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'&lt;cls&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">'&lt;sep&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">'&lt;sep&gt;'</span><span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">_get_mlm_data_from_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="o">=</span><span class="n">tokens</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'mlm_input_tokens: </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'pred_positions: </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'mlm_pred_labels: </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>mlm_input_tokens: 	 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
pred_positions: 	 [4, 9]
mlm_pred_labels: 	 [0, 0]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.7.5.3.-%E5%B0%86%E6%96%87%E6%9C%AC%E8%BD%AC%E6%8D%A2%E4%B8%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86">11.7.5.3. <a id="toc11_7_5_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.7.5.3.-%E5%B0%86%E6%96%87%E6%9C%AC%E8%BD%AC%E6%8D%A2%E4%B8%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86"></a></h4><p> _pad_bert_inputs BERT<code></code> MLM  NSP<code></code></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[167]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">_pad_bert_inputs</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''' </span>
<span class="sd">    BERT MLM  NSP</span>
<span class="sd">    Args:</span>
<span class="sd">        examples :list:  </span>
<span class="sd">                        - token_idsID</span>
<span class="sd">                        - pred_positions</span>
<span class="sd">                        - mlm_pred_label_ids</span>
<span class="sd">                        - segmentsID</span>
<span class="sd">                        - is_next</span>
<span class="sd">        max_len :int:  &lt;cls&gt;  &lt;sep&gt;,</span>
<span class="sd">        vocab :Vocab: idx_to_token</span>
<span class="sd">    Returns:</span>
<span class="sd">        all_token_ids, all_segments, valid_lens, all_pred_positions, all_mlm_weights, all_mlm_labels, nsp_labels</span>
<span class="sd">    '''</span>
    <span class="c1">#  max_len 15%</span>
    <span class="n">max_num_mlm_preds</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">max_len</span> <span class="o">*</span> <span class="mf">0.15</span><span class="p">)</span>
    <span class="c1"># </span>
    <span class="c1">## all_token_ids: </span>
    <span class="c1">## all_segments: ID</span>
    <span class="c1">## valid_lens: '&lt;pad&gt;'    </span>
    <span class="n">all_token_ids</span><span class="p">,</span> <span class="n">all_segments</span><span class="p">,</span> <span class="n">valid_lens</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="c1">## all_pred_positions: </span>
    <span class="c1">## all_mlm_weights: </span>
    <span class="c1">## all_mlm_labels: </span>
    <span class="n">all_pred_positions</span><span class="p">,</span> <span class="n">all_mlm_weights</span><span class="p">,</span> <span class="n">all_mlm_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="c1">## nsp_labels: </span>
    <span class="n">nsp_labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">pred_positions</span><span class="p">,</span> <span class="n">mlm_pred_label_ids</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="n">is_next</span><span class="p">)</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
        <span class="c1"># :  token_ids  max_len &lt;pad&gt; </span>
        <span class="n">all_token_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">token_ids</span> <span class="o">+</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>
        <span class="c1"># ID:  segments  max_len0</span>
        <span class="n">all_segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">segments</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">segments</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>
        <span class="c1"># valid_lens:  &lt;pad&gt; </span>
        <span class="n">valid_lens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="c1"># :  pred_positions  max_num_mlm_preds0</span>
        <span class="n">all_pred_positions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">pred_positions</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_num_mlm_preds</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_positions</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>
        <span class="c1"># MLM :  1.0 0.0</span>
        <span class="n">all_mlm_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">mlm_pred_label_ids</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_num_mlm_preds</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_positions</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="c1"># MLM :  0 </span>
        <span class="n">all_mlm_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mlm_pred_label_ids</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_num_mlm_preds</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">mlm_pred_label_ids</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>
        <span class="c1"># NSP :  0  1</span>
        <span class="n">nsp_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">is_next</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">all_token_ids</span><span class="p">,</span> <span class="n">all_segments</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">,</span> <span class="n">all_pred_positions</span><span class="p">,</span> <span class="n">all_mlm_weights</span><span class="p">,</span> <span class="n">all_mlm_labels</span><span class="p">,</span> <span class="n">nsp_labels</span><span class="p">)</span>


<span class="c1"># </span>
<span class="n">examples</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="kc">True</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">_pad_bert_inputs</span><span class="p">(</span><span class="n">examples</span><span class="o">=</span><span class="n">examples</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'all_token_ids: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'all_segments: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'valid_lens: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'all_pred_positions: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'all_mlm_weights: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'all_mlm_labels: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'nsp_labels: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>all_token_ids: [tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])]
all_segments: [tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])]
valid_lens: [tensor(10.)]
all_pred_positions: [tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])]
all_mlm_weights: [tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])]
all_mlm_labels: [tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])]
nsp_labels: [tensor(1)]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.7.5.4.-%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E9%9B%86">11.7.5.4. <a id="toc11_7_5_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.7.5.4.-%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E9%9B%86"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[172]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">_WikiTextDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">paragraphs</span><span class="p">,</span> <span class="n">max_len</span><span class="p">):</span>
        <span class="c1"># paragraphs[i]</span>
        <span class="c1"># paragraphs[i]</span>
        <span class="n">paragraphs</span> <span class="o">=</span> <span class="p">[</span><span class="n">d2l</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">paragraph</span><span class="p">,</span> <span class="n">token</span><span class="o">=</span><span class="s1">'word'</span><span class="p">)</span> <span class="k">for</span> <span class="n">paragraph</span> <span class="ow">in</span> <span class="n">paragraphs</span><span class="p">]</span>
        <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span> <span class="k">for</span> <span class="n">paragraph</span> <span class="ow">in</span> <span class="n">paragraphs</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">paragraph</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">reserved_tokens</span><span class="o">=</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">,</span> <span class="s1">'&lt;mask&gt;'</span><span class="p">,</span> <span class="s1">'&lt;cls&gt;'</span><span class="p">,</span> <span class="s1">'&lt;sep&gt;'</span><span class="p">])</span>
        <span class="c1"># </span>
        <span class="n">examples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">paragraph</span> <span class="ow">in</span> <span class="n">paragraphs</span><span class="p">:</span>
            <span class="n">examples</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">_get_nsp_data_from_paragraph</span><span class="p">(</span><span class="n">paragraph</span><span class="p">,</span> <span class="n">paragraphs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">max_len</span><span class="p">))</span>
        <span class="c1"># </span>
        <span class="n">examples</span> <span class="o">=</span> <span class="p">[(</span><span class="n">_get_mlm_data_from_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">segments</span><span class="p">,</span> <span class="n">is_next</span><span class="p">))</span>
                     <span class="k">for</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="n">is_next</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">]</span>
        <span class="c1"># </span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_token_ids</span><span class="p">,</span> 
         <span class="bp">self</span><span class="o">.</span><span class="n">all_segments</span><span class="p">,</span> 
         <span class="bp">self</span><span class="o">.</span><span class="n">valid_lens</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">all_pred_positions</span><span class="p">,</span> 
         <span class="bp">self</span><span class="o">.</span><span class="n">all_mlm_weights</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">all_mlm_labels</span><span class="p">,</span> 
         <span class="bp">self</span><span class="o">.</span><span class="n">nsp_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">_pad_bert_inputs</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_token_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">all_segments</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">valid_lens</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">all_pred_positions</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">all_mlm_weights</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">all_mlm_labels</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nsp_labels</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_token_ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[173]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">load_data_wiki</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_len</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""WikiText-2"""</span>
    <span class="n">num_workers</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">get_dataloader_workers</span><span class="p">()</span>
    <span class="c1"># data_dir = d2l.download_extract('wikitext-2', 'wikitext-2')</span>
    <span class="n">data_dir</span> <span class="o">=</span> <span class="s1">'./data/wikipedia_text'</span>
    <span class="n">paragraphs</span> <span class="o">=</span> <span class="n">_read_wiki</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="n">_WikiTextDataset</span><span class="p">(</span><span class="n">paragraphs</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
    <span class="n">train_iter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">train_set</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[174]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">max_len</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">64</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">load_data_wiki</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>

<span class="k">for</span> <span class="p">(</span><span class="n">tokens_X</span><span class="p">,</span> <span class="n">segments_X</span><span class="p">,</span> <span class="n">valid_lens_x</span><span class="p">,</span> <span class="n">pred_positions_X</span><span class="p">,</span> <span class="n">mlm_weights_X</span><span class="p">,</span> <span class="n">mlm_Y</span><span class="p">,</span> <span class="n">nsp_y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tokens_X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> 
          <span class="n">segments_X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> 
          <span class="n">valid_lens_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
          <span class="n">pred_positions_X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> 
          <span class="n">mlm_weights_X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> 
          <span class="n">mlm_Y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
          <span class="n">nsp_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([512, 64]) torch.Size([512, 64]) torch.Size([512]) torch.Size([512, 10]) torch.Size([512, 10]) torch.Size([512, 10]) torch.Size([512])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[175]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[175]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>20256</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.7.6.-%E9%A2%84%E8%AE%AD%E7%BB%83BERT">11.7.6. <a id="toc11_7_6_"></a><a href="#toc0_">BERT</a><a class="anchor-link" href="#11.7.6.-%E9%A2%84%E8%AE%AD%E7%BB%83BERT"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[176]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_len</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">64</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">load_data_wiki</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[177]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch, paddle</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">BERTModel</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> 
                <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
                <span class="n">norm_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">128</span><span class="p">],</span>
                <span class="n">ffn_num_input</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
                <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> 
                <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
                <span class="n">key_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
                <span class="n">query_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                <span class="n">value_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
                <span class="n">hid_in_features</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
                <span class="n">mlm_in_features</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                <span class="n">nsp_in_features</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">devices</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_all_gpus</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[181]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">_get_batch_loss_bert</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">tokens_X</span><span class="p">,</span> <span class="n">segments_X</span><span class="p">,</span> <span class="n">valid_lens_x</span><span class="p">,</span> <span class="n">pred_positions_X</span><span class="p">,</span> <span class="n">mlm_weights_X</span><span class="p">,</span> <span class="n">mlm_Y</span><span class="p">,</span> <span class="n">nsp_y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''' </span>
<span class="sd">    BERT</span>
<span class="sd">    Args:</span>
<span class="sd">        net :BERTModel: BERT</span>
<span class="sd">        loss :nn.CrossEntropyLoss: </span>
<span class="sd">        vocab_size :int: </span>
<span class="sd">        tokens_X :torch.Tensor: </span>
<span class="sd">        segments_X :torch.Tensor: ID</span>
<span class="sd">        valid_lens_x :torch.Tensor: </span>
<span class="sd">    Returns:</span>
<span class="sd">        mlm_l :torch.Tensor: </span>
<span class="sd">        nsp_l :torch.Tensor: </span>
<span class="sd">        l :torch.Tensor: </span>
<span class="sd">    '''</span>
    <span class="c1"># </span>
    <span class="n">_</span><span class="p">,</span> <span class="n">mlm_Y_hat</span><span class="p">,</span> <span class="n">nsp_Y_hat</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">tokens_X</span><span class="p">,</span> <span class="n">segments_X</span><span class="p">,</span> <span class="n">valid_lens_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">pred_positions_X</span><span class="p">)</span>
    <span class="c1"># </span>
    <span class="n">mlm_l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">mlm_Y_hat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">mlm_Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">mlm_weights_X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">mlm_l</span> <span class="o">=</span> <span class="n">mlm_l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">mlm_weights_X</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
    <span class="c1"># </span>
    <span class="n">nsp_l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">nsp_Y_hat</span><span class="p">,</span> <span class="n">nsp_y</span><span class="p">)</span>
    <span class="n">l</span> <span class="o">=</span> <span class="n">mlm_l</span> <span class="o">+</span> <span class="n">nsp_l</span>
    <span class="k">return</span> <span class="n">mlm_l</span><span class="p">,</span> <span class="n">nsp_l</span><span class="p">,</span> <span class="n">l</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[183]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="k">def</span> <span class="nf">train_bert</span><span class="p">(</span><span class="n">train_iter</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">devices</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="n">devices</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">step</span><span class="p">,</span> <span class="n">timer</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
    <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">'step'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'loss'</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">],</span> <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">'mlm'</span><span class="p">,</span> <span class="s1">'nsp'</span><span class="p">])</span>
    <span class="c1"># </span>
    <span class="n">metric</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Accumulator</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">num_steps_reached</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">while</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="n">num_steps</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">num_steps_reached</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">tokens_X</span><span class="p">,</span> <span class="n">segments_X</span><span class="p">,</span> <span class="n">valid_lens_x</span><span class="p">,</span> <span class="n">pred_positions_X</span><span class="p">,</span> <span class="n">mlm_weights_X</span><span class="p">,</span> <span class="n">mlm_Y</span><span class="p">,</span> <span class="n">nsp_y</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
            <span class="n">tokens_X</span> <span class="o">=</span> <span class="n">tokens_X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">segments_X</span> <span class="o">=</span> <span class="n">segments_X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">valid_lens_x</span> <span class="o">=</span> <span class="n">valid_lens_x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">pred_positions_X</span> <span class="o">=</span> <span class="n">pred_positions_X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">mlm_weights_X</span> <span class="o">=</span> <span class="n">mlm_weights_X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">mlm_Y</span><span class="p">,</span> <span class="n">nsp_y</span> <span class="o">=</span> <span class="n">mlm_Y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">nsp_y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="n">mlm_l</span><span class="p">,</span> <span class="n">nsp_l</span><span class="p">,</span> <span class="n">l</span> <span class="o">=</span> <span class="n">_get_batch_loss_bert</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">tokens_X</span><span class="p">,</span> <span class="n">segments_X</span><span class="p">,</span> <span class="n">valid_lens_x</span><span class="p">,</span> <span class="n">pred_positions_X</span><span class="p">,</span> <span class="n">mlm_weights_X</span><span class="p">,</span> <span class="n">mlm_Y</span><span class="p">,</span> <span class="n">nsp_y</span><span class="p">)</span>
            <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">metric</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mlm_l</span><span class="p">,</span> <span class="n">nsp_l</span><span class="p">,</span> <span class="n">tokens_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">metric</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">metric</span><span class="p">[</span><span class="mi">3</span><span class="p">]))</span>
            <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">==</span> <span class="n">num_steps</span><span class="p">:</span>
                <span class="n">num_steps_reached</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">break</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'MLM loss </span><span class="si">{</span><span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">metric</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, '</span>
          <span class="sa">f</span><span class="s1">'NSP loss </span><span class="si">{</span><span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">metric</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">metric</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">timer</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1"> sentence pairs/sec on '</span>
          <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">devices</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    

<span class="c1">#@tab mxnet, pytorch</span>
<span class="c1"># train_bert(train_iter, net, loss, len(vocab), devices, 100000)</span>
<span class="n">train_bert</span><span class="p">(</span><span class="n">train_iter</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">devices</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>MLM loss 5.186, NSP loss 0.710
7029.2 sentence pairs/sec on [device(type='cuda', index=0), device(type='cuda', index=1)]
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="246.284375pt" height="183.35625pt" viewBox="0 0 246.284375 183.35625" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-12-04T16:46:42.723398</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 183.35625 
L 246.284375 183.35625 
L 246.284375 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 34.240625 145.8 
L 229.540625 145.8 
L 229.540625 7.2 
L 34.240625 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 71.722443 145.8 
L 71.722443 7.2 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_2">
      <defs>
       <path id="ma9d9d08dda" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#ma9d9d08dda" x="71.722443" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- 20 -->
      <g transform="translate(65.359943 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-32"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_3">
      <path d="M 111.176989 145.8 
L 111.176989 7.2 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_4">
      <g>
       <use xlink:href="#ma9d9d08dda" x="111.176989" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 40 -->
      <g transform="translate(104.814489 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-34"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_5">
      <path d="M 150.631534 145.8 
L 150.631534 7.2 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_6">
      <g>
       <use xlink:href="#ma9d9d08dda" x="150.631534" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 60 -->
      <g transform="translate(144.269034 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-36" d="M 2113 2584 
Q 1688 2584 1439 2293 
Q 1191 2003 1191 1497 
Q 1191 994 1439 701 
Q 1688 409 2113 409 
Q 2538 409 2786 701 
Q 3034 994 3034 1497 
Q 3034 2003 2786 2293 
Q 2538 2584 2113 2584 
z
M 3366 4563 
L 3366 3988 
Q 3128 4100 2886 4159 
Q 2644 4219 2406 4219 
Q 1781 4219 1451 3797 
Q 1122 3375 1075 2522 
Q 1259 2794 1537 2939 
Q 1816 3084 2150 3084 
Q 2853 3084 3261 2657 
Q 3669 2231 3669 1497 
Q 3669 778 3244 343 
Q 2819 -91 2113 -91 
Q 1303 -91 875 529 
Q 447 1150 447 2328 
Q 447 3434 972 4092 
Q 1497 4750 2381 4750 
Q 2619 4750 2861 4703 
Q 3103 4656 3366 4563 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-36"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_7">
      <path d="M 190.08608 145.8 
L 190.08608 7.2 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_8">
      <g>
       <use xlink:href="#ma9d9d08dda" x="190.08608" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 80 -->
      <g transform="translate(183.72358 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-38" d="M 2034 2216 
Q 1584 2216 1326 1975 
Q 1069 1734 1069 1313 
Q 1069 891 1326 650 
Q 1584 409 2034 409 
Q 2484 409 2743 651 
Q 3003 894 3003 1313 
Q 3003 1734 2745 1975 
Q 2488 2216 2034 2216 
z
M 1403 2484 
Q 997 2584 770 2862 
Q 544 3141 544 3541 
Q 544 4100 942 4425 
Q 1341 4750 2034 4750 
Q 2731 4750 3128 4425 
Q 3525 4100 3525 3541 
Q 3525 3141 3298 2862 
Q 3072 2584 2669 2484 
Q 3125 2378 3379 2068 
Q 3634 1759 3634 1313 
Q 3634 634 3220 271 
Q 2806 -91 2034 -91 
Q 1263 -91 848 271 
Q 434 634 434 1313 
Q 434 1759 690 2068 
Q 947 2378 1403 2484 
z
M 1172 3481 
Q 1172 3119 1398 2916 
Q 1625 2713 2034 2713 
Q 2441 2713 2670 2916 
Q 2900 3119 2900 3481 
Q 2900 3844 2670 4047 
Q 2441 4250 2034 4250 
Q 1625 4250 1398 4047 
Q 1172 3844 1172 3481 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-38"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_9">
      <path d="M 229.540625 145.8 
L 229.540625 7.2 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_10">
      <g>
       <use xlink:href="#ma9d9d08dda" x="229.540625" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- 100 -->
      <g transform="translate(219.996875 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="text_6">
     <!-- step -->
     <g transform="translate(121.075 174.076563) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-73"/>
      <use xlink:href="#DejaVuSans-74" x="52.099609"/>
      <use xlink:href="#DejaVuSans-65" x="91.308594"/>
      <use xlink:href="#DejaVuSans-70" x="152.832031"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_11">
      <path d="M 34.240625 131.038103 
L 229.540625 131.038103 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_12">
      <defs>
       <path id="m0b92ebdb72" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m0b92ebdb72" x="34.240625" y="131.038103" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 1 -->
      <g transform="translate(20.878125 134.837321) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_13">
      <path d="M 34.240625 103.094346 
L 229.540625 103.094346 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_14">
      <g>
       <use xlink:href="#m0b92ebdb72" x="34.240625" y="103.094346" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 2 -->
      <g transform="translate(20.878125 106.893565) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_15">
      <path d="M 34.240625 75.150589 
L 229.540625 75.150589 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_16">
      <g>
       <use xlink:href="#m0b92ebdb72" x="34.240625" y="75.150589" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <!-- 3 -->
      <g transform="translate(20.878125 78.949808) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-33" d="M 2597 2516 
Q 3050 2419 3304 2112 
Q 3559 1806 3559 1356 
Q 3559 666 3084 287 
Q 2609 -91 1734 -91 
Q 1441 -91 1130 -33 
Q 819 25 488 141 
L 488 750 
Q 750 597 1062 519 
Q 1375 441 1716 441 
Q 2309 441 2620 675 
Q 2931 909 2931 1356 
Q 2931 1769 2642 2001 
Q 2353 2234 1838 2234 
L 1294 2234 
L 1294 2753 
L 1863 2753 
Q 2328 2753 2575 2939 
Q 2822 3125 2822 3475 
Q 2822 3834 2567 4026 
Q 2313 4219 1838 4219 
Q 1578 4219 1281 4162 
Q 984 4106 628 3988 
L 628 4550 
Q 988 4650 1302 4700 
Q 1616 4750 1894 4750 
Q 2613 4750 3031 4423 
Q 3450 4097 3450 3541 
Q 3450 3153 3228 2886 
Q 3006 2619 2597 2516 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-33"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_17">
      <path d="M 34.240625 47.206833 
L 229.540625 47.206833 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_18">
      <g>
       <use xlink:href="#m0b92ebdb72" x="34.240625" y="47.206833" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_10">
      <!-- 4 -->
      <g transform="translate(20.878125 51.006052) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_19">
      <path d="M 34.240625 19.263076 
L 229.540625 19.263076 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_20">
      <g>
       <use xlink:href="#m0b92ebdb72" x="34.240625" y="19.263076" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_11">
      <!-- 5 -->
      <g transform="translate(20.878125 23.062295) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-35"/>
      </g>
     </g>
    </g>
    <g id="text_12">
     <!-- loss -->
     <g transform="translate(14.798438 86.157813) rotate(-90) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-6c" d="M 603 4863 
L 1178 4863 
L 1178 0 
L 603 0 
L 603 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-6c"/>
      <use xlink:href="#DejaVuSans-6f" x="27.783203"/>
      <use xlink:href="#DejaVuSans-73" x="88.964844"/>
      <use xlink:href="#DejaVuSans-73" x="141.064453"/>
     </g>
    </g>
   </g>
   <g id="line2d_21">
    <path d="M 34.240625 20.903577 
L 36.213352 13.802267 
L 38.18608 13.5 
L 40.158807 14.630619 
L 42.131534 14.559514 
L 44.104261 14.508618 
L 46.076989 14.022115 
L 48.049716 13.66997 
L 50.022443 13.88565 
L 51.99517 13.731327 
L 53.967898 13.847564 
L 55.940625 14.208833 
L 57.913352 14.275295 
L 59.88608 14.351134 
L 61.858807 14.589103 
L 63.831534 14.75783 
L 65.804261 14.927362 
L 67.776989 15.094592 
L 69.749716 15.174902 
L 71.722443 15.366871 
L 73.69517 15.548088 
L 75.667898 15.522577 
L 77.640625 15.61866 
L 79.613352 15.780156 
L 81.58608 15.914679 
L 83.558807 15.889489 
L 85.531534 15.974556 
L 87.504261 15.997628 
L 89.476989 15.886018 
L 91.449716 15.813872 
L 93.422443 15.723006 
L 95.39517 15.587436 
L 97.367898 15.427942 
L 99.340625 15.358521 
L 101.313352 15.329825 
L 103.28608 15.213746 
L 105.258807 15.173815 
L 107.231534 15.230476 
L 109.204261 15.220404 
L 111.176989 15.186138 
L 113.149716 15.246116 
L 115.122443 15.34406 
L 117.09517 15.448065 
L 119.067898 15.573411 
L 121.040625 15.662006 
L 123.013352 15.717509 
L 124.98608 15.766082 
L 126.958807 15.80288 
L 128.931534 15.865363 
L 130.904261 15.890349 
L 132.876989 15.974455 
L 134.849716 16.012234 
L 136.822443 16.085007 
L 138.79517 16.063108 
L 140.767898 16.101074 
L 142.740625 16.122984 
L 144.713352 16.057141 
L 146.68608 16.003456 
L 148.658807 15.977528 
L 150.631534 15.925344 
L 152.604261 15.855067 
L 154.576989 15.809418 
L 156.549716 15.720963 
L 158.522443 15.670921 
L 160.49517 15.664502 
L 162.467898 15.622411 
L 164.440625 15.581195 
L 166.413352 15.518188 
L 168.38608 15.456759 
L 170.358807 15.39547 
L 172.331534 15.346783 
L 174.304261 15.281695 
L 176.276989 15.279309 
L 178.249716 15.248953 
L 180.222443 15.223552 
L 182.19517 15.207444 
L 184.167898 15.158689 
L 186.140625 15.124637 
L 188.113352 15.092284 
L 190.08608 15.0338 
L 192.058807 14.965607 
L 194.031534 14.899137 
L 196.004261 14.811166 
L 197.976989 14.760905 
L 199.949716 14.713318 
L 201.922443 14.669182 
L 203.89517 14.601166 
L 205.867898 14.574533 
L 207.840625 14.538569 
L 209.813352 14.495079 
L 211.78608 14.419283 
L 213.758807 14.395228 
L 215.731534 14.359457 
L 217.704261 14.321226 
L 219.676989 14.313369 
L 221.649716 14.254512 
L 223.622443 14.212512 
L 225.59517 14.155021 
L 227.567898 14.102998 
L 229.540625 14.078921 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="line2d_22">
    <path d="M 34.240625 139.5 
L 36.213352 132.608934 
L 38.18608 134.371188 
L 40.158807 135.049982 
L 42.131534 134.944533 
L 44.104261 135.443153 
L 46.076989 136.022645 
L 48.049716 136.122908 
L 50.022443 136.272661 
L 51.99517 136.571169 
L 53.967898 136.816521 
L 55.940625 136.947446 
L 57.913352 137.088231 
L 59.88608 137.236492 
L 61.858807 137.3921 
L 63.831534 137.511058 
L 65.804261 137.57889 
L 67.776989 137.661504 
L 69.749716 137.766558 
L 71.722443 137.857458 
L 73.69517 137.913807 
L 75.667898 137.967848 
L 77.640625 138.036683 
L 79.613352 138.098246 
L 81.58608 138.133357 
L 83.558807 138.18279 
L 85.531534 138.233969 
L 87.504261 138.264803 
L 89.476989 138.299098 
L 91.449716 138.333028 
L 93.422443 138.373952 
L 95.39517 138.402746 
L 97.367898 138.430562 
L 99.340625 138.454695 
L 101.313352 138.481486 
L 103.28608 138.51337 
L 105.258807 138.542739 
L 107.231534 138.565004 
L 109.204261 138.59369 
L 111.176989 138.613904 
L 113.149716 138.637864 
L 115.122443 138.661791 
L 117.09517 138.675807 
L 119.067898 138.694981 
L 121.040625 138.714169 
L 123.013352 138.733752 
L 124.98608 138.746915 
L 126.958807 138.76619 
L 128.931534 138.781711 
L 130.904261 138.79826 
L 132.876989 138.810694 
L 134.849716 138.82723 
L 136.822443 138.838201 
L 138.79517 138.852085 
L 140.767898 138.864618 
L 142.740625 138.877985 
L 144.713352 138.893845 
L 146.68608 138.90511 
L 148.658807 138.920697 
L 150.631534 138.929181 
L 152.604261 138.939508 
L 154.576989 138.946871 
L 156.549716 138.9558 
L 158.522443 138.965365 
L 160.49517 138.976777 
L 162.467898 138.984824 
L 164.440625 138.992634 
L 166.413352 139.0012 
L 168.38608 139.011272 
L 170.358807 139.016927 
L 172.331534 139.025921 
L 174.304261 139.032209 
L 176.276989 139.037139 
L 178.249716 139.040689 
L 180.222443 139.04835 
L 182.19517 139.05451 
L 184.167898 139.060905 
L 186.140625 139.065281 
L 188.113352 139.072395 
L 190.08608 139.075351 
L 192.058807 139.082346 
L 194.031534 139.088611 
L 196.004261 139.094326 
L 197.976989 139.100363 
L 199.949716 139.105499 
L 201.922443 139.110177 
L 203.89517 139.117005 
L 205.867898 139.116055 
L 207.840625 139.12019 
L 209.813352 139.125496 
L 211.78608 139.123962 
L 213.758807 139.126578 
L 215.731534 139.131658 
L 217.704261 139.130952 
L 219.676989 139.13378 
L 221.649716 139.138273 
L 223.622443 139.14327 
L 225.59517 139.144313 
L 227.567898 139.149249 
L 229.540625 139.153259 
" clip-path="url(#pc5a2ebba0f)" style="fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5"/>
   </g>
   <g id="patch_3">
    <path d="M 34.240625 145.8 
L 34.240625 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 229.540625 145.8 
L 229.540625 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 34.240625 145.8 
L 229.540625 145.8 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 34.240625 7.2 
L 229.540625 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="legend_1">
    <g id="patch_7">
     <path d="M 168.28125 92.678125 
L 222.540625 92.678125 
Q 224.540625 92.678125 224.540625 90.678125 
L 224.540625 62.321875 
Q 224.540625 60.321875 222.540625 60.321875 
L 168.28125 60.321875 
Q 166.28125 60.321875 166.28125 62.321875 
L 166.28125 90.678125 
Q 166.28125 92.678125 168.28125 92.678125 
z
" style="fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter"/>
    </g>
    <g id="line2d_23">
     <path d="M 170.28125 68.420313 
L 180.28125 68.420313 
L 190.28125 68.420313 
" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
    </g>
    <g id="text_13">
     <!-- mlm -->
     <g transform="translate(198.28125 71.920313) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-6d" d="M 3328 2828 
Q 3544 3216 3844 3400 
Q 4144 3584 4550 3584 
Q 5097 3584 5394 3201 
Q 5691 2819 5691 2113 
L 5691 0 
L 5113 0 
L 5113 2094 
Q 5113 2597 4934 2840 
Q 4756 3084 4391 3084 
Q 3944 3084 3684 2787 
Q 3425 2491 3425 1978 
L 3425 0 
L 2847 0 
L 2847 2094 
Q 2847 2600 2669 2842 
Q 2491 3084 2119 3084 
Q 1678 3084 1418 2786 
Q 1159 2488 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1356 3278 1631 3431 
Q 1906 3584 2284 3584 
Q 2666 3584 2933 3390 
Q 3200 3197 3328 2828 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-6d"/>
      <use xlink:href="#DejaVuSans-6c" x="97.412109"/>
      <use xlink:href="#DejaVuSans-6d" x="125.195312"/>
     </g>
    </g>
    <g id="line2d_24">
     <path d="M 170.28125 83.098438 
L 180.28125 83.098438 
L 190.28125 83.098438 
" style="fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5"/>
    </g>
    <g id="text_14">
     <!-- nsp -->
     <g transform="translate(198.28125 86.598438) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-6e"/>
      <use xlink:href="#DejaVuSans-73" x="63.378906"/>
      <use xlink:href="#DejaVuSans-70" x="115.478516"/>
     </g>
    </g>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="pc5a2ebba0f">
   <rect x="34.240625" y="7.2" width="195.3" height="138.6"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[110]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># torch.save(net.state_dict(), 'Pytorch_params/BERT/bert_5000.pt')</span>
<span class="c1"># torch.save(net.state_dict(), 'Pytorch_params/BERT/bert_50000.pt')</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.7.7.-%E7%94%A8BERT%E8%A1%A8%E7%A4%BA%E6%96%87%E6%9C%AC">11.7.7. <a id="toc11_7_7_"></a><a href="#toc0_">BERT</a><a class="anchor-link" href="#11.7.7.-%E7%94%A8BERT%E8%A1%A8%E7%A4%BA%E6%96%87%E6%9C%AC"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[184]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="k">def</span> <span class="nf">get_bert_encoding</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">tokens_a</span><span class="p">,</span> <span class="n">tokens_b</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''' </span>
<span class="sd">    BERT</span>
<span class="sd">    Args:</span>
<span class="sd">        net :BERTModel: BERT</span>
<span class="sd">        tokens_a :list: </span>
<span class="sd">        tokens_b :list: </span>
<span class="sd">    Returns:</span>
<span class="sd">        encoded_X :torch.Tensor: BERT</span>
<span class="sd">    '''</span>
    <span class="n">tokens</span><span class="p">,</span> <span class="n">segments</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">get_tokens_and_segments</span><span class="p">(</span><span class="n">tokens_a</span><span class="p">,</span> <span class="n">tokens_b</span><span class="p">)</span>
    <span class="n">token_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">tokens</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">segments</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">segments</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">valid_len</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">encoded_X</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="n">valid_len</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">encoded_X</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[187]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="n">tokens_a</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'a'</span><span class="p">,</span> <span class="s1">'crane'</span><span class="p">,</span> <span class="s1">'is'</span><span class="p">,</span> <span class="s1">'flying'</span><span class="p">]</span>
<span class="n">encoded_text</span> <span class="o">=</span> <span class="n">get_bert_encoding</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">tokens_a</span><span class="p">)</span>
<span class="c1"># '&lt;cls&gt;','a','crane','is','flying','&lt;sep&gt;'</span>
<span class="n">encoded_text_cls</span> <span class="o">=</span> <span class="n">encoded_text</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">encoded_text_crane</span> <span class="o">=</span> <span class="n">encoded_text</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>

<span class="c1"># encoded_text.shape, encoded_text_cls.shape, encoded_text_crane[0][:3]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'encoded_text.shape: </span><span class="si">{</span><span class="n">encoded_text</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'encoded_text_cls.shape: </span><span class="si">{</span><span class="n">encoded_text_cls</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'encoded_text_crane.shape: </span><span class="si">{</span><span class="n">encoded_text_crane</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'encoded_text_crane[0][:3]: </span><span class="si">{</span><span class="n">encoded_text_crane</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>encoded_text.shape: torch.Size([1, 6, 128])
encoded_text_cls.shape: torch.Size([1, 128])
encoded_text_crane.shape: torch.Size([1, 128])
encoded_text_crane[0][:3]: tensor([ 0.8293,  0.6733, -0.6594], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[190]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="n">tokens_a</span><span class="p">,</span> <span class="n">tokens_b</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'a'</span><span class="p">,</span> <span class="s1">'crane'</span><span class="p">,</span> <span class="s1">'driver'</span><span class="p">,</span> <span class="s1">'came'</span><span class="p">],</span> <span class="p">[</span><span class="s1">'he'</span><span class="p">,</span> <span class="s1">'just'</span><span class="p">,</span> <span class="s1">'left'</span><span class="p">]</span>
<span class="n">encoded_pair</span> <span class="o">=</span> <span class="n">get_bert_encoding</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">tokens_a</span><span class="p">,</span> <span class="n">tokens_b</span><span class="p">)</span>
<span class="c1"># '&lt;cls&gt;','a','crane','driver','came','&lt;sep&gt;','he','just','left','&lt;sep&gt;'</span>
<span class="n">encoded_pair_cls</span> <span class="o">=</span> <span class="n">encoded_pair</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">encoded_pair_crane</span> <span class="o">=</span> <span class="n">encoded_pair</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>

<span class="c1"># encoded_pair.shape, encoded_pair_cls.shape, encoded_pair_crane[0][:3]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'encoded_pair.shape: </span><span class="si">{</span><span class="n">encoded_pair</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'encoded_pair_cls.shape: </span><span class="si">{</span><span class="n">encoded_pair_cls</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'encoded_pair_crane.shape: </span><span class="si">{</span><span class="n">encoded_pair_crane</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'encoded_pair_crane[0][:3]: </span><span class="si">{</span><span class="n">encoded_pair_crane</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>encoded_pair.shape: torch.Size([1, 10, 128])
encoded_pair_cls.shape: torch.Size([1, 128])
encoded_pair_crane.shape: torch.Size([1, 128])
encoded_pair_crane[0][:3]: tensor([ 0.9727,  0.6800, -0.6174], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11.8.-%E7%94%A8BERT%E5%81%9A%E5%BE%AE%E8%B0%83">11.8. <a id="toc11_8_"></a><a href="#toc0_">BERT</a><a class="anchor-link" href="#11.8.-%E7%94%A8BERT%E5%81%9A%E5%BE%AE%E8%B0%83"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.8.1.-%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90">11.8.1. <a id="toc11_8_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.8.1.-%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[194]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">DATA_HUB</span><span class="p">[</span><span class="s1">'aclImdb'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s1">'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'</span><span class="p">,</span>
    <span class="s1">'01ada507287d82875905620988597833ad4e0903'</span><span class="p">)</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">download_extract</span><span class="p">(</span><span class="s1">'aclImdb'</span><span class="p">,</span> <span class="s1">'aclImdb'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[196]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">read_imdb</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">is_train</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Read the IMDb review dataset text sequences and labels."""</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">'pos'</span><span class="p">,</span> <span class="s1">'neg'</span><span class="p">):</span>
        <span class="n">folder_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'train'</span> <span class="k">if</span> <span class="n">is_train</span> <span class="k">else</span> <span class="s1">'test'</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">folder_name</span><span class="p">):</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder_name</span><span class="p">,</span> <span class="n">file</span><span class="p">),</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">review</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
                <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>
                <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="s1">'pos'</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">read_imdb</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'# trainings:'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">3</span><span class="p">],</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">][:</span><span class="mi">3</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'label:'</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">'review:'</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre># trainings: 25000
label: 1 review: Zentropa has much in common with The Third Man, another noir-like film set among the rubble of postw
label: 1 review: Zentropa is the most original movie I've seen in years. If you like unique thrillers that are influe
label: 1 review: Lars Von Trier is never backward in trying out new techniques. Some of them are very original while 
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[197]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="n">train_tokens</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">token</span><span class="o">=</span><span class="s1">'word'</span><span class="p">)</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">(</span><span class="n">train_tokens</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">reserved_tokens</span><span class="o">=</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[198]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">set_figsize</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'# tokens per review'</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'count'</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">train_tokens</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">50</span><span class="p">));</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="255.828125pt" height="183.35625pt" viewBox="0 0 255.828125 183.35625" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-12-04T18:34:40.474257</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 183.35625 
L 255.828125 183.35625 
L 255.828125 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 53.328125 145.8 
L 248.628125 145.8 
L 248.628125 7.2 
L 53.328125 7.2 
z
" style="fill: #ffffff"/>
   </g>
   <g id="patch_3">
    <path d="M 62.205398 145.8 
L 71.549895 145.8 
L 71.549895 135.096774 
L 62.205398 135.096774 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_4">
    <path d="M 71.549895 145.8 
L 80.894393 145.8 
L 80.894393 99.870968 
L 71.549895 99.870968 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_5">
    <path d="M 80.894393 145.8 
L 90.238891 145.8 
L 90.238891 13.8 
L 80.894393 13.8 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_6">
    <path d="M 90.238891 145.8 
L 99.583388 145.8 
L 99.583388 52.23871 
L 90.238891 52.23871 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_7">
    <path d="M 99.583388 145.8 
L 108.927886 145.8 
L 108.927886 91.277419 
L 99.583388 91.277419 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_8">
    <path d="M 108.927886 145.8 
L 118.272383 145.8 
L 118.272383 110.032258 
L 108.927886 110.032258 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_9">
    <path d="M 118.272383 145.8 
L 127.616881 145.8 
L 127.616881 119.090323 
L 118.272383 119.090323 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_10">
    <path d="M 127.616881 145.8 
L 136.961379 145.8 
L 136.961379 126.348387 
L 127.616881 126.348387 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_11">
    <path d="M 136.961379 145.8 
L 146.305876 145.8 
L 146.305876 131.109677 
L 136.961379 131.109677 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_12">
    <path d="M 146.305876 145.8 
L 155.650374 145.8 
L 155.650374 134.554839 
L 146.305876 134.554839 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_13">
    <path d="M 155.650374 145.8 
L 164.994871 145.8 
L 164.994871 137.341935 
L 155.650374 137.341935 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_14">
    <path d="M 164.994871 145.8 
L 174.339369 145.8 
L 174.339369 139.045161 
L 164.994871 139.045161 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_15">
    <path d="M 174.339369 145.8 
L 183.683867 145.8 
L 183.683867 140.825806 
L 174.339369 140.825806 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_16">
    <path d="M 183.683867 145.8 
L 193.028364 145.8 
L 193.028364 141.793548 
L 183.683867 141.793548 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_17">
    <path d="M 193.028364 145.8 
L 202.372862 145.8 
L 202.372862 142.432258 
L 193.028364 142.432258 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_18">
    <path d="M 202.372862 145.8 
L 211.717359 145.8 
L 211.717359 143.225806 
L 202.372862 143.225806 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_19">
    <path d="M 211.717359 145.8 
L 221.061857 145.8 
L 221.061857 143.554839 
L 211.717359 143.554839 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_20">
    <path d="M 221.061857 145.8 
L 230.406355 145.8 
L 230.406355 144.154839 
L 221.061857 144.154839 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="patch_21">
    <path d="M 230.406355 145.8 
L 239.750852 145.8 
L 239.750852 144.348387 
L 230.406355 144.348387 
z
" clip-path="url(#p5e0091b9bb)" style="fill: #1f77b4"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <defs>
       <path id="m6bd9c69798" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m6bd9c69798" x="62.205398" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- 0 -->
      <g transform="translate(59.024148 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <g>
       <use xlink:href="#m6bd9c69798" x="99.583388" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 200 -->
      <g transform="translate(90.039638 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-32"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_3">
      <g>
       <use xlink:href="#m6bd9c69798" x="136.961379" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 400 -->
      <g transform="translate(127.417629 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-34"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_4">
      <g>
       <use xlink:href="#m6bd9c69798" x="174.339369" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 600 -->
      <g transform="translate(164.795619 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-36" d="M 2113 2584 
Q 1688 2584 1439 2293 
Q 1191 2003 1191 1497 
Q 1191 994 1439 701 
Q 1688 409 2113 409 
Q 2538 409 2786 701 
Q 3034 994 3034 1497 
Q 3034 2003 2786 2293 
Q 2538 2584 2113 2584 
z
M 3366 4563 
L 3366 3988 
Q 3128 4100 2886 4159 
Q 2644 4219 2406 4219 
Q 1781 4219 1451 3797 
Q 1122 3375 1075 2522 
Q 1259 2794 1537 2939 
Q 1816 3084 2150 3084 
Q 2853 3084 3261 2657 
Q 3669 2231 3669 1497 
Q 3669 778 3244 343 
Q 2819 -91 2113 -91 
Q 1303 -91 875 529 
Q 447 1150 447 2328 
Q 447 3434 972 4092 
Q 1497 4750 2381 4750 
Q 2619 4750 2861 4703 
Q 3103 4656 3366 4563 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-36"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_5">
      <g>
       <use xlink:href="#m6bd9c69798" x="211.717359" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- 800 -->
      <g transform="translate(202.173609 160.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-38" d="M 2034 2216 
Q 1584 2216 1326 1975 
Q 1069 1734 1069 1313 
Q 1069 891 1326 650 
Q 1584 409 2034 409 
Q 2484 409 2743 651 
Q 3003 894 3003 1313 
Q 3003 1734 2745 1975 
Q 2488 2216 2034 2216 
z
M 1403 2484 
Q 997 2584 770 2862 
Q 544 3141 544 3541 
Q 544 4100 942 4425 
Q 1341 4750 2034 4750 
Q 2731 4750 3128 4425 
Q 3525 4100 3525 3541 
Q 3525 3141 3298 2862 
Q 3072 2584 2669 2484 
Q 3125 2378 3379 2068 
Q 3634 1759 3634 1313 
Q 3634 634 3220 271 
Q 2806 -91 2034 -91 
Q 1263 -91 848 271 
Q 434 634 434 1313 
Q 434 1759 690 2068 
Q 947 2378 1403 2484 
z
M 1172 3481 
Q 1172 3119 1398 2916 
Q 1625 2713 2034 2713 
Q 2441 2713 2670 2916 
Q 2900 3119 2900 3481 
Q 2900 3844 2670 4047 
Q 2441 4250 2034 4250 
Q 1625 4250 1398 4047 
Q 1172 3844 1172 3481 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-38"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
      </g>
     </g>
    </g>
    <g id="text_6">
     <!-- # tokens per review -->
     <g transform="translate(100.597656 174.076563) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-23" d="M 3272 2816 
L 2363 2816 
L 2100 1772 
L 3016 1772 
L 3272 2816 
z
M 2803 4594 
L 2478 3297 
L 3391 3297 
L 3719 4594 
L 4219 4594 
L 3897 3297 
L 4872 3297 
L 4872 2816 
L 3775 2816 
L 3519 1772 
L 4513 1772 
L 4513 1294 
L 3397 1294 
L 3072 0 
L 2572 0 
L 2894 1294 
L 1978 1294 
L 1656 0 
L 1153 0 
L 1478 1294 
L 494 1294 
L 494 1772 
L 1594 1772 
L 1856 2816 
L 850 2816 
L 850 3297 
L 1978 3297 
L 2297 4594 
L 2803 4594 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-20" transform="scale(0.015625)"/>
       <path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6b" d="M 581 4863 
L 1159 4863 
L 1159 1991 
L 2875 3500 
L 3609 3500 
L 1753 1863 
L 3688 0 
L 2938 0 
L 1159 1709 
L 1159 0 
L 581 0 
L 581 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-72" d="M 2631 2963 
Q 2534 3019 2420 3045 
Q 2306 3072 2169 3072 
Q 1681 3072 1420 2755 
Q 1159 2438 1159 1844 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1341 3275 1631 3429 
Q 1922 3584 2338 3584 
Q 2397 3584 2469 3576 
Q 2541 3569 2628 3553 
L 2631 2963 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-76" d="M 191 3500 
L 800 3500 
L 1894 563 
L 2988 3500 
L 3597 3500 
L 2284 0 
L 1503 0 
L 191 3500 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-69" d="M 603 3500 
L 1178 3500 
L 1178 0 
L 603 0 
L 603 3500 
z
M 603 4863 
L 1178 4863 
L 1178 4134 
L 603 4134 
L 603 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-77" d="M 269 3500 
L 844 3500 
L 1563 769 
L 2278 3500 
L 2956 3500 
L 3675 769 
L 4391 3500 
L 4966 3500 
L 4050 0 
L 3372 0 
L 2619 2869 
L 1863 0 
L 1184 0 
L 269 3500 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-23"/>
      <use xlink:href="#DejaVuSans-20" x="83.789062"/>
      <use xlink:href="#DejaVuSans-74" x="115.576172"/>
      <use xlink:href="#DejaVuSans-6f" x="154.785156"/>
      <use xlink:href="#DejaVuSans-6b" x="215.966797"/>
      <use xlink:href="#DejaVuSans-65" x="270.251953"/>
      <use xlink:href="#DejaVuSans-6e" x="331.775391"/>
      <use xlink:href="#DejaVuSans-73" x="395.154297"/>
      <use xlink:href="#DejaVuSans-20" x="447.253906"/>
      <use xlink:href="#DejaVuSans-70" x="479.041016"/>
      <use xlink:href="#DejaVuSans-65" x="542.517578"/>
      <use xlink:href="#DejaVuSans-72" x="604.041016"/>
      <use xlink:href="#DejaVuSans-20" x="645.154297"/>
      <use xlink:href="#DejaVuSans-72" x="676.941406"/>
      <use xlink:href="#DejaVuSans-65" x="715.804688"/>
      <use xlink:href="#DejaVuSans-76" x="777.328125"/>
      <use xlink:href="#DejaVuSans-69" x="836.507812"/>
      <use xlink:href="#DejaVuSans-65" x="864.291016"/>
      <use xlink:href="#DejaVuSans-77" x="925.814453"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_6">
      <defs>
       <path id="m7623bebad8" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m7623bebad8" x="53.328125" y="145.8" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 0 -->
      <g transform="translate(39.965625 149.599219) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_7">
      <g>
       <use xlink:href="#m7623bebad8" x="53.328125" y="107.090323" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 2000 -->
      <g transform="translate(20.878125 110.889541) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
       <use xlink:href="#DejaVuSans-30" x="190.869141"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_8">
      <g>
       <use xlink:href="#m7623bebad8" x="53.328125" y="68.380645" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <!-- 4000 -->
      <g transform="translate(20.878125 72.179864) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-34"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
       <use xlink:href="#DejaVuSans-30" x="190.869141"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_9">
      <g>
       <use xlink:href="#m7623bebad8" x="53.328125" y="29.670968" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_10">
      <!-- 6000 -->
      <g transform="translate(20.878125 33.470186) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-36"/>
       <use xlink:href="#DejaVuSans-30" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="127.246094"/>
       <use xlink:href="#DejaVuSans-30" x="190.869141"/>
      </g>
     </g>
    </g>
    <g id="text_11">
     <!-- count -->
     <g transform="translate(14.798437 90.60625) rotate(-90) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-75" d="M 544 1381 
L 544 3500 
L 1119 3500 
L 1119 1403 
Q 1119 906 1312 657 
Q 1506 409 1894 409 
Q 2359 409 2629 706 
Q 2900 1003 2900 1516 
L 2900 3500 
L 3475 3500 
L 3475 0 
L 2900 0 
L 2900 538 
Q 2691 219 2414 64 
Q 2138 -91 1772 -91 
Q 1169 -91 856 284 
Q 544 659 544 1381 
z
M 1991 3584 
L 1991 3584 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-63"/>
      <use xlink:href="#DejaVuSans-6f" x="54.980469"/>
      <use xlink:href="#DejaVuSans-75" x="116.162109"/>
      <use xlink:href="#DejaVuSans-6e" x="179.541016"/>
      <use xlink:href="#DejaVuSans-74" x="242.919922"/>
     </g>
    </g>
   </g>
   <g id="patch_22">
    <path d="M 53.328125 145.8 
L 53.328125 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_23">
    <path d="M 248.628125 145.8 
L 248.628125 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_24">
    <path d="M 53.328125 145.8 
L 248.628125 145.8 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_25">
    <path d="M 53.328125 7.2 
L 248.628125 7.2 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="p5e0091b9bb">
   <rect x="53.328125" y="7.2" width="195.3" height="138.6"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[199]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># sequence length</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">d2l</span><span class="o">.</span><span class="n">truncate_pad</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">line</span><span class="p">],</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">train_tokens</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([25000, 500])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[200]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_array</span><span class="p">((</span><span class="n">train_features</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span> <span class="mi">64</span><span class="p">)</span>

<span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'X:'</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">', y:'</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">break</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'# batches:'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_iter</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>X: torch.Size([64, 500]) , y: torch.Size([64])
# batches: 391
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[201]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">load_data_imdb</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Return data iterators and the vocabulary of the IMDb review dataset."""</span>
    <span class="n">data_dir</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">download_extract</span><span class="p">(</span><span class="s1">'aclImdb'</span><span class="p">,</span> <span class="s1">'aclImdb'</span><span class="p">)</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">read_imdb</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">read_imdb</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">train_tokens</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">token</span><span class="o">=</span><span class="s1">'word'</span><span class="p">)</span>
    <span class="n">test_tokens</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">token</span><span class="o">=</span><span class="s1">'word'</span><span class="p">)</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">(</span><span class="n">train_tokens</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">train_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">d2l</span><span class="o">.</span><span class="n">truncate_pad</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">line</span><span class="p">],</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">train_tokens</span><span class="p">])</span>
    <span class="n">test_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">d2l</span><span class="o">.</span><span class="n">truncate_pad</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">line</span><span class="p">],</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">test_tokens</span><span class="p">])</span>
    <span class="n">train_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_array</span><span class="p">((</span><span class="n">train_features</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_array</span><span class="p">((</span><span class="n">test_features</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span> <span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.8.1.1.-%E4%BD%BF%E7%94%A8RNN">11.8.1.1. <a id="toc11_8_1_1_"></a><a href="#toc0_">RNN</a><a class="anchor-link" href="#11.8.1.1.-%E4%BD%BF%E7%94%A8RNN"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[202]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>


<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_imdb</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.8.1.2.-%E4%BD%BF%E7%94%A8CNN">11.8.1.2. <a id="toc11_8_1_2_"></a><a href="#toc0_">CNN</a><a class="anchor-link" href="#11.8.1.2.-%E4%BD%BF%E7%94%A8CNN"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="11.8.2.-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%8E%A8%E6%96%AD">11.8.2. <a id="toc11_8_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#11.8.2.-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%8E%A8%E6%96%AD"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.8.2.1.-%E4%BD%BF%E7%94%A8Attention">11.8.2.1. <a id="toc11_8_2_1_"></a><a href="#toc0_">Attention</a><a class="anchor-link" href="#11.8.2.1.-%E4%BD%BF%E7%94%A8Attention"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="11.8.2.2.-%E5%BE%AE%E8%B0%83BERT">11.8.2.2. <a id="toc11_8_2_2_"></a><a href="#toc0_">BERT</a><a class="anchor-link" href="#11.8.2.2.-%E5%BE%AE%E8%B0%83BERT"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[205]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">os</span>


<span class="c1">#@tab pytorch</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">DATA_HUB</span><span class="p">[</span><span class="s1">'bert.base'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">DATA_URL</span> <span class="o">+</span> <span class="s1">'bert.base.torch.zip'</span><span class="p">,</span>
                             <span class="s1">'225d66f04cae318b841a13d32af3acc165f253ac'</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">DATA_HUB</span><span class="p">[</span><span class="s1">'bert.small'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">DATA_URL</span> <span class="o">+</span> <span class="s1">'bert.small.torch.zip'</span><span class="p">,</span>
                              <span class="s1">'c72329e68a732bef0452e4b96a1c341c8910f81f'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[252]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="k">def</span> <span class="nf">load_pretrained_model</span><span class="p">(</span><span class="n">pretrained_model</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span>
                          <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">devices</span><span class="p">,</span> <span class="n">bert_type</span><span class="o">=</span><span class="s1">'small'</span><span class="p">):</span>
    <span class="n">data_dir</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">download_extract</span><span class="p">(</span><span class="n">pretrained_model</span><span class="p">)</span>
    <span class="c1"># Define an empty vocabulary to load the predefined vocabulary</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">()</span>
    <span class="n">vocab</span><span class="o">.</span><span class="n">idx_to_token</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'vocab.json'</span><span class="p">)))</span>
    <span class="n">vocab</span><span class="o">.</span><span class="n">token_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">)}</span>
    <span class="k">if</span> <span class="n">bert_type</span> <span class="o">==</span> <span class="s1">'small'</span><span class="p">:</span>    
        <span class="c1"># parameters of BERT-small</span>
        <span class="n">bert</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">BERTModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">256</span><span class="p">],</span>
                         <span class="n">ffn_num_input</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="n">ffn_num_hiddens</span><span class="p">,</span>
                         <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
                         <span class="n">max_len</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">key_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">query_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                         <span class="n">value_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">hid_in_features</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                         <span class="n">mlm_in_features</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">nsp_in_features</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># parameters of BERT-base</span>
        <span class="n">bert</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">BERTModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">768</span><span class="p">],</span>
                         <span class="n">ffn_num_input</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="n">ffn_num_hiddens</span><span class="p">,</span>
                         <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
                         <span class="n">max_len</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">key_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">query_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
                         <span class="n">value_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">hid_in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
                         <span class="n">mlm_in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">nsp_in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">)</span>
    <span class="c1"># Load pretrained BERT parameters</span>
    <span class="n">bert</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'pretrained.params'</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">bert</span><span class="p">,</span> <span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[253]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab all</span>
<span class="c1"># BERT-small</span>
<span class="n">devices</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_all_gpus</span><span class="p">()</span>
<span class="n">bert</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">load_pretrained_model</span><span class="p">(</span>
    <span class="n">pretrained_model</span><span class="o">=</span><span class="s1">'bert.small'</span><span class="p">,</span> 
    <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> 
    <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> 
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> 
    <span class="n">max_len</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> 
    <span class="n">devices</span><span class="o">=</span><span class="n">devices</span><span class="p">,</span>
    <span class="n">bert_type</span><span class="o">=</span><span class="s1">'small'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/tmp/ipykernel_3760909/853994745.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  bert.load_state_dict(torch.load(os.path.join(data_dir, 'pretrained.params')))
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[254]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># BERT-base</span>
<span class="n">bert</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">load_pretrained_model</span><span class="p">(</span>
    <span class="n">pretrained_model</span><span class="o">=</span><span class="s1">'bert.base'</span><span class="p">,</span>
    <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> 
    <span class="n">ffn_num_hiddens</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> 
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> 
    <span class="n">max_len</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> 
    <span class="n">devices</span><span class="o">=</span><span class="n">devices</span><span class="p">,</span>
    <span class="n">bert_type</span><span class="o">=</span><span class="s1">'base'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/tmp/ipykernel_3760909/853994745.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  bert.load_state_dict(torch.load(os.path.join(data_dir, 'pretrained.params')))
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[255]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="k">class</span> <span class="nc">SNLIBERTDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">all_premise_hypothesis_tokens</span> <span class="o">=</span> <span class="p">[[</span>
            <span class="n">p_tokens</span><span class="p">,</span> <span class="n">h_tokens</span><span class="p">]</span> <span class="k">for</span> <span class="n">p_tokens</span><span class="p">,</span> <span class="n">h_tokens</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">d2l</span><span class="o">.</span><span class="n">tokenize</span><span class="p">([</span><span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">])</span>
              <span class="k">for</span> <span class="n">sentences</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[:</span><span class="mi">2</span><span class="p">]])]</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="n">max_len</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_token_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_segments</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">valid_lens</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">(</span><span class="n">all_premise_hypothesis_tokens</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'read '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_token_ids</span><span class="p">))</span> <span class="o">+</span> <span class="s1">' examples'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">all_premise_hypothesis_tokens</span><span class="p">):</span>
        <span class="n">pool</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>  <span class="c1"># Use 4 worker processes</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mp_worker</span><span class="p">,</span> <span class="n">all_premise_hypothesis_tokens</span><span class="p">)</span>
        <span class="n">all_token_ids</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">token_ids</span> <span class="k">for</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="n">valid_len</span> <span class="ow">in</span> <span class="n">out</span><span class="p">]</span>
        <span class="n">all_segments</span> <span class="o">=</span> <span class="p">[</span><span class="n">segments</span> <span class="k">for</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="n">valid_len</span> <span class="ow">in</span> <span class="n">out</span><span class="p">]</span>
        <span class="n">valid_lens</span> <span class="o">=</span> <span class="p">[</span><span class="n">valid_len</span> <span class="k">for</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="n">valid_len</span> <span class="ow">in</span> <span class="n">out</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_token_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_segments</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span> 
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">valid_lens</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_mp_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">premise_hypothesis_tokens</span><span class="p">):</span>
        <span class="n">p_tokens</span><span class="p">,</span> <span class="n">h_tokens</span> <span class="o">=</span> <span class="n">premise_hypothesis_tokens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_truncate_pair_of_tokens</span><span class="p">(</span><span class="n">p_tokens</span><span class="p">,</span> <span class="n">h_tokens</span><span class="p">)</span>
        <span class="n">tokens</span><span class="p">,</span> <span class="n">segments</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">get_tokens_and_segments</span><span class="p">(</span><span class="n">p_tokens</span><span class="p">,</span> <span class="n">h_tokens</span><span class="p">)</span>
        <span class="n">token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">tokens</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span>
        <span class="n">segments</span> <span class="o">=</span> <span class="n">segments</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">segments</span><span class="p">))</span>
        <span class="n">valid_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">segments</span><span class="p">,</span> <span class="n">valid_len</span>

    <span class="k">def</span> <span class="nf">_truncate_pair_of_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_tokens</span><span class="p">,</span> <span class="n">h_tokens</span><span class="p">):</span>
        <span class="c1"># Reserve slots for '&lt;CLS&gt;', '&lt;SEP&gt;', and '&lt;SEP&gt;' tokens for the BERT</span>
        <span class="c1"># input</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">p_tokens</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">h_tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">-</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">p_tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">h_tokens</span><span class="p">):</span>
                <span class="n">p_tokens</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">h_tokens</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_token_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_segments</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_lens</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_token_ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[256]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="c1"># Reduce `batch_size` if there is an out of memory error. In the original BERT</span>
<span class="c1"># model, `max_len` = 512</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">get_dataloader_workers</span><span class="p">()</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">download_extract</span><span class="p">(</span><span class="s1">'SNLI'</span><span class="p">)</span>
<span class="n">train_set</span> <span class="o">=</span> <span class="n">SNLIBERTDataset</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">read_snli</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">SNLIBERTDataset</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">read_snli</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<span class="n">test_iter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>read 549367 examples
read 9824 examples
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[257]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="k">class</span> <span class="nc">BERTClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bert</span><span class="p">,</span> <span class="n">bert_type</span><span class="o">=</span><span class="s1">'small'</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BERTClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">bert</span><span class="o">.</span><span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">bert</span><span class="o">.</span><span class="n">hidden</span>
        <span class="k">if</span> <span class="n">bert_type</span> <span class="o">==</span> <span class="s1">'small'</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">tokens_X</span><span class="p">,</span> <span class="n">segments_X</span><span class="p">,</span> <span class="n">valid_lens_x</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">encoded_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">tokens_X</span><span class="p">,</span> <span class="n">segments_X</span><span class="p">,</span> <span class="n">valid_lens_x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">encoded_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]))</span>


<span class="c1">#@tab pytorch</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">BERTClassifier</span><span class="p">(</span><span class="n">bert</span><span class="p">,</span> <span class="n">bert_type</span><span class="o">=</span><span class="s1">'base'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[258]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#@tab pytorch</span>
<span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mi">5</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">'none'</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch13</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">devices</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[258], line 5</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> trainer <span style="color: rgb(98,98,98)">=</span> torch<span style="color: rgb(98,98,98)">.</span>optim<span style="color: rgb(98,98,98)">.</span>Adam(net<span style="color: rgb(98,98,98)">.</span>parameters(), lr<span style="color: rgb(98,98,98)">=</span>lr)
<span class="ansi-green-intense-fg ansi-bold">      4</span> loss <span style="color: rgb(98,98,98)">=</span> nn<span style="color: rgb(98,98,98)">.</span>CrossEntropyLoss(reduction<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">none</span><span style="color: rgb(175,0,0)">'</span>)
<span class="ansi-green-fg">----&gt; 5</span> <span class="ansi-yellow-bg">d2l</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">train_ch13</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">net</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">train_iter</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">test_iter</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">loss</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">trainer</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">num_epochs</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">devices</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/d2l/torch.py:1586</span>, in <span class="ansi-cyan-fg">train_ch13</span><span class="ansi-blue-fg">(net, train_iter, test_iter, loss, trainer, num_epochs, devices)</span>
<span class="ansi-green-intense-fg ansi-bold">   1584</span> <span class="ansi-bold" style="color: rgb(0,135,0)">for</span> i, (features, labels) <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> <span style="color: rgb(0,135,0)">enumerate</span>(train_iter):
<span class="ansi-green-intense-fg ansi-bold">   1585</span>     timer<span style="color: rgb(98,98,98)">.</span>start()
<span class="ansi-green-fg">-&gt; 1586</span>     l, acc <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">train_batch_ch13</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">net</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">features</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">labels</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">loss</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">trainer</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1587</span> <span class="ansi-yellow-bg">                              </span><span class="ansi-yellow-bg">devices</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1588</span>     metric<span style="color: rgb(98,98,98)">.</span>add(l, acc, labels<span style="color: rgb(98,98,98)">.</span>shape[<span style="color: rgb(98,98,98)">0</span>], labels<span style="color: rgb(98,98,98)">.</span>numel())
<span class="ansi-green-intense-fg ansi-bold">   1589</span>     timer<span style="color: rgb(98,98,98)">.</span>stop()

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/d2l/torch.py:1568</span>, in <span class="ansi-cyan-fg">train_batch_ch13</span><span class="ansi-blue-fg">(net, X, y, loss, trainer, devices)</span>
<span class="ansi-green-intense-fg ansi-bold">   1566</span> trainer<span style="color: rgb(98,98,98)">.</span>step()
<span class="ansi-green-intense-fg ansi-bold">   1567</span> train_loss_sum <span style="color: rgb(98,98,98)">=</span> l<span style="color: rgb(98,98,98)">.</span>sum()
<span class="ansi-green-fg">-&gt; 1568</span> train_acc_sum <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">d2l</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">accuracy</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">pred</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">y</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1569</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> train_loss_sum, train_acc_sum

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/d2l/torch.py:226</span>, in <span class="ansi-cyan-fg">accuracy</span><span class="ansi-blue-fg">(y_hat, y)</span>
<span class="ansi-green-intense-fg ansi-bold">    224</span>     y_hat <span style="color: rgb(98,98,98)">=</span> d2l<span style="color: rgb(98,98,98)">.</span>argmax(y_hat, axis<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">1</span>)
<span class="ansi-green-intense-fg ansi-bold">    225</span> cmp <span style="color: rgb(98,98,98)">=</span> d2l<span style="color: rgb(98,98,98)">.</span>astype(y_hat, y<span style="color: rgb(98,98,98)">.</span>dtype) <span style="color: rgb(98,98,98)">==</span> y
<span class="ansi-green-fg">--&gt; 226</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">float</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">d2l</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">reduce_sum</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">d2l</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">astype</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">cmp</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">y</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">dtype</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">)</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="235.784375pt" height="187.155469pt" viewBox="0 0 235.784375 187.155469" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2024-12-04T21:10:33.114694</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 187.155469 
L 235.784375 187.155469 
L 235.784375 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 30.103125 149.599219 
L 225.403125 149.599219 
L 225.403125 10.999219 
L 30.103125 10.999219 
z
" style="fill: #ffffff"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 30.103125 149.599219 
L 30.103125 10.999219 
" clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_2">
      <defs>
       <path id="mfce722aaa1" d="M 0 0 
L 0 3.5 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#mfce722aaa1" x="30.103125" y="149.599219" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_1">
      <!-- 1 -->
      <g transform="translate(26.921875 164.197656) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-31"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_3">
      <path d="M 78.928125 149.599219 
L 78.928125 10.999219 
" clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_4">
      <g>
       <use xlink:href="#mfce722aaa1" x="78.928125" y="149.599219" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_2">
      <!-- 2 -->
      <g transform="translate(75.746875 164.197656) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_5">
      <path d="M 127.753125 149.599219 
L 127.753125 10.999219 
" clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_6">
      <g>
       <use xlink:href="#mfce722aaa1" x="127.753125" y="149.599219" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_3">
      <!-- 3 -->
      <g transform="translate(124.571875 164.197656) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-33" d="M 2597 2516 
Q 3050 2419 3304 2112 
Q 3559 1806 3559 1356 
Q 3559 666 3084 287 
Q 2609 -91 1734 -91 
Q 1441 -91 1130 -33 
Q 819 25 488 141 
L 488 750 
Q 750 597 1062 519 
Q 1375 441 1716 441 
Q 2309 441 2620 675 
Q 2931 909 2931 1356 
Q 2931 1769 2642 2001 
Q 2353 2234 1838 2234 
L 1294 2234 
L 1294 2753 
L 1863 2753 
Q 2328 2753 2575 2939 
Q 2822 3125 2822 3475 
Q 2822 3834 2567 4026 
Q 2313 4219 1838 4219 
Q 1578 4219 1281 4162 
Q 984 4106 628 3988 
L 628 4550 
Q 988 4650 1302 4700 
Q 1616 4750 1894 4750 
Q 2613 4750 3031 4423 
Q 3450 4097 3450 3541 
Q 3450 3153 3228 2886 
Q 3006 2619 2597 2516 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-33"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_7">
      <path d="M 176.578125 149.599219 
L 176.578125 10.999219 
" clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_8">
      <g>
       <use xlink:href="#mfce722aaa1" x="176.578125" y="149.599219" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_4">
      <!-- 4 -->
      <g transform="translate(173.396875 164.197656) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_9">
      <path d="M 225.403125 149.599219 
L 225.403125 10.999219 
" clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_10">
      <g>
       <use xlink:href="#mfce722aaa1" x="225.403125" y="149.599219" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_5">
      <!-- 5 -->
      <g transform="translate(222.221875 164.197656) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-35"/>
      </g>
     </g>
    </g>
    <g id="text_6">
     <!-- epoch -->
     <g transform="translate(112.525 177.875781) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-68" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 4863 
L 1159 4863 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-65"/>
      <use xlink:href="#DejaVuSans-70" x="61.523438"/>
      <use xlink:href="#DejaVuSans-6f" x="125"/>
      <use xlink:href="#DejaVuSans-63" x="186.181641"/>
      <use xlink:href="#DejaVuSans-68" x="241.162109"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_11">
      <path d="M 30.103125 149.599219 
L 225.403125 149.599219 
" clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_12">
      <defs>
       <path id="m0ad7f4a6ee" d="M 0 0 
L -3.5 0 
" style="stroke: #000000; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m0ad7f4a6ee" x="30.103125" y="149.599219" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_7">
      <!-- 0.0 -->
      <g transform="translate(7.2 153.398438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_13">
      <path d="M 30.103125 121.879219 
L 225.403125 121.879219 
" clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_14">
      <g>
       <use xlink:href="#m0ad7f4a6ee" x="30.103125" y="121.879219" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_8">
      <!-- 0.2 -->
      <g transform="translate(7.2 125.678438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-32" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_15">
      <path d="M 30.103125 94.159219 
L 225.403125 94.159219 
" clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_16">
      <g>
       <use xlink:href="#m0ad7f4a6ee" x="30.103125" y="94.159219" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_9">
      <!-- 0.4 -->
      <g transform="translate(7.2 97.958438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-34" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_17">
      <path d="M 30.103125 66.439219 
L 225.403125 66.439219 
" clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_18">
      <g>
       <use xlink:href="#m0ad7f4a6ee" x="30.103125" y="66.439219" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_10">
      <!-- 0.6 -->
      <g transform="translate(7.2 70.238437) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-36" d="M 2113 2584 
Q 1688 2584 1439 2293 
Q 1191 2003 1191 1497 
Q 1191 994 1439 701 
Q 1688 409 2113 409 
Q 2538 409 2786 701 
Q 3034 994 3034 1497 
Q 3034 2003 2786 2293 
Q 2538 2584 2113 2584 
z
M 3366 4563 
L 3366 3988 
Q 3128 4100 2886 4159 
Q 2644 4219 2406 4219 
Q 1781 4219 1451 3797 
Q 1122 3375 1075 2522 
Q 1259 2794 1537 2939 
Q 1816 3084 2150 3084 
Q 2853 3084 3261 2657 
Q 3669 2231 3669 1497 
Q 3669 778 3244 343 
Q 2819 -91 2113 -91 
Q 1303 -91 875 529 
Q 447 1150 447 2328 
Q 447 3434 972 4092 
Q 1497 4750 2381 4750 
Q 2619 4750 2861 4703 
Q 3103 4656 3366 4563 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-36" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_19">
      <path d="M 30.103125 38.719219 
L 225.403125 38.719219 
" clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_20">
      <g>
       <use xlink:href="#m0ad7f4a6ee" x="30.103125" y="38.719219" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_11">
      <!-- 0.8 -->
      <g transform="translate(7.2 42.518438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-38" d="M 2034 2216 
Q 1584 2216 1326 1975 
Q 1069 1734 1069 1313 
Q 1069 891 1326 650 
Q 1584 409 2034 409 
Q 2484 409 2743 651 
Q 3003 894 3003 1313 
Q 3003 1734 2745 1975 
Q 2488 2216 2034 2216 
z
M 1403 2484 
Q 997 2584 770 2862 
Q 544 3141 544 3541 
Q 544 4100 942 4425 
Q 1341 4750 2034 4750 
Q 2731 4750 3128 4425 
Q 3525 4100 3525 3541 
Q 3525 3141 3298 2862 
Q 3072 2584 2669 2484 
Q 3125 2378 3379 2068 
Q 3634 1759 3634 1313 
Q 3634 634 3220 271 
Q 2806 -91 2034 -91 
Q 1263 -91 848 271 
Q 434 634 434 1313 
Q 434 1759 690 2068 
Q 947 2378 1403 2484 
z
M 1172 3481 
Q 1172 3119 1398 2916 
Q 1625 2713 2034 2713 
Q 2441 2713 2670 2916 
Q 2900 3119 2900 3481 
Q 2900 3844 2670 4047 
Q 2441 4250 2034 4250 
Q 1625 4250 1398 4047 
Q 1172 3844 1172 3481 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-38" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_6">
     <g id="line2d_21">
      <path d="M 30.103125 10.999219 
L 225.403125 10.999219 
" clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square"/>
     </g>
     <g id="line2d_22">
      <g>
       <use xlink:href="#m0ad7f4a6ee" x="30.103125" y="10.999219" style="stroke: #000000; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_12">
      <!-- 1.0 -->
      <g transform="translate(7.2 14.798438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
      </g>
     </g>
    </g>
   </g>
   <g id="line2d_23">
    <path clip-path="url(#pa81473ddd1)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
   </g>
   <g id="line2d_24">
    <path clip-path="url(#pa81473ddd1)" style="fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5"/>
   </g>
   <g id="line2d_25"/>
   <g id="patch_3">
    <path d="M 30.103125 149.599219 
L 30.103125 10.999219 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 225.403125 149.599219 
L 225.403125 10.999219 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 30.103125 149.599219 
L 225.403125 149.599219 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 30.103125 10.999219 
L 225.403125 10.999219 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="legend_1">
    <g id="patch_7">
     <path d="M 140.634375 63.033594 
L 218.403125 63.033594 
Q 220.403125 63.033594 220.403125 61.033594 
L 220.403125 17.999219 
Q 220.403125 15.999219 218.403125 15.999219 
L 140.634375 15.999219 
Q 138.634375 15.999219 138.634375 17.999219 
L 138.634375 61.033594 
Q 138.634375 63.033594 140.634375 63.033594 
z
" style="fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter"/>
    </g>
    <g id="line2d_26">
     <path d="M 142.634375 24.097656 
L 152.634375 24.097656 
L 162.634375 24.097656 
" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"/>
    </g>
    <g id="text_13">
     <!-- train loss -->
     <g transform="translate(170.634375 27.597656) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-72" d="M 2631 2963 
Q 2534 3019 2420 3045 
Q 2306 3072 2169 3072 
Q 1681 3072 1420 2755 
Q 1159 2438 1159 1844 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1341 3275 1631 3429 
Q 1922 3584 2338 3584 
Q 2397 3584 2469 3576 
Q 2541 3569 2628 3553 
L 2631 2963 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-61" d="M 2194 1759 
Q 1497 1759 1228 1600 
Q 959 1441 959 1056 
Q 959 750 1161 570 
Q 1363 391 1709 391 
Q 2188 391 2477 730 
Q 2766 1069 2766 1631 
L 2766 1759 
L 2194 1759 
z
M 3341 1997 
L 3341 0 
L 2766 0 
L 2766 531 
Q 2569 213 2275 61 
Q 1981 -91 1556 -91 
Q 1019 -91 701 211 
Q 384 513 384 1019 
Q 384 1609 779 1909 
Q 1175 2209 1959 2209 
L 2766 2209 
L 2766 2266 
Q 2766 2663 2505 2880 
Q 2244 3097 1772 3097 
Q 1472 3097 1187 3025 
Q 903 2953 641 2809 
L 641 3341 
Q 956 3463 1253 3523 
Q 1550 3584 1831 3584 
Q 2591 3584 2966 3190 
Q 3341 2797 3341 1997 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-69" d="M 603 3500 
L 1178 3500 
L 1178 0 
L 603 0 
L 603 3500 
z
M 603 4863 
L 1178 4863 
L 1178 4134 
L 603 4134 
L 603 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-20" transform="scale(0.015625)"/>
       <path id="DejaVuSans-6c" d="M 603 4863 
L 1178 4863 
L 1178 0 
L 603 0 
L 603 4863 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-74"/>
      <use xlink:href="#DejaVuSans-72" x="39.208984"/>
      <use xlink:href="#DejaVuSans-61" x="80.322266"/>
      <use xlink:href="#DejaVuSans-69" x="141.601562"/>
      <use xlink:href="#DejaVuSans-6e" x="169.384766"/>
      <use xlink:href="#DejaVuSans-20" x="232.763672"/>
      <use xlink:href="#DejaVuSans-6c" x="264.550781"/>
      <use xlink:href="#DejaVuSans-6f" x="292.333984"/>
      <use xlink:href="#DejaVuSans-73" x="353.515625"/>
      <use xlink:href="#DejaVuSans-73" x="405.615234"/>
     </g>
    </g>
    <g id="line2d_27">
     <path d="M 142.634375 38.775781 
L 152.634375 38.775781 
L 162.634375 38.775781 
" style="fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5"/>
    </g>
    <g id="text_14">
     <!-- train acc -->
     <g transform="translate(170.634375 42.275781) scale(0.1 -0.1)">
      <use xlink:href="#DejaVuSans-74"/>
      <use xlink:href="#DejaVuSans-72" x="39.208984"/>
      <use xlink:href="#DejaVuSans-61" x="80.322266"/>
      <use xlink:href="#DejaVuSans-69" x="141.601562"/>
      <use xlink:href="#DejaVuSans-6e" x="169.384766"/>
      <use xlink:href="#DejaVuSans-20" x="232.763672"/>
      <use xlink:href="#DejaVuSans-61" x="264.550781"/>
      <use xlink:href="#DejaVuSans-63" x="325.830078"/>
      <use xlink:href="#DejaVuSans-63" x="380.810547"/>
     </g>
    </g>
    <g id="line2d_28">
     <path d="M 142.634375 53.453906 
L 152.634375 53.453906 
L 162.634375 53.453906 
" style="fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5"/>
    </g>
    <g id="text_15">
     <!-- test acc -->
     <g transform="translate(170.634375 56.953906) scale(0.1 -0.1)">
      <use xlink:href="#DejaVuSans-74"/>
      <use xlink:href="#DejaVuSans-65" x="39.208984"/>
      <use xlink:href="#DejaVuSans-73" x="100.732422"/>
      <use xlink:href="#DejaVuSans-74" x="152.832031"/>
      <use xlink:href="#DejaVuSans-20" x="192.041016"/>
      <use xlink:href="#DejaVuSans-61" x="223.828125"/>
      <use xlink:href="#DejaVuSans-63" x="285.107422"/>
      <use xlink:href="#DejaVuSans-63" x="340.087891"/>
     </g>
    </g>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="pa81473ddd1">
   <rect x="30.103125" y="10.999219" width="195.3" height="138.6"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11.9.-GPT">11.9. <a id="toc11_9_"></a><a href="#toc0_">GPT</a><a class="anchor-link" href="#11.9.-GPT"></a></h2><p>GPTGenerative Pre-trained TransformerOpenAITransformerGPTTransformerUnidirectionalGPTGPT-12018GPT-22019GPT-32020</p>
<div class="highlight"><pre><span></span><span class="n">TransformerDecoder</span><span class="err"></span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11.10.-Mamba">11.10. <a id="toc11_10_"></a><a href="#toc0_">Mamba</a><a class="anchor-link" href="#11.10.-Mamba"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>


<span class="c1"># SSM</span>
<span class="k">class</span> <span class="nc">SSM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">state_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SSM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1">#  A, B, C, D</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">state_size</span><span class="p">,</span> <span class="n">state_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">state_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">state_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h_prev</span><span class="p">):</span>
        <span class="c1"># : h_t = A * h_{t-1} + B * x_t</span>
        <span class="n">h_next</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">@</span> <span class="n">h_prev</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">@</span> <span class="n">x</span><span class="p">)</span>
        <span class="c1"># : y_t = C * h_t + D * x_t</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">@</span> <span class="n">h_next</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">@</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">h_next</span>

<span class="c1"># </span>
<span class="k">class</span> <span class="nc">AttentionModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AttentionModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x : [seq_len, batch_size, embed_size]</span>
        <span class="n">attn_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">attn_output</span>

<span class="c1">#  Mamba </span>
<span class="k">class</span> <span class="nc">MambaModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">state_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">select_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MambaModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ssm</span> <span class="o">=</span> <span class="n">SSM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">state_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_module</span> <span class="o">=</span> <span class="n">AttentionModule</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">select_threshold</span> <span class="o">=</span> <span class="n">select_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed_size</span> <span class="o">=</span> <span class="n">embed_size</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x : [seq_len, batch_size, input_size]</span>
        <span class="n">seq_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">input_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># </span>
        
        <span class="c1"># </span>
        <span class="n">select_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">seq_len</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_threshold</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">seq_len</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">select_mask</span><span class="p">[</span><span class="n">t</span><span class="p">]:</span>
                <span class="c1"># </span>
                <span class="n">y</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ssm</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">h</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># </span>
                <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_module</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># </span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">outputs</span>


<span class="c1"># </span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">512</span>     <span class="c1"># </span>
<span class="n">state_size</span> <span class="o">=</span> <span class="mi">256</span>     <span class="c1"># </span>
<span class="n">embed_size</span> <span class="o">=</span> <span class="mi">512</span>     <span class="c1"># </span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">8</span>        <span class="c1"># </span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">6</span>       <span class="c1"># </span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">10</span>     <span class="c1"># </span>
<span class="n">select_threshold</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># </span>

<span class="c1"># </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MambaModel</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">state_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">select_threshold</span><span class="p">)</span>

<span class="c1">#  ( 30batch size  16)</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># : [batch_size, output_size]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[1], line 84</span>
<span class="ansi-green-intense-fg ansi-bold">     82</span> <span style="color: rgb(95,135,135)">#  ( 30batch size  16)</span>
<span class="ansi-green-intense-fg ansi-bold">     83</span> input_data <span style="color: rgb(98,98,98)">=</span> torch<span style="color: rgb(98,98,98)">.</span>rand(<span style="color: rgb(98,98,98)">30</span>, <span style="color: rgb(98,98,98)">16</span>, input_size)
<span class="ansi-green-fg">---&gt; 84</span> output <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">model</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">input_data</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     86</span> <span style="color: rgb(0,135,0)">print</span>(output<span style="color: rgb(98,98,98)">.</span>shape)  <span style="color: rgb(95,135,135)"># : [batch_size, output_size]</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1553</span>, in <span class="ansi-cyan-fg">Module._wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1551</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_compiled_call_impl(<span style="color: rgb(98,98,98)">*</span>args, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs)  <span style="color: rgb(95,135,135)"># type: ignore[misc]</span>
<span class="ansi-green-intense-fg ansi-bold">   1552</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1553</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_call_impl</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1562</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1557</span> <span style="color: rgb(95,135,135)"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="ansi-green-intense-fg ansi-bold">   1558</span> <span style="color: rgb(95,135,135)"># this function, and just call forward.</span>
<span class="ansi-green-intense-fg ansi-bold">   1559</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> (<span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_backward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_backward_pre_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_pre_hooks
<span class="ansi-green-intense-fg ansi-bold">   1560</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_backward_pre_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_backward_hooks
<span class="ansi-green-intense-fg ansi-bold">   1561</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_forward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1562</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">forward_call</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1564</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-intense-fg ansi-bold">   1565</span>     result <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>

Cell <span class="ansi-green-fg">In[1], line 57</span>, in <span class="ansi-cyan-fg">MambaModel.forward</span><span class="ansi-blue-fg">(self, x)</span>
<span class="ansi-green-intense-fg ansi-bold">     54</span> <span class="ansi-bold" style="color: rgb(0,135,0)">for</span> t <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> <span style="color: rgb(0,135,0)">range</span>(seq_len):
<span class="ansi-green-intense-fg ansi-bold">     55</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> select_mask[t]:
<span class="ansi-green-intense-fg ansi-bold">     56</span>         <span style="color: rgb(95,135,135)"># </span>
<span class="ansi-green-fg">---&gt; 57</span>         y, h <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">ssm</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">x</span><span class="ansi-yellow-bg">[</span><span class="ansi-yellow-bg">t</span><span class="ansi-yellow-bg">]</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">h</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     58</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-intense-fg ansi-bold">     59</span>         <span style="color: rgb(95,135,135)"># </span>
<span class="ansi-green-intense-fg ansi-bold">     60</span>         y <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>attention_module(x[t]<span style="color: rgb(98,98,98)">.</span>unsqueeze(<span style="color: rgb(98,98,98)">0</span>))<span style="color: rgb(98,98,98)">.</span>squeeze(<span style="color: rgb(98,98,98)">0</span>)

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1553</span>, in <span class="ansi-cyan-fg">Module._wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1551</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_compiled_call_impl(<span style="color: rgb(98,98,98)">*</span>args, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs)  <span style="color: rgb(95,135,135)"># type: ignore[misc]</span>
<span class="ansi-green-intense-fg ansi-bold">   1552</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1553</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_call_impl</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1562</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1557</span> <span style="color: rgb(95,135,135)"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="ansi-green-intense-fg ansi-bold">   1558</span> <span style="color: rgb(95,135,135)"># this function, and just call forward.</span>
<span class="ansi-green-intense-fg ansi-bold">   1559</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> (<span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_backward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_backward_pre_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_pre_hooks
<span class="ansi-green-intense-fg ansi-bold">   1560</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_backward_pre_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_backward_hooks
<span class="ansi-green-intense-fg ansi-bold">   1561</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_forward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1562</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">forward_call</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1564</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-intense-fg ansi-bold">   1565</span>     result <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>

Cell <span class="ansi-green-fg">In[1], line 18</span>, in <span class="ansi-cyan-fg">SSM.forward</span><span class="ansi-blue-fg">(self, x, h_prev)</span>
<span class="ansi-green-intense-fg ansi-bold">     16</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">forward</span>(<span style="color: rgb(0,135,0)">self</span>, x, h_prev):
<span class="ansi-green-intense-fg ansi-bold">     17</span>     <span style="color: rgb(95,135,135)"># : h_t = A * h_{t-1} + B * x_t</span>
<span class="ansi-green-fg">---&gt; 18</span>     h_next <span style="color: rgb(98,98,98)">=</span> torch<span style="color: rgb(98,98,98)">.</span>tanh(<span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">A</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">@</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">h_prev</span> <span style="color: rgb(98,98,98)">+</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>B <span style="color: rgb(98,98,98)">@</span> x)
<span class="ansi-green-intense-fg ansi-bold">     19</span>     <span style="color: rgb(95,135,135)"># : y_t = C * h_t + D * x_t</span>
<span class="ansi-green-intense-fg ansi-bold">     20</span>     y <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>C <span style="color: rgb(98,98,98)">@</span> h_next <span style="color: rgb(98,98,98)">+</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>D <span style="color: rgb(98,98,98)">@</span> x

<span class="ansi-red-fg">RuntimeError</span>: mat1 and mat2 shapes cannot be multiplied (256x256 and 16x512)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">AutoModelForMaskedLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="kn">import</span> <span class="nn">torch</span>


<span class="n">model_path</span> <span class="o">=</span> <span class="s1">'kuleshov-group/PlantCaduceus_l24'</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForMaskedLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">sequence</span> <span class="o">=</span> <span class="s2">"ATGCGTACGATCGTAG"</span>
<span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_plus</span><span class="p">(</span>
            <span class="n">sequence</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">,</span>
            <span class="n">return_attention_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">return_token_type_ids</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">OSError</span>                                   Traceback (most recent call last)
File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/urllib3/connection.py:196</span>, in <span class="ansi-cyan-fg">HTTPConnection._new_conn</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    195</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-fg">--&gt; 196</span>     sock <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">connection</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">create_connection</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    197</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_dns_host</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">port</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    198</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">timeout</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    199</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">source_address</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">source_address</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    200</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">socket_options</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">socket_options</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    201</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    202</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> socket<span style="color: rgb(98,98,98)">.</span>gaierror <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> e:

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/urllib3/util/connection.py:85</span>, in <span class="ansi-cyan-fg">create_connection</span><span class="ansi-blue-fg">(address, timeout, source_address, socket_options)</span>
<span class="ansi-green-intense-fg ansi-bold">     84</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-fg">---&gt; 85</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> err
<span class="ansi-green-intense-fg ansi-bold">     86</span> <span class="ansi-bold" style="color: rgb(0,135,0)">finally</span>:
<span class="ansi-green-intense-fg ansi-bold">     87</span>     <span style="color: rgb(95,135,135)"># Break explicitly a reference cycle</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/urllib3/util/connection.py:73</span>, in <span class="ansi-cyan-fg">create_connection</span><span class="ansi-blue-fg">(address, timeout, source_address, socket_options)</span>
<span class="ansi-green-intense-fg ansi-bold">     72</span>     sock<span style="color: rgb(98,98,98)">.</span>bind(source_address)
<span class="ansi-green-fg">---&gt; 73</span> <span class="ansi-yellow-bg">sock</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">connect</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">sa</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     74</span> <span style="color: rgb(95,135,135)"># Break explicitly a reference cycle</span>

<span class="ansi-red-fg">OSError</span>: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

<span class="ansi-red-fg">NewConnectionError</span>                        Traceback (most recent call last)
File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/urllib3/connectionpool.py:789</span>, in <span class="ansi-cyan-fg">HTTPConnectionPool.urlopen</span><span class="ansi-blue-fg">(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)</span>
<span class="ansi-green-intense-fg ansi-bold">    788</span> <span style="color: rgb(95,135,135)"># Make the request on the HTTPConnection object</span>
<span class="ansi-green-fg">--&gt; 789</span> response <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_make_request</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    790</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">conn</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    791</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">method</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    792</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    793</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">timeout</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">timeout_obj</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    794</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">body</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">body</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    795</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">headers</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">headers</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    796</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">chunked</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">chunked</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    797</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">retries</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">retries</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    798</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">response_conn</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">response_conn</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    799</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">preload_content</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">preload_content</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    800</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">decode_content</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">decode_content</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    801</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">response_kw</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    802</span> <span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    804</span> <span style="color: rgb(95,135,135)"># Everything went great!</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/urllib3/connectionpool.py:490</span>, in <span class="ansi-cyan-fg">HTTPConnectionPool._make_request</span><span class="ansi-blue-fg">(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)</span>
<span class="ansi-green-intense-fg ansi-bold">    489</span>         new_e <span style="color: rgb(98,98,98)">=</span> _wrap_proxy_error(new_e, conn<span style="color: rgb(98,98,98)">.</span>proxy<span style="color: rgb(98,98,98)">.</span>scheme)
<span class="ansi-green-fg">--&gt; 490</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> new_e
<span class="ansi-green-intense-fg ansi-bold">    492</span> <span style="color: rgb(95,135,135)"># conn.request() calls http.client.*.request, not the method in</span>
<span class="ansi-green-intense-fg ansi-bold">    493</span> <span style="color: rgb(95,135,135)"># urllib3.request. It also calls makefile (recv) on the socket.</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/urllib3/connectionpool.py:466</span>, in <span class="ansi-cyan-fg">HTTPConnectionPool._make_request</span><span class="ansi-blue-fg">(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)</span>
<span class="ansi-green-intense-fg ansi-bold">    465</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-fg">--&gt; 466</span>     <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_validate_conn</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">conn</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    467</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> (SocketTimeout, BaseSSLError) <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> e:

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/urllib3/connectionpool.py:1095</span>, in <span class="ansi-cyan-fg">HTTPSConnectionPool._validate_conn</span><span class="ansi-blue-fg">(self, conn)</span>
<span class="ansi-green-intense-fg ansi-bold">   1094</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> conn<span style="color: rgb(98,98,98)">.</span>is_closed:
<span class="ansi-green-fg">-&gt; 1095</span>     <span class="ansi-yellow-bg">conn</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">connect</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1097</span> <span style="color: rgb(95,135,135)"># TODO revise this, see https://github.com/urllib3/urllib3/issues/2791</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/urllib3/connection.py:615</span>, in <span class="ansi-cyan-fg">HTTPSConnection.connect</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    614</span> sock: socket<span style="color: rgb(98,98,98)">.</span>socket <span style="color: rgb(98,98,98)">|</span> ssl<span style="color: rgb(98,98,98)">.</span>SSLSocket
<span class="ansi-green-fg">--&gt; 615</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>sock <span style="color: rgb(98,98,98)">=</span> sock <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_new_conn</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    616</span> server_hostname: <span style="color: rgb(0,135,0)">str</span> <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>host

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/urllib3/connection.py:211</span>, in <span class="ansi-cyan-fg">HTTPConnection._new_conn</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    210</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> <span class="ansi-bold" style="color: rgb(215,95,95)">OSError</span> <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> e:
<span class="ansi-green-fg">--&gt; 211</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> NewConnectionError(
<span class="ansi-green-intense-fg ansi-bold">    212</span>         <span style="color: rgb(0,135,0)">self</span>, <span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">Failed to establish a new connection: </span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span>e<span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)">"</span>
<span class="ansi-green-intense-fg ansi-bold">    213</span>     ) <span class="ansi-bold" style="color: rgb(0,135,0)">from</span> <span class="ansi-bold" style="color: rgb(0,0,255)">e</span>
<span class="ansi-green-intense-fg ansi-bold">    215</span> <span style="color: rgb(95,135,135)"># Audit hooks are only available in Python 3.8+</span>

<span class="ansi-red-fg">NewConnectionError</span>: &lt;urllib3.connection.HTTPSConnection object at 0x7fd52090eb10&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

<span class="ansi-red-fg">MaxRetryError</span>                             Traceback (most recent call last)
File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/requests/adapters.py:667</span>, in <span class="ansi-cyan-fg">HTTPAdapter.send</span><span class="ansi-blue-fg">(self, request, stream, timeout, verify, cert, proxies)</span>
<span class="ansi-green-intense-fg ansi-bold">    666</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-fg">--&gt; 667</span>     resp <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">conn</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">urlopen</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    668</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">method</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">request</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">method</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    669</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    670</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">body</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">request</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">body</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    671</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">headers</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">request</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">headers</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    672</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">redirect</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">False</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    673</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">assert_same_host</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">False</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    674</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">preload_content</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">False</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    675</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">decode_content</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">False</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    676</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">retries</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">max_retries</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    677</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">timeout</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">timeout</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    678</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">chunked</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">chunked</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    679</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    681</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> (ProtocolError, <span class="ansi-bold" style="color: rgb(215,95,95)">OSError</span>) <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> err:

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/urllib3/connectionpool.py:843</span>, in <span class="ansi-cyan-fg">HTTPConnectionPool.urlopen</span><span class="ansi-blue-fg">(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)</span>
<span class="ansi-green-intense-fg ansi-bold">    841</span>     new_e <span style="color: rgb(98,98,98)">=</span> ProtocolError(<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">Connection aborted.</span><span style="color: rgb(175,0,0)">"</span>, new_e)
<span class="ansi-green-fg">--&gt; 843</span> retries <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">retries</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">increment</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    844</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">method</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">error</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">new_e</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">_pool</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">_stacktrace</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">sys</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">exc_info</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">[</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">2</span><span class="ansi-yellow-bg">]</span>
<span class="ansi-green-intense-fg ansi-bold">    845</span> <span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    846</span> retries<span style="color: rgb(98,98,98)">.</span>sleep()

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/urllib3/util/retry.py:519</span>, in <span class="ansi-cyan-fg">Retry.increment</span><span class="ansi-blue-fg">(self, method, url, response, error, _pool, _stacktrace)</span>
<span class="ansi-green-intense-fg ansi-bold">    518</span>     reason <span style="color: rgb(98,98,98)">=</span> error <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> ResponseError(cause)
<span class="ansi-green-fg">--&gt; 519</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> MaxRetryError(_pool, url, reason) <span class="ansi-bold" style="color: rgb(0,135,0)">from</span> <span class="ansi-bold" style="color: rgb(0,0,255)">reason</span>  <span style="color: rgb(95,135,135)"># type: ignore[arg-type]</span>
<span class="ansi-green-intense-fg ansi-bold">    521</span> log<span style="color: rgb(98,98,98)">.</span>debug(<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">Incremented Retry for (url=</span><span style="color: rgb(175,0,0)">'</span><span class="ansi-bold" style="color: rgb(175,95,135)">%s</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">): </span><span class="ansi-bold" style="color: rgb(175,95,135)">%r</span><span style="color: rgb(175,0,0)">"</span>, url, new_retry)

<span class="ansi-red-fg">MaxRetryError</span>: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /kuleshov-group/PlantCaduceus_l24/resolve/main/config.json (Caused by NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x7fd52090eb10&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable'))

During handling of the above exception, another exception occurred:

<span class="ansi-red-fg">ConnectionError</span>                           Traceback (most recent call last)
File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1746</span>, in <span class="ansi-cyan-fg">_get_metadata_or_catch_error</span><span class="ansi-blue-fg">(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)</span>
<span class="ansi-green-intense-fg ansi-bold">   1745</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-fg">-&gt; 1746</span>     metadata <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">get_hf_file_metadata</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">   1747</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">proxies</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">proxies</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">timeout</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">etag_timeout</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">headers</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">headers</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">token</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">token</span>
<span class="ansi-green-intense-fg ansi-bold">   1748</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1749</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> EntryNotFoundError <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> http_error:

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114</span>, in <span class="ansi-cyan-fg">validate_hf_hub_args.&lt;locals&gt;._inner_fn</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    112</span>     kwargs <span style="color: rgb(98,98,98)">=</span> smoothly_deprecate_use_auth_token(fn_name<span style="color: rgb(98,98,98)">=</span>fn<span style="color: rgb(98,98,98)">.</span><span style="color: rgb(0,0,135)">__name__</span>, has_token<span style="color: rgb(98,98,98)">=</span>has_token, kwargs<span style="color: rgb(98,98,98)">=</span>kwargs)
<span class="ansi-green-fg">--&gt; 114</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">fn</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1666</span>, in <span class="ansi-cyan-fg">get_hf_file_metadata</span><span class="ansi-blue-fg">(url, token, proxies, timeout, library_name, library_version, user_agent, headers)</span>
<span class="ansi-green-intense-fg ansi-bold">   1665</span> <span style="color: rgb(95,135,135)"># Retrieve metadata</span>
<span class="ansi-green-fg">-&gt; 1666</span> r <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">_request_wrapper</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">   1667</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">method</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">"</span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">HEAD</span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">"</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1668</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1669</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">headers</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">headers</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1670</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">allow_redirects</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">False</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1671</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">follow_relative_redirects</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">True</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1672</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">proxies</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">proxies</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1673</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">timeout</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">timeout</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1674</span> <span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1675</span> hf_raise_for_status(r)

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/huggingface_hub/file_download.py:364</span>, in <span class="ansi-cyan-fg">_request_wrapper</span><span class="ansi-blue-fg">(method, url, follow_relative_redirects, **params)</span>
<span class="ansi-green-intense-fg ansi-bold">    363</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> follow_relative_redirects:
<span class="ansi-green-fg">--&gt; 364</span>     response <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">_request_wrapper</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    365</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">method</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">method</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    366</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    367</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">follow_relative_redirects</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">False</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    368</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">params</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    369</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    371</span>     <span style="color: rgb(95,135,135)"># If redirection, we redirect only relative paths.</span>
<span class="ansi-green-intense-fg ansi-bold">    372</span>     <span style="color: rgb(95,135,135)"># This is useful in case of a renamed repository.</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/huggingface_hub/file_download.py:387</span>, in <span class="ansi-cyan-fg">_request_wrapper</span><span class="ansi-blue-fg">(method, url, follow_relative_redirects, **params)</span>
<span class="ansi-green-intense-fg ansi-bold">    386</span> <span style="color: rgb(95,135,135)"># Perform request and return if status_code is not in the retry list.</span>
<span class="ansi-green-fg">--&gt; 387</span> response <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">get_session</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">request</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">method</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">method</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">url</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">params</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    388</span> hf_raise_for_status(response)

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/requests/sessions.py:589</span>, in <span class="ansi-cyan-fg">Session.request</span><span class="ansi-blue-fg">(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)</span>
<span class="ansi-green-intense-fg ansi-bold">    588</span> send_kwargs<span style="color: rgb(98,98,98)">.</span>update(settings)
<span class="ansi-green-fg">--&gt; 589</span> resp <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">send</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">prep</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">send_kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    591</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> resp

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/requests/sessions.py:703</span>, in <span class="ansi-cyan-fg">Session.send</span><span class="ansi-blue-fg">(self, request, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    702</span> <span style="color: rgb(95,135,135)"># Send the request</span>
<span class="ansi-green-fg">--&gt; 703</span> r <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">adapter</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">send</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">request</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    705</span> <span style="color: rgb(95,135,135)"># Total elapsed time of the request (approximately)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:93</span>, in <span class="ansi-cyan-fg">UniqueRequestIdAdapter.send</span><span class="ansi-blue-fg">(self, request, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     92</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-fg">---&gt; 93</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">super</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">send</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">request</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     94</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> requests<span style="color: rgb(98,98,98)">.</span>RequestException <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> e:

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/requests/adapters.py:700</span>, in <span class="ansi-cyan-fg">HTTPAdapter.send</span><span class="ansi-blue-fg">(self, request, stream, timeout, verify, cert, proxies)</span>
<span class="ansi-green-intense-fg ansi-bold">    698</span>         <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> SSLError(e, request<span style="color: rgb(98,98,98)">=</span>request)
<span class="ansi-green-fg">--&gt; 700</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">ConnectionError</span>(e, request<span style="color: rgb(98,98,98)">=</span>request)
<span class="ansi-green-intense-fg ansi-bold">    702</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> ClosedPoolError <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> e:

<span class="ansi-red-fg">ConnectionError</span>: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /kuleshov-group/PlantCaduceus_l24/resolve/main/config.json (Caused by NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x7fd52090eb10&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: 5f13dc32-2cb8-4601-8826-7a37e560cb83)')

The above exception was the direct cause of the following exception:

<span class="ansi-red-fg">LocalEntryNotFoundError</span>                   Traceback (most recent call last)
File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/utils/hub.py:403</span>, in <span class="ansi-cyan-fg">cached_file</span><span class="ansi-blue-fg">(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    401</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-intense-fg ansi-bold">    402</span>     <span style="color: rgb(95,135,135)"># Load from URL or cache if already cached</span>
<span class="ansi-green-fg">--&gt; 403</span>     resolved_file <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">hf_hub_download</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    404</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">path_or_repo_id</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    405</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">filename</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    406</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">subfolder</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">None</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">if</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">len</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">subfolder</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">==</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">0</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">else</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">subfolder</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    407</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">repo_type</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">repo_type</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    408</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">revision</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">revision</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    409</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">cache_dir</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">cache_dir</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    410</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">user_agent</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">user_agent</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    411</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">force_download</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">force_download</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    412</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">proxies</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">proxies</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    413</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">resume_download</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">resume_download</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    414</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">token</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">token</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    415</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">local_files_only</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">local_files_only</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    416</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    417</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> GatedRepoError <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> e:

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101</span>, in <span class="ansi-cyan-fg">_deprecate_arguments.&lt;locals&gt;._inner_deprecate_positional_args.&lt;locals&gt;.inner_f</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    100</span>     warnings<span style="color: rgb(98,98,98)">.</span>warn(message, <span class="ansi-bold" style="color: rgb(215,95,95)">FutureWarning</span>)
<span class="ansi-green-fg">--&gt; 101</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">f</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114</span>, in <span class="ansi-cyan-fg">validate_hf_hub_args.&lt;locals&gt;._inner_fn</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    112</span>     kwargs <span style="color: rgb(98,98,98)">=</span> smoothly_deprecate_use_auth_token(fn_name<span style="color: rgb(98,98,98)">=</span>fn<span style="color: rgb(98,98,98)">.</span><span style="color: rgb(0,0,135)">__name__</span>, has_token<span style="color: rgb(98,98,98)">=</span>has_token, kwargs<span style="color: rgb(98,98,98)">=</span>kwargs)
<span class="ansi-green-fg">--&gt; 114</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">fn</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1232</span>, in <span class="ansi-cyan-fg">hf_hub_download</span><span class="ansi-blue-fg">(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)</span>
<span class="ansi-green-intense-fg ansi-bold">   1231</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1232</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">_hf_hub_download_to_cache_dir</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">   1233</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(95,135,135)"># Destination</span>
<span class="ansi-green-intense-fg ansi-bold">   1234</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">cache_dir</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">cache_dir</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1235</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(95,135,135)"># File info</span>
<span class="ansi-green-intense-fg ansi-bold">   1236</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">repo_id</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">repo_id</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1237</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">filename</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">filename</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1238</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">repo_type</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">repo_type</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1239</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">revision</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">revision</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1240</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(95,135,135)"># HTTP info</span>
<span class="ansi-green-intense-fg ansi-bold">   1241</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">endpoint</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">endpoint</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1242</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">etag_timeout</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">etag_timeout</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1243</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">headers</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">headers</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1244</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">proxies</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">proxies</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1245</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">token</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">token</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1246</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(95,135,135)"># Additional options</span>
<span class="ansi-green-intense-fg ansi-bold">   1247</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">local_files_only</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">local_files_only</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1248</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">force_download</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">force_download</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1249</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1339</span>, in <span class="ansi-cyan-fg">_hf_hub_download_to_cache_dir</span><span class="ansi-blue-fg">(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)</span>
<span class="ansi-green-intense-fg ansi-bold">   1338</span>     <span style="color: rgb(95,135,135)"># Otherwise, raise appropriate error</span>
<span class="ansi-green-fg">-&gt; 1339</span>     <span class="ansi-yellow-bg">_raise_on_head_call_error</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">head_call_error</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">force_download</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">local_files_only</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1341</span> <span style="color: rgb(95,135,135)"># From now on, etag, commit_hash, url and size are not None.</span>

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1857</span>, in <span class="ansi-cyan-fg">_raise_on_head_call_error</span><span class="ansi-blue-fg">(head_call_error, force_download, local_files_only)</span>
<span class="ansi-green-intense-fg ansi-bold">   1855</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-intense-fg ansi-bold">   1856</span>     <span style="color: rgb(95,135,135)"># Otherwise: most likely a connection issue or Hub downtime =&gt; let's warn the user</span>
<span class="ansi-green-fg">-&gt; 1857</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> LocalEntryNotFoundError(
<span class="ansi-green-intense-fg ansi-bold">   1858</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">An error happened while trying to locate the file on the Hub and we cannot find the requested files</span><span style="color: rgb(175,0,0)">"</span>
<span class="ansi-green-intense-fg ansi-bold">   1859</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)"> in the local cache. Please check your connection and try again or make sure your Internet connection</span><span style="color: rgb(175,0,0)">"</span>
<span class="ansi-green-intense-fg ansi-bold">   1860</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)"> is on.</span><span style="color: rgb(175,0,0)">"</span>
<span class="ansi-green-intense-fg ansi-bold">   1861</span>     ) <span class="ansi-bold" style="color: rgb(0,135,0)">from</span> <span class="ansi-bold" style="color: rgb(0,0,255)">head_call_error</span>

<span class="ansi-red-fg">LocalEntryNotFoundError</span>: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.

The above exception was the direct cause of the following exception:

<span class="ansi-red-fg">OSError</span>                                   Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[14], line 5</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> model_path <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">kuleshov-group/PlantCaduceus_l24</span><span style="color: rgb(175,0,0)">'</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> device <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">cuda:0</span><span style="color: rgb(175,0,0)">"</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> torch<span style="color: rgb(98,98,98)">.</span>cuda<span style="color: rgb(98,98,98)">.</span>is_available() <span class="ansi-bold" style="color: rgb(0,135,0)">else</span> <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">cpu</span><span style="color: rgb(175,0,0)">"</span>
<span class="ansi-green-fg">----&gt; 5</span> model <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">AutoModelForMaskedLM</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">from_pretrained</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">model_path</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">trust_remote_code</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">True</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">device_map</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">device</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      6</span> model<span style="color: rgb(98,98,98)">.</span>eval()
<span class="ansi-green-intense-fg ansi-bold">      7</span> tokenizer <span style="color: rgb(98,98,98)">=</span> AutoTokenizer<span style="color: rgb(98,98,98)">.</span>from_pretrained(model_path, trust_remote_code<span style="color: rgb(98,98,98)">=</span><span class="ansi-bold" style="color: rgb(0,135,0)">True</span>)

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:526</span>, in <span class="ansi-cyan-fg">_BaseAutoModelClass.from_pretrained</span><span class="ansi-blue-fg">(cls, pretrained_model_name_or_path, *model_args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    523</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> kwargs<span style="color: rgb(98,98,98)">.</span>get(<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">quantization_config</span><span style="color: rgb(175,0,0)">"</span>, <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>) <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>:
<span class="ansi-green-intense-fg ansi-bold">    524</span>     _ <span style="color: rgb(98,98,98)">=</span> kwargs<span style="color: rgb(98,98,98)">.</span>pop(<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">quantization_config</span><span style="color: rgb(175,0,0)">"</span>)
<span class="ansi-green-fg">--&gt; 526</span> config, kwargs <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">AutoConfig</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">from_pretrained</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    527</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">pretrained_model_name_or_path</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    528</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">return_unused_kwargs</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">True</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    529</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">trust_remote_code</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">trust_remote_code</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    530</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">code_revision</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">code_revision</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    531</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">_commit_hash</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">commit_hash</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    532</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">hub_kwargs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    533</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    534</span> <span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    536</span> <span style="color: rgb(95,135,135)"># if torch_dtype=auto was passed here, ensure to pass it on</span>
<span class="ansi-green-intense-fg ansi-bold">    537</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> kwargs_orig<span style="color: rgb(98,98,98)">.</span>get(<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">torch_dtype</span><span style="color: rgb(175,0,0)">"</span>, <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>) <span style="color: rgb(98,98,98)">==</span> <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">auto</span><span style="color: rgb(175,0,0)">"</span>:

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1006</span>, in <span class="ansi-cyan-fg">AutoConfig.from_pretrained</span><span class="ansi-blue-fg">(cls, pretrained_model_name_or_path, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1003</span> trust_remote_code <span style="color: rgb(98,98,98)">=</span> kwargs<span style="color: rgb(98,98,98)">.</span>pop(<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">trust_remote_code</span><span style="color: rgb(175,0,0)">"</span>, <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>)
<span class="ansi-green-intense-fg ansi-bold">   1004</span> code_revision <span style="color: rgb(98,98,98)">=</span> kwargs<span style="color: rgb(98,98,98)">.</span>pop(<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">code_revision</span><span style="color: rgb(175,0,0)">"</span>, <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>)
<span class="ansi-green-fg">-&gt; 1006</span> config_dict, unused_kwargs <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">PretrainedConfig</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">get_config_dict</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">pretrained_model_name_or_path</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1007</span> has_remote_code <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">auto_map</span><span style="color: rgb(175,0,0)">"</span> <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> config_dict <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">AutoConfig</span><span style="color: rgb(175,0,0)">"</span> <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> config_dict[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">auto_map</span><span style="color: rgb(175,0,0)">"</span>]
<span class="ansi-green-intense-fg ansi-bold">   1008</span> has_local_code <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">model_type</span><span style="color: rgb(175,0,0)">"</span> <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> config_dict <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> config_dict[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">model_type</span><span style="color: rgb(175,0,0)">"</span>] <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> CONFIG_MAPPING

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/configuration_utils.py:570</span>, in <span class="ansi-cyan-fg">PretrainedConfig.get_config_dict</span><span class="ansi-blue-fg">(cls, pretrained_model_name_or_path, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    568</span> original_kwargs <span style="color: rgb(98,98,98)">=</span> copy<span style="color: rgb(98,98,98)">.</span>deepcopy(kwargs)
<span class="ansi-green-intense-fg ansi-bold">    569</span> <span style="color: rgb(95,135,135)"># Get config dict associated with the base config file</span>
<span class="ansi-green-fg">--&gt; 570</span> config_dict, kwargs <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">cls</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_get_config_dict</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">pretrained_model_name_or_path</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    571</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> config_dict <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>:
<span class="ansi-green-intense-fg ansi-bold">    572</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> {}, kwargs

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/configuration_utils.py:629</span>, in <span class="ansi-cyan-fg">PretrainedConfig._get_config_dict</span><span class="ansi-blue-fg">(cls, pretrained_model_name_or_path, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    625</span> configuration_file <span style="color: rgb(98,98,98)">=</span> kwargs<span style="color: rgb(98,98,98)">.</span>pop(<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">_configuration_file</span><span style="color: rgb(175,0,0)">"</span>, CONFIG_NAME) <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> gguf_file <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span> gguf_file
<span class="ansi-green-intense-fg ansi-bold">    627</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-intense-fg ansi-bold">    628</span>     <span style="color: rgb(95,135,135)"># Load from local folder or from cache or download from model Hub and cache</span>
<span class="ansi-green-fg">--&gt; 629</span>     resolved_config_file <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">cached_file</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    630</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">pretrained_model_name_or_path</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    631</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">configuration_file</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    632</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">cache_dir</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">cache_dir</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    633</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">force_download</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">force_download</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    634</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">proxies</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">proxies</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    635</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">resume_download</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">resume_download</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    636</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">local_files_only</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">local_files_only</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    637</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">token</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">token</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    638</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">user_agent</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">user_agent</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    639</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">revision</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">revision</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    640</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">subfolder</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">subfolder</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    641</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">_commit_hash</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">commit_hash</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    642</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    643</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> resolved_config_file <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>:
<span class="ansi-green-intense-fg ansi-bold">    644</span>         <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>, kwargs

File <span class="ansi-green-fg">~/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/utils/hub.py:446</span>, in <span class="ansi-cyan-fg">cached_file</span><span class="ansi-blue-fg">(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    440</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> (
<span class="ansi-green-intense-fg ansi-bold">    441</span>         resolved_file <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>
<span class="ansi-green-intense-fg ansi-bold">    442</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> _raise_exceptions_for_missing_entries
<span class="ansi-green-intense-fg ansi-bold">    443</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> _raise_exceptions_for_connection_errors
<span class="ansi-green-intense-fg ansi-bold">    444</span>     ):
<span class="ansi-green-intense-fg ansi-bold">    445</span>         <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> resolved_file
<span class="ansi-green-fg">--&gt; 446</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">EnvironmentError</span>(
<span class="ansi-green-intense-fg ansi-bold">    447</span>         <span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">We couldn</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">t connect to </span><span style="color: rgb(175,0,0)">'</span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span>HUGGINGFACE_CO_RESOLVE_ENDPOINT<span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)"> to load this file, couldn</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">t find it in the</span><span style="color: rgb(175,0,0)">"</span>
<span class="ansi-green-intense-fg ansi-bold">    448</span>         <span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)"> cached files and it looks like </span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span>path_or_repo_id<span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)"> is not the path to a directory containing a file named</span><span style="color: rgb(175,0,0)">"</span>
<span class="ansi-green-intense-fg ansi-bold">    449</span>         <span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)"> </span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span>full_filename<span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)">.</span><span class="ansi-bold" style="color: rgb(175,95,0)">\n</span><span style="color: rgb(175,0,0)">Checkout your internet connection or see how to run the library in offline mode at</span><span style="color: rgb(175,0,0)">"</span>
<span class="ansi-green-intense-fg ansi-bold">    450</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)"> </span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">https://huggingface.co/docs/transformers/installation#offline-mode</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">.</span><span style="color: rgb(175,0,0)">"</span>
<span class="ansi-green-intense-fg ansi-bold">    451</span>     ) <span class="ansi-bold" style="color: rgb(0,135,0)">from</span> <span class="ansi-bold" style="color: rgb(0,0,255)">e</span>
<span class="ansi-green-intense-fg ansi-bold">    452</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> EntryNotFoundError <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> e:
<span class="ansi-green-intense-fg ansi-bold">    453</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> _raise_exceptions_for_missing_entries:

<span class="ansi-red-fg">OSError</span>: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like kuleshov-group/PlantCaduceus_l24 is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="12.-==============">12. <a id="toc12_"></a><a href="#toc0_">==============</a><a class="anchor-link" href="#12.-=============="></a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="13.-%E7%82%BC%E4%B8%B9%E5%BF%83%E5%BE%97">13. <a id="toc13_"></a><a href="#toc0_"></a><a class="anchor-link" href="#13.-%E7%82%BC%E4%B8%B9%E5%BF%83%E5%BE%97"></a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="13.1.-%E5%85%B3%E4%BA%8E%E8%B0%83%E5%8F%82">13.1. <a id="toc13_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#13.1.-%E5%85%B3%E4%BA%8E%E8%B0%83%E5%8F%82"></a></h2><ol>
<li><p>Pytorch</p>
</li>
<li><p></p>
</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[88]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span> 

<span class="k">class</span> <span class="nc">MyLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''''''</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>  <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>    <span class="c1"># </span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="nd">@X</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
        <span class="c1"># y_hat = torch.matmul(self.weight.data, X) + self.bias.data    # </span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>

<span class="n">myLayer</span> <span class="o">=</span> <span class="n">MyLayer</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">myLayer</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[88]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0.3751])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">myLayer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>OrderedDict([('weight', tensor([-1.2126,  0.9969])), ('bias', tensor([0.]))])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="13.2.-%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9">13.2. <a id="toc13_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#13.2.-%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"></a></h2><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="13.3.-one-hot">13.3. <a id="toc13_3_"></a><a href="#toc0_">one-hot</a><a class="anchor-link" href="#13.3.-one-hot"></a></h2><div class="highlight"><pre><span></span>

</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[107]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 


<span class="c1"># </span>
<span class="n">raw</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">raw</span><span class="p">);</span> <span class="n">raw</span>
<span class="n">col_raw</span> <span class="o">=</span> <span class="n">raw</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span> <span class="n">col_raw</span>
<span class="n">col_raw</span> <span class="o">==</span> <span class="n">raw</span> <span class="c1"># 5 1  1 5</span>
<span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">col_raw</span> <span class="o">==</span> <span class="n">raw</span><span class="p">)</span> <span class="c1"># bool</span>
<span class="n">one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">col_raw</span> <span class="o">==</span> <span class="n">raw</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># bool -&gt; torch.float32</span>
<span class="n">col_raw</span><span class="p">,</span> <span class="n">one_hot</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/tmp/ipykernel_32820/3359500813.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(col_raw == raw) # bool
/tmp/ipykernel_32820/3359500813.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  one_hot = torch.tensor(col_raw == raw, dtype=torch.float32) # bool -&gt; torch.float32
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[107]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[0],
         [1],
         [2],
         [3],
         [4]]),
 tensor([[1., 0., 0., 0., 0.],
         [0., 1., 0., 0., 0.],
         [0., 0., 1., 0., 0.],
         [0., 0., 0., 1., 0.],
         [0., 0., 0., 0., 1.]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[31]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span> 


<span class="c1"># </span>
<span class="n">raw</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">raw</span><span class="p">);</span> <span class="n">raw</span>

<span class="c1"># help(F.one_hot)</span>
<span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">raw</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[31]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1., 0., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 1.]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="13.4.-embedding">13.4. <a id="toc13_4_"></a><a href="#toc0_">embedding</a><a class="anchor-link" href="#13.4.-embedding"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span> 


<span class="c1"># </span>
<span class="n">raw</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">raw</span><span class="p">);</span> <span class="n">raw</span>
<span class="c1"># </span>
<span class="c1"># help(F.embedding)</span>
<span class="c1"># F.embedding(raw)</span>

<span class="c1"># </span>
<span class="c1"># help(nn.Embedding)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[32]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0, 1, 2, 3, 4])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="13.5.-BN%E5%92%8CLN">13.5. <a id="toc13_5_"></a><a href="#toc0_">BNLN</a><a class="anchor-link" href="#13.5.-BN%E5%92%8CLN"></a></h2><p>Batch normLayer norm</p>
<ul>
<li><p>BatchNormnormalization standerlization</p>
</li>
<li><p>LayerNormnormalization standerlization</p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 


<span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[166]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">normalized_shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="n">x</span><span class="p">,</span> <span class="n">ln</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[166]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[0., 1., 2., 3., 4.],
         [5., 6., 7., 8., 9.]]),
 tensor([[-1.5667, -1.2185, -0.8704, -0.5222, -0.1741],
         [ 0.1741,  0.5222,  0.8704,  1.2185,  1.5667]],
        grad_fn=&lt;NativeLayerNormBackward0&gt;))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="13.6.-%E6%8E%A9%E7%A0%81-(masked)">13.6. <a id="toc13_6_"></a><a href="#toc0_"> (masked)</a><a class="anchor-link" href="#13.6.-%E6%8E%A9%E7%A0%81-(masked)"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[82]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>  


<span class="c1"># 5</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># 0 </span>
    <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="p">])</span>
<span class="n">sequences</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[82]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1, 2, 3, 0, 0],
        [4, 5, 0, 0, 0],
        [6, 7, 8, 9, 0]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[84]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># mask10</span>
<span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">sequences</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">mask</span><span class="p">,</span> <span class="n">mask</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[84]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[ True,  True,  True, False, False],
         [ True,  True, False, False, False],
         [ True,  True,  True,  True, False]]),
 torch.Size([3, 5]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[85]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">attention_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_length, seq_length)</span>
<span class="n">attention_scores</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[85]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[[0.7284, 0.8325, 0.7335, 0.1139, 0.1076],
         [0.4551, 0.3431, 0.4233, 0.4487, 0.4088],
         [0.6648, 0.7469, 0.0081, 0.3561, 0.6371],
         [0.1827, 0.9752, 0.4536, 0.1833, 0.0134],
         [0.2960, 0.3019, 0.9114, 0.7341, 0.1060]],

        [[0.7884, 0.0216, 0.1738, 0.4676, 0.9999],
         [0.7880, 0.1560, 0.8824, 0.6159, 0.1431],
         [0.8611, 0.5480, 0.3371, 0.6470, 0.0264],
         [0.0806, 0.9418, 0.8446, 0.7451, 0.1869],
         [0.2446, 0.0949, 0.8124, 0.3302, 0.1335]],

        [[0.0106, 0.8559, 0.8870, 0.3322, 0.6260],
         [0.2074, 0.1152, 0.6055, 0.7251, 0.2114],
         [0.3443, 0.9339, 0.3960, 0.9770, 0.5540],
         [0.1821, 0.4533, 0.3604, 0.4188, 0.2743],
         [0.3007, 0.6403, 0.9883, 0.0820, 0.4548]]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[91]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># masked_fill</span>
<span class="c1"># maskattention_scores</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">sequences</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">mask</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[91]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[[ True,  True,  True, False, False],
         [ True,  True,  True, False, False],
         [ True,  True,  True, False, False],
         [ True,  True,  True, False, False],
         [ True,  True,  True, False, False]],

        [[ True,  True, False, False, False],
         [ True,  True, False, False, False],
         [ True,  True, False, False, False],
         [ True,  True, False, False, False],
         [ True,  True, False, False, False]],

        [[ True,  True,  True,  True, False],
         [ True,  True,  True,  True, False],
         [ True,  True,  True,  True, False],
         [ True,  True,  True,  True, False],
         [ True,  True,  True,  True, False]]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[93]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">~</span><span class="n">mask</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[93]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[[False, False, False,  True,  True],
         [False, False, False,  True,  True],
         [False, False, False,  True,  True],
         [False, False, False,  True,  True],
         [False, False, False,  True,  True]],

        [[False, False,  True,  True,  True],
         [False, False,  True,  True,  True],
         [False, False,  True,  True,  True],
         [False, False,  True,  True,  True],
         [False, False,  True,  True,  True]],

        [[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[96]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">attention_scores</span> <span class="o">=</span> <span class="n">attention_scores</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'-inf'</span><span class="p">))</span>
<span class="n">attention_scores</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[96]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[[0.7284, 0.8325, 0.7335,   -inf,   -inf],
         [0.4551, 0.3431, 0.4233,   -inf,   -inf],
         [0.6648, 0.7469, 0.0081,   -inf,   -inf],
         [0.1827, 0.9752, 0.4536,   -inf,   -inf],
         [0.2960, 0.3019, 0.9114,   -inf,   -inf]],

        [[0.7884, 0.0216,   -inf,   -inf,   -inf],
         [0.7880, 0.1560,   -inf,   -inf,   -inf],
         [0.8611, 0.5480,   -inf,   -inf,   -inf],
         [0.0806, 0.9418,   -inf,   -inf,   -inf],
         [0.2446, 0.0949,   -inf,   -inf,   -inf]],

        [[0.0106, 0.8559, 0.8870, 0.3322,   -inf],
         [0.2074, 0.1152, 0.6055, 0.7251,   -inf],
         [0.3443, 0.9339, 0.3960, 0.9770,   -inf],
         [0.1821, 0.4533, 0.3604, 0.4188,   -inf],
         [0.3007, 0.6403, 0.9883, 0.0820,   -inf]]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">attention_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attention_scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">":</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>:
 tensor([[[0.3210, 0.3563, 0.3227, 0.0000, 0.0000],
         [0.3493, 0.3123, 0.3384, 0.0000, 0.0000],
         [0.3840, 0.4169, 0.1991, 0.0000, 0.0000],
         [0.2212, 0.4887, 0.2901, 0.0000, 0.0000],
         [0.2593, 0.2608, 0.4798, 0.0000, 0.0000]],

        [[0.6828, 0.3172, 0.0000, 0.0000, 0.0000],
         [0.6529, 0.3471, 0.0000, 0.0000, 0.0000],
         [0.5776, 0.4224, 0.0000, 0.0000, 0.0000],
         [0.2971, 0.7029, 0.0000, 0.0000, 0.0000],
         [0.5373, 0.4627, 0.0000, 0.0000, 0.0000]],

        [[0.1406, 0.3275, 0.3378, 0.1940, 0.0000],
         [0.1969, 0.1795, 0.2932, 0.3304, 0.0000],
         [0.1743, 0.3142, 0.1835, 0.3281, 0.0000],
         [0.2095, 0.2747, 0.2504, 0.2654, 0.0000],
         [0.1924, 0.2702, 0.3827, 0.1546, 0.0000]]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="13.7.-MLP%E3%80%81FC%E3%80%81FNN%E3%80%81CNN%E3%80%81RNN">13.7. <a id="toc13_7_"></a><a href="#toc0_">MLPFCFNNCNNRNN</a><a class="anchor-link" href="#13.7.-MLP%E3%80%81FC%E3%80%81FNN%E3%80%81CNN%E3%80%81RNN"></a></h2><p>Linear()<br/>
MLP()<br/>
FNN()MLP<br/>
CNN()<br/>
RNN()</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="13.8.-%E4%BC%98%E5%8C%96%E6%98%BE%E5%AD%98">13.8. <a id="toc13_8_"></a><a href="#toc0_"></a><a class="anchor-link" href="#13.8.-%E4%BC%98%E5%8C%96%E6%98%BE%E5%AD%98"></a></h2><p>PyTorch  4 (parameters)(gradients)(optimizer states)  (intermediate activations) (intermediate results)</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="13.8.1.-%E5%88%A0%E9%99%A4%E4%B8%AD%E9%97%B4%E6%9A%82%E6%97%B6%E4%B8%8D%E7%94%A8%E7%9A%84%E5%8F%98%E9%87%8F">13.8.1. <a id="toc13_8_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#13.8.1.-%E5%88%A0%E9%99%A4%E4%B8%AD%E9%97%B4%E6%9A%82%E6%97%B6%E4%B8%8D%E7%94%A8%E7%9A%84%E5%8F%98%E9%87%8F"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 


<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># </span>
<span class="k">del</span> <span class="n">x</span> 

<span class="c1"># </span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="13.8.2.-%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83(Mixed-Precision-Training)">13.8.2. <a id="toc13_8_2_"></a><a href="#toc0_">(Mixed Precision Training)</a><a class="anchor-link" href="#13.8.2.-%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83(Mixed-Precision-Training)"></a></h3><p>FP16AMP</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[62]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch.cuda.amp</span> <span class="kn">import</span> <span class="n">autocast</span><span class="p">,</span> <span class="n">GradScaler</span>


<span class="c1"># </span>
<span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1"># GradScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">GradScaler</span><span class="p">()</span>

<span class="c1"># </span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    
    <span class="c1"># autocast</span>
    <span class="k">with</span> <span class="n">autocast</span><span class="p">():</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    
    <span class="c1"># GradScaler</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 0, Loss: 1.0867466926574707
Epoch 1, Loss: 1.086431860923767
Epoch 2, Loss: 1.0861190557479858
Epoch 3, Loss: 1.085815191268921
Epoch 4, Loss: 1.0855047702789307
Epoch 5, Loss: 1.0851939916610718
Epoch 6, Loss: 1.0848859548568726
Epoch 7, Loss: 1.0845799446105957
Epoch 8, Loss: 1.0842695236206055
Epoch 9, Loss: 1.0839548110961914
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/tmp/ipykernel_138882/2738718393.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
/tmp/ipykernel_138882/2738718393.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="13.8.3.-%E6%A2%AF%E5%BA%A6%E6%A3%80%E6%9F%A5%E7%82%B9%EF%BC%88Gradient-Checkpointing%EF%BC%89">13.8.3. <a id="toc13_8_3_"></a><a href="#toc0_">Gradient Checkpointing</a><a class="anchor-link" href="#13.8.3.-%E6%A2%AF%E5%BA%A6%E6%A3%80%E6%9F%A5%E7%82%B9%EF%BC%88Gradient-Checkpointing%EF%BC%89"></a></h3><ul>
<li><p>AlphaFold2</p>
</li>
<li><p>functiontorch.no_gradfunctionfunctionfunction</p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># torch.utils.checkpoint</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="c1"># import torch.utils.checkpoint as checkpoint</span>
<span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">checkpoint</span>


<span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># </span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1"># </span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="13.8.4.-%E5%88%86%E5%9D%97%E8%AE%A1%E7%AE%97-(Chunking)">13.8.4. <a id="toc13_8_4_"></a><a href="#toc0_"> (Chunking)</a><a class="anchor-link" href="#13.8.4.-%E5%88%86%E5%9D%97%E8%AE%A1%E7%AE%97-(Chunking)"></a></h3><p>AlphaFold2</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[47]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">channels</span> <span class="o">=</span> <span class="mi">3</span> 
<span class="n">height</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">width</span> <span class="o">=</span> <span class="mi">6</span>

<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
    <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">channels</span><span class="p">,</span>
    <span class="n">height</span><span class="p">,</span>
    <span class="n">width</span>   
<span class="p">)</span>

<span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tensor</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[47]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([2, 3, 3, 6]),
 tensor([[[[-7.9069e-01, -1.3978e-01, -1.3105e+00,  3.2958e-01, -9.6672e-01,
             1.5669e-01],
           [-4.3966e-01, -3.6362e-01, -6.8742e-01,  8.5228e-01, -2.2042e-01,
             1.0232e+00],
           [ 2.0972e+00,  1.9113e+00, -1.2787e+00, -7.1223e-01, -7.4183e-01,
            -1.3678e+00]],
 
          [[-5.3987e-01,  6.1068e-01,  2.2028e-01,  3.5663e-01,  1.5288e-01,
             9.7362e-01],
           [-1.1045e-01,  2.0648e-03,  2.4895e+00,  9.2371e-01, -2.5878e-02,
             1.2908e+00],
           [ 4.6787e-01, -8.8361e-01, -2.2292e-01,  7.2482e-01,  1.2045e+00,
            -5.9140e-01]],
 
          [[ 5.4964e-01,  1.3850e+00, -1.3860e-01,  1.5700e+00,  9.1813e-01,
            -1.0955e+00],
           [-3.5939e-01,  1.2476e+00,  7.5518e-01,  1.4270e-01, -6.3863e-01,
             5.0880e-01],
           [ 1.4854e+00,  5.9792e-01,  1.6734e-01, -2.5159e-01, -3.4093e-02,
            -5.8474e-01]]],
 
 
         [[[-1.9991e-01,  4.0300e-02, -3.9834e-02,  2.4741e-01, -6.8095e-01,
             2.8142e+00],
           [ 6.8924e-02, -5.2322e-02, -4.5837e-01, -2.5605e-02, -2.1560e-01,
            -3.6294e-01],
           [-5.5251e-01, -1.2981e-01,  1.6472e+00,  3.8976e-01, -6.1036e-01,
             4.4009e-01]],
 
          [[-1.9163e-01,  2.4639e-01, -1.2487e+00, -2.5951e+00, -1.0280e+00,
             1.2397e+00],
           [ 1.5435e+00,  3.4421e-01, -8.4561e-02,  1.1062e+00, -1.3477e+00,
            -1.1824e+00],
           [ 4.2062e-02,  3.4695e-02,  3.1417e-01,  1.7299e+00,  9.6170e-02,
             7.3319e-01]],
 
          [[ 2.0886e-01,  2.2282e+00, -5.1467e-01,  1.4173e-01,  1.0504e+00,
             3.1643e-02],
           [-6.7497e-02,  1.4354e-01, -6.4417e-01, -5.7900e-01, -1.0892e+00,
             6.9761e-01],
           [-7.6837e-01,  1.5663e+00, -8.8883e-01, -2.4440e+00, -1.5353e+00,
            -1.0908e+00]]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[50]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">chunks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># chunks.shape, chunks</span>
<span class="n">chunks</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[50]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[[[-7.9069e-01, -1.3978e-01, -1.3105e+00,  3.2958e-01, -9.6672e-01,
             1.5669e-01],
           [-4.3966e-01, -3.6362e-01, -6.8742e-01,  8.5228e-01, -2.2042e-01,
             1.0232e+00],
           [ 2.0972e+00,  1.9113e+00, -1.2787e+00, -7.1223e-01, -7.4183e-01,
            -1.3678e+00]],
 
          [[-5.3987e-01,  6.1068e-01,  2.2028e-01,  3.5663e-01,  1.5288e-01,
             9.7362e-01],
           [-1.1045e-01,  2.0648e-03,  2.4895e+00,  9.2371e-01, -2.5878e-02,
             1.2908e+00],
           [ 4.6787e-01, -8.8361e-01, -2.2292e-01,  7.2482e-01,  1.2045e+00,
            -5.9140e-01]],
 
          [[ 5.4964e-01,  1.3850e+00, -1.3860e-01,  1.5700e+00,  9.1813e-01,
            -1.0955e+00],
           [-3.5939e-01,  1.2476e+00,  7.5518e-01,  1.4270e-01, -6.3863e-01,
             5.0880e-01],
           [ 1.4854e+00,  5.9792e-01,  1.6734e-01, -2.5159e-01, -3.4093e-02,
            -5.8474e-01]]]]),
 tensor([[[[-0.1999,  0.0403, -0.0398,  0.2474, -0.6809,  2.8142],
           [ 0.0689, -0.0523, -0.4584, -0.0256, -0.2156, -0.3629],
           [-0.5525, -0.1298,  1.6472,  0.3898, -0.6104,  0.4401]],
 
          [[-0.1916,  0.2464, -1.2487, -2.5951, -1.0280,  1.2397],
           [ 1.5435,  0.3442, -0.0846,  1.1062, -1.3477, -1.1824],
           [ 0.0421,  0.0347,  0.3142,  1.7299,  0.0962,  0.7332]],
 
          [[ 0.2089,  2.2282, -0.5147,  0.1417,  1.0504,  0.0316],
           [-0.0675,  0.1435, -0.6442, -0.5790, -1.0892,  0.6976],
           [-0.7684,  1.5663, -0.8888, -2.4440, -1.5353, -1.0908]]]]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[51]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chunks</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'chunk </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">:'</span><span class="p">,</span> <span class="n">chunk</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">chunk</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>chunk 0: torch.Size([1, 3, 3, 6]) tensor([[[[-7.9069e-01, -1.3978e-01, -1.3105e+00,  3.2958e-01, -9.6672e-01,
            1.5669e-01],
          [-4.3966e-01, -3.6362e-01, -6.8742e-01,  8.5228e-01, -2.2042e-01,
            1.0232e+00],
          [ 2.0972e+00,  1.9113e+00, -1.2787e+00, -7.1223e-01, -7.4183e-01,
           -1.3678e+00]],

         [[-5.3987e-01,  6.1068e-01,  2.2028e-01,  3.5663e-01,  1.5288e-01,
            9.7362e-01],
          [-1.1045e-01,  2.0648e-03,  2.4895e+00,  9.2371e-01, -2.5878e-02,
            1.2908e+00],
          [ 4.6787e-01, -8.8361e-01, -2.2292e-01,  7.2482e-01,  1.2045e+00,
           -5.9140e-01]],

         [[ 5.4964e-01,  1.3850e+00, -1.3860e-01,  1.5700e+00,  9.1813e-01,
           -1.0955e+00],
          [-3.5939e-01,  1.2476e+00,  7.5518e-01,  1.4270e-01, -6.3863e-01,
            5.0880e-01],
          [ 1.4854e+00,  5.9792e-01,  1.6734e-01, -2.5159e-01, -3.4093e-02,
           -5.8474e-01]]]])
chunk 1: torch.Size([1, 3, 3, 6]) tensor([[[[-0.1999,  0.0403, -0.0398,  0.2474, -0.6809,  2.8142],
          [ 0.0689, -0.0523, -0.4584, -0.0256, -0.2156, -0.3629],
          [-0.5525, -0.1298,  1.6472,  0.3898, -0.6104,  0.4401]],

         [[-0.1916,  0.2464, -1.2487, -2.5951, -1.0280,  1.2397],
          [ 1.5435,  0.3442, -0.0846,  1.1062, -1.3477, -1.1824],
          [ 0.0421,  0.0347,  0.3142,  1.7299,  0.0962,  0.7332]],

         [[ 0.2089,  2.2282, -0.5147,  0.1417,  1.0504,  0.0316],
          [-0.0675,  0.1435, -0.6442, -0.5790, -1.0892,  0.6976],
          [-0.7684,  1.5663, -0.8888, -2.4440, -1.5353, -1.0908]]]])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>


<span class="k">def</span> <span class="nf">chunked_attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    </span>
<span class="sd">    """</span>
    <span class="n">num_chunks</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">//</span> <span class="n">chunk_size</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_chunks</span><span class="p">):</span>
        <span class="c1"># query, key, value</span>
        <span class="n">q_chunk</span> <span class="o">=</span> <span class="n">query</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">chunk_size</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">chunk_size</span><span class="p">]</span>
        <span class="n">k_chunk</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">chunk_size</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">chunk_size</span><span class="p">]</span>
        <span class="n">v_chunk</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">chunk_size</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">chunk_size</span><span class="p">]</span>

        <span class="c1"># </span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q_chunk</span><span class="p">,</span> <span class="n">k_chunk</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># </span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">,</span> <span class="n">v_chunk</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="c1"># </span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">seq_length</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">256</span>

<span class="n">query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">output</span> <span class="o">=</span> <span class="n">chunked_attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([1024, 64])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="14.-PyTorch%E5%81%9A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0">14. <a id="toc14_"></a><a href="#toc0_">PyTorch</a><a class="anchor-link" href="#14.-PyTorch%E5%81%9A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"></a></h1><ul>
<li><p>Fine-tuning</p>
</li>
<li><p>Fine-tuning in CV</p>
<ul>
<li><p>1.Pre-trainedEncoder</p>
</li>
<li><p>2.lerning-rateepochs</p>
</li>
<li><p>3.learning-rate0</p>
</li>
</ul>
</li>
<li><p>Pre-trained model</p>
<ul>
<li><p>TIMMpytorch-Ross</p>
</li>
<li><p>HugginFace - </p>
</li>
</ul>
</li>
<li><p>Fine-tuning in NLP</p>
<ul>
<li>1.Self-supervised pre-training;</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="14.1.-Fine-tuning">14.1. <a id="toc14_1_"></a><a href="#toc0_">Fine-tuning</a><a class="anchor-link" href="#14.1.-Fine-tuning"></a></h2><ul>
<li>Fine-tuning:<ul>
<li>lr</li>
<li>param.requires_grad = False</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="14.1.1.-%E5%B0%8F%E7%9A%84lr">14.1.1. <a id="toc14_1_1_"></a><a href="#toc0_">lr</a><a class="anchor-link" href="#14.1.1.-%E5%B0%8F%E7%9A%84lr"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>

<span class="n">param_1x</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'fc.weight'</span><span class="p">,</span> <span class="s1">'fc.bias'</span><span class="p">]]</span>    <span class="c1"># fc</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">params</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s1">'params'</span><span class="p">:</span> <span class="n">param_1x</span><span class="p">},</span>                                           <span class="c1"># lr</span>
        <span class="p">{</span><span class="s1">'params'</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">'lr'</span><span class="p">:</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="mf">0.001</span><span class="p">}</span>    <span class="c1"># lr</span>
    <span class="p">],</span> 
    <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> 
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.001</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="14.1.2.-%E5%81%9C%E6%AD%A2%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6">14.1.2. <a id="toc14_1_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#14.1.2.-%E5%81%9C%E6%AD%A2%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[67]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">''</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">'&gt;&gt;&gt;'</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">10</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'fc.weight'</span><span class="p">,</span> <span class="s1">'fc.bias'</span><span class="p">]:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">'&gt;&gt;&gt;'</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
input.weight &gt;&gt;&gt; True
input.bias &gt;&gt;&gt; True
hidden.weight &gt;&gt;&gt; True
hidden.bias &gt;&gt;&gt; True
output.weight &gt;&gt;&gt; True
output.bias &gt;&gt;&gt; True
fc.weight &gt;&gt;&gt; True
fc.bias &gt;&gt;&gt; True
========== 
 
input.weight &gt;&gt;&gt; False
input.bias &gt;&gt;&gt; False
hidden.weight &gt;&gt;&gt; False
hidden.bias &gt;&gt;&gt; False
output.weight &gt;&gt;&gt; False
output.bias &gt;&gt;&gt; False
fc.weight &gt;&gt;&gt; True
fc.bias &gt;&gt;&gt; True
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="14.2.-torchvision%E7%9A%84%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B">14.2. <a id="toc14_2_"></a><a href="#toc0_">torchvision</a><a class="anchor-link" href="#14.2.-torchvision%E7%9A%84%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="14.3.-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%A1%88%E4%BE%8B">14.3. <a id="toc14_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#14.3.-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%A1%88%E4%BE%8B"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="kn">import</span> <span class="nn">os</span>


<span class="k">class</span> <span class="nc">MyDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''torch.utils.data.Dataset'''</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dirname</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyDataset</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span> <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">dirname</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">classes</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">):</span>
            <span class="n">classes_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dirname</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">image_name</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">classes_path</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">classes_path</span><span class="p">,</span> <span class="n">image_name</span><span class="p">),</span> <span class="n">i</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">'''__len__()'''</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">images</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">'''__getitem__()'''</span>
        <span class="n">image_name</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">classes</span>
    
    <span class="k">def</span> <span class="nf">get_claesses</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span>
    
<span class="c1"># transform</span>
<span class="n">train_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Grayscale</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span> <span class="c1">#arearesize</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span> <span class="c1">#</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">val_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Grayscale</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># loader</span>
<span class="c1"># ws = 'Pytorch_datasets/hymenoptera_data/'</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="s1">'Pytorch_datasets/hymenoptera_data/train/'</span><span class="p">,</span> <span class="n">train_transform</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>

<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="s1">'Pytorch_datasets/hymenoptera_data/val/'</span><span class="p">,</span> <span class="n">val_transform</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/bmp/backup/zhaosy/miniconda3/envs/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[8]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1000, bias=True)
)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># model</span>
<span class="n">only_train_fc</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">only_train_fc</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        
<span class="n">fc_in_features</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">fc_in_features</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Parameter containing:
tensor([[ 0.0026, -0.0350, -0.0355,  ...,  0.0068,  0.0349,  0.0407],
        [-0.0257,  0.0340, -0.0237,  ..., -0.0052, -0.0351,  0.0249]],
       requires_grad=True)
Parameter containing:
tensor([-0.0364,  0.0310], requires_grad=True)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda:0'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'cpu'</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'cuda:0'</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">opt_step</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">max_acc</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">epoch_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">epoch_loss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">type_id</span><span class="p">,</span> <span class="n">loader</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">]):</span>
        <span class="c1"># print('type_id:',type_id)</span>
        <span class="n">mean_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">mean_acc</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">type_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># opt_step.step()</span>
                <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">type_id</span><span class="o">==</span><span class="mi">0</span><span class="p">):</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">pre_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">type_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pre_labels</span><span class="o">==</span><span class="n">labels</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>        
            <span class="n">mean_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">mean_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">type_id</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">epoch_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_acc</span><span class="p">))</span>
            <span class="n">epoch_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_loss</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">max_acc</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_acc</span><span class="p">):</span>
                <span class="n">max_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_acc</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">type_id</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_loss</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_acc</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">max_acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>0 0.31711972 0.88244045
1 0.30389076 0.85200006
0 0.33484977 0.858817
1 0.4615616 0.80550003
0.85200006
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="15.-TorchMetrics">15. <a id="toc15_"></a><a href="#toc0_">TorchMetrics</a><a class="anchor-link" href="#15.-TorchMetrics"></a></h1><ul>
<li><p></p>
</li>
<li><p> F1 </p>
</li>
<li><p>GAN Frechet Inception DistanceFID</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="15.1.-%E5%87%86%E7%A1%AE%E7%8E%87%E3%80%81%E7%B2%BE%E7%A1%AE%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E5%92%8CF1%E5%88%86%E6%95%B0">15.1. <a id="toc15_1_"></a><a href="#toc0_">F1</a><a class="anchor-link" href="#15.1.-%E5%87%86%E7%A1%AE%E7%8E%87%E3%80%81%E7%B2%BE%E7%A1%AE%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E5%92%8CF1%E5%88%86%E6%95%B0"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">torchmetrics</span> 

<span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="c1">#  Accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">"multiclass"</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'acc:'</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>

<span class="c1">#  precision</span>
<span class="n">precision</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Precision</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">'multiclass'</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">prec</span> <span class="o">=</span> <span class="n">precision</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'prec:'</span><span class="p">,</span> <span class="n">prec</span><span class="p">)</span>

<span class="c1">#  recall</span>
<span class="n">recall</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Recall</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">'multiclass'</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">rec</span> <span class="o">=</span> <span class="n">recall</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'rec:'</span><span class="p">,</span> <span class="n">rec</span><span class="p">)</span>

<span class="c1"># F1</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">F1Score</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">'multiclass'</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'F1 score:'</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>acc: tensor(0.5000)
prec: tensor(0.5000)
rec: tensor(0.5000)
F1 score: tensor(0.5000)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="15.2.-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AE%A1%E7%AE%97%E6%8C%87%E6%A0%87">15.2. <a id="toc15_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#15.2.-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AE%A1%E7%AE%97%E6%8C%87%E6%A0%87"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">torchmetrics</span> 

<span class="k">class</span> <span class="nc">CustomMetrics</span><span class="p">(</span><span class="n">torchmetrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="15.3.-%E4%BA%8EPyTorch-Lightning%E8%81%94%E5%90%88%E4%BD%BF%E7%94%A8">15.3. <a id="toc15_3_"></a><a href="#toc0_">PyTorch Lightning</a><a class="anchor-link" href="#15.3.-%E4%BA%8EPyTorch-Lightning%E8%81%94%E5%90%88%E4%BD%BF%E7%94%A8"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">L</span> 
<span class="kn">import</span> <span class="nn">torchmetrics</span>  
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="c1"># import our library</span>
<span class="kn">import</span> <span class="nn">torchmetrics</span>

<span class="c1"># simulate a classification problem</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="c1"># target = torch.randn(5, (10,))</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">"multiclass"</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">preds</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">acc</span>
<span class="c1"># preds.dtype, target.dtype, acc.dtype</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[12]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(tensor([[0.2903, 0.3722, 0.0199, 0.3067, 0.0109],
         [0.4634, 0.0822, 0.1153, 0.1082, 0.2309],
         [0.2371, 0.4400, 0.0101, 0.0359, 0.2770],
         [0.1717, 0.0242, 0.0344, 0.6931, 0.0766],
         [0.1555, 0.2979, 0.2756, 0.0383, 0.2328],
         [0.2484, 0.1408, 0.1883, 0.0630, 0.3596],
         [0.3829, 0.0814, 0.1469, 0.3578, 0.0310],
         [0.0218, 0.2064, 0.3804, 0.2019, 0.1896],
         [0.1798, 0.3152, 0.1579, 0.1464, 0.2007],
         [0.0955, 0.0309, 0.1288, 0.2167, 0.5280]]),
 tensor([0, 2, 1, 1, 1, 3, 1, 0, 2, 2]),
 tensor(0.2000))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="16.-PyTorch-lightning">16. <a id="toc16_"></a><a href="#toc0_">PyTorch lightning</a><a class="anchor-link" href="#16.-PyTorch-lightning"></a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="16.1.-%E8%AE%AD%E7%BB%83%E9%80%BB%E8%BE%91">16.1. <a id="toc16_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#16.1.-%E8%AE%AD%E7%BB%83%E9%80%BB%E8%BE%91"></a></h2><ul>
<li><p>PyTorch lightning<code>PyTorch lightning</code><a href="https://lightning.ai/docs/pytorch/stable/expertise_levels.html">https://lightning.ai/docs/pytorch/stable/expertise_levels.html</a></p>
</li>
<li><p>PyTorch lightning<code>PyTorch</code><a href="https://lightning.ai/docs/pytorch/stable/tutorials.html">https://lightning.ai/docs/pytorch/stable/tutorials.html</a></p>
</li>
<li><p>PuTorch lightning<code>PyTorch code to PyTorchLightning</code><a href="https://lightning.ai/docs/pytorch/stable/starter/converting.html">https://lightning.ai/docs/pytorch/stable/starter/converting.html</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><img alt="Frame" src="./Pytorch_Pictures/PyTorch_lightning/Frame1.jpg">
<img alt="Frame2" src="./Pytorch_Pictures/PyTorch_lightning/Frame2.jpg">
<img alt="Frame3" src="./Pytorch_Pictures/PyTorch_lightning/Frame3.jpg">
<img alt="Frame4" src="./Pytorch_Pictures/PyTorch_lightning/Frame4.jpg">
<img alt="Frame5" src="./Pytorch_Pictures/PyTorch_lightning/Frame5.jpg"/></img></img></img></img></p>
<!-- <img src="./Pytorch_Pictures/PyTorch_lightning/Frame1.jpg" width = 600 height = 600 /> -->
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[70]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">lightning</span> <span class="k">as</span> <span class="nn">L</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Pytorch lightning version: </span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/bmp/backup/zhaosy/miniconda3/envs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Pytorch lightning version: 2.4.0
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="16.2.-Data.py">16.2. <a id="toc16_2_"></a><a href="#toc0_">Data.py</a><a class="anchor-link" href="#16.2.-Data.py"></a></h2><p></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="c1"># </span>

<span class="kn">import</span> <span class="nn">torch</span> 

<span class="k">def</span> <span class="nf">syn_datas</span><span class="p">(</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.0</span><span class="p">]),</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.4</span><span class="p">]),</span> 
    <span class="n">nums</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nums</span><span class="p">,</span> <span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span>
    <span class="n">y</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> 

<span class="c1">#  /</span>
<span class="n">preset_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">preset_bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">syn_datas</span><span class="p">(</span><span class="n">w</span><span class="o">=</span><span class="n">preset_weight</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">preset_bias</span><span class="p">,</span> <span class="n">nums</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[1]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torch.Size([10000, 2]),
 torch.Size([10000, 1]),
 tensor([ 0.1441, -0.0539]),
 tensor([3.7984]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span> 

<span class="n">datasets</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="n">train_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="16.3.-Model.py">16.3. <a id="toc16_3_"></a><a href="#toc0_">Model.py</a><a class="anchor-link" href="#16.3.-Model.py"></a></h2><p>PyTorch</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[59]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># PyTorch</span>

<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">AlphaFold2</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="16.4.-ModelWrapper.py">16.4. <a id="toc16_4_"></a><a href="#toc0_">ModelWrapper.py</a><a class="anchor-link" href="#16.4.-ModelWrapper.py"></a></h2><p>PyTorch lightning<code></code>PyTorch<br/>
API</p>
<ul>
<li><a href="https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#backward">L.LightningModule API</a></li>
<li><a href="https://lightning.ai/docs/pytorch/stable/common/trainer.html">Trainer API</a><ul>
<li>Automatically enabling/disabling grads</li>
<li>Running the training, validation and test dataloaders</li>
<li>Calling the Callbacks at the appropriate times</li>
<li>Putting batches and computations on the correct devices</li>
</ul>
</li>
</ul>
<p><img alt="Trainer_API" src="./Pytorch_Pictures/PyTorch_lightning/Trainer_API.jpg"/></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[120]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># PyTorch lightning</span>


<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>

<span class="kn">import</span> <span class="nn">lightning</span> <span class="k">as</span> <span class="nn">L</span>


<span class="k">class</span> <span class="nc">AlphaFold2Wrapper</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1">## save hyperparameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>                                 <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>                          <span class="c1"># </span>
        <span class="c1">## model initiate from model constructed by pure PyTorch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">demo_model</span> <span class="o">=</span> <span class="n">AlphaFold2</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>      <span class="c1">## </span>
        <span class="c1">## loss_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>                           <span class="c1">## </span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">demo_model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>                                 <span class="c1">## </span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">opt</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span> 
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">'train_loss'</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                 <span class="c1"># </span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>                     <span class="c1">#  (on_train_epoch_end(self))</span>
        <span class="k">return</span> <span class="n">loss</span>
    
    <span class="c1"># def on_train_batch_start(self, batch, batch_idx):</span>
    <span class="c1">#     '''</span>
    <span class="c1">#     Called in the training loop before anything happens for that batch.</span>
    <span class="c1">#     If you return -1 here, you will skip training for the rest of the current epoch.</span>
    <span class="c1">#     '''</span>
    <span class="c1">#     pass</span>

    <span class="c1"># def on_train_batch_end(self, outputs, batch, batch_idx):</span>
    <span class="c1">#     '''</span>
    <span class="c1">#     Called in the training loop after the batch.</span>
    <span class="c1">#     Parameters:</span>
    <span class="c1">#             outputs (Union[Tensor, Mapping[str, Any], None])  The outputs of training_step(x)</span>
    <span class="c1">#             batch (Any)  The batched data as it is returned by the training DataLoader.</span>
    <span class="c1">#             batch_idx (int)  the index of the batch</span>
    <span class="c1">#     '''</span>
    <span class="c1">#     pass</span>

    <span class="c1"># def on_train_epoch_start(self):</span>
    <span class="c1">#     '''Called in the training loop at the very beginning of the epoch.'''</span>
    <span class="c1">#     pass</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">'''</span>
<span class="sd">        Called in the training loop at the very end of the epoch.</span>
<span class="sd">        To access all batch outputs at the end of the epoch, </span>
<span class="sd">        you can cache step outputs as an attribute of the LightningModule and access them in this hook:</span>
<span class="sd">        '''</span>
        <span class="c1"># do something with all training_step outputs, for example:</span>
        <span class="n">epoch_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># training_step()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">"training_epoch_mean"</span><span class="p">,</span> <span class="n">epoch_mean</span><span class="p">)</span>
        <span class="c1"># free up the memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span> 
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">'val_loss'</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
    
    <span class="c1"># def on_validation_batch_start(self, batch, batch_idx, dataloader_idx=0):</span>
    <span class="c1">#     '''Called in the validation loop before anything happens for that batch.'''</span>
    <span class="c1">#     pass </span>

    <span class="c1"># def on_validation_batch_end(self, outputs, batch, batch_idx, dataloader_idx=0):</span>
    <span class="c1">#     '''Called in the validation loop after the batch.</span>
    <span class="c1">#     Parameters:</span>
    <span class="c1">#             outputs (Union[Tensor, Mapping[str, Any], None])  The outputs of validation_step(x)</span>
    <span class="c1">#             batch (Any)  The batched data as it is returned by the validation DataLoader.</span>
    <span class="c1">#             batch_idx (int)  the index of the batch</span>
    <span class="c1">#             dataloader_idx (int)  the index of the dataloader</span>
    <span class="c1">#     '''</span>
    <span class="c1">#     pass</span>

    <span class="c1"># def on_validation_epoch_start(self):</span>
    <span class="c1">#     '''Called in the validation loop at the very beginning of the epoch.'''</span>
    <span class="c1">#     pass</span>

    <span class="k">def</span> <span class="nf">on_validation_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">'''Called in the validation loop at the very end of the epoch.'''</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span> 
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">'test_loss'</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">prediction_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">''''''</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span> 
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">'y_hat'</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y_hat</span>

<span class="c1">## </span>
<span class="n">alphafold2</span> <span class="o">=</span> <span class="n">AlphaFold2Wrapper</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">accelerator</span><span class="o">=</span><span class="s2">"gpu"</span><span class="p">,</span>              <span class="c1"># cpu, gpu, tpu, auto</span>
    <span class="n">devices</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
    <span class="c1"># strategy="ddp",                 # ddp, ddp_spawn, ddp_notebook</span>
    <span class="c1"># num_nodes=1,                    # Number of GPU nodes for distributed training.</span>

    <span class="c1"># precision="32-true",            # There are two different techniques to set the mixed precision. True precision and Mixed precision.</span>

    <span class="c1"># callbacks = ,</span>
    
    <span class="c1"># min_epochs=1,</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="c1"># min_steps=None,                 # Force training for at least this number of global steps. Trainer will train model for at least min_steps or min_epochs (latest).</span>
    <span class="n">max_steps</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>                   <span class="c1"># Stop training after this number of global steps. Training will stop if max_steps or max_epochs have reached (earliest).</span>
    <span class="n">log_every_n_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>           <span class="c1">## How often to add logging rows (does not write to disk)</span>
    <span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>      <span class="c1"># default used by the Trainer</span>

    <span class="c1"># default_root_dir=os.getcwd(),   # os.getcwd()</span>
    <span class="c1"># enable_progress_bar=True,       # Whether to enable or disable the progress bar. Defaults to True.</span>
    <span class="c1"># enable_model_summary=True,      # Whether to enable or disable the model summarization. Defaults to True.</span>

    <span class="n">profiler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>                  <span class="c1"># simple, advanced, None: To profile individual steps during training and assist in identifying bottlenecks.</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="16.4.1.-Training-and-vlidation">16.4.1. <a id="toc16_4_1_"></a><a href="#toc0_">Training and vlidation</a><a class="anchor-link" href="#16.4.1.-Training-and-vlidation"></a></h3><p>TrainingValidation</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[98]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">alphafold2</span><span class="p">,</span> 
    <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train_iter</span><span class="p">,</span> 
    <span class="n">val_dataloaders</span><span class="o">=</span><span class="n">train_iter</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name       | Type       | Params | Mode 
--------------------------------------------------
0 | demo_model | AlphaFold2 | 3      | train
1 | loss_fn    | MSELoss    | 0      | train
--------------------------------------------------
3         Trainable params
0         Non-trainable params
3         Total params
0.000     Total estimated model params size (MB)
4         Modules in train mode
0         Modules in eval mode
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Sanity Checking: |          | 0/? [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/bmp/backup/zhaosy/miniconda3/envs/pytorch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 9: 100%|| 79/79 [00:01&lt;00:00, 75.30it/s, v_num=0, train_loss=0.217, val_loss=0.133] </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>`Trainer.fit` stopped: `max_epochs=10` reached.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 9: 100%|| 79/79 [00:01&lt;00:00, 74.95it/s, v_num=0, train_loss=0.217, val_loss=0.133]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="16.4.2.-Validation">16.4.2. <a id="toc16_4_2_"></a><a href="#toc0_">Validation</a><a class="anchor-link" href="#16.4.2.-Validation"></a></h3><p>validation</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[99]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">alphafold2</span><span class="p">,</span> <span class="n">dataloaders</span><span class="o">=</span><span class="n">train_iter</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Validation DataLoader 0: 100%|| 79/79 [00:00&lt;00:00, 359.93it/s]

     Validate metric           DataLoader 0

        val_loss            0.13269878923892975

</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[99]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[{'val_loss': 0.13269878923892975}]</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="16.4.3.-Test">16.4.3. <a id="toc16_4_3_"></a><a href="#toc0_">Test</a><a class="anchor-link" href="#16.4.3.-Test"></a></h3><p>test</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[100]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">alphafold2</span><span class="p">,</span> <span class="n">dataloaders</span><span class="o">=</span><span class="n">train_iter</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
/bmp/backup/zhaosy/miniconda3/envs/pytorch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Testing DataLoader 0: 100%|| 79/79 [00:00&lt;00:00, 404.56it/s]

       Test metric             DataLoader 0

        test_loss           0.13269877433776855

</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[100]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[{'test_loss': 0.13269877433776855}]</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="16.4.4.-Prediction">16.4.4. <a id="toc16_4_4_"></a><a href="#toc0_">Prediction</a><a class="anchor-link" href="#16.4.4.-Prediction"></a></h3><p></p>
<p><img alt="Prediction summary" src="./Pytorch_Pictures/PyTorch_lightning/Frame4.jpg"/></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="16.4.4.1.-PyTorch-lightning%E8%87%AA%E8%BA%ABTrainer%E7%9B%B4%E6%8E%A5predict">16.4.4.1. <a id="toc16_4_4_1_"></a><a href="#toc0_">PyTorch lightningTrainerpredict</a><a class="anchor-link" href="#16.4.4.1.-PyTorch-lightning%E8%87%AA%E8%BA%ABTrainer%E7%9B%B4%E6%8E%A5predict"></a></h4><p>PyTorch lightningTrainerpredict</p>
<ul>
<li>model.eval()</li>
<li>with torch.no_grad():</li>
<li> torch.set_grad_enable(True/False)</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[101]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">alphafold2</span><span class="p">,</span> <span class="n">dataloaders</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Predicting DataLoader 0: 100%|| 10000/10000 [00:08&lt;00:00, 1224.36it/s]
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[101]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[tensor([3.4124]),
 tensor([3.3868]),
 tensor([3.3909]),
 tensor([3.3817]),
 tensor([3.4208]),
 tensor([3.3964]),
 tensor([3.3973]),
 tensor([3.3862]),
 tensor([3.3966]),
 tensor([3.4032]),
 tensor([3.4066]),
 tensor([3.3905]),
 tensor([3.3932]),
 tensor([3.3774]),
 tensor([3.3949]),
 tensor([3.3956]),
 tensor([3.3845]),
 tensor([3.3931]),
 tensor([3.3935]),
 tensor([3.3898]),
 tensor([3.4090]),
 tensor([3.4059]),
 tensor([3.3987]),
 tensor([3.3881]),
 tensor([3.3913]),
 tensor([3.4166]),
 tensor([3.3755]),
 tensor([3.4028]),
 tensor([3.4021]),
 tensor([3.4224]),
 tensor([3.3956]),
 tensor([3.3914]),
 tensor([3.3979]),
 tensor([3.3889]),
 tensor([3.3950]),
 tensor([3.3908]),
 tensor([3.4049]),
 tensor([3.4014]),
 tensor([3.3925]),
 tensor([3.3970]),
 tensor([3.4043]),
 tensor([3.4050]),
 tensor([3.4055]),
 tensor([3.4033]),
 tensor([3.3873]),
 tensor([3.3934]),
 tensor([3.4031]),
 tensor([3.4101]),
 tensor([3.3942]),
 tensor([3.3713]),
 tensor([3.3908]),
 tensor([3.3955]),
 tensor([3.3886]),
 tensor([3.4044]),
 tensor([3.3781]),
 tensor([3.4005]),
 tensor([3.4258]),
 tensor([3.3873]),
 tensor([3.3782]),
 tensor([3.3928]),
 tensor([3.4193]),
 tensor([3.3874]),
 tensor([3.3984]),
 tensor([3.3887]),
 tensor([3.4131]),
 tensor([3.4129]),
 tensor([3.4034]),
 tensor([3.3979]),
 tensor([3.3874]),
 tensor([3.3870]),
 tensor([3.4152]),
 tensor([3.3893]),
 tensor([3.3938]),
 tensor([3.3955]),
 tensor([3.3921]),
 tensor([3.3895]),
 tensor([3.3981]),
 tensor([3.3871]),
 tensor([3.4101]),
 tensor([3.4051]),
 tensor([3.3864]),
 tensor([3.4033]),
 tensor([3.3987]),
 tensor([3.3935]),
 tensor([3.4010]),
 tensor([3.3961]),
 tensor([3.3918]),
 tensor([3.3886]),
 tensor([3.4129]),
 tensor([3.3801]),
 tensor([3.3956]),
 tensor([3.3981]),
 tensor([3.3972]),
 tensor([3.3699]),
 tensor([3.3770]),
 tensor([3.4040]),
 tensor([3.3986]),
 tensor([3.3855]),
 tensor([3.3998]),
 tensor([3.4040]),
 tensor([3.3861]),
 tensor([3.3966]),
 tensor([3.4106]),
 tensor([3.4038]),
 tensor([3.4075]),
 tensor([3.3972]),
 tensor([3.3843]),
 tensor([3.3849]),
 tensor([3.3885]),
 tensor([3.3999]),
 tensor([3.3865]),
 tensor([3.3973]),
 tensor([3.3804]),
 tensor([3.3916]),
 tensor([3.3607]),
 tensor([3.3936]),
 tensor([3.3948]),
 tensor([3.3984]),
 tensor([3.3910]),
 tensor([3.4078]),
 tensor([3.4075]),
 tensor([3.3888]),
 tensor([3.3929]),
 tensor([3.3968]),
 tensor([3.3875]),
 tensor([3.3859]),
 tensor([3.3864]),
 tensor([3.4090]),
 tensor([3.3977]),
 tensor([3.4027]),
 tensor([3.4120]),
 tensor([3.4087]),
 tensor([3.3966]),
 tensor([3.3961]),
 tensor([3.3787]),
 tensor([3.3978]),
 tensor([3.3952]),
 tensor([3.3897]),
 tensor([3.4006]),
 tensor([3.4003]),
 tensor([3.4146]),
 tensor([3.4132]),
 tensor([3.3967]),
 tensor([3.3859]),
 tensor([3.3974]),
 tensor([3.3895]),
 tensor([3.4091]),
 tensor([3.3953]),
 tensor([3.3847]),
 tensor([3.3809]),
 tensor([3.4056]),
 tensor([3.3944]),
 tensor([3.4027]),
 tensor([3.3968]),
 tensor([3.3890]),
 tensor([3.4088]),
 tensor([3.4081]),
 tensor([3.4046]),
 tensor([3.4032]),
 tensor([3.3874]),
 tensor([3.3803]),
 tensor([3.3998]),
 tensor([3.4051]),
 tensor([3.4086]),
 tensor([3.3976]),
 tensor([3.3843]),
 tensor([3.4084]),
 tensor([3.3904]),
 tensor([3.3955]),
 tensor([3.3869]),
 tensor([3.3834]),
 tensor([3.4043]),
 tensor([3.4136]),
 tensor([3.4164]),
 tensor([3.3850]),
 tensor([3.3986]),
 tensor([3.3877]),
 tensor([3.3948]),
 tensor([3.4094]),
 tensor([3.3838]),
 tensor([3.3951]),
 tensor([3.3938]),
 tensor([3.4015]),
 tensor([3.3974]),
 tensor([3.3974]),
 tensor([3.3943]),
 tensor([3.4021]),
 tensor([3.3885]),
 tensor([3.3933]),
 tensor([3.4221]),
 tensor([3.3944]),
 tensor([3.3702]),
 tensor([3.3849]),
 tensor([3.3721]),
 tensor([3.4130]),
 tensor([3.4109]),
 tensor([3.3931]),
 tensor([3.4006]),
 tensor([3.3931]),
 tensor([3.3830]),
 tensor([3.4076]),
 tensor([3.4150]),
 tensor([3.3928]),
 tensor([3.3854]),
 tensor([3.3955]),
 tensor([3.3874]),
 tensor([3.3804]),
 tensor([3.3996]),
 tensor([3.3997]),
 tensor([3.3945]),
 tensor([3.3966]),
 tensor([3.3844]),
 tensor([3.4151]),
 tensor([3.3878]),
 tensor([3.4081]),
 tensor([3.3861]),
 tensor([3.3918]),
 tensor([3.3909]),
 tensor([3.3790]),
 tensor([3.3976]),
 tensor([3.3993]),
 tensor([3.3754]),
 tensor([3.3959]),
 tensor([3.4031]),
 tensor([3.3949]),
 tensor([3.3995]),
 tensor([3.4028]),
 tensor([3.3978]),
 tensor([3.3845]),
 tensor([3.3905]),
 tensor([3.4012]),
 tensor([3.4248]),
 tensor([3.4041]),
 tensor([3.3908]),
 tensor([3.3819]),
 tensor([3.3824]),
 tensor([3.4074]),
 tensor([3.4040]),
 tensor([3.3797]),
 tensor([3.3876]),
 tensor([3.3864]),
 tensor([3.3888]),
 tensor([3.3748]),
 tensor([3.3762]),
 tensor([3.3839]),
 tensor([3.4036]),
 tensor([3.4012]),
 tensor([3.4112]),
 tensor([3.3962]),
 tensor([3.3846]),
 tensor([3.3814]),
 tensor([3.4060]),
 tensor([3.3960]),
 tensor([3.3785]),
 tensor([3.4101]),
 tensor([3.3812]),
 tensor([3.4179]),
 tensor([3.3958]),
 tensor([3.4003]),
 tensor([3.3811]),
 tensor([3.3881]),
 tensor([3.3697]),
 tensor([3.3896]),
 tensor([3.4057]),
 tensor([3.4168]),
 tensor([3.4068]),
 tensor([3.3944]),
 tensor([3.3939]),
 tensor([3.3898]),
 tensor([3.4055]),
 tensor([3.4003]),
 tensor([3.3825]),
 tensor([3.3823]),
 tensor([3.3900]),
 tensor([3.4036]),
 tensor([3.3910]),
 tensor([3.3669]),
 tensor([3.4105]),
 tensor([3.3908]),
 tensor([3.3930]),
 tensor([3.3747]),
 tensor([3.4005]),
 tensor([3.4129]),
 tensor([3.3842]),
 tensor([3.4011]),
 tensor([3.3984]),
 tensor([3.3772]),
 tensor([3.4038]),
 tensor([3.3999]),
 tensor([3.3987]),
 tensor([3.3911]),
 tensor([3.4013]),
 tensor([3.4021]),
 tensor([3.3991]),
 tensor([3.3840]),
 tensor([3.4171]),
 tensor([3.4068]),
 tensor([3.4061]),
 tensor([3.3943]),
 tensor([3.4080]),
 tensor([3.3757]),
 tensor([3.3950]),
 tensor([3.3848]),
 tensor([3.3827]),
 tensor([3.4070]),
 tensor([3.4035]),
 tensor([3.3793]),
 tensor([3.3813]),
 tensor([3.4006]),
 tensor([3.3937]),
 tensor([3.3855]),
 tensor([3.3849]),
 tensor([3.3879]),
 tensor([3.4032]),
 tensor([3.3842]),
 tensor([3.4141]),
 tensor([3.3924]),
 tensor([3.3830]),
 tensor([3.4130]),
 tensor([3.3903]),
 tensor([3.3871]),
 tensor([3.4162]),
 tensor([3.4080]),
 tensor([3.3905]),
 tensor([3.3957]),
 tensor([3.3950]),
 tensor([3.3955]),
 tensor([3.4070]),
 tensor([3.4014]),
 tensor([3.3858]),
 tensor([3.3889]),
 tensor([3.3913]),
 tensor([3.4134]),
 tensor([3.3972]),
 tensor([3.4066]),
 tensor([3.4012]),
 tensor([3.3954]),
 tensor([3.3905]),
 tensor([3.3966]),
 tensor([3.3846]),
 tensor([3.4101]),
 tensor([3.4278]),
 tensor([3.4167]),
 tensor([3.3849]),
 tensor([3.4030]),
 tensor([3.3895]),
 tensor([3.3883]),
 tensor([3.3797]),
 tensor([3.3906]),
 tensor([3.3962]),
 tensor([3.3998]),
 tensor([3.3837]),
 tensor([3.3906]),
 tensor([3.3814]),
 tensor([3.3948]),
 tensor([3.4101]),
 tensor([3.3900]),
 tensor([3.3951]),
 tensor([3.3977]),
 tensor([3.3841]),
 tensor([3.4076]),
 tensor([3.4021]),
 tensor([3.3867]),
 tensor([3.3944]),
 tensor([3.3987]),
 tensor([3.3875]),
 tensor([3.3883]),
 tensor([3.3954]),
 tensor([3.4117]),
 tensor([3.3833]),
 tensor([3.4028]),
 tensor([3.3847]),
 tensor([3.3911]),
 tensor([3.4061]),
 tensor([3.3887]),
 tensor([3.4028]),
 tensor([3.3935]),
 tensor([3.4019]),
 tensor([3.3861]),
 tensor([3.3714]),
 tensor([3.3898]),
 tensor([3.4068]),
 tensor([3.3961]),
 tensor([3.4316]),
 tensor([3.3874]),
 tensor([3.3967]),
 tensor([3.4210]),
 tensor([3.4201]),
 tensor([3.4086]),
 tensor([3.3852]),
 tensor([3.3954]),
 tensor([3.4149]),
 tensor([3.4019]),
 tensor([3.4001]),
 tensor([3.3926]),
 tensor([3.4000]),
 tensor([3.4079]),
 tensor([3.3977]),
 tensor([3.3997]),
 tensor([3.3957]),
 tensor([3.4179]),
 tensor([3.4061]),
 tensor([3.3923]),
 tensor([3.4027]),
 tensor([3.3974]),
 tensor([3.3904]),
 tensor([3.4022]),
 tensor([3.3988]),
 tensor([3.3825]),
 tensor([3.3840]),
 tensor([3.4073]),
 tensor([3.3974]),
 tensor([3.3830]),
 tensor([3.3974]),
 tensor([3.3870]),
 tensor([3.4090]),
 tensor([3.3719]),
 tensor([3.4009]),
 tensor([3.3729]),
 tensor([3.4007]),
 tensor([3.3830]),
 tensor([3.4080]),
 tensor([3.3862]),
 tensor([3.3794]),
 tensor([3.3971]),
 tensor([3.3994]),
 tensor([3.3896]),
 tensor([3.3780]),
 tensor([3.4054]),
 tensor([3.3893]),
 tensor([3.3879]),
 tensor([3.3838]),
 tensor([3.3832]),
 tensor([3.4018]),
 tensor([3.3888]),
 tensor([3.3988]),
 tensor([3.3934]),
 tensor([3.3899]),
 tensor([3.4056]),
 tensor([3.3880]),
 tensor([3.3884]),
 tensor([3.4088]),
 tensor([3.3989]),
 tensor([3.3885]),
 tensor([3.4058]),
 tensor([3.4244]),
 tensor([3.4051]),
 tensor([3.4101]),
 tensor([3.3924]),
 tensor([3.4058]),
 tensor([3.4032]),
 tensor([3.4103]),
 tensor([3.4106]),
 tensor([3.4228]),
 tensor([3.4213]),
 tensor([3.3915]),
 tensor([3.4078]),
 tensor([3.3992]),
 tensor([3.3945]),
 tensor([3.3877]),
 tensor([3.3812]),
 tensor([3.3730]),
 tensor([3.4031]),
 tensor([3.3698]),
 tensor([3.4008]),
 tensor([3.3902]),
 tensor([3.3899]),
 tensor([3.3998]),
 tensor([3.4109]),
 tensor([3.4035]),
 tensor([3.3786]),
 tensor([3.3959]),
 tensor([3.3848]),
 tensor([3.4000]),
 tensor([3.3748]),
 tensor([3.4036]),
 tensor([3.4022]),
 tensor([3.3908]),
 tensor([3.3926]),
 tensor([3.3972]),
 tensor([3.4044]),
 tensor([3.4077]),
 tensor([3.3990]),
 tensor([3.3943]),
 tensor([3.3992]),
 tensor([3.3849]),
 tensor([3.4102]),
 tensor([3.3814]),
 tensor([3.4102]),
 tensor([3.3866]),
 tensor([3.4003]),
 tensor([3.4128]),
 tensor([3.3874]),
 tensor([3.4031]),
 tensor([3.3985]),
 tensor([3.3962]),
 tensor([3.3875]),
 tensor([3.4017]),
 tensor([3.3998]),
 tensor([3.3957]),
 tensor([3.3932]),
 tensor([3.3958]),
 tensor([3.3973]),
 tensor([3.3950]),
 tensor([3.3947]),
 tensor([3.3999]),
 tensor([3.4081]),
 tensor([3.3979]),
 tensor([3.4067]),
 tensor([3.3806]),
 tensor([3.4036]),
 tensor([3.4196]),
 tensor([3.3900]),
 tensor([3.3872]),
 tensor([3.3964]),
 tensor([3.3935]),
 tensor([3.4003]),
 tensor([3.3981]),
 tensor([3.4003]),
 tensor([3.3864]),
 tensor([3.3797]),
 tensor([3.3957]),
 tensor([3.4134]),
 tensor([3.4020]),
 tensor([3.3841]),
 tensor([3.3775]),
 tensor([3.3854]),
 tensor([3.3974]),
 tensor([3.3947]),
 tensor([3.4116]),
 tensor([3.4051]),
 tensor([3.3892]),
 tensor([3.4026]),
 tensor([3.3893]),
 tensor([3.4023]),
 tensor([3.3904]),
 tensor([3.3944]),
 tensor([3.4056]),
 tensor([3.4035]),
 tensor([3.3766]),
 tensor([3.3897]),
 tensor([3.3936]),
 tensor([3.4063]),
 tensor([3.3832]),
 tensor([3.4096]),
 tensor([3.3850]),
 tensor([3.4216]),
 tensor([3.4043]),
 tensor([3.3882]),
 tensor([3.3908]),
 tensor([3.3987]),
 tensor([3.3989]),
 tensor([3.4090]),
 tensor([3.3868]),
 tensor([3.3926]),
 tensor([3.3796]),
 tensor([3.3829]),
 tensor([3.4089]),
 tensor([3.3850]),
 tensor([3.3933]),
 tensor([3.3950]),
 tensor([3.3988]),
 tensor([3.4028]),
 tensor([3.3891]),
 tensor([3.4035]),
 tensor([3.3948]),
 tensor([3.3858]),
 tensor([3.3911]),
 tensor([3.3868]),
 tensor([3.3836]),
 tensor([3.3964]),
 tensor([3.4149]),
 tensor([3.3960]),
 tensor([3.3946]),
 tensor([3.4032]),
 tensor([3.3866]),
 tensor([3.4022]),
 tensor([3.3883]),
 tensor([3.3948]),
 tensor([3.3981]),
 tensor([3.4169]),
 tensor([3.3975]),
 tensor([3.4144]),
 tensor([3.3744]),
 tensor([3.4058]),
 tensor([3.3935]),
 tensor([3.3881]),
 tensor([3.3699]),
 tensor([3.4189]),
 tensor([3.3954]),
 tensor([3.3870]),
 tensor([3.3865]),
 tensor([3.3838]),
 tensor([3.3925]),
 tensor([3.3861]),
 tensor([3.3957]),
 tensor([3.4019]),
 tensor([3.4072]),
 tensor([3.3948]),
 tensor([3.4002]),
 tensor([3.3793]),
 tensor([3.4097]),
 tensor([3.3896]),
 tensor([3.4005]),
 tensor([3.3942]),
 tensor([3.3988]),
 tensor([3.3954]),
 tensor([3.3904]),
 tensor([3.4143]),
 tensor([3.3803]),
 tensor([3.4204]),
 tensor([3.3789]),
 tensor([3.3836]),
 tensor([3.4065]),
 tensor([3.3721]),
 tensor([3.3925]),
 tensor([3.3979]),
 tensor([3.4049]),
 tensor([3.3764]),
 tensor([3.3928]),
 tensor([3.3979]),
 tensor([3.3951]),
 tensor([3.4004]),
 tensor([3.3832]),
 tensor([3.4129]),
 tensor([3.4088]),
 tensor([3.3887]),
 tensor([3.3962]),
 tensor([3.3855]),
 tensor([3.3939]),
 tensor([3.3819]),
 tensor([3.3905]),
 tensor([3.4249]),
 tensor([3.4143]),
 tensor([3.4135]),
 tensor([3.3960]),
 tensor([3.4036]),
 tensor([3.3716]),
 tensor([3.3956]),
 tensor([3.4005]),
 tensor([3.3983]),
 tensor([3.4125]),
 tensor([3.3915]),
 tensor([3.4220]),
 tensor([3.3756]),
 tensor([3.3922]),
 tensor([3.3857]),
 tensor([3.4030]),
 tensor([3.3887]),
 tensor([3.3770]),
 tensor([3.3992]),
 tensor([3.4071]),
 tensor([3.4107]),
 tensor([3.4151]),
 tensor([3.4113]),
 tensor([3.4054]),
 tensor([3.4038]),
 tensor([3.3863]),
 tensor([3.4015]),
 tensor([3.4036]),
 tensor([3.3857]),
 tensor([3.3983]),
 tensor([3.3962]),
 tensor([3.3979]),
 tensor([3.3808]),
 tensor([3.4076]),
 tensor([3.4043]),
 tensor([3.3870]),
 tensor([3.3957]),
 tensor([3.3880]),
 tensor([3.3957]),
 tensor([3.3983]),
 tensor([3.3919]),
 tensor([3.4050]),
 tensor([3.3837]),
 tensor([3.4005]),
 tensor([3.3585]),
 tensor([3.4139]),
 tensor([3.3854]),
 tensor([3.4070]),
 tensor([3.3916]),
 tensor([3.3823]),
 tensor([3.3984]),
 tensor([3.4058]),
 tensor([3.3818]),
 tensor([3.4084]),
 tensor([3.3786]),
 tensor([3.3798]),
 tensor([3.3991]),
 tensor([3.3876]),
 tensor([3.3987]),
 tensor([3.4036]),
 tensor([3.4024]),
 tensor([3.3893]),
 tensor([3.3973]),
 tensor([3.3846]),
 tensor([3.4137]),
 tensor([3.3864]),
 tensor([3.3943]),
 tensor([3.3881]),
 tensor([3.3978]),
 tensor([3.4078]),
 tensor([3.3929]),
 tensor([3.3951]),
 tensor([3.3995]),
 tensor([3.4120]),
 tensor([3.4318]),
 tensor([3.3795]),
 tensor([3.3785]),
 tensor([3.3924]),
 tensor([3.3759]),
 tensor([3.3997]),
 tensor([3.3840]),
 tensor([3.4264]),
 tensor([3.4175]),
 tensor([3.3834]),
 tensor([3.3861]),
 tensor([3.3997]),
 tensor([3.4206]),
 tensor([3.3871]),
 tensor([3.3845]),
 tensor([3.4004]),
 tensor([3.3881]),
 tensor([3.3914]),
 tensor([3.4153]),
 tensor([3.3979]),
 tensor([3.4035]),
 tensor([3.3940]),
 tensor([3.3738]),
 tensor([3.3919]),
 tensor([3.3889]),
 tensor([3.3880]),
 tensor([3.3940]),
 tensor([3.4042]),
 tensor([3.4017]),
 tensor([3.4033]),
 tensor([3.4213]),
 tensor([3.3893]),
 tensor([3.3788]),
 tensor([3.3851]),
 tensor([3.3969]),
 tensor([3.3791]),
 tensor([3.3855]),
 tensor([3.3906]),
 tensor([3.3865]),
 tensor([3.3909]),
 tensor([3.3916]),
 tensor([3.3898]),
 tensor([3.3884]),
 tensor([3.3852]),
 tensor([3.3982]),
 tensor([3.4141]),
 tensor([3.3893]),
 tensor([3.4094]),
 tensor([3.3684]),
 tensor([3.4163]),
 tensor([3.3763]),
 tensor([3.3887]),
 tensor([3.3932]),
 tensor([3.3873]),
 tensor([3.3944]),
 tensor([3.3999]),
 tensor([3.4012]),
 tensor([3.3957]),
 tensor([3.4031]),
 tensor([3.3958]),
 tensor([3.3873]),
 tensor([3.3865]),
 tensor([3.4221]),
 tensor([3.4161]),
 tensor([3.3898]),
 tensor([3.3983]),
 tensor([3.3923]),
 tensor([3.4119]),
 tensor([3.3873]),
 tensor([3.3876]),
 tensor([3.3926]),
 tensor([3.3767]),
 tensor([3.4065]),
 tensor([3.3951]),
 tensor([3.4100]),
 tensor([3.3970]),
 tensor([3.3796]),
 tensor([3.4057]),
 tensor([3.3976]),
 tensor([3.3955]),
 tensor([3.3911]),
 tensor([3.3922]),
 tensor([3.3937]),
 tensor([3.3938]),
 tensor([3.3969]),
 tensor([3.3936]),
 tensor([3.3967]),
 tensor([3.3899]),
 tensor([3.3775]),
 tensor([3.4075]),
 tensor([3.3957]),
 tensor([3.3970]),
 tensor([3.3836]),
 tensor([3.4081]),
 tensor([3.3845]),
 tensor([3.3839]),
 tensor([3.3944]),
 tensor([3.3899]),
 tensor([3.3913]),
 tensor([3.4027]),
 tensor([3.3920]),
 tensor([3.3838]),
 tensor([3.4055]),
 tensor([3.4126]),
 tensor([3.4025]),
 tensor([3.3967]),
 tensor([3.4007]),
 tensor([3.3952]),
 tensor([3.3953]),
 tensor([3.4139]),
 tensor([3.4124]),
 tensor([3.3936]),
 tensor([3.4005]),
 tensor([3.4197]),
 tensor([3.3932]),
 tensor([3.3995]),
 tensor([3.3759]),
 tensor([3.3923]),
 tensor([3.3989]),
 tensor([3.3915]),
 tensor([3.3882]),
 tensor([3.4209]),
 tensor([3.3956]),
 tensor([3.3979]),
 tensor([3.3857]),
 tensor([3.4188]),
 tensor([3.3918]),
 tensor([3.4094]),
 tensor([3.3897]),
 tensor([3.3953]),
 tensor([3.3892]),
 tensor([3.3970]),
 tensor([3.3870]),
 tensor([3.3946]),
 tensor([3.3978]),
 tensor([3.3755]),
 tensor([3.4047]),
 tensor([3.4014]),
 tensor([3.4015]),
 tensor([3.3726]),
 tensor([3.3975]),
 tensor([3.4013]),
 tensor([3.4140]),
 tensor([3.3905]),
 tensor([3.3780]),
 tensor([3.3963]),
 tensor([3.4032]),
 tensor([3.3950]),
 tensor([3.3960]),
 tensor([3.3978]),
 tensor([3.3896]),
 tensor([3.4156]),
 tensor([3.4089]),
 tensor([3.3999]),
 tensor([3.3753]),
 tensor([3.3867]),
 tensor([3.4000]),
 tensor([3.4068]),
 tensor([3.4117]),
 tensor([3.4168]),
 tensor([3.3935]),
 tensor([3.4048]),
 tensor([3.4027]),
 tensor([3.3758]),
 tensor([3.4010]),
 tensor([3.4005]),
 tensor([3.3967]),
 tensor([3.4026]),
 tensor([3.3929]),
 tensor([3.3893]),
 tensor([3.3895]),
 tensor([3.4025]),
 tensor([3.3774]),
 tensor([3.3910]),
 tensor([3.3889]),
 tensor([3.4063]),
 tensor([3.3899]),
 tensor([3.3971]),
 tensor([3.3923]),
 tensor([3.4122]),
 tensor([3.3859]),
 tensor([3.3962]),
 tensor([3.3989]),
 tensor([3.3804]),
 tensor([3.4029]),
 tensor([3.3983]),
 tensor([3.3745]),
 tensor([3.4155]),
 tensor([3.3889]),
 tensor([3.3940]),
 tensor([3.3936]),
 tensor([3.3784]),
 tensor([3.4200]),
 tensor([3.3796]),
 tensor([3.3854]),
 tensor([3.3860]),
 tensor([3.4193]),
 tensor([3.4039]),
 tensor([3.4040]),
 tensor([3.4007]),
 tensor([3.3829]),
 tensor([3.3982]),
 tensor([3.3808]),
 tensor([3.4081]),
 tensor([3.3952]),
 tensor([3.4156]),
 tensor([3.4112]),
 tensor([3.4128]),
 tensor([3.4121]),
 tensor([3.3957]),
 tensor([3.3943]),
 tensor([3.3799]),
 tensor([3.3915]),
 tensor([3.4176]),
 tensor([3.3785]),
 tensor([3.3834]),
 tensor([3.4043]),
 tensor([3.3938]),
 tensor([3.3826]),
 tensor([3.4024]),
 tensor([3.3841]),
 tensor([3.3795]),
 tensor([3.3810]),
 tensor([3.3850]),
 tensor([3.3951]),
 tensor([3.3959]),
 tensor([3.3843]),
 tensor([3.3688]),
 tensor([3.3970]),
 tensor([3.4021]),
 tensor([3.3768]),
 tensor([3.4121]),
 tensor([3.3758]),
 tensor([3.3795]),
 tensor([3.3867]),
 tensor([3.3911]),
 tensor([3.4070]),
 tensor([3.3904]),
 tensor([3.4122]),
 tensor([3.4100]),
 tensor([3.3890]),
 tensor([3.4108]),
 tensor([3.3873]),
 tensor([3.3842]),
 tensor([3.3999]),
 tensor([3.4127]),
 tensor([3.3960]),
 tensor([3.4027]),
 tensor([3.3887]),
 tensor([3.4074]),
 tensor([3.3842]),
 tensor([3.3875]),
 tensor([3.3933]),
 tensor([3.3945]),
 tensor([3.3959]),
 tensor([3.3963]),
 tensor([3.3896]),
 tensor([3.4010]),
 tensor([3.3924]),
 tensor([3.4082]),
 tensor([3.3833]),
 tensor([3.3936]),
 tensor([3.3899]),
 tensor([3.3990]),
 tensor([3.3942]),
 tensor([3.3891]),
 tensor([3.3880]),
 tensor([3.4155]),
 tensor([3.3919]),
 tensor([3.3955]),
 tensor([3.3861]),
 tensor([3.4238]),
 tensor([3.3786]),
 tensor([3.4097]),
 tensor([3.4214]),
 tensor([3.3743]),
 tensor([3.3897]),
 tensor([3.4080]),
 tensor([3.4082]),
 tensor([3.3964]),
 tensor([3.3845]),
 tensor([3.4070]),
 tensor([3.3896]),
 tensor([3.4056]),
 tensor([3.3756]),
 tensor([3.3853]),
 tensor([3.4129]),
 tensor([3.4044]),
 tensor([3.3836]),
 tensor([3.3902]),
 tensor([3.3959]),
 tensor([3.3827]),
 tensor([3.4051]),
 tensor([3.3900]),
 ...]</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="16.4.4.2.-PyTorch-lightning%E5%8A%A0%E8%BD%BD%E6%9D%83%E9%87%8D%E5%90%8E%E9%A2%84%E6%B5%8B">16.4.4.2. <a id="toc16_4_4_2_"></a><a href="#toc0_">PyTorch lightning</a><a class="anchor-link" href="#16.4.4.2.-PyTorch-lightning%E5%8A%A0%E8%BD%BD%E6%9D%83%E9%87%8D%E5%90%8E%E9%A2%84%E6%B5%8B"></a></h4><p></p>
<ul>
<li>model.eval()</li>
<li>with torch.no_grad():</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[102]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">pretrained_alphafold2</span> <span class="o">=</span> <span class="n">AlphaFold2Wrapper</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s1">'./lightning_logs/version_0/checkpoints/epoch=9-step=790.ckpt'</span><span class="p">)</span>

<span class="c1"># /</span>
<span class="n">pretrained_alphafold2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">pretrained_alphafold2</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cuda:0'</span><span class="p">))</span>
<span class="n">y_hat</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[102]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[3.4124],
        [3.3868],
        [3.3909],
        ...,
        [3.4022],
        [3.3898],
        [3.3934]], device='cuda:0')</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="16.4.4.3.-%E6%8F%90%E5%8F%96%E6%9D%83%E9%87%8D%E5%90%8E%E5%8A%A0%E8%BD%BD%E8%87%B3%E7%BA%AFPyTorch%E6%A8%A1%E5%9E%8B">16.4.4.3. <a id="toc16_4_4_3_"></a><a href="#toc0_">PyTorch</a><a class="anchor-link" href="#16.4.4.3.-%E6%8F%90%E5%8F%96%E6%9D%83%E9%87%8D%E5%90%8E%E5%8A%A0%E8%BD%BD%E8%87%B3%E7%BA%AFPyTorch%E6%A8%A1%E5%9E%8B"></a></h4><p>checkpoint<code></code><code></code>PyTorchPyTorch</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[103]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">checkpoint_path</span> <span class="o">=</span> <span class="s1">'./lightning_logs/version_0/checkpoints/epoch=9-step=790.ckpt'</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>
<span class="n">checkpoint</span>  <span class="c1"># checkpoint 'state_dict'</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/tmp/ipykernel_268120/3329860571.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path)
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[103]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>{'epoch': 9,
 'global_step': 790,
 'pytorch-lightning_version': '2.4.0',
 'state_dict': OrderedDict([('demo_model.hidden.0.weight',
               tensor([[ 0.0967, -0.0567]], device='cuda:0')),
              ('demo_model.hidden.0.bias',
               tensor([3.3954], device='cuda:0'))]),
 'loops': {'fit_loop': {'state_dict': {},
   'epoch_loop.state_dict': {'_batches_that_stepped': 790},
   'epoch_loop.batch_progress': {'total': {'ready': 790,
     'completed': 790,
     'started': 790,
     'processed': 790},
    'current': {'ready': 79, 'completed': 79, 'started': 79, 'processed': 79},
    'is_last_batch': True},
   'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0},
    'current': {'ready': 0, 'completed': 0}},
   'epoch_loop.automatic_optimization.state_dict': {},
   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 790,
       'completed': 790},
      'current': {'ready': 79, 'completed': 79}},
     'zero_grad': {'total': {'ready': 790, 'completed': 790, 'started': 790},
      'current': {'ready': 79, 'completed': 79, 'started': 79}}}},
   'epoch_loop.manual_optimization.state_dict': {},
   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,
     'completed': 0},
    'current': {'ready': 0, 'completed': 0}},
   'epoch_loop.val_loop.state_dict': {},
   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 79,
     'completed': 79,
     'started': 79,
     'processed': 79},
    'current': {'ready': 79, 'completed': 79, 'started': 79, 'processed': 79},
    'is_last_batch': True},
   'epoch_progress': {'total': {'ready': 10,
     'completed': 9,
     'started': 10,
     'processed': 10},
    'current': {'ready': 10, 'completed': 9, 'started': 10, 'processed': 10}}},
  'validate_loop': {'state_dict': {},
   'batch_progress': {'total': {'ready': 0,
     'completed': 0,
     'started': 0,
     'processed': 0},
    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},
    'is_last_batch': False}},
  'test_loop': {'state_dict': {},
   'batch_progress': {'total': {'ready': 0,
     'completed': 0,
     'started': 0,
     'processed': 0},
    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},
    'is_last_batch': False}},
  'predict_loop': {'state_dict': {},
   'batch_progress': {'total': {'ready': 0,
     'completed': 0,
     'started': 0,
     'processed': 0},
    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},
 'callbacks': {"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}": {'monitor': None,
   'best_model_score': None,
   'best_model_path': '/bmp/backup/zhaosy/ws/PyTorch_learning/lightning_logs/version_0/checkpoints/epoch=9-step=790.ckpt',
   'current_score': None,
   'dirpath': '/bmp/backup/zhaosy/ws/PyTorch_learning/lightning_logs/version_0/checkpoints',
   'best_k_models': {},
   'kth_best_model_path': '',
   'kth_value': tensor(inf),
   'last_model_path': ''}},
 'optimizer_states': [{'state': {},
   'param_groups': [{'lr': 0.01,
     'momentum': 0,
     'dampening': 0,
     'weight_decay': 0,
     'nesterov': False,
     'maximize': False,
     'foreach': None,
     'differentiable': False,
     'fused': None,
     'params': [0, 1]}]}],
 'lr_schedulers': [],
 'hparams_name': 'kwargs',
 'hyper_parameters': {'learning_rate': 0.01}}</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[104]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">alphafold2</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'state_dict'</span><span class="p">]</span>    <span class="c1"># with AlphaFold2Wrapper, demo_model.</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[104]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(AlphaFold2Wrapper(
   (demo_model): AlphaFold2(
     (hidden): Sequential(
       (0): Linear(in_features=2, out_features=1, bias=True)
     )
   )
   (loss_fn): MSELoss()
 ),
 OrderedDict([('demo_model.hidden.0.weight',
               tensor([[ 0.0967, -0.0567]], device='cuda:0')),
              ('demo_model.hidden.0.bias',
               tensor([3.3954], device='cuda:0'))]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[106]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'state_dict'</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>demo_model.hidden.0.weight
demo_model.hidden.0.bias
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li><code>PyTorchstate_dict</code><code>checkpoint</code>state_dict<code></code></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[108]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">alphafold_with_pure_pytorch</span> <span class="o">=</span> <span class="n">AlphaFold2</span><span class="p">()</span>
<span class="n">alphafold_with_pure_pytorch</span><span class="p">,</span> <span class="n">alphafold_with_pure_pytorch</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[108]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(AlphaFold2(
   (hidden): Sequential(
     (0): Linear(in_features=2, out_features=1, bias=True)
   )
 ),
 OrderedDict([('hidden.0.weight', tensor([[-0.5207,  0.0861]])),
              ('hidden.0.bias', tensor([0.0467]))]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li></li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model_weights</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'state_dict'</span><span class="p">]</span>

<span class="c1"># demo_model.</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">model_weights</span><span class="p">:</span>
    <span class="n">model_weights</span><span class="p">[</span><span class="n">key</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"demo_model."</span><span class="p">,</span> <span class="s2">""</span><span class="p">)]</span> <span class="o">=</span> <span class="n">model_weights</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[117]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'state_dict'</span><span class="p">],</span> <span class="n">model_weights</span> <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[117]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(OrderedDict([('hidden.0.weight',
               tensor([[ 0.0967, -0.0567]], device='cuda:0')),
              ('hidden.0.bias', tensor([3.3954], device='cuda:0'))]),
 OrderedDict([('hidden.0.weight',
               tensor([[ 0.0967, -0.0567]], device='cuda:0')),
              ('hidden.0.bias', tensor([3.3954], device='cuda:0'))]))</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[118]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># </span>
<span class="n">alphafold_with_pure_pytorch</span> <span class="o">=</span> <span class="n">AlphaFold2</span><span class="p">()</span>

<span class="c1"># </span>
<span class="n">alphafold_with_pure_pytorch</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_weights</span><span class="p">)</span>  <span class="c1"># model_weights</span>

<span class="c1"># /</span>
<span class="n">alphafold_with_pure_pytorch</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">alphafold_with_pure_pytorch</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="n">y_hat</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[118]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[3.4124],
        [3.3868],
        [3.3909],
        ...,
        [3.4022],
        [3.3898],
        [3.3934]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="17.-Torchvision">17. <a id="toc17_"></a><a href="#toc0_">Torchvision</a><a class="anchor-link" href="#17.-Torchvision"></a></h1><p>Torchvision Docs: <a href="https://pytorch.org/vision/stable/models.html">https://pytorch.org/vision/stable/models.html</a></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[88]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision</span> 


<span class="nb">print</span><span class="p">(</span><span class="s1">'torchvision version:'</span><span class="p">,</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torchvision version: 0.19.0
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="17.1.-Models">17.1. <a id="toc17_1_"></a><a href="#toc0_">Models</a><a class="anchor-link" href="#17.1.-Models"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="17.1.1.-%E5%8F%AF%E7%94%A8%E6%A8%A1%E5%9E%8B">17.1.1. <a id="toc17_1_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#17.1.1.-%E5%8F%AF%E7%94%A8%E6%A8%A1%E5%9E%8B"></a></h3><p><code></code><a href="https://pytorch.org/vision/stable/models.html">https://pytorch.org/vision/stable/models.html</a></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span> 


<span class="n">models</span><span class="o">.</span><span class="n">list_models</span><span class="p">()</span>    <span class="c1"># List all models</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[26]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>['alexnet',
 'convnext_base',
 'convnext_large',
 'convnext_small',
 'convnext_tiny',
 'deeplabv3_mobilenet_v3_large',
 'deeplabv3_resnet101',
 'deeplabv3_resnet50',
 'densenet121',
 'densenet161',
 'densenet169',
 'densenet201',
 'efficientnet_b0',
 'efficientnet_b1',
 'efficientnet_b2',
 'efficientnet_b3',
 'efficientnet_b4',
 'efficientnet_b5',
 'efficientnet_b6',
 'efficientnet_b7',
 'efficientnet_v2_l',
 'efficientnet_v2_m',
 'efficientnet_v2_s',
 'fasterrcnn_mobilenet_v3_large_320_fpn',
 'fasterrcnn_mobilenet_v3_large_fpn',
 'fasterrcnn_resnet50_fpn',
 'fasterrcnn_resnet50_fpn_v2',
 'fcn_resnet101',
 'fcn_resnet50',
 'fcos_resnet50_fpn',
 'googlenet',
 'inception_v3',
 'keypointrcnn_resnet50_fpn',
 'lraspp_mobilenet_v3_large',
 'maskrcnn_resnet50_fpn',
 'maskrcnn_resnet50_fpn_v2',
 'maxvit_t',
 'mc3_18',
 'mnasnet0_5',
 'mnasnet0_75',
 'mnasnet1_0',
 'mnasnet1_3',
 'mobilenet_v2',
 'mobilenet_v3_large',
 'mobilenet_v3_small',
 'mvit_v1_b',
 'mvit_v2_s',
 'quantized_googlenet',
 'quantized_inception_v3',
 'quantized_mobilenet_v2',
 'quantized_mobilenet_v3_large',
 'quantized_resnet18',
 'quantized_resnet50',
 'quantized_resnext101_32x8d',
 'quantized_resnext101_64x4d',
 'quantized_shufflenet_v2_x0_5',
 'quantized_shufflenet_v2_x1_0',
 'quantized_shufflenet_v2_x1_5',
 'quantized_shufflenet_v2_x2_0',
 'r2plus1d_18',
 'r3d_18',
 'raft_large',
 'raft_small',
 'regnet_x_16gf',
 'regnet_x_1_6gf',
 'regnet_x_32gf',
 'regnet_x_3_2gf',
 'regnet_x_400mf',
 'regnet_x_800mf',
 'regnet_x_8gf',
 'regnet_y_128gf',
 'regnet_y_16gf',
 'regnet_y_1_6gf',
 'regnet_y_32gf',
 'regnet_y_3_2gf',
 'regnet_y_400mf',
 'regnet_y_800mf',
 'regnet_y_8gf',
 'resnet101',
 'resnet152',
 'resnet18',
 'resnet34',
 'resnet50',
 'resnext101_32x8d',
 'resnext101_64x4d',
 'resnext50_32x4d',
 'retinanet_resnet50_fpn',
 'retinanet_resnet50_fpn_v2',
 's3d',
 'shufflenet_v2_x0_5',
 'shufflenet_v2_x1_0',
 'shufflenet_v2_x1_5',
 'shufflenet_v2_x2_0',
 'squeezenet1_0',
 'squeezenet1_1',
 'ssd300_vgg16',
 'ssdlite320_mobilenet_v3_large',
 'swin3d_b',
 'swin3d_s',
 'swin3d_t',
 'swin_b',
 'swin_s',
 'swin_t',
 'swin_v2_b',
 'swin_v2_s',
 'swin_v2_t',
 'vgg11',
 'vgg11_bn',
 'vgg13',
 'vgg13_bn',
 'vgg16',
 'vgg16_bn',
 'vgg19',
 'vgg19_bn',
 'vit_b_16',
 'vit_b_32',
 'vit_h_14',
 'vit_l_16',
 'vit_l_32',
 'wide_resnet101_2',
 'wide_resnet50_2']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="17.1.2.-%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%9D%83%E9%87%8D">17.1.2. <a id="toc17_1_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#17.1.2.-%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%9D%83%E9%87%8D"></a></h3><p><code></code><a href="https://pytorch.org/vision/stable/models.html">https://pytorch.org/vision/stable/models.html</a></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[74]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Get model</span>
<span class="n">alexnet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'alexnet'</span><span class="p">)</span>

<span class="c1"># 1. Get weight</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">get_weight</span><span class="p">(</span><span class="s1">'AlexNet_Weights.IMAGENET1K_V1'</span><span class="p">)</span>
<span class="c1"># weights = models.get_weight('ResNet50_Weights.IMAGENET1K_V1')</span>
<span class="c1"># weights = models.get_weight('ResNet50_Weights.IMAGENET1K_V2')</span>

<span class="c1"># 2. (Recommendation) Get weight with model name</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">get_model_weights</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'alexnet'</span><span class="p">)</span>

<span class="c1"># Get the state_dict parameters from loaded weights wrapper</span>
<span class="n">state_dict</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="o">.</span><span class="n">get_state_dict</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="17.1.3.-%E6%A8%A1%E5%9E%8B%E5%8A%A0%E8%BD%BD%E6%9D%83%E9%87%8D">17.1.3. <a id="toc17_1_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#17.1.3.-%E6%A8%A1%E5%9E%8B%E5%8A%A0%E8%BD%BD%E6%9D%83%E9%87%8D"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[82]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>


<span class="n">alexnet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">)</span>
<span class="n">alexnet</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">pass</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="17.1.4.-%E6%80%BB%E7%BB%93">17.1.4. <a id="toc17_1_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#17.1.4.-%E6%80%BB%E7%BB%93"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[90]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># wrapper to the following:</span>
<span class="k">def</span> <span class="nf">get_pretrained_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">    </span><span class="sd">'''Default to get: IMAGENET1K_V1'''</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">weight_wrapper</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">get_model_weights</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">weight_wrapper</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="o">.</span><span class="n">get_state_dict</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># pretrained_model = get_pretrained_model(model_name='resnet50')</span>
<span class="n">pretrained_model</span> <span class="o">=</span> <span class="n">get_pretrained_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">'alexnet'</span><span class="p">)</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[90]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="17.2.-Dataset">17.2. <a id="toc17_2_"></a><a href="#toc0_">Dataset</a><a class="anchor-link" href="#17.2.-Dataset"></a></h2><p>torchvision Docs: <a href="https://pytorch.org/vision/stable/datasets.html">https://pytorch.org/vision/stable/datasets.html</a></p>
<ol>
<li><p>torchvisiondatasets</p>
<ul>
<li>Image classification<ul>
<li>FashionMNIST(root[, train, transform, ...])</li>
<li>MNIST(root[, train, transform, ...])</li>
</ul>
</li>
<li>Image detection or segmentation<ul>
<li>CocoDetection(root, annFile[, transform, ...])</li>
</ul>
</li>
<li>Video classification<ul>
<li>HMDB51(root, annotation_path, frames_per_clip)</li>
</ul>
</li>
<li>Video prediction<ul>
<li>MovingMNIST(root[, split, split_ratio, ...])</li>
</ul>
</li>
</ul>
</li>
<li><p></p>
<ul>
<li>Base classes for custom datasets<ul>
<li><code>DatasetFolder</code>(root, loader[, extensions, ...])    # A generic data loader.</li>
<li><code>ImageFolder</code>(root, transform, ...)                 # A generic data loader where the images are arranged in this way by default: .</li>
<li><code>VisionDataset</code>([root, transforms, transform, ...]) # Base Class For making datasets which are compatible with torchvision.</li>
</ul>
</li>
</ul>
</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[94]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision</span>

<span class="n">dbs</span> <span class="o">=</span> <span class="s1">'./Pytorch_datasets/'</span>

<span class="n">trans</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>                  <span class="c1"># PILtensor</span>
        <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">1.0</span><span class="p">,))</span>    <span class="c1"># </span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> 
<span class="c1">#   target_transform=False</span>
<span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dbs</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">transform</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> 
<span class="c1">#   target_transform=False</span>
<span class="p">)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[94]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(torchvision.datasets.mnist.FashionMNIST,
 torchvision.datasets.mnist.FashionMNIST)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="18.-Hugging-face">18. <a id="toc18_"></a><a href="#toc0_">Hugging face</a><a class="anchor-link" href="#18.-Hugging-face"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">"sentiment-analysis"</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">"Today is a nice day."</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span> <span class="nn">torch</span>


<span class="c1">#  BERT </span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">"bert-base-uncased"</span>  <span class="c1"># </span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># </span>

<span class="c1"># </span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"I love Hugging Face!"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>

<span class="c1">#  (inference)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>

<span class="c1"># </span>
<span class="n">predicted_class</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Predicted class: </span><span class="si">{</span><span class="n">predicted_class</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="19.-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-(Supervised-learning)">19. <a id="toc19_"></a><a href="#toc0_"> (Supervised learning)</a><a class="anchor-link" href="#19.-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-(Supervised-learning)"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">dataloader</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="20.-%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-(Semi-supervised-learning)">20. <a id="toc20_"></a><a href="#toc0_"> (Semi-supervised learning)</a><a class="anchor-link" href="#20.-%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-(Semi-supervised-learning)"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="21.-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-(Unsupervised-learning)">21. <a id="toc21_"></a><a href="#toc0_"> (Unsupervised learning)</a><a class="anchor-link" href="#21.-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-(Unsupervised-learning)"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="22.-%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-(DRL,-Deep-Reforcement-Learning)">22. <a id="toc22_"></a><a href="#toc0_"> (DRL, Deep Reforcement Learning)</a><a class="anchor-link" href="#22.-%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-(DRL,-Deep-Reforcement-Learning)"></a></h1><p>Deep Reinforcement Learning, DRL <code>Reinforcement Learning, RLDeep Learning</code> AI </p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="22.1.-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5">22.1. <a id="toc22_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#22.1.-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5"></a></h2><p><code>Trial and Error</code></p>
<ul>
<li>Environment</li>
<li>Agent</li>
<li>State, </li>
<li>Action, </li>
<li>Reward, </li>
<li>Policy, </li>
<li>Value Function ()  (,)</li>
</ul>
<p>  </p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="22.2.-%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%89%B9%E7%82%B9">22.2. <a id="toc22_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#22.2.-%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%89%B9%E7%82%B9"></a></h2><p><code>DNN</code></p>
<p></p>
<ul>
<li>DRL </li>
<li></li>
<li>DRL </li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="22.3.-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB">22.3. <a id="toc22_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#22.3.-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="22.4.-%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%BB%E8%A6%81%E6%96%B9%E6%B3%95">22.4. <a id="toc22_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#22.4.-%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%BB%E8%A6%81%E6%96%B9%E6%B3%95"></a></h2><h3 id="22.4.1.-%E6%B7%B1%E5%BA%A6-Q-%E7%BD%91%E7%BB%9C%EF%BC%88Deep-Q-Network,-DQN%EF%BC%89">22.4.1. <a id="toc22_4_1_"></a><a href="#toc0_"> Q Deep Q-Network, DQN</a><a class="anchor-link" href="#22.4.1.-%E6%B7%B1%E5%BA%A6-Q-%E7%BD%91%E7%BB%9C%EF%BC%88Deep-Q-Network,-DQN%EF%BC%89"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="22.4.2.-%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E6%96%B9%E6%B3%95%EF%BC%88Policy-Gradient-Methods%EF%BC%89">22.4.2. <a id="toc22_4_2_"></a><a href="#toc0_">Policy Gradient Methods</a><a class="anchor-link" href="#22.4.2.-%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E6%96%B9%E6%B3%95%EF%BC%88Policy-Gradient-Methods%EF%BC%89"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="22.4.3.-%E6%BC%94%E5%91%98-%E8%AF%84%E8%AE%BA%E5%AE%B6%E6%96%B9%E6%B3%95%EF%BC%88Actor-Critic-Methods%EF%BC%89">22.4.3. <a id="toc22_4_3_"></a><a href="#toc0_">-Actor-Critic Methods</a><a class="anchor-link" href="#22.4.3.-%E6%BC%94%E5%91%98-%E8%AF%84%E8%AE%BA%E5%AE%B6%E6%96%B9%E6%B3%95%EF%BC%88Actor-Critic-Methods%EF%BC%89"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="22.4.4.-%E6%B7%B1%E5%BA%A6%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%EF%BC%88Deep-Deterministic-Policy-Gradient,-DDPG%EF%BC%89">22.4.4. <a id="toc22_4_4_"></a><a href="#toc0_">Deep Deterministic Policy Gradient, DDPG</a><a class="anchor-link" href="#22.4.4.-%E6%B7%B1%E5%BA%A6%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%EF%BC%88Deep-Deterministic-Policy-Gradient,-DDPG%EF%BC%89"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="22.5.-%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BA%94%E7%94%A8">22.5. <a id="toc22_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#22.5.-%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BA%94%E7%94%A8"></a></h2><p></p>
<ul>
<li> AI AlphaGoDQN  A3C  Atari StarCraft </li>
<li> DRL</li>
<li>DRL </li>
<li></li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="23.-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C-(GAN,-Generative-Adversarial-Networks)">23. <a id="toc23_"></a><a href="#toc0_"> (GAN, Generative Adversarial Networks)</a><a class="anchor-link" href="#23.-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C-(GAN,-Generative-Adversarial-Networks)"></a></h1><p>Generative Adversarial Networks  Ian Goodfellow  2014 GAN GeneratorDiscriminatorGAN </p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="24.-%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B-(DM,-Diffusion-Models)">24. <a id="toc24_"></a><a href="#toc0_"> (DM, Diffusion Models)</a><a class="anchor-link" href="#24.-%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B-(DM,-Diffusion-Models)"></a></h1><p>Diffusion Models GANVAE</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="25.-%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-(GNN,-Graph-Neural-Networks)">25. <a id="toc25_"></a><a href="#toc0_"> (GNN, Graph Neural Networks)</a><a class="anchor-link" href="#25.-%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-(GNN,-Graph-Neural-Networks)"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="26.-%E5%A4%9A%E6%A8%A1%E6%80%81-(ML,-MultiModal-Learning)">26. <a id="toc26_"></a><a href="#toc0_"> (ML, MultiModal Learning)</a><a class="anchor-link" href="#26.-%E5%A4%9A%E6%A8%A1%E6%80%81-(ML,-MultiModal-Learning)"></a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="26.1.-%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88">26.1. <a id="toc26_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#26.1.-%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="26.1.1.-concatenate%E8%9E%8D%E5%90%88">26.1.1. <a id="toc26_1_1_"></a><a href="#toc0_">concatenate</a><a class="anchor-link" href="#26.1.1.-concatenate%E8%9E%8D%E5%90%88"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="k">class</span> <span class="nc">ConcatenationFusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span> 
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="n">text_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">image_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">text_embed</span><span class="p">,</span> <span class="n">image_embed</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">embed</span><span class="p">)</span>


<span class="c1"># </span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">text_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">image_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">text_dim</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ConcatenationFusion</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[2]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[-0.6195, -0.3160],
        [ 0.2971, -0.1323],
        [ 0.0390, -0.1370],
        [-0.5115, -0.0740],
        [-0.2206,  0.1055],
        [ 0.2138,  0.4587],
        [ 0.0137,  0.4941],
        [-0.7639,  0.2320],
        [ 0.1132, -0.0281],
        [ 0.3580, -0.5043],
        [-0.2224, -0.0530],
        [ 0.2169, -0.5772],
        [-0.4945,  0.1773],
        [ 0.4219, -0.6502],
        [ 0.7815,  0.1727],
        [ 0.1638, -0.5882],
        [-0.4790,  0.4223],
        [ 0.8619, -0.0411],
        [-0.0017,  0.1959],
        [-0.0870, -0.5702]], grad_fn=&lt;AddmmBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="26.1.2.-%E5%8A%A0%E6%9D%83%E8%9E%8D%E5%90%88">26.1.2. <a id="toc26_1_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#26.1.2.-%E5%8A%A0%E6%9D%83%E8%9E%8D%E5%90%88"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="k">class</span> <span class="nc">WeightedFusionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WeightedFusionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="n">text_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
        <span class="n">image_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
        <span class="c1"># </span>
        <span class="n">combined</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_weight</span> <span class="o">*</span> <span class="n">text_feat</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_weight</span> <span class="o">*</span> <span class="n">image_feat</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">combined</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
    

<span class="c1"># </span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">text_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">image_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">WeightedFusionModel</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[3]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0.4882,  0.2628],
        [-0.2350,  0.1624],
        [-0.1564, -0.3804],
        [ 0.9307,  0.3243],
        [-0.4938, -0.1195],
        [ 0.4288,  0.0948],
        [-0.0257, -0.4239],
        [ 0.4966,  0.1993],
        [ 0.1152, -0.0426],
        [-0.2395,  0.0357]], grad_fn=&lt;AddmmBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="26.1.3.-%E5%85%83%E7%B4%A0%E7%BA%A7%E8%9E%8D%E5%90%88">26.1.3. <a id="toc26_1_3_"></a><a href="#toc0_"></a><a class="anchor-link" href="#26.1.3.-%E5%85%83%E7%B4%A0%E7%BA%A7%E8%9E%8D%E5%90%88"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="k">class</span> <span class="nc">ElementWiseFusionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ElementWiseFusionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="n">text_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
        <span class="n">image_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
        <span class="c1"># </span>
        <span class="n">combined</span> <span class="o">=</span> <span class="n">text_feat</span> <span class="o">+</span> <span class="n">image_feat</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">combined</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
    

<span class="c1"># </span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">text_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">image_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ElementWiseFusionModel</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[4]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0.6244,  0.2016],
        [ 0.8621,  0.2443],
        [ 0.9425,  0.1201],
        [ 0.9802,  0.4019],
        [ 0.3661,  0.6483],
        [ 0.7553,  0.1573],
        [-0.1221,  0.4012],
        [ 0.7014,  0.3860],
        [ 0.4824, -0.0051],
        [ 0.0542,  0.5417]], grad_fn=&lt;AddmmBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="26.1.4.-%E5%BC%A0%E9%87%8F%E8%9E%8D%E5%90%88">26.1.4. <a id="toc26_1_4_"></a><a href="#toc0_"></a><a class="anchor-link" href="#26.1.4.-%E5%BC%A0%E9%87%8F%E8%9E%8D%E5%90%88"></a></h3><p></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> 


<span class="k">class</span> <span class="nc">TensorFusionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TensorFusionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bilinear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Bilinear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="n">text_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>  <span class="c1"># (batch, hidden_dim)</span>
        <span class="n">image_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>  <span class="c1"># (batch, hidden_dim)</span>
        <span class="c1"># </span>
        <span class="n">fused_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bilinear</span><span class="p">(</span><span class="n">text_feat</span><span class="p">,</span> <span class="n">image_feat</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">fused_feat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
    

<span class="c1"># </span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">text_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">image_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TensorFusionModel</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[5]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 1.1044,  1.9264],
        [ 1.4953,  0.3077],
        [ 0.0490, -0.7681],
        [-0.2574,  0.9185],
        [-0.1704,  1.5164],
        [ 0.0709,  0.1978],
        [ 0.5048,  0.2998],
        [-0.0954,  0.7170],
        [ 0.4186,  0.0913],
        [-0.0310,  0.3840]], grad_fn=&lt;AddmmBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="26.1.5.-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E8%9E%8D%E5%90%88">26.1.5. <a id="toc26_1_5_"></a><a href="#toc0_"></a><a class="anchor-link" href="#26.1.5.-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E8%9E%8D%E5%90%88"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># models/attention_fusion.py</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">AttentionFusionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AttentionFusionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="n">text_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>  <span class="c1"># (batch, hidden_dim)</span>
        <span class="n">image_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>  <span class="c1"># (batch, hidden_dim)</span>
        <span class="c1"># </span>
        <span class="n">combined</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">text_feat</span><span class="p">,</span> <span class="n">image_feat</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">combined</span><span class="p">))</span>  <span class="c1"># (batch, 1)</span>
        <span class="c1"># </span>
        <span class="n">fused_feat</span> <span class="o">=</span> <span class="n">attention_weights</span> <span class="o">*</span> <span class="n">text_feat</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">attention_weights</span><span class="p">)</span> <span class="o">*</span> <span class="n">image_feat</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">fused_feat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="c1"># </span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">text_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">image_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AttentionFusionModel</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[6]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[-0.0205,  0.1797],
        [ 0.2680,  0.2053],
        [-0.2812, -0.2311],
        [-0.1339,  0.1499],
        [-0.0546,  0.1342],
        [ 0.1965,  0.1365],
        [-0.0536,  0.0970],
        [ 0.0025, -0.0526],
        [ 0.0618,  0.1367],
        [-0.0903,  0.2358]], grad_fn=&lt;AddmmBackward0&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="26.1.6.-%E9%AB%98%E9%98%B6%E8%9E%8D%E5%90%88">26.1.6. <a id="toc26_1_6_"></a><a href="#toc0_"></a><a class="anchor-link" href="#26.1.6.-%E9%AB%98%E9%98%B6%E8%9E%8D%E5%90%88"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># models/high_order_fusion.py</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="k">class</span> <span class="nc">HighOrderFusionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">HighOrderFusionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">=</span> <span class="n">order</span>
        <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">high_order_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">**</span> <span class="n">order</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="n">text_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_fc</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>  <span class="c1"># (batch, hidden_dim)</span>
        <span class="n">image_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_fc</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>  <span class="c1"># (batch, hidden_dim)</span>
        <span class="c1"># </span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">fused_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">text_feat</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">image_feat</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># (batch, hidden_dim, hidden_dim)</span>
            <span class="n">fused_feat</span> <span class="o">=</span> <span class="n">fused_feat</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">fused_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch, hidden_dim^2)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">""</span><span class="p">)</span>
        <span class="n">fused_feat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">high_order_fc</span><span class="p">(</span><span class="n">fused_feat</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">fused_feat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
    

<span class="c1"># </span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">text_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">image_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">HighOrderFusionModel</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="26.2.-%E7%AE%80%E5%8D%95%E7%A4%BA%E4%BE%8B">26.2. <a id="toc26_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#26.2.-%E7%AE%80%E5%8D%95%E7%A4%BA%E4%BE%8B"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>


<span class="c1"># </span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">genomics_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>  <span class="c1">#  (1000 samples, 500 features)</span>
<span class="n">transcriptomics_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>  <span class="c1">#  (1000 samples, 300 features)</span>
<span class="n">metabolomics_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>  <span class="c1">#  (1000 samples, 100 features)</span>

<span class="c1">#  ()</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">genomics_data</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">genomics_data</span><span class="p">)</span>
<span class="n">transcriptomics_data</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">transcriptomics_data</span><span class="p">)</span>
<span class="n">metabolomics_data</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">metabolomics_data</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">X_train_genomics</span><span class="p">,</span> <span class="n">X_test_genomics</span><span class="p">,</span> <span class="n">X_train_transcript</span><span class="p">,</span> <span class="n">X_test_transcript</span><span class="p">,</span> <span class="n">X_train_metabol</span><span class="p">,</span> <span class="n">X_test_metabol</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">genomics_data</span><span class="p">,</span> 
    <span class="n">transcriptomics_data</span><span class="p">,</span> 
    <span class="n">metabolomics_data</span><span class="p">,</span> 
    <span class="n">labels</span><span class="p">,</span> 
    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> 
    <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Tensor</span>
<span class="n">X_train_genomics</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_train_genomics</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_test_genomics</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_test_genomics</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_train_transcript</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_train_transcript</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_test_transcript</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_test_transcript</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_train_metabol</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_train_metabol</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_test_metabol</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_test_metabol</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MultiModalDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">genomics</span><span class="p">,</span> <span class="n">transcriptomics</span><span class="p">,</span> <span class="n">metabolomics</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">genomics</span> <span class="o">=</span> <span class="n">genomics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transcriptomics</span> <span class="o">=</span> <span class="n">transcriptomics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metabolomics</span> <span class="o">=</span> <span class="n">metabolomics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">genomics</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">transcriptomics</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">metabolomics</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

<span class="c1"># DataLoader</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">MultiModalDataset</span><span class="p">(</span><span class="n">X_train_genomics</span><span class="p">,</span> <span class="n">X_train_transcript</span><span class="p">,</span> <span class="n">X_train_metabol</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">MultiModalDataset</span><span class="p">(</span><span class="n">X_test_genomics</span><span class="p">,</span> <span class="n">X_test_transcript</span><span class="p">,</span> <span class="n">X_test_metabol</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>


<span class="k">class</span> <span class="nc">MultiModalNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiModalNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">genomics_fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">genomics_fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>

        <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transcript_fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transcript_fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>

        <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metabol_fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metabol_fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

        <span class="c1"># </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span> <span class="o">+</span> <span class="mi">128</span> <span class="o">+</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># </span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">genomics</span><span class="p">,</span> <span class="n">transcriptomics</span><span class="p">,</span> <span class="n">metabolomics</span><span class="p">):</span>
        <span class="c1"># </span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">genomics_fc1</span><span class="p">(</span><span class="n">genomics</span><span class="p">))</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">genomics_fc2</span><span class="p">(</span><span class="n">x1</span><span class="p">))</span>
        
        <span class="c1"># </span>
        <span class="n">x2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transcript_fc1</span><span class="p">(</span><span class="n">transcriptomics</span><span class="p">))</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transcript_fc2</span><span class="p">(</span><span class="n">x2</span><span class="p">))</span>
        
        <span class="c1"># </span>
        <span class="n">x3</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metabol_fc1</span><span class="p">(</span><span class="n">metabolomics</span><span class="p">))</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metabol_fc2</span><span class="p">(</span><span class="n">x3</span><span class="p">))</span>

        <span class="c1"># </span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># </span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1">#  (softmax  loss )</span>

        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>

<span class="c1"># </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MultiModalNet</span><span class="p">()</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># </span>
<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">genomics</span><span class="p">,</span> <span class="n">transcriptomics</span><span class="p">,</span> <span class="n">metabolomics</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">genomics</span><span class="p">,</span> <span class="n">transcriptomics</span><span class="p">,</span> <span class="n">metabolomics</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">running_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># </span>
<span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">genomics</span><span class="p">,</span> <span class="n">transcriptomics</span><span class="p">,</span> <span class="n">metabolomics</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">genomics</span><span class="p">,</span> <span class="n">transcriptomics</span><span class="p">,</span> <span class="n">metabolomics</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Accuracy: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>

<span class="c1"># </span>
<span class="n">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100, Loss: 108.54958134889603
Epoch 2/100, Loss: 4.135224883556366
Epoch 3/100, Loss: 2.6385957312583925
Epoch 4/100, Loss: 0.6935833239555359
Epoch 5/100, Loss: 0.6948023843765259
Epoch 6/100, Loss: 0.698513593673706
Epoch 7/100, Loss: 0.6958599543571472
Epoch 8/100, Loss: 0.6969271898269653
Epoch 9/100, Loss: 0.6937605094909668
Epoch 10/100, Loss: 0.6936862874031067
Epoch 11/100, Loss: 0.6943797707557678
Epoch 12/100, Loss: 0.6971164178848267
Epoch 13/100, Loss: 0.6948093438148498
Epoch 14/100, Loss: 0.6967662334442138
Epoch 15/100, Loss: 0.6949256801605225
Epoch 16/100, Loss: 0.695241117477417
Epoch 17/100, Loss: 0.6972526645660401
Epoch 18/100, Loss: 0.6937112951278687
Epoch 19/100, Loss: 0.6992354965209961
Epoch 20/100, Loss: 0.6977572059631347
Epoch 21/100, Loss: 0.6933968138694763
Epoch 22/100, Loss: 0.6942662429809571
Epoch 23/100, Loss: 0.6990512418746948
Epoch 24/100, Loss: 0.7020175790786743
Epoch 25/100, Loss: 0.6971980500221252
Epoch 26/100, Loss: 0.6988357472419738
Epoch 27/100, Loss: 0.6993172907829285
Epoch 28/100, Loss: 0.695647988319397
Epoch 29/100, Loss: 0.6949885272979737
Epoch 30/100, Loss: 0.6965868735313415
Epoch 31/100, Loss: 0.6960195851325989
Epoch 32/100, Loss: 0.6967833948135376
Epoch 33/100, Loss: 0.6988573646545411
Epoch 34/100, Loss: 0.6958928561210632
Epoch 35/100, Loss: 0.6944725155830384
Epoch 36/100, Loss: 0.6985653638839722
Epoch 37/100, Loss: 0.6945236992835998
Epoch 38/100, Loss: 0.6958037447929383
Epoch 39/100, Loss: 0.6981622338294983
Epoch 40/100, Loss: 0.699951548576355
Epoch 41/100, Loss: 0.7010440397262573
Epoch 42/100, Loss: 0.6996695232391358
Epoch 43/100, Loss: 0.6947126746177673
Epoch 44/100, Loss: 0.6998348593711853
Epoch 45/100, Loss: 0.698057565689087
Epoch 46/100, Loss: 0.6945283937454224
Epoch 47/100, Loss: 0.697084653377533
Epoch 48/100, Loss: 0.6943980312347412
Epoch 49/100, Loss: 0.6961186456680298
Epoch 50/100, Loss: 0.6969403219223023
Epoch 51/100, Loss: 0.6967438077926635
Epoch 52/100, Loss: 0.6989381742477417
Epoch 53/100, Loss: 0.693901059627533
Epoch 54/100, Loss: 0.6946544551849365
Epoch 55/100, Loss: 0.6936815404891967
Epoch 56/100, Loss: 0.7013679599761963
Epoch 57/100, Loss: 0.6988341665267944
Epoch 58/100, Loss: 0.6957477474212647
Epoch 59/100, Loss: 0.6964562892913818
Epoch 60/100, Loss: 0.7005986928939819
Epoch 61/100, Loss: 0.6953284955024719
Epoch 62/100, Loss: 0.6999827551841736
Epoch 63/100, Loss: 0.7050584983825684
Epoch 64/100, Loss: 0.6944698143005371
Epoch 65/100, Loss: 0.6991106462478638
Epoch 66/100, Loss: 0.7011834383010864
Epoch 67/100, Loss: 0.69974041223526
Epoch 68/100, Loss: 0.6953120112419129
Epoch 69/100, Loss: 0.6984820246696473
Epoch 70/100, Loss: 0.702326295375824
Epoch 71/100, Loss: 0.7008291363716126
Epoch 72/100, Loss: 0.7018577075004577
Epoch 73/100, Loss: 0.7048114895820617
Epoch 74/100, Loss: 0.6940262198448182
Epoch 75/100, Loss: 0.6968365430831909
Epoch 76/100, Loss: 0.7065490674972534
Epoch 77/100, Loss: 0.6928381443023681
Epoch 78/100, Loss: 0.699993531703949
Epoch 79/100, Loss: 0.6943574452400207
Epoch 80/100, Loss: 0.6942070937156677
Epoch 81/100, Loss: 0.6962732601165772
Epoch 82/100, Loss: 0.6969137501716614
Epoch 83/100, Loss: 0.6947614693641663
Epoch 84/100, Loss: 0.6981009387969971
Epoch 85/100, Loss: 0.6961423540115357
Epoch 86/100, Loss: 0.6947582244873047
Epoch 87/100, Loss: 0.7031455755233764
Epoch 88/100, Loss: 0.696880784034729
Epoch 89/100, Loss: 0.6948024916648865
Epoch 90/100, Loss: 0.6938769030570984
Epoch 91/100, Loss: 0.6981698584556579
Epoch 92/100, Loss: 0.6983580541610718
Epoch 93/100, Loss: 0.6962730884552002
Epoch 94/100, Loss: 0.6981739687919617
Epoch 95/100, Loss: 0.6944485783576966
Epoch 96/100, Loss: 0.6950165700912475
Epoch 97/100, Loss: 0.6992542886734009
Epoch 98/100, Loss: 0.6966559171676636
Epoch 99/100, Loss: 0.6942050862312317
Epoch 100/100, Loss: 0.6940448403358459
Accuracy: 49.5%
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="27.-argparse">27. <a id="toc27_"></a><a href="#toc0_">argparse</a><a class="anchor-link" href="#27.-argparse"></a></h1><p>import argparse</p>
<p>parser = argparse.ArgumentParser(description='PyTorch Multi-Modal Learning')
parser.add_argument('--batch_size', type=int, default=32, help='batch size')
args = parser.parse_args()</p>
<p>args</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span> 


<span class="c1"># ArgumentParser</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
    <span class="n">prog</span><span class="o">=</span><span class="s2">"argparse demo in PyTorch"</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">"demo for argparse which is used to parse command-line arguments"</span><span class="p">,</span>
    <span class="n">usage</span><span class="o">=</span><span class="s2">"python argparse_demo.py [options]"</span><span class="p">,</span>
    <span class="n">epilog</span><span class="o">=</span><span class="s2">"End of ArgumentParser demo"</span><span class="p">,</span>
    <span class="n">add_help</span><span class="o">=</span><span class="kc">True</span>   <span class="c1"># </span>
<span class="p">)</span>

<span class="c1"># </span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
    <span class="s1">'-b'</span><span class="p">,</span>                                               <span class="c1">#    </span>
    <span class="s1">'--batch_size'</span><span class="p">,</span>                                      <span class="c1"># </span>
    <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>                                           <span class="c1"># </span>
    <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>                                          <span class="c1"># </span>
    <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>                                    <span class="c1"># </span>
    <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">],</span>       <span class="c1"># </span>
    <span class="n">help</span><span class="o">=</span><span class="s1">'batch size for training or inference'</span><span class="p">,</span>          <span class="c1"># </span>
    <span class="n">action</span><span class="o">=</span><span class="s1">'store'</span>                                      <span class="c1"># </span>
<span class="p">)</span>

<span class="c1"># </span>
<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="n">args</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="28.-ml_collections">28. <a id="toc28_"></a><a href="#toc0_">ml_collections</a><a class="anchor-link" href="#28.-ml_collections"></a></h1><p><a href="https://github.com/google/ml_collections">https://github.com/google/ml_collections</a><br/>
<a href="https://ml-collections.readthedocs.io/en/latest/">https://ml-collections.readthedocs.io/en/latest/</a></p>
<div class="highlight"><pre><span></span><span class="c1"># Install</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">ml</span><span class="o">-</span><span class="n">collections</span> 

<span class="c1"># Module structure</span>
<span class="n">mlc</span><span class="o">.</span><span class="n">ConfigDict</span><span class="p">()</span>                <span class="c1"># </span>
<span class="n">mlc</span><span class="o">.</span><span class="n">FrozenConfigDict</span><span class="p">()</span>          <span class="c1"># </span>
<span class="n">mlc</span><span class="o">.</span><span class="n">FieldReference</span><span class="p">()</span>            <span class="c1">#  ()</span>
<span class="n">mlc</span><span class="o">.</span><span class="n">config_dict</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[133]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">ml_collections</span> <span class="k">as</span> <span class="nn">mlc</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[134]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">'''</span>
<span class="sd">ml_collections</span>
<span class="sd">'''</span>


<span class="c1"># 1. ConfigDict: </span>
<span class="n">config</span> <span class="o">=</span> <span class="n">mlc</span><span class="o">.</span><span class="n">ConfigDict</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
        <span class="s1">'save_dir'</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">'dir_base'</span><span class="p">:</span> <span class="s1">'./bs/train/checkpoints'</span><span class="p">,</span>
            <span class="s1">'prefix'</span><span class="p">:</span> <span class="s1">'demo'</span><span class="p">,</span> 
            <span class="s1">'suffix'</span><span class="p">:</span> <span class="s1">'.ckpt'</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># 2. </span>
<span class="n">config</span><span class="o">.</span><span class="n">steps_counter</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># x.x</span>
<span class="n">config</span><span class="o">.</span><span class="n">learning_rate</span>
<span class="n">config</span><span class="o">.</span><span class="n">epochs</span>
<span class="n">config</span><span class="o">.</span><span class="n">save_dir</span>
<span class="n">config</span><span class="o">.</span><span class="n">save_dir</span><span class="o">.</span><span class="n">dir_base</span>
<span class="n">config</span><span class="o">.</span><span class="n">save_dir</span><span class="o">.</span><span class="n">prefix</span>
<span class="n">config</span><span class="o">.</span><span class="n">save_dir</span><span class="o">.</span><span class="n">suffix</span>
<span class="n">config</span><span class="o">.</span><span class="n">steps_counter</span>
<span class="n">config</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[134]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>epochs: 100
learning_rate: 0.01
save_dir:
  dir_base: ./bs/train/checkpoints
  prefix: demo
  suffix: .ckpt
steps_counter: 0</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[124]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">config</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mi">0</span>    <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[132]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">'''</span>
<span class="sd">FrozenConfigDict</span>
<span class="sd">'''</span>


<span class="n">fc</span> <span class="o">=</span> <span class="n">mlc</span><span class="o">.</span><span class="n">FrozenConfigDict</span><span class="p">({</span>
    <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="s1">'optm'</span><span class="p">:</span> <span class="s1">'optm'</span>
<span class="p">})</span>

<span class="n">fc</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[132]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>learning_rate: 0.001
optm: optm</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">fc</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mi">0</span>    <span class="c1"># </span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[131]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">'''</span>
<span class="sd">FieldReference</span>
<span class="sd">'''</span>


<span class="n">lr</span> <span class="o">=</span> <span class="n">mlc</span><span class="o">.</span><span class="n">FieldReference</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">field_type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="n">gama</span> <span class="o">=</span> <span class="n">mlc</span><span class="o">.</span><span class="n">FieldReference</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">field_type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

<span class="n">c</span> <span class="o">=</span> <span class="n">mlc</span><span class="o">.</span><span class="n">ConfigDict</span><span class="p">({</span>
    <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">gama</span>  <span class="c1"># </span>
<span class="p">})</span>

<span class="n">c</span><span class="o">.</span><span class="n">learning_rate</span>
<span class="n">c</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[131]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>learning_rate: !!python/object:ml_collections.config_dict.config_dict.FieldReference
  _field_type: !!python/name:builtins.float ''
  _ops: []
  _required: false
  _value: 1.0e-05</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="29.-functools">29. <a id="toc29_"></a><a href="#toc0_">functools</a><a class="anchor-link" href="#29.-functools"></a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="29.1.-partial">29.1. <a id="toc29_1_"></a><a href="#toc0_">partial</a><a class="anchor-link" href="#29.1.-partial"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[157]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>


<span class="k">def</span> <span class="nf">add_fn</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

<span class="n">a_add</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">add_fn</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>    <span class="c1"># a</span>

<span class="n">a_add</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">a_add</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> <span class="n">a_add</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[157]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(3, 4, 6)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="30.-copy">30. <a id="toc30_"></a><a href="#toc0_">copy</a><a class="anchor-link" href="#30.-copy"></a></h1><p></p>
<p>(copy)</p>
<p>(deepcopy) copy  deepcopy </p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="30.1.-%E5%88%97%E8%A1%A8%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%8B%B7%E8%B4%9D">30.1. <a id="toc30_1_"></a><a href="#toc0_"></a><a class="anchor-link" href="#30.1.-%E5%88%97%E8%A1%A8%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%8B%B7%E8%B4%9D"></a></h2><p><strong></strong></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[138]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">''''''</span>

<span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">a</span><span class="p">,</span> <span class="n">b</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[138]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>([1, 2, 3], [1, 2, 3])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[139]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">a</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>

<span class="n">a</span><span class="p">,</span> <span class="n">b</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[139]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>([1, 2, 3, 100], [1, 2, 3])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="30.2.-%E5%AD%97%E5%85%B8%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%8B%B7%E8%B4%9D">30.2. <a id="toc30_2_"></a><a href="#toc0_"></a><a class="anchor-link" href="#30.2.-%E5%AD%97%E5%85%B8%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%8B%B7%E8%B4%9D"></a></h2><p><strong></strong></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[146]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">''''''</span>

<span class="n">a_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"k1"</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]}</span>
<span class="n">b_dict</span> <span class="o">=</span> <span class="n">a_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>                      <span class="c1"># copy.copy(a_dict)     </span>
<span class="n">c_dict</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">a_dict</span><span class="p">)</span>              <span class="c1"># copy.deepcopy(a_dict) </span>

<span class="n">a_dict</span><span class="p">,</span> <span class="n">b_dict</span><span class="p">,</span> <span class="n">c_dict</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[146]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>({'k1': [1, 2, 3]}, {'k1': [1, 2, 3]}, {'k1': [1, 2, 3]})</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[147]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">a_dict</span><span class="p">[</span><span class="s1">'k1'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>    <span class="c1"># a_dict</span>

<span class="n">a_dict</span><span class="p">,</span> <span class="n">b_dict</span><span class="p">,</span> <span class="n">c_dict</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[147]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>({'k1': [1, 2, 3, 100]}, {'k1': [1, 2, 3, 100]}, {'k1': [1, 2, 3]})</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="31.-%E8%BD%AC%E6%A0%BC%E5%BC%8F">31. <a id="toc31_"></a><a href="#toc0_"></a><a class="anchor-link" href="#31.-%E8%BD%AC%E6%A0%BC%E5%BC%8F"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[191]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># ipynb to html</span>
<span class="o">!</span>jupyter<span class="w"> </span>nbconvert<span class="w"> </span>--to<span class="w"> </span>html<span class="w"> </span>Learn-Pytorch.ipynb

<span class="c1"># browse translate html to pdf</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[NbConvertApp] Converting notebook Learn-Pytorch.ipynb to html
[NbConvertApp] WARNING | Alternative text is missing on 28 image(s).
[NbConvertApp] Writing 3475171 bytes to Learn-Pytorch.html
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[192]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># ipynb to markdown</span>
<span class="o">!</span>jupyter<span class="w"> </span>nbconvert<span class="w"> </span>--to<span class="w"> </span>markdown<span class="w"> </span>Learn-Pytorch.ipynb
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[NbConvertApp] Converting notebook Learn-Pytorch.ipynb to markdown
[NbConvertApp] Support files will be in Learn-Pytorch_files/
[NbConvertApp] Writing 563913 bytes to Learn-Pytorch.md
</pre>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
