{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [概述](#toc1_)    \n",
    "- 2. [环境配置](#toc2_)    \n",
    "- 3. [utils](#toc3_)    \n",
    "  - 3.1. [代码稳定性](#toc3_1_)    \n",
    "  - 3.2. [计时器](#toc3_2_)    \n",
    "  - 3.3. [训练统计](#toc3_3_)    \n",
    "  - 3.4. [比较numpy和pytorch](#toc3_4_)    \n",
    "- 4. [安装GPU驱动](#toc4_)    \n",
    "  - 4.1. [安装策略](#toc4_1_)    \n",
    "  - 4.2. [首先确认内核版本和发行版本，再确认显卡型号](#toc4_2_)    \n",
    "  - 4.3. [安装驱动-CUDA Driver](#toc4_3_)    \n",
    "    - 4.3.1. [下载CUDA Driver](#toc4_3_1_)    \n",
    "    - 4.3.2. [禁用nouveau](#toc4_3_2_)    \n",
    "    - 4.3.3. [安装CUDA Driver](#toc4_3_3_)    \n",
    "    - 4.3.4. [查看显卡是否安装成功](#toc4_3_4_)    \n",
    "    - 4.3.5. [查看nvcc](#toc4_3_5_)    \n",
    "  - 4.4. [CUDA Toolkit和CuDNN](#toc4_4_)    \n",
    "    - 4.4.1. [下载对应的CUDA Toolkit版本](#toc4_4_1_)    \n",
    "    - 4.4.2. [安装CUDA Toolkit](#toc4_4_2_)    \n",
    "    - 4.4.3. [下载对应的CuDNN](#toc4_4_3_)    \n",
    "    - 4.4.4. [安装CuDNN](#toc4_4_4_)    \n",
    "  - 4.5. [安装对应版本的Pytorch](#toc4_5_)    \n",
    "  - 4.6. [推荐A100](#toc4_6_)    \n",
    "  - 4.7. [GPU测试程序](#toc4_7_)    \n",
    "    - 4.7.1. [测试单机单卡GPU性能](#toc4_7_1_)    \n",
    "    - 4.7.2. [测试单机多卡GPU性能](#toc4_7_2_)    \n",
    "    - 4.7.3. [GPU burn压力测试](#toc4_7_3_)    \n",
    "- 5. [Pytorch模块介绍](#toc5_)    \n",
    "  - 5.1. [导入模块](#toc5_1_)    \n",
    "- 6. [数据封装和加载](#toc6_)    \n",
    "  - 6.1. [直接加载torchvison.datasets获得Dataset](#toc6_1_)    \n",
    "  - 6.2. [自定义数据集获得Dataset](#toc6_2_)    \n",
    "    - 6.2.1. [利用TensorDataset()封装成Dataset](#toc6_2_1_)    \n",
    "    - 6.2.2. [重载Dataset类](#toc6_2_2_)    \n",
    "    - 6.2.3. [Pytoch.utils.data.Dataset类分析和总结](#toc6_2_3_)    \n",
    "  - 6.3. [数据加载-DataLoader()](#toc6_3_)    \n",
    "    - 6.3.1. [估计数据加载时间](#toc6_3_1_)    \n",
    "- 7. [张量(Tensors)](#toc7_)    \n",
    "  - 7.1. [Tensors定义](#toc7_1_)    \n",
    "  - 7.2. [Tensors属性](#toc7_2_)    \n",
    "  - 7.3. [Tensors操作](#toc7_3_)    \n",
    "    - 7.3.1. [索引和切片](#toc7_3_1_)    \n",
    "    - 7.3.2. [修改维度](#toc7_3_2_)    \n",
    "      - 7.3.2.1. [reshape函数](#toc7_3_2_1_)    \n",
    "      - 7.3.2.2. [view函数](#toc7_3_2_2_)    \n",
    "      - 7.3.2.3. [transpose函数](#toc7_3_2_3_)    \n",
    "      - 7.3.2.4. [permute函数](#toc7_3_2_4_)    \n",
    "  - 7.4. [线性代数运算](#toc7_4_)    \n",
    "    - 7.4.1. [数值运算](#toc7_4_1_)    \n",
    "    - 7.4.2. [哈达玛积](#toc7_4_2_)    \n",
    "    - 7.4.3. [点积（Dot Product）](#toc7_4_3_)    \n",
    "    - 7.4.4. [矩阵-向量积](#toc7_4_4_)    \n",
    "    - 7.4.5. [矩阵-矩阵积](#toc7_4_5_)    \n",
    "    - 7.4.6. [批量矩阵乘法](#toc7_4_6_)    \n",
    "    - 7.4.7. [乘总结](#toc7_4_7_)    \n",
    "    - 7.4.8. [统计运算](#toc7_4_8_)    \n",
    "  - 7.5. [Pytorch的计算图 和 自动微分 (autograd)](#toc7_5_)    \n",
    "    - 7.5.1. [反向传播 (backward)-批量求梯度，但未进行参数更新](#toc7_5_1_)    \n",
    "    - 7.5.2. [仅计算梯度 (求导计算)](#toc7_5_2_)    \n",
    "  - 7.6. [自动微积-autograd](#toc7_6_)    \n",
    "    - 7.6.1. [自己探索](#toc7_6_1_)    \n",
    "      - 7.6.1.1. [标量-一阶导数（得标量）](#toc7_6_1_1_)    \n",
    "      - 7.6.1.2. [标量/向量-一阶导数（得向量）](#toc7_6_1_2_)    \n",
    "      - 7.6.1.3. [向量/向量-一阶导数（得矩阵）](#toc7_6_1_3_)    \n",
    "      - 7.6.1.4. [求高阶导数](#toc7_6_1_4_)    \n",
    "    - 7.6.2. [一个简单的例子](#toc7_6_2_)    \n",
    "    - 7.6.3. [计算另一个](#toc7_6_3_)    \n",
    "    - 7.6.4. [非标量变量的反向传播](#toc7_6_4_)    \n",
    "    - 7.6.5. [分离计算](#toc7_6_5_)    \n",
    "    - 7.6.6. [Python控制流的梯度计算](#toc7_6_6_)    \n",
    "  - 7.7. [概率论](#toc7_7_)    \n",
    "- 8. [神经网络-训练八股](#toc8_)    \n",
    "  - 8.1. [现线性回归模型于训练过程-从零开始](#toc8_1_)    \n",
    "    - 8.1.1. [虚拟出数据](#toc8_1_1_)    \n",
    "    - 8.1.2. [读取数据](#toc8_1_2_)    \n",
    "    - 8.1.3. [初始化模型参数](#toc8_1_3_)    \n",
    "    - 8.1.4. [定义模型](#toc8_1_4_)    \n",
    "    - 8.1.5. [定义损失函数](#toc8_1_5_)    \n",
    "    - 8.1.6. [定义优化算法](#toc8_1_6_)    \n",
    "    - 8.1.7. [训练](#toc8_1_7_)    \n",
    "  - 8.2. [现线性回归模型于训练过程-简洁实现](#toc8_2_)    \n",
    "    - 8.2.1. [虚拟数据](#toc8_2_1_)    \n",
    "    - 8.2.2. [读取数据](#toc8_2_2_)    \n",
    "    - 8.2.3. [定义模型](#toc8_2_3_)    \n",
    "    - 8.2.4. [初始化模型参数](#toc8_2_4_)    \n",
    "    - 8.2.5. [定义损失函数](#toc8_2_5_)    \n",
    "    - 8.2.6. [定义优化算法](#toc8_2_6_)    \n",
    "    - 8.2.7. [训练](#toc8_2_7_)    \n",
    "    - 8.2.8. [参数保存](#toc8_2_8_)    \n",
    "    - 8.2.9. [重载](#toc8_2_9_)    \n",
    "  - 8.3. [专题-模型定义（计算预测值）](#toc8_3_)    \n",
    "    - 8.3.1. [torch.nn模块](#toc8_3_1_)    \n",
    "    - 8.3.2. [自定义-块](#toc8_3_2_)    \n",
    "      - 8.3.2.1. [自定义块](#toc8_3_2_1_)    \n",
    "      - 8.3.2.2. [顺序块](#toc8_3_2_2_)    \n",
    "      - 8.3.2.3. [效率](#toc8_3_2_3_)    \n",
    "    - 8.3.3. [参数管理](#toc8_3_3_)    \n",
    "      - 8.3.3.1. [参数访问](#toc8_3_3_1_)    \n",
    "      - 8.3.3.2. [参数初始化](#toc8_3_3_2_)    \n",
    "        - 8.3.3.2.1. [内置初始化](#toc8_3_3_2_1_)    \n",
    "        - 8.3.3.2.2. [自定义初始化](#toc8_3_3_2_2_)    \n",
    "        - 8.3.3.2.3. [参数绑定](#toc8_3_3_2_3_)    \n",
    "    - 8.3.4. [自定义-层](#toc8_3_4_)    \n",
    "      - 8.3.4.1. [不带参数的层](#toc8_3_4_1_)    \n",
    "      - 8.3.4.2. [带参数的层](#toc8_3_4_2_)    \n",
    "  - 8.4. [专题-损失函数](#toc8_4_)    \n",
    "    - 8.4.1. [均方误差](#toc8_4_1_)    \n",
    "    - 8.4.2. [交叉熵](#toc8_4_2_)    \n",
    "    - 8.4.3. [自定义](#toc8_4_3_)    \n",
    "  - 8.5. [专题-反向传播（求梯度）](#toc8_5_)    \n",
    "  - 8.6. [专题-更新权重（优化算法）](#toc8_6_)    \n",
    "    - 8.6.1. [小批量梯度下降（SGD）](#toc8_6_1_)    \n",
    "    - 8.6.2. [adam](#toc8_6_2_)    \n",
    "    - 8.6.3. [RMSprop](#toc8_6_3_)    \n",
    "  - 8.7. [专题-训练](#toc8_7_)    \n",
    "    - 8.7.1. [开始训练](#toc8_7_1_)    \n",
    "    - 8.7.2. [自己探索](#toc8_7_2_)    \n",
    "      - 8.7.2.1. [lr的影响](#toc8_7_2_1_)    \n",
    "      - 8.7.2.2. [不同模型的效率](#toc8_7_2_2_)    \n",
    "    - 8.7.3. [K折交叉验证](#toc8_7_3_)    \n",
    "  - 8.8. [可视化训练过程](#toc8_8_)    \n",
    "- 9. [在 GPU 上训练](#toc9_)    \n",
    "  - 9.1. [查看GPU配置](#toc9_1_)    \n",
    "  - 9.2. [单机单卡（GPU）](#toc9_2_)    \n",
    "  - 9.3. [单机多卡（GPU）](#toc9_3_)    \n",
    "    - 9.3.1. [DP](#toc9_3_1_)    \n",
    "    - 9.3.2. [DDP](#toc9_3_2_)    \n",
    "      - 9.3.2.1. [在colab上测试可用](#toc9_3_2_1_)    \n",
    "  - 9.4. [多机多卡（GPU）- 分布式训练](#toc9_4_)    \n",
    "- 10. [模型和参数的保存与加载](#toc10_)    \n",
    "  - 10.1. [加载和保存-张量](#toc10_1_)    \n",
    "  - 10.2. [加载和保存-模型参数](#toc10_2_)    \n",
    "- 11. [神经网络类型](#toc11_)    \n",
    "  - 11.1. [CNN](#toc11_1_)    \n",
    "    - 11.1.1. [概述](#toc11_1_1_)    \n",
    "    - 11.1.2. [简单CNN](#toc11_1_2_)    \n",
    "      - 11.1.2.1. [从头实现](#toc11_1_2_1_)    \n",
    "        - 11.1.2.1.1. [卷积计算过程](#toc11_1_2_1_1_)    \n",
    "        - 11.1.2.1.2. [从头卷积层](#toc11_1_2_1_2_)    \n",
    "      - 11.1.2.2. [简洁实现](#toc11_1_2_2_)    \n",
    "      - 11.1.2.3. [填充和步幅](#toc11_1_2_3_)    \n",
    "      - 11.1.2.4. [多输入和多输出通道](#toc11_1_2_4_)    \n",
    "      - 11.1.2.5. [Pooling (汇聚层)](#toc11_1_2_5_)    \n",
    "        - 11.1.2.5.1. [平均Pooling](#toc11_1_2_5_1_)    \n",
    "        - 11.1.2.5.2. [最大Pooling](#toc11_1_2_5_2_)    \n",
    "    - 11.1.3. [LeNet](#toc11_1_3_)    \n",
    "    - 11.1.4. [AlexNet](#toc11_1_4_)    \n",
    "    - 11.1.5. [VGG](#toc11_1_5_)    \n",
    "    - 11.1.6. [NiN](#toc11_1_6_)    \n",
    "    - 11.1.7. [GoogLeNet](#toc11_1_7_)    \n",
    "    - 11.1.8. [批量规范化](#toc11_1_8_)    \n",
    "    - 11.1.9. [ResNet](#toc11_1_9_)    \n",
    "      - 11.1.9.1. [从头实现](#toc11_1_9_1_)    \n",
    "  - 11.2. [序列数据](#toc11_2_)    \n",
    "    - 11.2.1. [什么是序列](#toc11_2_1_)    \n",
    "    - 11.2.2. [语言模型](#toc11_2_2_)    \n",
    "    - 11.2.3. [文本预处理](#toc11_2_3_)    \n",
    "      - 11.2.3.1. [下载《Time machine》并读取数据](#toc11_2_3_1_)    \n",
    "      - 11.2.3.2. [词元化（Token）](#toc11_2_3_2_)    \n",
    "      - 11.2.3.3. [词表（vocab）](#toc11_2_3_3_)    \n",
    "      - 11.2.3.4. [整合所有功能](#toc11_2_3_4_)    \n",
    "    - 11.2.4. [语言模型数据集](#toc11_2_4_)    \n",
    "      - 11.2.4.1. [顺序采样](#toc11_2_4_1_)    \n",
    "      - 11.2.4.2. [随机采样](#toc11_2_4_2_)    \n",
    "      - 11.2.4.3. [包装](#toc11_2_4_3_)    \n",
    "  - 11.3. [RNN](#toc11_3_)    \n",
    "    - 11.3.1. [RNN-循环神经网络原理](#toc11_3_1_)    \n",
    "      - 11.3.1.1. [从头实现网络](#toc11_3_1_1_)    \n",
    "      - 11.3.1.2. [简洁实现](#toc11_3_1_2_)    \n",
    "      - 11.3.1.3. [训练和预测](#toc11_3_1_3_)    \n",
    "      - 11.3.1.4. [深层RNN](#toc11_3_1_4_)    \n",
    "      - 11.3.1.5. [双向RNN](#toc11_3_1_5_)    \n",
    "    - 11.3.2. [GRU](#toc11_3_2_)    \n",
    "      - 11.3.2.1. [从头实现](#toc11_3_2_1_)    \n",
    "      - 11.3.2.2. [简洁实现](#toc11_3_2_2_)    \n",
    "    - 11.3.3. [LSTM](#toc11_3_3_)    \n",
    "      - 11.3.3.1. [从头实现](#toc11_3_3_1_)    \n",
    "      - 11.3.3.2. [简洁实现](#toc11_3_3_2_)    \n",
    "    - 11.3.4. [Encoder-Decoder框架](#toc11_3_4_)    \n",
    "      - 11.3.4.1. [Encoder部分](#toc11_3_4_1_)    \n",
    "      - 11.3.4.2. [Decoder部分](#toc11_3_4_2_)    \n",
    "      - 11.3.4.3. [Encoder-Decoder（合并编码器和解码器）](#toc11_3_4_3_)    \n",
    "    - 11.3.5. [seq2seq (Sequence to sequence learning)](#toc11_3_5_)    \n",
    "      - 11.3.5.1. [简洁实现](#toc11_3_5_1_)    \n",
    "  - 11.4. [Attention](#toc11_4_)    \n",
    "    - 11.4.1. [非参数注意力汇聚（Attention Pooling）](#toc11_4_1_)    \n",
    "    - 11.4.2. [参数注意力汇聚（Attention Pooling）](#toc11_4_2_)    \n",
    "    - 11.4.3. [注意力分数函数](#toc11_4_3_)    \n",
    "      - 11.4.3.1. [加性注意力](#toc11_4_3_1_)    \n",
    "      - 11.4.3.2. [缩放点积注意力](#toc11_4_3_2_)    \n",
    "    - 11.4.4. [自注意力机制](#toc11_4_4_)    \n",
    "    - 11.4.5. [多头注意力机制](#toc11_4_5_)    \n",
    "    - 11.4.6. [attention-seq2seq](#toc11_4_6_)    \n",
    "    - 11.4.7. [Transformer](#toc11_4_7_)    \n",
    "      - 11.4.7.1. [位置编码](#toc11_4_7_1_)    \n",
    "      - 11.4.7.2. [Test](#toc11_4_7_2_)    \n",
    "      - 11.4.7.3. [基于Attention的Seq2Seq网络](#toc11_4_7_3_)    \n",
    "    - 11.4.8. [BERT](#toc11_4_8_)    \n",
    "    - 11.4.9. [GPT](#toc11_4_9_)    \n",
    "- 12. [炼丹心得](#toc12_)    \n",
    "  - 12.1. [关于改变形状](#toc12_1_)    \n",
    "  - 12.2. [关于调参](#toc12_2_)    \n",
    "  - 12.3. [模型选择](#toc12_3_)    \n",
    "  - 12.4. [one-hot](#toc12_4_)    \n",
    "  - 12.5. [embedding](#toc12_5_)    \n",
    "  - 12.6. [BN和LN](#toc12_6_)    \n",
    "  - 12.7. [MLP、FC、FNN、CNN、RNN](#toc12_7_)    \n",
    "  - 12.8. [机器学习](#toc12_8_)    \n",
    "- 13. [迁移学习-Transfer learning](#toc13_)    \n",
    "  - 13.1. [Fine-tuning](#toc13_1_)    \n",
    "  - 13.2. [torchvision的应用案例](#toc13_2_)    \n",
    "  - 13.3. [迁移学习案例](#toc13_3_)    \n",
    "- 14. [PyTorch lightning训练框架](#toc14_)    \n",
    "  - 14.1. [Data.py](#toc14_1_)    \n",
    "  - 14.2. [Model.py](#toc14_2_)    \n",
    "  - 14.3. [ModelWrapper.py](#toc14_3_)    \n",
    "    - 14.3.1. [Training and vlidation](#toc14_3_1_)    \n",
    "    - 14.3.2. [Validation](#toc14_3_2_)    \n",
    "    - 14.3.3. [Test](#toc14_3_3_)    \n",
    "    - 14.3.4. [Prediction](#toc14_3_4_)    \n",
    "      - 14.3.4.1. [调用PyTorch lightning自身Trainer的predict](#toc14_3_4_1_)    \n",
    "      - 14.3.4.2. [加载权重](#toc14_3_4_2_)    \n",
    "      - 14.3.4.3. [提取权重后加载至纯PyTorch模型](#toc14_3_4_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[概述](#toc0_)\n",
    "写这本书的主要目的是作为学些过程中知识的总结、归纳和反思。作为一个非科班出生的生物人，仅凭着热爱开始了自学深度学习这条路，前路漫漫不敢想，也不曾觉着以后能端这碗饭。只是，羡慕网上像智慧君、李沐这样的人，能够从事如此炫酷的工作，能把自己的热爱开发成一生从事的职业。仔细想想如果自己不做点什么或是不为此努力点什么，就觉得坐立不、安难以入眠。同时深知，这个过程会是无比艰辛，在百无聊赖之际，记录学习的过程或许会是一种苦中作乐的方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id='toc2_'></a>[环境配置](#toc0_)\n",
    "\n",
    "- [PyTorch教程](https://pytorch.org/)\n",
    "\n",
    "- [PyTorch lightning教程](https://lightning.ai/docs/pytorch/stable/)\n",
    "\n",
    "- 尽量用conda配置环境，不要conda和pip混搭。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment \n",
    "# and entry the environment\n",
    "conda create -n pytorch -y && conda activate pytorch\n",
    "\n",
    "# Install ipykernel and related packages via conda\n",
    "conda install ipykernel matplotlib pandas seaborn -y\n",
    "\n",
    "# Install PyTorch\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia\n",
    "\n",
    "# Instll PyTorch lightning\n",
    "conda install lightning -c conda-forge -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id='toc3_'></a>[utils](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. <a id='toc3_1_'></a>[代码稳定性](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "\n",
    "# Function for setting the seed\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():  # GPU operation have separate seed\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.2. <a id='toc3_2_'></a>[计时器](#toc0_)\n",
    "\n",
    "* 自定义的一些使用的脚本。\n",
    "```sehll\n",
    "    __init__(self) # 初始化实例时就会执行\n",
    "    __call__(self) # 再次调用时，自动执行\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 0.03024911880493164 s\n",
      "⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡ \n",
      "GPU time: 0.00044s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "class cpuTimer():\n",
    "    '''一个计时器'''\n",
    "    def __init__(self):\n",
    "        '''初始化时候自动执行'''\n",
    "        self.start = time.time()\n",
    "\n",
    "    def __call__(self):\n",
    "        '''再次调用该对象时，会自动执行'''\n",
    "        self.stop = time.time()\n",
    "        seconds = self.stop - self.start\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        print('='*20, '\\n', f\"Total：\\n {days} d \\n {hours} h \\n {minutes} m \\n {remaining_seconds} s\")\n",
    "        \n",
    "# Tiemr使用\n",
    "timer_on_cpu = cpuTimer()\n",
    "for i in range(3):\n",
    "    time.sleep(0.01)\n",
    "timer_on_cpu()\n",
    "\n",
    "class gpuTimer():\n",
    "    def __init__(self):\n",
    "        # CUDA is asynchronous, so we need to use different timing functions\n",
    "        self.start = torch.cuda.Event(enable_timing=True)\n",
    "        self.end = torch.cuda.Event(enable_timing=True)\n",
    "        self.start.record()\n",
    "\n",
    "    def __call__(self):\n",
    "        self.end.record()\n",
    "        torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
    "        print(\"⚡\"*20, f\"\\nGPU time: {0.001 * self.start.elapsed_time(self.end):6.5f}s\")  # Milliseconds to seconds\n",
    "\n",
    "# Demo for Timer on GPU devices\n",
    "timer_on_gpu = gpuTimer()\n",
    "a = torch.arange(45).reshape(3, 3, 5)\n",
    "b = torch.arange(45).reshape(3, 5, 3)\n",
    "c = torch.bmm(a, b)\n",
    "timer_on_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. <a id='toc3_3_'></a>[训练统计](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self):\n",
    "        self.start = 0\n",
    "\n",
    "    def __call__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. <a id='toc3_4_'></a>[比较numpy和pytorch](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a = np.random.rand(1000, 1000)\n",
    "b = np.random.rand(1000, 1000)\n",
    "\n",
    "at = torch.Tensor(a).to('cpu')\n",
    "bt = torch.Tensor(b).to('cpu')\n",
    "\n",
    "at_gpu = torch.Tensor(a).to('cuda:0')\n",
    "bt_gpu = torch.Tensor(b).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.28 ms ± 12.7 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a + b   # On cpu via numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 μs ± 1.81 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit at + bt # On cpu via PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.00024454399943351745 s\n"
     ]
    }
   ],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "stop = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "at_gpu + bt_gpu\n",
    "stop.record()\n",
    "\n",
    "# Waits for everything to finish running\n",
    "torch.cuda.synchronize()\n",
    "print(f'Time: {0.001 * start.elapsed_time(stop)} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id='toc4_'></a>[安装GPU驱动](#toc0_)\n",
    "\n",
    "- 以CentOS8安装NVIDIA Tesla A100为例；\n",
    "\n",
    "- 下载CUDA Toolkit和CuDNN，需要注意cudnn的版本必须与cuda的版本相匹配：\n",
    "\n",
    "    - 1.NVIDIA Driver：`NVIDIA驱动是NVIDIA显卡的驱动程序，它是CUDA和CuDNN的前提条件。显卡驱动下载地址：https://www.nvidia.com/Download/index.aspx`\n",
    "\n",
    "    - 2.CUDA Toolkit：`CUDA Toolkit是一个开发工具包，其中包含了CUDA编译器、IDE、调试器等工具，以及CUDA程序所需的各种库文件和头文件。CUDA Toolkit还包括NVIDIA驱动程序，但不包括CuDNN1，每个版本的CUDA Toolkit 都对应一个最低版本的显卡驱动版本（CUDA Driver）。`\n",
    "\n",
    "    - 3.NVCC：`其实就是CUDA的编译器,可以从CUDA Toolkit的/bin目录中获取,类似于gcc就是c语言的编译器。`\n",
    "\n",
    "    - 4.CUDA Deep Neural Network (cuDNN)：`CuDNN是NVIDIA提供的一个深度神经网络加速库，它包含了一系列高性能的基本函数和算法，用于加速深度学习任务的计算。CuDNN需要与CUDA Toolkit一起使用，以优化深度学习任务。`\n",
    "    \n",
    "## 4.1. <a id='toc4_1_'></a>[安装策略](#toc0_)\n",
    "\n",
    "- 方式一 `全局驱动，各自cuda`：\n",
    "    - `只安装NVIDIA Tesla A100的driver，每个用户自己利用conda安装CUDA Toolkit、cuDNN和对应的Pytorch版本（推荐），但是得注意选择兼容型号。（推荐）`\n",
    "\n",
    "- 方式二 `全局驱动，全局cuda`：\n",
    "    - `安装Driver、CUDA Toolkit (全局安装)`\n",
    "    \n",
    "- 方式三 `docker`：\n",
    "    - `安装Driver、NVIDIA docker (docker虚拟容器)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. <a id='toc4_2_'></a>[首先确认内核版本和发行版本，再确认显卡型号](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "echo 查看linux内核版本、架构\n",
    "uname -a\n",
    "# Linux 135.91.205.202.cau.edu.cn 4.18.0-147.el8.x86_64 #1 SMP Wed Dec 4 21:51:45 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\n",
    "# x86_64\n",
    "\n",
    "echo 发行版本\n",
    "cat /etc/redhat-release\n",
    "# CentOS Linux release 8.1.1911 (Core)\n",
    "# CentOS\n",
    "\n",
    "echo 显卡型号 （硬件层面）\n",
    "lspci | grep -i nvidia\n",
    "# 04:00.0 3D controller: NVIDIA Corporation GK208M [GeForce GT 730M] (rev a1)\n",
    "\n",
    "echo 验证系统是否安装gcc编译器\n",
    "gcc --version\n",
    "\n",
    "sudo yum install kernel-devel-$(uname -r) kernel-headers-$(uname -r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. <a id='toc4_3_'></a>[安装驱动-CUDA Driver](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. <a id='toc4_3_1_'></a>[下载CUDA Driver](#toc0_)\n",
    "\n",
    "![image.png](attachment:image.png) \n",
    "\n",
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 从NVIDIA官网下辖\n",
    "# https://www.nvidia.cn/Download/index.aspx?lang=cn\n",
    "\n",
    "# 2. 通过dnf search nvidia*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. <a id='toc4_3_2_'></a>[禁用nouveau](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 貌似在centos8上默认就禁用了，我没改，直接查看了lsmod | grep nouveau命令，发现没有输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3. <a id='toc4_3_3_'></a>[安装CUDA Driver](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'chmod' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n",
      "'sudo' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!chmod a+x *.run\n",
    "!sudo ./*.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4. <a id='toc4_3_4_'></a>[查看显卡是否安装成功](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.5. <a id='toc4_3_5_'></a>[查看nvcc](#toc0_)\n",
    "```shell\n",
    "nvcc只是CUDA Toolkit中的一个软件。此时，只是安装了驱动程序，没有安装CUDA Toolkit，所以无法查看nvcc。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvcc' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. <a id='toc4_4_'></a>[CUDA Toolkit和CuDNN](#toc0_)\n",
    "```shell\n",
    "不推荐一开始作为root为Linux全局配置CUDA Toolkit，每个用户和软件使用的CUDA Toolkit版本可能不一样。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1. <a id='toc4_4_1_'></a>[下载对应的CUDA Toolkit版本](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc -V # 查看是否安装好CUDA Toolkit\n",
    "\n",
    "wget https://us.download.nvidia.cn/tesla/535.129.03/NVIDIA-Linux-x86_64-535.129.03.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2. <a id='toc4_4_2_'></a>[安装CUDA Toolkit](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# 卸载之前安装的cuda\n",
    "sudo dnf remove nvidia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "chmod +x NVIDIA-Linux-x86_64-535.129.03.run\n",
    "sudo sh NVIDIA-Linux-x86_64-535.129.03.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3. <a id='toc4_4_3_'></a>[下载对应的CuDNN](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://link.zhihu.com/?target=https%3A//developer.nvidia.com/rdp/cudnn-download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4. <a id='toc4_4_4_'></a>[安装CuDNN](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. <a id='toc4_5_'></a>[安装对应版本的Pytorch](#toc0_)\n",
    "```shell\n",
    "在Pytorch的官网进行查询，按照条件检索符合要求的软件版本，最主要的是对应的cuda版本号。\n",
    "```\n",
    "[https://pytorch.org/](https://pytorch.org/)\n",
    "\n",
    "![PyTorch](./Pytorch_Pictures/Install_PyTorch/PyTorch_website.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# https://pytorch.org/\n",
    "# CUDA 12.1\n",
    "conda create -n pytorch-gpu -y\n",
    "conda activate pytorch-gpu \n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia # CUDA 12.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6. <a id='toc4_6_'></a>[推荐A100](#toc0_)\n",
    "\n",
    "- 全局A100驱动\n",
    "\n",
    "- conda下cuda toolkit、pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enviroment\n",
    "conda create -n pytorch-gpu \n",
    "\n",
    "# activate enviroment\n",
    "conda activate pytorch-gpu \n",
    "\n",
    "# install cuda12.1\n",
    "conda install cuda=12.1 -y \n",
    "\n",
    "# pip3 install torch (GPU version)\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7. <a id='toc4_7_'></a>[GPU测试程序](#toc0_)\n",
    "### 4.7.1. <a id='toc4_7_1_'></a>[测试单机单卡GPU性能](#toc0_)\n",
    "```shell\n",
    "net.to('cuda:0')\n",
    "x_gpu = x.to('cuda:0')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Runing on cpu\n",
      "====================================================================================================\n",
      "epoch 1/10: train_loss=1.5761462450027466, train_acc=90.3499984741211, test_acc=90.58000183105469\n",
      "epoch 2/10: train_loss=1.5509774684906006, train_acc=92.18000030517578, test_acc=92.25\n",
      "epoch 3/10: train_loss=1.531611442565918, train_acc=93.84666442871094, test_acc=93.66000366210938\n",
      "epoch 4/10: train_loss=1.5226444005966187, train_acc=94.68167114257812, test_acc=94.41000366210938\n",
      "epoch 5/10: train_loss=1.5157856941223145, train_acc=95.25333404541016, test_acc=94.91000366210938\n",
      "epoch 6/10: train_loss=1.5095164775848389, train_acc=95.75333404541016, test_acc=95.3800048828125\n",
      "epoch 7/10: train_loss=1.5046296119689941, train_acc=96.23666381835938, test_acc=95.6500015258789\n",
      "epoch 8/10: train_loss=1.501118540763855, train_acc=96.57499694824219, test_acc=96.0300064086914\n",
      "epoch 9/10: train_loss=1.4973342418670654, train_acc=96.92333221435547, test_acc=96.4000015258789\n",
      "epoch 10/10: train_loss=1.4947611093521118, train_acc=97.15833282470703, test_acc=96.4800033569336\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 39.68875694274902 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor(), \n",
    "        #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "        #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True\n",
    ")\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 10), nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                         # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)                          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)                # 计算loss\n",
    "            loss.backward()                         # 计算梯度\n",
    "            opt.step()                              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.2. <a id='toc4_7_2_'></a>[测试单机多卡GPU性能](#toc0_)\n",
    "```shell\n",
    "torch.nn.DataParallel()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Runing on cpu\n",
      "====================================================================================================\n",
      "epoch 1/10: train_loss=1.629683494567871, train_acc=84.03166198730469, test_acc=84.69000244140625\n",
      "epoch 2/10: train_loss=1.5497328042984009, train_acc=92.23500061035156, test_acc=92.5199966430664\n",
      "epoch 3/10: train_loss=1.5344191789627075, train_acc=93.5566635131836, test_acc=93.31999969482422\n",
      "epoch 4/10: train_loss=1.523071050643921, train_acc=94.54167175292969, test_acc=94.29000091552734\n",
      "epoch 5/10: train_loss=1.5164700746536255, train_acc=95.11666870117188, test_acc=94.76000213623047\n",
      "epoch 6/10: train_loss=1.5110586881637573, train_acc=95.63500213623047, test_acc=95.20000457763672\n",
      "epoch 7/10: train_loss=1.505732774734497, train_acc=96.13500213623047, test_acc=95.62000274658203\n",
      "epoch 8/10: train_loss=1.5016632080078125, train_acc=96.53666687011719, test_acc=95.84000396728516\n",
      "epoch 9/10: train_loss=1.5003046989440918, train_acc=96.70500183105469, test_acc=95.97000122070312\n",
      "epoch 10/10: train_loss=1.494889736175537, train_acc=97.18833923339844, test_acc=96.36000061035156\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 31.455957412719727 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True\n",
    ")\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 10), nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net = nn.DataParallel(module=net)\n",
    "    net = net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = [ 'cpu' if not torch.cuda.is_available() else ]\n",
    "device = [f'cuda:{i}' for i in range(torch.cuda.device_count())] if torch.cuda.is_available() else ['cpu']\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.3. <a id='toc4_7_3_'></a>[GPU burn压力测试](#toc0_)\n",
    "```shell\n",
    "李沐在装机配置后，进行GPU压力测试所用的程序为GPU_burn（可从github上下载）\n",
    "```\n",
    "\n",
    "- gpu_burn: \n",
    "  - github地址：`git clone https://github.com/wilicc/gpu-burn.git`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# git clone:\n",
    "git clone https://github.com/wilicc/gpu-burn.git\n",
    "\n",
    "cd gpu-burn\n",
    "\n",
    "# make \n",
    "make\n",
    "\n",
    "# 或\n",
    "# make CUDAPATH=~/minicnoda3/pytorch-gpu/\n",
    "\n",
    "# help\n",
    "gpu_burn --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# 2h * 60min * 60s = 7200s with tensor core (avaliable)\n",
    "gpu_burn -tc $(( 3 * 24 * 60 * 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. <a id='toc5_'></a>[Pytorch模块介绍](#toc0_)\n",
    "## 5.1. <a id='toc5_1_'></a>[导入模块](#toc0_)\n",
    "\n",
    "* torchvision\n",
    "  * models\n",
    "  * datasets\n",
    "  * transforms\n",
    "  * utils\n",
    "* torch\n",
    "  * utils\n",
    "    * data            # 数据加载相关\n",
    "      * TensorDataset\n",
    "      * Dataset\n",
    "      * DataLoader\n",
    "  * nn\n",
    "    * functional\n",
    "    * Sequential\n",
    "    * DataParallel\n",
    "    * Linear\n",
    "    * Softmax\n",
    "  * optim\n",
    "    * SGD\n",
    "    * Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version:  2.4.0\n",
      "torchvision version: 0.19.0\n"
     ]
    }
   ],
   "source": [
    "# 现成的数据库\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "\n",
    "import torch\n",
    "\n",
    "# 数据加载\n",
    "import torch.utils.data \n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "# 神经网络结构\n",
    "import torch.nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import torch.nn.DataParallel\n",
    "from torch.nn import DataParallel\n",
    "import torch.distributed as dist\n",
    "\n",
    "# 优化器\n",
    "import torch.optim \n",
    "\n",
    "print('pytorch version: ', torch.__version__)\n",
    "print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. <a id='toc6_'></a>[数据封装和加载](#toc0_)\n",
    "\n",
    "PyTorch为我们提供的`Dataset`和`DataLoader`类分别负责可被Pytorhc使用的数据集的`创建`以及向训练`传递数据`的任务。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. <a id='toc6_1_'></a>[直接加载torchvison.datasets获得Dataset](#toc0_)\n",
    "\n",
    "* `tochvision`主要处理图像数据，包含一些常用的数据集、模型、转换函数等。  \n",
    "* torchvision独立于PyTorch，需要专门安装。\n",
    "\n",
    "  * torchvision.`models`: 提供深度学习中各种经典的网络结构、预训练好的模型，如：Alex-Net、VGG、ResNet、Inception等。\n",
    "\n",
    "  * torchvision.`datasets`：提供常用的数据集，设计上继承 torch.utils.data.Dataset，主要包括：MNIST、CIFAR10/100、ImageNet、COCO等。\n",
    "\n",
    "  * torchvision.`transforms`：提供常用的数据预处理操作，主要包括对Tensor及PIL Image对象的操作。\n",
    "  \n",
    "  * torchvision.`utils`：工具类，如保存张量作为图像到磁盘，给一个小批量创建一个图像网格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torchvision.datasets.mnist.FashionMNIST,\n",
       " torchvision.datasets.mnist.FashionMNIST)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "dbs = './Pytorch_datasets/'\n",
    "\n",
    "trans = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),                  # PIL转换为tensor格式\n",
    "        torchvision.transforms.Normalize((0.5,), (1.0,))    # 标准化\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=trans, \n",
    "#   target_transform=False\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=trans, \n",
    "#   target_transform=False\n",
    ")\n",
    "type(train_dataset), type(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./Pytorch_datasets/\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5,), std=(1.0,))\n",
       "            ),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./Pytorch_datasets/\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5,), std=(1.0,))\n",
       "            ))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 封装成torch使用的dataset格式数据\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. <a id='toc6_2_'></a>[自定义数据集获得Dataset](#toc0_)\n",
    "### 6.2.1. <a id='toc6_2_1_'></a>[利用TensorDataset()封装成Dataset](#toc0_)\n",
    "\n",
    "- `TensorDataset`是一个现成的类，用于将数据表示为张量列表。\n",
    "\n",
    "- 如果你只是想创建一个包含输入特征和标签的数据集，可以直接使用 TensorDataset：\n",
    "\n",
    "  - `dataset = torch.utils.data.TensorDataset( input_features, labels )` # 按照下标顺序将input_features和labels值对应起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataset.TensorDataset,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x7f9030b56ab0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# 1. 自建数据集 (Tensor格式的数据)\n",
    "features = torch.tensor([i for i in range(1000)])\n",
    "labels = features * 2                               # labels = torch.mul(features, 2)\n",
    "\n",
    "# 2. 构建dataset数据集\n",
    "datasets = TensorDataset(features, labels) \n",
    "type(datasets), datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features0, labels0 = datasets[0] # 取第一个数据对\n",
    "features0, labels0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.__getitem__(0) # 同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(2))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[1] # 取第二个数据对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(2))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.__getitem__(1) # 同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.__len__()  # 数据对的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataloader.DataLoader,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f9030d214c0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_datasets = datasets\n",
    "\n",
    "# 3. 加载成batch数据\n",
    "data_iter = DataLoader(dataset=datasets, batch_size=256, shuffle=True, num_workers=3)\n",
    "type(data_iter), data_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2. <a id='toc6_2_2_'></a>[重载Dataset类](#toc0_)\n",
    "\n",
    "- `torch.utils.data.Dataset`是一个抽象类，用于定义新类型的自定义数据集。如果你想创建自己的数据集，可以继承这个类并实现以下方法：\n",
    "\n",
    "  - 重载`__init__(self, *args, **kwargs)`: 初始化方法，可以在其中加载你的数据；\n",
    "\n",
    "  - 重载`__len(self)__`: 返回数据集的长度；\n",
    "\n",
    "  - 重载`__getitem__(self, index)`: 根据索引返回数据集中的一个样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.MyData at 0x7f90308f7bc0>,\n",
       " (tensor(0), tensor(0)),\n",
       " (tensor(1), tensor(1)),\n",
       " (tensor(1), tensor(1)),\n",
       " (tensor(2), tensor(2)),\n",
       " (tensor(2), tensor(2)),\n",
       " 15)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1. 重载Dataset类\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, nums:int=15):\n",
    "        self.nums = nums\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nums\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        features = torch.arange(self.nums)\n",
    "        labels = torch.arange(self.nums)\n",
    "        return features[index], labels[index]\n",
    "\n",
    "# 2. 利用重载的Dataset创建数据集\n",
    "datasets = MyData()\n",
    "datasets, datasets[0], datasets[1], datasets.__getitem__(1), datasets[2], datasets.__getitem__(2), datasets.__len__()\n",
    "\n",
    "# 3. 利用DataLoader加载数据\n",
    "# data_iter = DataLoader(dataset=datasets, batch_size=256, shuffle=True, num_workers=3)\n",
    "# data_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3. <a id='toc6_2_3_'></a>[Pytoch.utils.data.Dataset类分析和总结](#toc0_)\n",
    "\n",
    "- 在PyTorch中数据的封装格式为torch.utils.data.Dataset类；\n",
    "\n",
    "- 第一种方式：直接加载`torchvision.datasets`中对应的数据库生成Dataset格式\n",
    "\n",
    "- 第二种方式：自定义\n",
    "  - 利用`Tensordataset(features, labels)`函数将features和labels配对并生成Dataset格式 (推荐，我觉得更加方便)\n",
    "  \n",
    "  - 重载`Dataset`类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. <a id='toc6_3_'></a>[数据加载-DataLoader()](#toc0_)\n",
    "- 1. 先将自制的数据集利用data.TensorDataset生成dataset；\n",
    "\n",
    "- 2. 再用data.DataLoader加载到dataset成最终可用的带有batch_size的格式，方便后续的训练\n",
    "\n",
    "- 3. 先测试以下数据加载的速度，必须比训练计算所耗的时间小，否则将降低训练效率；\n",
    "\n",
    "- 4. 当数据加载时间很长时可以预加载，缩短时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 加载torchvison数据集（格式化好的torch.utils.data.Dataset）\n",
    "train_iter = DataLoader(\n",
    "    dataset = my_datasets, \n",
    "    batch_size = 5, \n",
    "    shuffle = True,                # 打乱顺序\n",
    "    num_workers = 3                # 线程数\n",
    "    drop_last = False,             # 是否删除最后一个不是整数的batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataloader.DataLoader,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f90308f7770>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_iter), train_iter # 直接答应看不到内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机抽取: 1 [tensor([666, 761, 701, 637, 154]), tensor([1332, 1522, 1402, 1274,  308])]\n",
      "随机抽取: 2 [tensor([212,  58, 496, 383, 731]), tensor([ 424,  116,  992,  766, 1462])]\n",
      "随机抽取: 3 [tensor([641, 116, 414, 257, 748]), tensor([1282,  232,  828,  514, 1496])]\n",
      "随机抽取: 4 [tensor([507, 849, 451, 523, 613]), tensor([1014, 1698,  902, 1046, 1226])]\n",
      "随机抽取: 5 [tensor([422, 488, 671, 974, 195]), tensor([ 844,  976, 1342, 1948,  390])]\n",
      "随机抽取: 6 [tensor([258, 848, 583, 454, 328]), tensor([ 516, 1696, 1166,  908,  656])]\n",
      "随机抽取: 7 [tensor([ 73, 920, 288, 245, 486]), tensor([ 146, 1840,  576,  490,  972])]\n",
      "随机抽取: 8 [tensor([792, 152, 462,  71, 190]), tensor([1584,  304,  924,  142,  380])]\n",
      "随机抽取: 9 [tensor([599, 133,  26, 979, 789]), tensor([1198,  266,   52, 1958, 1578])]\n",
      "随机抽取: 10 [tensor([983, 301, 228, 236, 447]), tensor([1966,  602,  456,  472,  894])]\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, batch in enumerate(train_iter): # 小批量的batch_size数据\n",
    "    if batch_idx == 10:\n",
    "        break\n",
    "    print('随机抽取:', batch_idx+1, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1. <a id='toc6_3_1_'></a>[估计数据加载时间](#toc0_)\n",
    "\n",
    "估计加载数据所需时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 0.08644580841064453 s\n"
     ]
    }
   ],
   "source": [
    "# 读完一个epoch的一个batch，耗时\n",
    "timer = cpuTimer()\n",
    "for X, y in train_iter:\n",
    "    break \n",
    "timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 0.2713015079498291 s\n"
     ]
    }
   ],
   "source": [
    "# 读完一个epoch的所有batch，耗时\n",
    "timer = cpuTimer()\n",
    "for X, y in train_iter:\n",
    "    continue \n",
    "timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. <a id='toc7_'></a>[张量(Tensors)](#toc0_)\n",
    "## 7.1. <a id='toc7_1_'></a>[Tensors定义](#toc0_)\n",
    "\n",
    "* Pytorch 的一大作用就是可以代替 Numpy 库，所以首先介绍 Tensors ，也就是张量，它相当于 Numpy 的多维数组(ndarrays)。\n",
    "\n",
    "* 两者的区别就是：\n",
    "    * `数学或物理`概念：张量`Tensors`\n",
    "    \n",
    "    * `编程`概念：数组`Array`\n",
    "    \n",
    "* 总结\n",
    "\n",
    "|函数名称|注释|\n",
    "|:-|:-|\n",
    "|torch.tensor()|tensor|\n",
    "|torch.asarray()||\n",
    "|torch.from_numpy()|numpy2tensor|\n",
    "|torch.empty(size)|垃圾数|\n",
    "|torch.zeros(size)|0|\n",
    "|torch.ones(size)|1|\n",
    "|torch.rand(size)|随机数|\n",
    "|torch.randn(size)|标准正态分布|\n",
    "|torch.normal(mean,std,size)|正态分布|\n",
    "|torch.arange(start,end,step,size)|数组|\n",
    "|.reshape(size)|重塑|\n",
    "|.numpy()|转为numpy的ndarray|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor()\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.asarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asarray()\n",
    "\n",
    "x = torch.asarray([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.from_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]]),\n",
       " tensor([[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy转tensor, from_numpy()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(0, 15).reshape(5, 3)\n",
    "\n",
    "x, torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 2.0114e-25],\n",
       "        [3.0742e-41, 1.3127e-29, 3.0742e-41],\n",
       "        [9.2368e-10, 4.5761e-41, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty()\n",
    "\n",
    "torch.empty((5, 3), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zeros()\n",
    "\n",
    "torch.zeros(5, 3) # 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.ones()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ones()\n",
    "\n",
    "torch.ones((5, 3), dtype=torch.float32) # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.rand()，产生随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8833, 0.0454, 0.5669],\n",
       "        [0.2422, 0.8501, 0.7177],\n",
       "        [0.5687, 0.7171, 0.8636],\n",
       "        [0.3550, 0.5657, 0.5965],\n",
       "        [0.4050, 0.6776, 0.9841]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rand()\n",
    "\n",
    "torch.rand((5, 3), dtype=torch.float32) # 随机数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.randn()，标准正态分布随机数，产生正态分布随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7855, -0.0245, -0.9618, -1.4634, -0.2726],\n",
       "        [ 1.1404, -0.9721,  0.4194,  0.1732, -1.2649],\n",
       "        [ 0.0139,  1.0817, -2.1748,  0.5782, -1.0274]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randn()\n",
    "\n",
    "torch.randn((3, 5), dtype=torch.float32) # 标准正态分布随机数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.normal()，正态分布随机数，产生mean和std的size个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4510,  0.2798, -0.8032, -0.5851,  0.7675],\n",
       "        [ 2.0413,  1.1163, -0.1891,  0.9543,  0.6753],\n",
       "        [ 1.4002,  0.8864,  0.6356, -1.2399,  1.1891]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=0, std=1, size=(3, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arange()\n",
    "\n",
    "torch.arange(3) # 0, 1, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape()\n",
    "\n",
    "torch.arange(start=0, end=15, step=1).reshape(5, 3) # reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .numpy()，将tensor转化为numpy的ndarray格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14]]),\n",
       " array([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]], dtype=int64))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor转化为numpy\n",
    "\n",
    "x = torch.arange(start=0, end=15, step=1).reshape(5, 3)\n",
    "x, x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. <a id='toc7_2_'></a>[Tensors属性](#toc0_)\n",
    "\n",
    "|函数名称|注释|\n",
    "|:-|:-|\n",
    "|x.size()||\n",
    "|x.shape()||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0123, -1.3446,  0.6211, -0.9366, -0.1685],\n",
       "        [-0.1473,  0.0577, -0.5306, -1.7354, -0.6717],\n",
       "        [-2.4554, -0.3991, -0.5653, -0.6845,  0.2150]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.normal(mean=0, std=1, size=(3, 5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size() # shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. <a id='toc7_3_'></a>[Tensors操作](#toc0_)\n",
    "### 7.3.1. <a id='toc7_3_1_'></a>[索引和切片](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(15).reshape(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # 1行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1] # 2行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  3,  6,  9, 12])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0] # 1列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  4,  7, 10, 13])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1] # 2列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2. <a id='toc7_3_2_'></a>[修改维度](#toc0_)\n",
    "\n",
    "* 形状/维度：其实整个张量运算就是线性代数中的矩阵运算，所以最重要是明白`矩阵运算前后`的`形状/维度`。  \n",
    "\n",
    "* 高阶张量由若干低阶张量构成，如\n",
    "    * 结构为 (n, c, h, w)的 4 阶张量由 n 个结构为 (c, h, w) 的 3 阶张量构成，\n",
    "    * 结构为 (c, h, w)的 3 阶张量由 c 个结构为 (h, w) 的 2 阶张量构成，\n",
    "    * 结构为 (h, w)的 2 阶张量又由 h 个长度为 w 的 1 阶张量构成，h 为行数，w 为列数。\n",
    "\n",
    "* 修改形状/维度：reshape和view都是用来重塑tensor的shape的。view只适合对满足连续性条件（contiguous）的tensor进行操作，而reshape同时还可以对不满足连续性条件的tensor进行操作，具有更好的鲁棒性。view能干的reshape都能干，如果view不能干就可以用reshape来处理。\n",
    "\n",
    "- 维度`重组`：\n",
    "\n",
    "    - `.reshape()`\n",
    "\n",
    "    - `.view()`\n",
    "\n",
    "- 维度重排或转换或`挪动`：\n",
    "\n",
    "    - `permute()`\n",
    "\n",
    "    - `transpose()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.1. <a id='toc7_3_2_1_'></a>[reshape函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       " torch.Size([15]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(15)\n",
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14]]),\n",
       " torch.Size([3, 5]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape\n",
    "\n",
    "X.reshape(3, 5), X.reshape(3, 5).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.2. <a id='toc7_3_2_2_'></a>[view函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14]]),\n",
       " torch.Size([3, 5]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view\n",
    "\n",
    "X.view(3, 5), X.view(3, 5).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.3. <a id='toc7_3_2_3_'></a>[transpose函数](#toc0_)\n",
    "\n",
    "`transpose()`函数一次进行两个维度的交换，参数是 0, 1, 2, 3, … ，随着待转换张量的阶数上升参数越来越多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14]]),\n",
       " tensor([[ 0,  5, 10],\n",
       "         [ 1,  6, 11],\n",
       "         [ 2,  7, 12],\n",
       "         [ 3,  8, 13],\n",
       "         [ 4,  9, 14]]),\n",
       " tensor([[ 0,  5, 10],\n",
       "         [ 1,  6, 11],\n",
       "         [ 2,  7, 12],\n",
       "         [ 3,  8, 13],\n",
       "         [ 4,  9, 14]]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 阶张量，结构为 (h, w)，\n",
    "# 对应 transpose() 函数中的参数是 (0, 1) 两个索引，\n",
    "# 进行 transpose(0, 1) 操作就是在交换 h, w 两个维度，\n",
    "# 得到的结果与常见的矩阵转置相同。\n",
    "X = torch.arange(15).reshape(3, 5)\n",
    "X, X.transpose(0, 1), X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.4. <a id='toc7_3_2_4_'></a>[permute函数](#toc0_)\n",
    "\n",
    "`permute()`函数一次可以进行多个维度的交换或者可以成为维度重新排列，参数是 0, 1, 2, 3, … ，随着待转换张量的阶数上升参数越来越多，本质上可以理解为多个 transpose() 操作的叠加，因此理解 permute() 函数的关键在于理解 transpose() 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14]]),\n",
       " tensor([[ 0,  5, 10],\n",
       "         [ 1,  6, 11],\n",
       "         [ 2,  7, 12],\n",
       "         [ 3,  8, 13],\n",
       "         [ 4,  9, 14]]),\n",
       " tensor([[ 0,  5, 10],\n",
       "         [ 1,  6, 11],\n",
       "         [ 2,  7, 12],\n",
       "         [ 3,  8, 13],\n",
       "         [ 4,  9, 14]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(15).reshape(3, 5)\n",
    "X, X.permute(1, 0), X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. <a id='toc7_4_'></a>[线性代数运算](#toc0_)\n",
    "### 7.4.1. <a id='toc7_4_1_'></a>[数值运算](#toc0_)\n",
    "\n",
    "|操作|函数|\n",
    "|:-|:-|\n",
    "|+|torch.add(X, Y)|\n",
    "|-|torch.sub(X, Y)|\n",
    "|*|torch.mul(X, Y|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.],\n",
       "         [ 9., 10., 11.],\n",
       "         [12., 13., 14.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5, 3, dtype=torch.float32)\n",
    "y = torch.arange(0, 15, 1, dtype=torch.float32).reshape(5, 3)\n",
    "z = torch.arange(0, 15, 1, dtype=torch.float32).reshape(3, 5)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [10., 11., 12.],\n",
       "         [13., 14., 15.]]),\n",
       " tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [10., 11., 12.],\n",
       "         [13., 14., 15.]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y, torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.,   0.,  -1.],\n",
       "         [ -2.,  -3.,  -4.],\n",
       "         [ -5.,  -6.,  -7.],\n",
       "         [ -8.,  -9., -10.],\n",
       "         [-11., -12., -13.]]),\n",
       " tensor([[  1.,   0.,  -1.],\n",
       "         [ -2.,  -3.,  -4.],\n",
       "         [ -5.,  -6.,  -7.],\n",
       "         [ -8.,  -9., -10.],\n",
       "         [-11., -12., -13.]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - y, torch.sub(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * 3 # 数乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(x, 3) # 同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x, z) # 矩阵相乘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2. <a id='toc7_4_2_'></a>[哈达玛积](#toc0_)\n",
    "* 按照`元素`进行乘法\n",
    "* 乘前形状必须相同，乘后不改变形状\n",
    "* x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[ 0,  1,  4],\n",
       "         [ 9, 16, 25]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.arange(6).reshape(2, 3)\n",
    "x, x * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3. <a id='toc7_4_3_'></a>[点积（Dot Product）](#toc0_)\n",
    "* 按照元素进行乘法后相加\n",
    "* 乘前形状一样，乘后`标量`\n",
    "* `torch.dot(x, x)` # dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor([0, 1, 4]), tensor(5))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(3)\n",
    "x, x * x, torch.dot(x, x) # 打印， 哈德玛积， 点积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.4. <a id='toc7_4_4_'></a>[矩阵-向量积](#toc0_)\n",
    "* 矩阵乘法的特殊\n",
    "* 乘后`向量`\n",
    "* `torch.mv(A, x)` # matrix-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([4]), torch.Size([3]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "x = torch.ones(4, dtype=torch.float32)\n",
    "A.shape, x.shape, torch.mv(A, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]),)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * x).shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.5. <a id='toc7_4_5_'></a>[矩阵-矩阵积](#toc0_)\n",
    "* 乘后**矩阵**\n",
    "* `torch.matmul(X, Y)`  # 矩阵乘法，`支持广播`\n",
    "* `X @ Y`               # 同上\n",
    "* `torch.mm(X, Y)`      # 矩阵乘法，`不支持广播`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]),\n",
       " torch.Size([5, 3]),\n",
       " torch.Size([3, 3]),\n",
       " torch.Size([3, 3]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(15).reshape(3, 5)\n",
    "Y = torch.arange(15).reshape(5, 3)\n",
    "X.shape, Y.shape, (X @ Y).shape, torch.mm(X, Y).shape, torch.matmul(X, Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.6. <a id='toc7_4_6_'></a>[批量矩阵乘法](#toc0_)\n",
    "\n",
    "* A: (b x n x m) \n",
    "* B: (b x m x p)\n",
    "* `torch.bmm(A, B)`   # b x n x p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3, 5]), torch.Size([3, 5, 3]), torch.Size([3, 3, 3]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(45).reshape(3, 3, 5)\n",
    "Y = torch.arange(45).reshape(3, 5, 3)\n",
    "X.shape, Y.shape, torch.bmm(X, Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.7. <a id='toc7_4_7_'></a>[乘总结](#toc0_)\n",
    "\n",
    "参考PyTorch lightning 总结：[https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/01-introduction-to-pytorch.html](https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/01-introduction-to-pytorch.html)\n",
    "\n",
    "|乘法|函数|\n",
    "|:-|:-|\n",
    "|哈德玛积|A * B|\n",
    "|点积|dot(A, B)|\n",
    "|矩阵-向量|mv(A, x)|\n",
    "|矩阵-矩阵|matmul(A, B) 或  A @ B，同时mm(A, B)不支持广播|\n",
    "|批量矩阵乘法|`bmm(A, B)`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.8. <a id='toc7_4_8_'></a>[统计运算](#toc0_)\n",
    "\n",
    "|操作|注释|\n",
    "|:-|:-|\n",
    "|torch.mean()|取平均|\n",
    "|torch.median()||\n",
    "|torch.mode()||\n",
    "|torch.min()||\n",
    "|torch.max()||\n",
    "|torch.std()||\n",
    "|torch.var()||\n",
    "|torch.squar()||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(15, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.), tensor(7.))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x), x.mean() # 平均数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.), tensor(7.))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.median(x), x.median() # 中位数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x), x.min()   # 最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14.), tensor(14.))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), x.max()   # 最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.mode(\n",
       " values=tensor(0.),\n",
       " indices=tensor(0)),\n",
       " torch.return_types.mode(\n",
       " values=tensor(0.),\n",
       " indices=tensor(0)))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mode(x), x.mode() # 众数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.4721), tensor(4.4721))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(x), x.std()   # 标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(20.), tensor(20.))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.var(x), x.var()   # 方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. <a id='toc7_5_'></a>[Pytorch的计算图 和 自动微分 (autograd)](#toc0_)\n",
    "\n",
    "- PyTorch是动态图，即计算图的搭建和运算是同时的，随时可以输出结果；而TensorFlow是静态图。\n",
    "\n",
    "- 在pytorch的计算图里只有两种元素：`数据（tensor）`和 `运算（operation）`\n",
    "\n",
    "  - 运算包括了：加减乘除、开方、幂指对、三角函数等可求导运算\n",
    "\n",
    "  - 数据可分为：`叶子节点（leaf node`）和`非叶子节点`；\n",
    "    - 叶子节点：\n",
    "    - 非叶子节点：\n",
    "    - 叶子节点是用户创建的节点，不依赖其它节点；它们表现出来的区别在于`用y.backward()进行反向传播`结束之后，`非叶子节点的梯度会被释放掉`，只保留叶子节点的梯度，这样就节省了内存。如果想要保留非叶子节点的梯度，可以使用`retain_grad()`方法。\n",
    "\n",
    "- torch.tensor节点 具有如下属性：\n",
    "  - 查看 是否可以求导 `requires_grad`\n",
    "  - 查看 运算名称 `grad_fn`\n",
    "  - 查看 是否为叶子节点 `is_leaf`\n",
    "  - 查看 导数值 `grad`\n",
    "\n",
    "- 针对requires_grad属性，自己定义的叶子节点默认为False，而非叶子节点默认为True，神经网络中的权重默认为True。判断哪些节点是True/False的一个原则就是从你需要求导的叶子节点到loss节点之间是一条可求导的通路。\n",
    "\n",
    "---\n",
    "\n",
    "- PyTorch提供两种求梯度的方法：`backward()` 和 `torch.autograd.grad()` ，他们的区别在于前者是给叶子节点填充.grad字段，而后者是直接返回梯度给你，我会在后面举例说明。还需要知道y.backward()其实等同于`torch.autograd.backward(y)`。\n",
    "\n",
    "\n",
    "![PyTorch的计算图](./Pytorch_Pictures/PyTorch_graphacial_demo/graph.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.1. <a id='toc7_5_1_'></a>[反向传播 (backward)-批量求梯度，但未进行参数更新](#toc0_)\n",
    "\n",
    "计算`所有节点 (Tensor)` 的梯度并存储在节点的`grad属性中`，但未进行节点参数更新 (是优化函数干的事)。\n",
    "\n",
    "- `y.backward()` 或 `torch.autograd.backward(y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]], requires_grad=True),\n",
       " tensor([[ 1.1690,  1.1080, -1.3046, -0.0044, -1.4428],\n",
       "         [ 0.9029, -1.0754,  0.1783, -0.5008, -0.0571],\n",
       "         [ 1.5950, -0.4997, -0.5458,  0.8798, -0.9804]], requires_grad=True),\n",
       " tensor(15.6153, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.ones(size=(3, 5), dtype=torch.float32, requires_grad=True)       # 自定义需要存储梯度\n",
    "x2 = torch.randn(size=(3, 5), dtype=torch.float32, requires_grad=True)      # 默认是不存储梯度\n",
    "\n",
    "y = torch.add(x1**2, x2**3).sum()   # 应变量必须是标量\n",
    "\n",
    "x1, x2, y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 查看is_leaf属性\n",
    "x1.is_leaf, x2.is_leaf, y.is_leaf   \n",
    "# x1, x2是叶子节点，y不是叶子节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 查看requires_grad属性\n",
    "x1.requires_grad, x2.requires_grad, y.requires_grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, <SumBackward0 at 0x7fce06bff0d0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 查看grad_fn属性\n",
    "x1.grad_fn, x2.grad_fn, y.grad_fn   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32820/1085795512.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538439675/work/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  x1.grad, x2.grad, y.grad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 查看grad属性\n",
    "x1.grad, x2.grad, y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()\n",
    "# torch.autograd.backward(y)  # 同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32820/1085795512.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538439675/work/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  x1.grad, x2.grad, y.grad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]]),\n",
       " tensor([[4.0998e+00, 3.6832e+00, 5.1059e+00, 5.9216e-05, 6.2451e+00],\n",
       "         [2.4456e+00, 3.4693e+00, 9.5398e-02, 7.5255e-01, 9.7835e-03],\n",
       "         [7.6321e+00, 7.4899e-01, 8.9373e-01, 2.3219e+00, 2.8837e+00]]),\n",
       " None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 查看grad属性\n",
    "x1.grad, x2.grad, y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.2. <a id='toc7_5_2_'></a>[仅计算梯度 (求导计算)](#toc0_)\n",
    "\n",
    "和backward不同，torch.autograd.grad只是计算`应变量 (output)` 对`自变量 (input)`的`导数 (梯度)`；`应变量必须是标量`。\n",
    "\n",
    "- `torch.autograd.grad(output=y, input=x, retain_grad=False/True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.]],\n",
       " \n",
       "         [[3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.]],\n",
       " \n",
       "         [[3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.]]]),)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(size=(3, 3, 5), dtype=torch.float32, requires_grad=True) # 必须是float类型\n",
    "y = (x**3).sum()\n",
    "torch.autograd.grad(outputs=y, inputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6. <a id='toc7_6_'></a>[自动微积-autograd](#toc0_)\n",
    "```shell\n",
    "深度学习框架可以自动计算导数：\n",
    "```\n",
    "|操作|函数|\n",
    "|:-|:-|\n",
    "|1. 我们首先将梯度附加到想要对其计算偏导数的变量上，|x.requires_grad_(True)|\n",
    "|2. 然后记录目标值的计算，|y = x * x (grad_fn)|\n",
    "|3. 执行它的反向传播函数(求梯度)，|y.backward()|\n",
    "|4. 并访得到的梯度。|x.grad|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1. <a id='toc7_6_1_'></a>[自己探索](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6.1.1. <a id='toc7_6_1_1_'></a>[标量-一阶导数（得标量）](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2., requires_grad=True), tensor(4., grad_fn=<PowBackward0>))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2.0, dtype=torch.float32, requires_grad=True)  # 标量\n",
    "y = x**2                                                        # 标量\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为None\n",
    "x.grad, x.grad == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y对x进行求导\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为2 * 2 = 4\n",
    "x.grad                                                          # 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 2*x # y关于x的一阶导函数就是2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造新的关于x的函数：z = x**3\n",
    "z = x**2\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为：\n",
    "x.grad.zero_()\n",
    "x.grad # 应该为0才对，需要手动清零# x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z关于x求导\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为：\n",
    "x.grad # 应该为4，但是残留的4 + 本次的4 = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6.1.2. <a id='toc7_6_1_2_'></a>[标量/向量-一阶导数（得向量）](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0, dtype=torch.float32, requires_grad=True)  # 向量\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14., grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.dot(x, x)                                              # 标量\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad                                                          # 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 2*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6.1.3. <a id='toc7_6_1_3_'></a>[向量/向量-一阶导数（得矩阵）](#toc0_)\n",
    "\n",
    "- pytorch只能对标量/标量，标量/向量求导，`即x可以为标量也可以为向量，但是y必须为标量`\n",
    "\n",
    "- `只需要先将y转变为标量，对分别求导没影响的就是求和`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.arange(4, dtype=torch.float32, requires_grad=True)    # 向量\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = i ** 2                                                      # 向量\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h.backward()      # 报错\n",
    "h.sum().backward()  # 正常\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6.1.4. <a id='toc7_6_1_4_'></a>[求高阶导数](#toc0_)\n",
    "\n",
    "- 利用`torch.autograd.grad(outputs=y, inputs=x, create_grad=True)`\n",
    "\n",
    "- 保留计算图 (链表指针), `create_grad=True `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(12., grad_fn=<MulBackward0>),)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2, dtype=torch.float32, requires_grad=True)\n",
    "y = x**3\n",
    "grad1 = torch.autograd.grad(outputs=y, inputs=x, create_graph=True) # create_graph=True, 必须保留计算图才能进行后续的高阶导数计算\n",
    "grad1 # 3 * x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(12., grad_fn=<MulBackward0>),)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad2 = torch.autograd.grad(outputs=grad1, inputs=x, create_graph=True)\n",
    "grad2 # 6 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.),)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad3 = torch.autograd.grad(outputs=grad2, inputs=x)\n",
    "grad3 # 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2. <a id='toc7_6_2_'></a>[一个简单的例子](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在我们计算关于的梯度之前，需要一个地方来存储梯度。\n",
    "x.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)\n",
    "x.grad                  # 默认值是None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在计算。\n",
    "y = 2 * torch.dot(x, x)\n",
    "y                       # x是一个长度为4的向量，计算x和x的点积，得到了我们赋值给y的标量输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 接下来，通过调用反向传播函数来自动计算y关于x每个分量的梯度，并打印这些梯度。\n",
    "y.backward()            # [4x, 4x, 4x, 4x] 导函数\n",
    "x.grad                  # [4*0, 4*1, 4*2, 4*3] 导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x         # [4x, 4x, 4x, 4x] 导函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.3. <a id='toc7_6_3_'></a>[计算另一个](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值\n",
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor(6., grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.4. <a id='toc7_6_4_'></a>[非标量变量的反向传播](#toc0_)\n",
    "\n",
    "- 当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵。 \n",
    "\n",
    "- 对于高阶和高维的y和x，求导的结果可以是一个高阶张量。\n",
    "\n",
    "- 然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括深度学习中）， 但当调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的**偏导数之和**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n",
    "# 本例只想求偏导数的和，所以传递一个1的梯度是合适的\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "# 等价于y.backward(torch.ones(len(x)))\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x * x \n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0.]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad, x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([0., 2., 4., 6.]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum().backward(), x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.5. <a id='toc7_6_5_'></a>[分离计算](#toc0_)\n",
    "\n",
    "- 有时，我们希望将某些计算移动到记录的计算图之外。 例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。 想象一下，我们想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数， 并且只考虑到x在y被计算后发挥的作用。\n",
    "\n",
    "- 这里可以分离y来返回一个新变量u，该变量与y具有相同的值， 但丢弃计算图中如何计算y的任何信息。 换句话说，梯度不会向后流经u到x。 因此，下面的反向传播函数计算z=u*x关于x的偏导数，同时将u作为常数处理， 而不是z=x*x*x关于x的偏导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x\n",
    "u = y.detach()\n",
    "z = u * x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由于记录了y的计算结果，我们可以随后在y上调用反向传播， 得到y=x*x关于的x的导数，即2*x。\n",
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.6. <a id='toc7_6_6_'></a>[Python控制流的梯度计算](#toc0_)\n",
    "\n",
    "- 使用自动微分的一个好处是： 即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度。 在下面的代码中，while循环的迭代次数和if语句的结果都取决于输入a的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让我们计算梯度。\n",
    "a = torch.randn(size=(), requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们现在可以分析上面定义的f函数。 请注意，它在其输入a中是分段线性的。 换言之，对于任何a，存在某个常量标量k，使得f(a)=k*a，其中k的值取决于输入a，因此可以用d/a验证梯度是否正确。\n",
    "a.grad == d / a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7. <a id='toc7_7_'></a>[概率论](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. <a id='toc8_'></a>[神经网络-训练八股](#toc0_)\n",
    "\n",
    "|步骤|计算|操作|\n",
    "|:-|:-|:-|\n",
    "|1|定义网络模型|->计算出`y_hat`|\n",
    "|2|选择损失函数|->计算`loss值`、求梯度|\n",
    "|3|选择优化器|->`更新`网络权重参数|\n",
    "|4|训练|->实施1、2、3|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. <a id='toc8_1_'></a>[现线性回归模型于训练过程-从零开始](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1. <a id='toc8_1_1_'></a>[虚拟出数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([-0.5928,  0.3667])\n",
      "label: tensor([1.7654])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import random\n",
    "\n",
    "def synthetic_data(w, b, num_examples):  \n",
    "    \"\"\"生成y=Xw+b+噪声\"\"\"\n",
    "    X = torch.normal(mean=0, std=1, size=(num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(mean=0, std=0.01, size=y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "\n",
    "print('features:', features[0])\n",
    "print('label:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"231.442187pt\" height=\"169.678125pt\" viewBox=\"0 0 231.442187 169.678125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-05-18T15:08:53.316260</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 169.678125 \n",
       "L 231.442187 169.678125 \n",
       "L 231.442187 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "L 28.942188 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"m18bb6ce550\" d=\"M 0 0.5 \n",
       "C 0.132602 0.5 0.25979 0.447317 0.353553 0.353553 \n",
       "C 0.447317 0.25979 0.5 0.132602 0.5 0 \n",
       "C 0.5 -0.132602 0.447317 -0.25979 0.353553 -0.353553 \n",
       "C 0.25979 -0.447317 0.132602 -0.5 0 -0.5 \n",
       "C -0.132602 -0.5 -0.25979 -0.447317 -0.353553 -0.353553 \n",
       "C -0.447317 -0.25979 -0.5 -0.132602 -0.5 0 \n",
       "C -0.5 0.132602 -0.447317 0.25979 -0.353553 0.353553 \n",
       "C -0.25979 0.447317 -0.132602 0.5 0 0.5 \n",
       "z\n",
       "\" style=\"stroke: #1f77b4\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p149bb96678)\">\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.095479\" y=\"47.161377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.851713\" y=\"83.62544\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.208597\" y=\"87.238868\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"87.729918\" y=\"40.397538\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.573273\" y=\"74.594754\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.717888\" y=\"60.945456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.324851\" y=\"78.7769\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.745046\" y=\"79.445989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.425785\" y=\"38.908429\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.929806\" y=\"116.402206\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.433764\" y=\"88.486938\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.993977\" y=\"81.085971\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.88151\" y=\"87.997522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.448528\" y=\"88.393808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.731191\" y=\"76.554431\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.365738\" y=\"73.519191\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.023584\" y=\"74.321666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.343054\" y=\"93.603985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.480389\" y=\"88.551763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"82.783874\" y=\"35.366294\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.40635\" y=\"58.043827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.163633\" y=\"103.28369\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.402431\" y=\"57.861658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.67707\" y=\"81.847122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.810681\" y=\"77.415171\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.459828\" y=\"90.031881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"74.291277\" y=\"35.628451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.353451\" y=\"92.726373\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.567219\" y=\"65.921645\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.252503\" y=\"67.827082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.357592\" y=\"73.868138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.556005\" y=\"81.497491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.588391\" y=\"57.255578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.873451\" y=\"56.665809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.53247\" y=\"72.549742\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.363962\" y=\"85.38564\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.858176\" y=\"58.074153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.627228\" y=\"51.205587\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.274568\" y=\"46.708364\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.191399\" y=\"111.673949\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.057851\" y=\"75.989104\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.467418\" y=\"67.739194\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.631192\" y=\"59.798297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.163912\" y=\"74.989388\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.397586\" y=\"59.375105\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.25971\" y=\"59.267597\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.847122\" y=\"93.854999\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.1543\" y=\"71.690158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.433433\" y=\"87.617628\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.147698\" y=\"63.623364\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.640488\" y=\"73.829216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.738102\" y=\"89.36582\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.302647\" y=\"94.878713\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.085924\" y=\"98.631002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.452017\" y=\"69.606532\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.770517\" y=\"77.322051\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.949251\" y=\"72.458828\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"75.617311\" y=\"44.551745\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.242985\" y=\"71.231531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.456331\" y=\"87.507944\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.942623\" y=\"89.154946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"172.84967\" y=\"115.023299\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.293778\" y=\"57.941606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.996861\" y=\"64.990028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.079155\" y=\"124.951583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.600268\" y=\"47.266292\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.097375\" y=\"82.798065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"171.793196\" y=\"84.905216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.647189\" y=\"63.342156\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.612985\" y=\"71.311502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.608414\" y=\"71.440978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.656532\" y=\"109.509315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.409678\" y=\"76.930463\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.748237\" y=\"81.979596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.86734\" y=\"45.388764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.971797\" y=\"96.679841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.111144\" y=\"39.170635\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"172.522205\" y=\"104.843924\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"215.364915\" y=\"136.669454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.039242\" y=\"64.485384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.026192\" y=\"92.242205\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"87.829908\" y=\"58.495525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.715044\" y=\"43.485036\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.536737\" y=\"66.785002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.411851\" y=\"75.943248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.084039\" y=\"105.039855\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.865947\" y=\"90.586554\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.345475\" y=\"70.239975\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.715025\" y=\"86.234712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.761775\" y=\"72.272405\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"90.937862\" y=\"42.120415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"108.620502\" y=\"52.733002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.71258\" y=\"91.534395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.038561\" y=\"78.277075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.303632\" y=\"80.007046\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.680851\" y=\"123.495815\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.102381\" y=\"87.647679\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.983381\" y=\"68.147087\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.287017\" y=\"77.973753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.728341\" y=\"102.953634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.255003\" y=\"48.117778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.176357\" y=\"79.685957\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.072006\" y=\"105.065753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.081318\" y=\"94.163776\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.789688\" y=\"39.249632\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.093641\" y=\"94.996263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"179.020821\" y=\"110.657126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.413335\" y=\"56.029453\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.839972\" y=\"95.454916\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.064537\" y=\"95.256836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.861671\" y=\"79.859375\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.424467\" y=\"86.897922\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.523298\" y=\"94.19315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"174.220273\" y=\"100.574648\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.411392\" y=\"95.633883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"99.245321\" y=\"77.128793\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.974341\" y=\"42.823713\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.346943\" y=\"71.69238\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.730968\" y=\"43.229075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.599003\" y=\"84.788153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.921167\" y=\"72.66032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"87.318025\" y=\"58.450722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"194.960884\" y=\"131.832798\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.851446\" y=\"54.265354\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.738185\" y=\"79.788226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.232769\" y=\"39.581108\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.609002\" y=\"74.271061\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.604959\" y=\"96.641912\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.290707\" y=\"95.322537\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"86.920401\" y=\"37.140992\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.569027\" y=\"88.381482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.631163\" y=\"82.87251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.473124\" y=\"114.644034\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.089957\" y=\"81.887664\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"171.2269\" y=\"110.831563\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.389193\" y=\"79.688158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.145673\" y=\"72.500684\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.439791\" y=\"64.647256\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.448923\" y=\"83.772278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.538471\" y=\"126.892836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.310948\" y=\"52.077508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.07802\" y=\"71.031701\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.269235\" y=\"77.309642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.764291\" y=\"95.714536\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.771941\" y=\"78.662995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"88.05873\" y=\"52.853989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.825865\" y=\"85.024525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.04984\" y=\"65.790707\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.985694\" y=\"73.972357\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.372596\" y=\"73.366803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"179.97065\" y=\"103.786181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.344855\" y=\"70.019699\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"93.447802\" y=\"46.796222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.990588\" y=\"71.131398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.143886\" y=\"67.727624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.66859\" y=\"87.823199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.899883\" y=\"74.458643\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.576442\" y=\"119.338468\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.434056\" y=\"65.114343\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.373461\" y=\"90.545777\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"74.95746\" y=\"32.072086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.379211\" y=\"89.646188\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"179.659058\" y=\"131.976622\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.916788\" y=\"37.519916\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.311539\" y=\"68.471924\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.407896\" y=\"58.213502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.98083\" y=\"67.209455\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.578836\" y=\"83.648026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.530611\" y=\"81.247013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.676106\" y=\"78.386436\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"188.590076\" y=\"110.099002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.701229\" y=\"79.870857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.85927\" y=\"86.82456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.10514\" y=\"55.800128\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.751938\" y=\"95.543365\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.73323\" y=\"80.716385\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"97.229499\" y=\"49.869361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.169676\" y=\"78.313592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"181.657673\" y=\"108.965791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.523107\" y=\"89.407648\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.105095\" y=\"102.732158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"168.184204\" y=\"130.289923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.883837\" y=\"77.297087\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.828564\" y=\"77.985982\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.511402\" y=\"86.539024\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.205736\" y=\"88.497173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.420465\" y=\"82.445164\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.183605\" y=\"100.566278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.508009\" y=\"78.2606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.071365\" y=\"104.95213\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.33869\" y=\"90.006435\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.497756\" y=\"66.676858\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.538572\" y=\"44.376892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.319541\" y=\"50.800963\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.013391\" y=\"73.130755\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.436765\" y=\"90.054365\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.851902\" y=\"88.832337\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.298429\" y=\"109.265351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.81924\" y=\"105.520126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"99.125532\" y=\"45.042519\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.520817\" y=\"71.352702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.616857\" y=\"87.712444\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.361615\" y=\"93.431903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.955365\" y=\"115.084394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.302701\" y=\"65.664837\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.00782\" y=\"41.543072\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.22642\" y=\"65.483171\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.02213\" y=\"73.541159\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.117686\" y=\"107.280884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.369294\" y=\"81.808232\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.787771\" y=\"92.773059\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.140729\" y=\"110.615348\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.002826\" y=\"87.620506\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.425689\" y=\"95.841866\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.446106\" y=\"67.122825\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.509686\" y=\"77.513579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.088532\" y=\"65.123268\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"172.731574\" y=\"108.43805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.832592\" y=\"59.570065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.975699\" y=\"71.318317\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.907336\" y=\"103.523987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"92.159527\" y=\"43.963427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.55038\" y=\"71.800816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"86.639005\" y=\"50.486663\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.806314\" y=\"80.491925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.015768\" y=\"101.020893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.847569\" y=\"103.960201\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.777105\" y=\"64.961187\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"178.333764\" y=\"108.101154\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.172839\" y=\"71.272436\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"86.066135\" y=\"54.533553\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.714613\" y=\"77.715356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.050538\" y=\"85.805685\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.294464\" y=\"84.457284\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.123238\" y=\"110.462091\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.150669\" y=\"40.894705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.184716\" y=\"69.718393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.640153\" y=\"99.022385\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"103.863809\" y=\"47.724193\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.626844\" y=\"94.62609\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.241278\" y=\"69.007238\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"178.5462\" y=\"115.545579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.599468\" y=\"50.701739\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.598236\" y=\"93.231596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.028281\" y=\"48.494835\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.972378\" y=\"60.52896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"175.093025\" y=\"115.579612\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.674163\" y=\"57.422106\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"81.816997\" y=\"48.033332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.268201\" y=\"92.460497\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.982868\" y=\"94.537197\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"166.366972\" y=\"105.885217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.981166\" y=\"89.998881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.909952\" y=\"57.369795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.800072\" y=\"109.391435\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.3025\" y=\"68.146646\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.112621\" y=\"77.863288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.019004\" y=\"82.309716\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.437598\" y=\"64.998791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.85551\" y=\"62.189196\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.337286\" y=\"90.072432\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.260642\" y=\"75.777629\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.736644\" y=\"88.600963\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.817745\" y=\"62.371521\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.558975\" y=\"81.635209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.054067\" y=\"54.280767\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.664876\" y=\"73.743823\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.419599\" y=\"70.005569\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.615409\" y=\"67.434763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.973077\" y=\"76.827061\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.851912\" y=\"83.246127\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.465775\" y=\"62.814925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.69414\" y=\"82.432944\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.5567\" y=\"66.571063\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.865298\" y=\"61.460029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.895165\" y=\"84.160395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.69307\" y=\"68.818434\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.775156\" y=\"52.552853\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.131616\" y=\"95.612473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.314575\" y=\"60.307027\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.398024\" y=\"65.64585\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.260952\" y=\"90.950681\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.303587\" y=\"67.75297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.26854\" y=\"53.050234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"184.810641\" y=\"106.433803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.187906\" y=\"49.907413\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.298809\" y=\"81.185502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.691714\" y=\"64.86224\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.551724\" y=\"63.739985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"190.442405\" y=\"101.59375\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"168.636939\" y=\"110.318736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"189.434988\" y=\"122.525807\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"83.010608\" y=\"38.326326\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.135154\" y=\"91.321178\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.262778\" y=\"77.393835\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.275451\" y=\"49.56985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.832572\" y=\"85.533263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.746231\" y=\"72.671207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.820777\" y=\"99.386596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.683545\" y=\"67.775845\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.196624\" y=\"74.056585\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.203098\" y=\"75.661508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.907138\" y=\"61.146314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.719176\" y=\"105.44496\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"90.349765\" y=\"37.429393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.196461\" y=\"78.800497\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.30426\" y=\"76.243697\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.995264\" y=\"65.434945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.206289\" y=\"95.744662\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.555366\" y=\"60.535636\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.926729\" y=\"87.970989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.454368\" y=\"86.192893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.242903\" y=\"57.788411\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.740043\" y=\"75.358756\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.248791\" y=\"35.551553\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.69951\" y=\"78.30334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.329754\" y=\"64.711556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.247098\" y=\"101.88973\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.406229\" y=\"97.819789\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.031335\" y=\"88.734081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.843379\" y=\"45.330227\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.434758\" y=\"44.209348\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.13027\" y=\"76.632356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.58724\" y=\"108.769978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.484005\" y=\"100.102314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.946035\" y=\"88.620482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.437023\" y=\"96.788656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.015895\" y=\"60.901465\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.169374\" y=\"93.607883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.803278\" y=\"74.933473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.571926\" y=\"82.22746\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.47718\" y=\"95.62631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.262069\" y=\"60.61157\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.718515\" y=\"81.496522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"92.181732\" y=\"41.516842\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.331169\" y=\"88.36295\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.890814\" y=\"70.030588\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.969004\" y=\"78.772412\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.483839\" y=\"69.940603\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.305641\" y=\"72.17007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.064401\" y=\"108.453568\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.168083\" y=\"66.977319\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"186.070028\" y=\"121.685772\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.440592\" y=\"96.364357\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.615906\" y=\"83.36262\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.334251\" y=\"77.685671\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.832708\" y=\"77.021255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.584402\" y=\"81.933449\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.030805\" y=\"56.89179\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"169.2568\" y=\"109.930138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"81.284677\" y=\"46.477058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.833589\" y=\"107.725896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.628025\" y=\"95.836344\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.51822\" y=\"25.80849\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.05078\" y=\"83.93642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.24022\" y=\"41.798879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"176.812922\" y=\"100.699816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"206.112711\" y=\"132.059178\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.459017\" y=\"61.119264\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"166.340598\" y=\"102.003628\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.568646\" y=\"90.938355\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"178.466042\" y=\"135.076353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.576191\" y=\"89.697253\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.493513\" y=\"84.102082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.957632\" y=\"70.643879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.199816\" y=\"77.271077\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"175.249178\" y=\"118.26173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.033036\" y=\"100.42625\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.798255\" y=\"85.449113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.32953\" y=\"91.51232\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.504324\" y=\"98.445219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.286187\" y=\"69.827219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.735623\" y=\"96.551888\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.230718\" y=\"69.991721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.659505\" y=\"77.144345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.011388\" y=\"53.943991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"97.674035\" y=\"42.491325\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.566322\" y=\"71.860096\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.753018\" y=\"71.452624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.905282\" y=\"87.64505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.361549\" y=\"59.370096\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.572454\" y=\"71.761607\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"97.975877\" y=\"59.617879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.789529\" y=\"76.742222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.474806\" y=\"104.341687\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.264875\" y=\"68.026442\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.512114\" y=\"87.193492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.937993\" y=\"69.71948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"108.383548\" y=\"45.774082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.136088\" y=\"64.811021\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.571522\" y=\"54.048753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.810063\" y=\"47.273691\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.294015\" y=\"79.306596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.120782\" y=\"90.852565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.06859\" y=\"66.468719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.146701\" y=\"63.262394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.221559\" y=\"65.665216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.708983\" y=\"89.563288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.273493\" y=\"66.439287\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.837173\" y=\"83.170556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.803884\" y=\"65.386806\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.632525\" y=\"94.60237\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.695338\" y=\"77.253336\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.70951\" y=\"40.351655\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.687648\" y=\"79.915883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"88.793452\" y=\"52.793148\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.863376\" y=\"74.635042\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.501331\" y=\"91.09296\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.99569\" y=\"73.305529\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.416351\" y=\"88.123721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.367629\" y=\"93.357726\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.029471\" y=\"96.797956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.194088\" y=\"101.376634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.180676\" y=\"59.779791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.57167\" y=\"83.17462\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.986711\" y=\"58.26251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.046832\" y=\"93.280006\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.214217\" y=\"89.448882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.969972\" y=\"92.86561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.20047\" y=\"76.563584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.767122\" y=\"73.075454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.681444\" y=\"59.21978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.292355\" y=\"66.063946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.960186\" y=\"93.067459\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.53253\" y=\"74.32969\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"177.84401\" y=\"120.319759\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.647964\" y=\"89.083226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"75.729887\" y=\"21.716144\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.927387\" y=\"67.650078\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.175365\" y=\"65.223208\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.556223\" y=\"97.346334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.029483\" y=\"110.278113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"92.402947\" y=\"55.04702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"88.987071\" y=\"36.320377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.230393\" y=\"66.727421\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.536374\" y=\"54.699249\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.740495\" y=\"68.524397\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"68.20164\" y=\"18.152251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.864201\" y=\"96.415787\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"103.393444\" y=\"53.098791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.272119\" y=\"55.945706\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.119748\" y=\"67.417656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.167812\" y=\"50.437323\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.387767\" y=\"53.971836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.477571\" y=\"60.758656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.02508\" y=\"108.205526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.285307\" y=\"67.258656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.331823\" y=\"82.418834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.486232\" y=\"77.876968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.91161\" y=\"82.143424\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.717006\" y=\"57.152768\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.891315\" y=\"94.68598\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.848712\" y=\"112.619282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.33896\" y=\"84.338058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"169.909578\" y=\"105.269701\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.05359\" y=\"90.123526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.726965\" y=\"103.768415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.333197\" y=\"90.380013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.915242\" y=\"55.457805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.672469\" y=\"80.84138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.840902\" y=\"70.947599\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.958121\" y=\"23.162991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.110344\" y=\"77.873558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.218008\" y=\"105.443857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.779349\" y=\"91.711486\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.503636\" y=\"44.255994\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.471323\" y=\"95.849579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.37937\" y=\"83.283928\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.675286\" y=\"47.93496\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"76.540277\" y=\"41.384245\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.953678\" y=\"78.467352\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"99.887518\" y=\"50.069211\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.066197\" y=\"94.835505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.852849\" y=\"108.472892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.112367\" y=\"104.72846\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.869502\" y=\"106.281367\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.342459\" y=\"51.793366\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.511957\" y=\"70.717656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.192634\" y=\"98.065695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.357245\" y=\"93.409271\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.565301\" y=\"91.783085\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.027944\" y=\"60.077816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.546238\" y=\"51.08775\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.902369\" y=\"70.340151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.13645\" y=\"64.663011\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.119843\" y=\"55.93901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.90781\" y=\"54.780247\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.844246\" y=\"88.241005\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.684121\" y=\"81.15877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.593471\" y=\"81.571363\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.760849\" y=\"62.661631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.407119\" y=\"69.693332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.228326\" y=\"74.384589\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.196136\" y=\"98.598832\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"97.523503\" y=\"66.33793\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"206.761358\" y=\"125.79795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.095197\" y=\"98.4751\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.539013\" y=\"64.56139\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.164185\" y=\"81.606658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.702628\" y=\"98.219326\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.258917\" y=\"94.831201\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.037722\" y=\"104.699339\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.170226\" y=\"89.41371\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.059483\" y=\"72.784708\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.702482\" y=\"87.411776\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"88.989185\" y=\"52.687565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"87.075942\" y=\"50.725829\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.970726\" y=\"65.130989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.883673\" y=\"63.986565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.96272\" y=\"80.834248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.150811\" y=\"81.052541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.807994\" y=\"68.298331\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.10131\" y=\"63.476082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.210835\" y=\"84.375522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.352392\" y=\"73.802402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.34687\" y=\"91.968214\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"103.696498\" y=\"35.232469\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.963518\" y=\"78.597462\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.385956\" y=\"70.788778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.184783\" y=\"59.685314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.853204\" y=\"90.993283\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.690509\" y=\"129.760231\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.434951\" y=\"95.79107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.306675\" y=\"49.856484\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.074512\" y=\"86.650945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.928025\" y=\"84.532026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.962191\" y=\"63.882353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.203076\" y=\"56.071804\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.794781\" y=\"91.749217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.275888\" y=\"88.082351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.2505\" y=\"105.130473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.045802\" y=\"51.890282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.08613\" y=\"58.570508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.192583\" y=\"59.913878\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.382741\" y=\"77.805222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.026704\" y=\"88.190008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.660371\" y=\"52.29818\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.102869\" y=\"74.407627\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.28041\" y=\"86.544145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.533615\" y=\"97.2812\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.039942\" y=\"47.401588\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.798571\" y=\"72.467508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.605425\" y=\"117.705185\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.117282\" y=\"77.578839\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.863978\" y=\"68.35539\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.916677\" y=\"67.610349\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"70.69861\" y=\"29.829656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.49309\" y=\"101.365519\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.800132\" y=\"65.258895\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.875062\" y=\"77.986457\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"37.81946\" y=\"22.041043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.9688\" y=\"82.919953\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"184.717724\" y=\"139.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.23157\" y=\"93.679042\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"177.22424\" y=\"110.310029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.395139\" y=\"96.225358\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.573684\" y=\"51.327124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.758672\" y=\"58.736199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.570633\" y=\"66.047748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.098949\" y=\"80.562145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"180.18112\" y=\"122.612181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.484323\" y=\"72.588527\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.19446\" y=\"68.419977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.194549\" y=\"69.203448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.39048\" y=\"99.604671\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.836511\" y=\"95.278895\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"168.276288\" y=\"116.960095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.729036\" y=\"62.502891\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.406236\" y=\"75.34703\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.079402\" y=\"65.876611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.053701\" y=\"59.436446\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.071025\" y=\"94.729298\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.838797\" y=\"65.936659\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.557707\" y=\"66.413173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.492099\" y=\"71.617763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.297919\" y=\"65.554642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.249566\" y=\"50.537598\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.751482\" y=\"60.66267\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.829179\" y=\"85.850677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.804102\" y=\"69.59409\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.009757\" y=\"33.39075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.889071\" y=\"84.740389\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"92.930904\" y=\"56.896367\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.109569\" y=\"80.144903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.085701\" y=\"78.820328\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.607475\" y=\"90.114192\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.197228\" y=\"90.689906\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.888189\" y=\"86.676935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.803833\" y=\"100.273606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.385509\" y=\"71.28935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"168.428015\" y=\"93.395327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.227251\" y=\"75.908799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"83.610668\" y=\"47.334452\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"77.11768\" y=\"42.681032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.21452\" y=\"68.254932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"194.397655\" y=\"121.483361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.216604\" y=\"92.04012\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.076437\" y=\"84.291729\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.395224\" y=\"80.507211\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"189.387072\" y=\"111.456825\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.094041\" y=\"70.558834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.844024\" y=\"99.113743\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.045958\" y=\"79.203896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.793533\" y=\"43.082933\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.747365\" y=\"49.999154\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.860075\" y=\"80.905868\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.956165\" y=\"53.759361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.715826\" y=\"57.926678\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"86.062914\" y=\"30.864672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.261816\" y=\"84.073393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.33017\" y=\"85.092948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.086697\" y=\"59.609608\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.664584\" y=\"85.599525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.832551\" y=\"37.233837\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.292719\" y=\"57.501901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"197.885911\" y=\"136.476002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.417242\" y=\"93.124352\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.590631\" y=\"79.8113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.826924\" y=\"62.819942\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.21641\" y=\"81.136541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.116507\" y=\"106.779282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.198812\" y=\"73.861437\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"166.610014\" y=\"107.285008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.8329\" y=\"86.318162\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"85.447827\" y=\"41.339427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.662964\" y=\"98.494541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.15241\" y=\"55.854203\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.675945\" y=\"74.743863\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.303793\" y=\"96.890186\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.650283\" y=\"68.410737\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.823973\" y=\"86.884353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.11893\" y=\"48.318827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.12326\" y=\"82.182124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"86.71922\" y=\"43.483263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.301609\" y=\"72.569612\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.466356\" y=\"72.806161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.890497\" y=\"47.114905\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"69.84394\" y=\"49.194621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.667698\" y=\"66.412408\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.492479\" y=\"105.564466\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.887408\" y=\"100.306264\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.067891\" y=\"106.950633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.148809\" y=\"64.954008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.429482\" y=\"90.1105\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.664646\" y=\"86.995488\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.867215\" y=\"62.85089\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.549793\" y=\"93.940841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.053745\" y=\"79.150901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.650576\" y=\"68.84641\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.230696\" y=\"101.662611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.701619\" y=\"49.77235\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.691186\" y=\"69.579363\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"169.18138\" y=\"111.892028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.551708\" y=\"60.302929\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.733292\" y=\"103.65314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"58.010948\" y=\"15.765491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.198177\" y=\"94.586921\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.120971\" y=\"54.787315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.041368\" y=\"83.67882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.275511\" y=\"68.62897\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.086569\" y=\"82.079448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.750245\" y=\"67.164617\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.120777\" y=\"97.354337\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.347228\" y=\"90.121634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.348334\" y=\"79.292481\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.444262\" y=\"61.17923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.839766\" y=\"64.295246\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.445458\" y=\"116.605219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.649238\" y=\"82.715272\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.715663\" y=\"92.86394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.159696\" y=\"70.888666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"65.476058\" y=\"13.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.099375\" y=\"69.149559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.263962\" y=\"42.032186\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.166695\" y=\"57.837107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.732869\" y=\"75.377153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"169.679882\" y=\"131.895592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.939425\" y=\"59.141719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.714627\" y=\"111.353278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.763694\" y=\"96.236795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.906559\" y=\"64.276207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.604701\" y=\"60.290799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.973405\" y=\"106.724808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.629961\" y=\"85.050771\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.981322\" y=\"107.254549\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"180.513474\" y=\"111.184544\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.836516\" y=\"95.462359\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.914484\" y=\"67.259161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.479348\" y=\"70.232714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.272523\" y=\"49.957704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.135323\" y=\"66.102736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.628174\" y=\"83.945404\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.519095\" y=\"77.177288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.061573\" y=\"76.923153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.333124\" y=\"90.314048\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.929194\" y=\"62.515236\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.347144\" y=\"59.281458\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.947892\" y=\"101.318345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.997123\" y=\"64.226513\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.902053\" y=\"102.041242\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.913735\" y=\"77.644053\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.177522\" y=\"91.387142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.664466\" y=\"27.810463\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.855771\" y=\"81.917821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.229796\" y=\"89.348764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"79.634661\" y=\"35.092983\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.891549\" y=\"65.048166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"93.968327\" y=\"43.871166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.907416\" y=\"75.364399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.486247\" y=\"76.088841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.810386\" y=\"72.693093\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.978057\" y=\"83.175531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.110827\" y=\"79.505546\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.016312\" y=\"100.975342\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.702803\" y=\"124.807206\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.412038\" y=\"90.983812\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.235486\" y=\"83.077619\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.534762\" y=\"83.761282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.610104\" y=\"87.596558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.090768\" y=\"84.604151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"187.20176\" y=\"116.228875\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.439972\" y=\"77.64884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.274607\" y=\"113.955505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.646856\" y=\"68.287306\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.591017\" y=\"71.528892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.994477\" y=\"74.031821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.041914\" y=\"98.097999\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"103.900527\" y=\"48.35415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.638862\" y=\"86.280172\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.804202\" y=\"67.597294\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.845581\" y=\"77.180758\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.671126\" y=\"64.412474\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"174.310451\" y=\"112.626968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.847771\" y=\"95.91145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.881409\" y=\"79.49606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.306849\" y=\"84.052712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.250617\" y=\"83.414741\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.994616\" y=\"75.428867\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.067052\" y=\"78.310834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.191582\" y=\"70.326748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.147501\" y=\"73.301386\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.13053\" y=\"71.147066\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.426643\" y=\"99.081935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.168215\" y=\"78.237334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.189183\" y=\"89.874683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.419576\" y=\"74.284852\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.419249\" y=\"72.372303\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.053958\" y=\"75.555399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.359279\" y=\"121.223819\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.815822\" y=\"80.050575\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.911547\" y=\"78.240407\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.923255\" y=\"75.147613\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.133718\" y=\"102.542952\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.329025\" y=\"87.033987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"93.422504\" y=\"45.301327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.517571\" y=\"91.822422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.024305\" y=\"76.642438\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.614931\" y=\"77.949601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"64.970981\" y=\"30.519615\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.081606\" y=\"73.579209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.838706\" y=\"82.110649\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.292935\" y=\"79.188468\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.982502\" y=\"104.574014\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.096378\" y=\"61.68454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.129246\" y=\"62.090174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.758126\" y=\"64.382054\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.906803\" y=\"114.576675\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.911888\" y=\"93.266282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.247932\" y=\"45.160321\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.519383\" y=\"104.21218\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.846885\" y=\"71.754109\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.148961\" y=\"68.087322\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.615576\" y=\"81.411749\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"90.316396\" y=\"50.130527\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.132399\" y=\"50.705691\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.188074\" y=\"63.967413\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.547703\" y=\"57.232677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.194564\" y=\"84.365181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.661788\" y=\"77.832046\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.034306\" y=\"113.094996\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.93483\" y=\"91.140991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.505665\" y=\"105.741195\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.334975\" y=\"68.392803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.794785\" y=\"75.12353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.469321\" y=\"90.649089\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.66032\" y=\"104.070657\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.906548\" y=\"63.468873\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.338784\" y=\"82.86794\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.549296\" y=\"85.608542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.546588\" y=\"97.206753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.718311\" y=\"68.260558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.147706\" y=\"56.226981\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"97.842273\" y=\"60.232185\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.668063\" y=\"51.873542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"84.617334\" y=\"18.103516\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.451103\" y=\"93.246023\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.265351\" y=\"73.027207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.902407\" y=\"43.075637\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.954757\" y=\"67.577574\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.89097\" y=\"79.029583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"187.621362\" y=\"119.915368\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.612109\" y=\"83.74487\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.686826\" y=\"76.370095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.799684\" y=\"92.48442\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.290279\" y=\"49.338792\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.838858\" y=\"100.184448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.269882\" y=\"97.096052\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.038635\" y=\"67.031251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.041575\" y=\"87.363325\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"84.014338\" y=\"21.562226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.515553\" y=\"69.816669\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.565861\" y=\"78.500167\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.95154\" y=\"89.430395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.14065\" y=\"91.456843\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"103.202022\" y=\"56.366234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.22455\" y=\"64.606874\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.958635\" y=\"78.651995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.252548\" y=\"72.41565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.756206\" y=\"107.662652\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.515326\" y=\"99.172621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.706676\" y=\"96.370217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.105019\" y=\"79.02333\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.779544\" y=\"89.016402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.200818\" y=\"104.754022\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.632423\" y=\"96.801986\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"172.282279\" y=\"111.927308\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.18855\" y=\"82.793202\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.458103\" y=\"41.859056\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.123526\" y=\"93.851658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.584503\" y=\"60.980031\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.909372\" y=\"74.145029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.550977\" y=\"94.163492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.472081\" y=\"68.159095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.929361\" y=\"102.06078\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.826549\" y=\"57.863059\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.134436\" y=\"85.641259\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.168939\" y=\"94.75956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"169.293359\" y=\"112.293427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.506265\" y=\"90.257794\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"99.356788\" y=\"65.223327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.398334\" y=\"83.79076\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.570078\" y=\"75.850764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.328916\" y=\"55.738297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.610495\" y=\"72.706857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.378193\" y=\"78.429072\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.583122\" y=\"73.384083\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.425629\" y=\"88.150926\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.353432\" y=\"84.380879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.209797\" y=\"89.189101\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.685341\" y=\"62.18428\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.618398\" y=\"71.018209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.333136\" y=\"70.038488\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.322245\" y=\"72.531255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.823646\" y=\"74.393081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.608225\" y=\"53.162821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"202.783655\" y=\"121.830153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.99309\" y=\"80.320939\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.391942\" y=\"64.345249\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.876304\" y=\"80.548704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.58977\" y=\"63.643561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.906441\" y=\"81.658512\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.266019\" y=\"101.152384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.281286\" y=\"66.060699\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.366461\" y=\"92.592949\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.516261\" y=\"67.56122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.92194\" y=\"90.036556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.144481\" y=\"57.539528\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.135178\" y=\"79.329016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.908034\" y=\"78.861112\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.491266\" y=\"83.921422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.807697\" y=\"75.450786\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.051651\" y=\"66.182709\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"166.019487\" y=\"98.983666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.111516\" y=\"65.131705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.162638\" y=\"69.319809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.660903\" y=\"78.456473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"91.734064\" y=\"51.867579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.351045\" y=\"82.685242\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.6349\" y=\"73.055611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.068739\" y=\"84.355827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.63787\" y=\"87.599534\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.409568\" y=\"93.319693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.704529\" y=\"67.56309\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.300494\" y=\"63.42464\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.499743\" y=\"48.451007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.69255\" y=\"55.90116\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.128581\" y=\"62.556877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.883643\" y=\"67.885119\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.241836\" y=\"77.585043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.797919\" y=\"87.156956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.0616\" y=\"58.183763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.015626\" y=\"82.54097\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.302346\" y=\"63.575948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.302998\" y=\"76.863967\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.911611\" y=\"99.133675\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.123813\" y=\"66.921095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.865968\" y=\"52.645248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.78829\" y=\"79.424332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.709863\" y=\"63.33256\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.644056\" y=\"39.476263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.256625\" y=\"86.515271\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.738507\" y=\"99.654722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.612702\" y=\"91.443661\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.821672\" y=\"93.766817\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.388459\" y=\"72.543665\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.919281\" y=\"96.980838\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.278235\" y=\"93.142453\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"179.94484\" y=\"130.32799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.820298\" y=\"37.928601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.650908\" y=\"62.978298\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.414425\" y=\"73.937807\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.594095\" y=\"88.439678\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"170.995955\" y=\"109.732608\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.47018\" y=\"97.713903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"91.416199\" y=\"51.397677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.637216\" y=\"69.78173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.319177\" y=\"71.655387\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.374822\" y=\"74.834836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.427259\" y=\"52.43887\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.449895\" y=\"78.713174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.719218\" y=\"70.531854\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"108.072781\" y=\"61.076881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.88235\" y=\"74.547729\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"88.217137\" y=\"52.674687\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.762105\" y=\"59.810942\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.558407\" y=\"61.533266\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.053974\" y=\"105.538605\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.286644\" y=\"83.827882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.266477\" y=\"73.022932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.574237\" y=\"72.99407\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.381512\" y=\"64.55689\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.693437\" y=\"83.376626\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.460302\" y=\"91.934398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.00611\" y=\"85.236683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.702211\" y=\"80.325857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.346003\" y=\"53.38592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.269631\" y=\"86.51086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.152682\" y=\"68.541043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.952226\" y=\"100.24009\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"171.111968\" y=\"118.103977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.53369\" y=\"90.561111\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.717881\" y=\"69.697515\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.815171\" y=\"62.456778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.308034\" y=\"94.957518\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.427407\" y=\"92.102869\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.582537\" y=\"66.853116\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.54365\" y=\"90.435422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.207181\" y=\"71.333254\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.161298\" y=\"103.614709\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.907013\" y=\"98.96007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.818717\" y=\"81.294635\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.449835\" y=\"81.23083\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.090995\" y=\"102.947303\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.379022\" y=\"79.235428\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.079829\" y=\"82.178295\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.273181\" y=\"91.059508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.334522\" y=\"86.045153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.770433\" y=\"65.405451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"108.552052\" y=\"69.00258\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.765937\" y=\"82.574475\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.607644\" y=\"115.920234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.087753\" y=\"89.551559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.319823\" y=\"77.133567\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.731657\" y=\"68.029976\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.131994\" y=\"84.591819\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.73471\" y=\"95.674044\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.18093\" y=\"83.951852\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.339812\" y=\"48.107719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.868383\" y=\"91.144692\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.915862\" y=\"77.966158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.038497\" y=\"101.867718\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.953976\" y=\"69.104578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.381854\" y=\"95.437832\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.145448\" y=\"91.398395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.161531\" y=\"82.985289\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.390359\" y=\"113.470475\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.705958\" y=\"87.582783\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.643029\" y=\"80.594545\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.61515\" y=\"75.882131\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.371491\" y=\"83.48542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.091775\" y=\"75.831255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.084409\" y=\"84.442152\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.313126\" y=\"66.885205\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.356645\" y=\"87.367559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.569709\" y=\"75.389946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"99.88968\" y=\"62.102534\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.395297\" y=\"89.780347\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.960033\" y=\"73.903159\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.651549\" y=\"115.759169\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.600207\" y=\"99.445677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.972016\" y=\"100.660773\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.195861\" y=\"95.951702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.305644\" y=\"91.992748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.934713\" y=\"93.511792\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.517035\" y=\"93.644631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.15317\" y=\"39.124589\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.259368\" y=\"89.347345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.762384\" y=\"69.862951\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.40995\" y=\"101.115803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.643811\" y=\"68.037402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m2cbfe66e94\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2cbfe66e94\" x=\"37.108605\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −4 -->\n",
       "      <g transform=\"translate(29.737511 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2cbfe66e94\" x=\"84.839648\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- −2 -->\n",
       "      <g transform=\"translate(77.468554 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2cbfe66e94\" x=\"132.57069\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(129.38944 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2cbfe66e94\" x=\"180.301733\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(177.120483 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <defs>\n",
       "       <path id=\"m67ee9f9fc6\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m67ee9f9fc6\" x=\"28.942188\" y=\"125.71812\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- −5 -->\n",
       "      <g transform=\"translate(7.2 129.517339) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m67ee9f9fc6\" x=\"28.942188\" y=\"99.751174\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(15.579688 103.550393) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m67ee9f9fc6\" x=\"28.942188\" y=\"73.784228\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(15.579688 77.583446) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m67ee9f9fc6\" x=\"28.942188\" y=\"47.817281\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(9.217188 51.6165) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m67ee9f9fc6\" x=\"28.942188\" y=\"21.850335\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(9.217188 25.649554) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 28.942188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 224.242188 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 28.942188 7.2 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p149bb96678\">\n",
       "   <rect x=\"28.942188\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘图，查看分布\n",
    "d2l.set_figsize()\n",
    "d2l.plt.scatter(features[:, (1)].detach().numpy(), \n",
    "                labels.detach().numpy(), 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"231.442187pt\" height=\"169.678125pt\" viewBox=\"0 0 231.442187 169.678125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-05-18T15:08:56.251352</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 169.678125 \n",
       "L 231.442187 169.678125 \n",
       "L 231.442187 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "L 28.942188 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"m823589f946\" d=\"M 0 0.5 \n",
       "C 0.132602 0.5 0.25979 0.447317 0.353553 0.353553 \n",
       "C 0.447317 0.25979 0.5 0.132602 0.5 0 \n",
       "C 0.5 -0.132602 0.447317 -0.25979 0.353553 -0.353553 \n",
       "C 0.25979 -0.447317 0.132602 -0.5 0 -0.5 \n",
       "C -0.132602 -0.5 -0.25979 -0.447317 -0.353553 -0.353553 \n",
       "C -0.447317 -0.25979 -0.5 -0.132602 -0.5 0 \n",
       "C -0.5 0.132602 -0.447317 0.25979 -0.353553 0.353553 \n",
       "C -0.25979 0.447317 -0.132602 0.5 0 0.5 \n",
       "z\n",
       "\" style=\"stroke: #1f77b4\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p4610e2cf3f)\">\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.049598\" y=\"47.161377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.963107\" y=\"83.62544\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.927232\" y=\"87.238868\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.499187\" y=\"40.397538\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.738829\" y=\"74.594754\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"168.177498\" y=\"60.945456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.120588\" y=\"78.7769\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.100157\" y=\"79.445989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"167.203315\" y=\"38.908429\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"66.24924\" y=\"116.402206\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"96.90644\" y=\"88.486938\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.287288\" y=\"81.085971\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.367315\" y=\"87.997522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.325299\" y=\"88.393808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.647682\" y=\"76.554431\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.127695\" y=\"73.519191\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"174.422087\" y=\"74.321666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.875464\" y=\"93.603985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.86115\" y=\"88.551763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.341229\" y=\"35.366294\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.2019\" y=\"58.043827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.565749\" y=\"103.28369\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.72149\" y=\"57.861658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"73.517474\" y=\"81.847122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.731428\" y=\"77.415171\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.879391\" y=\"90.031881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.688161\" y=\"35.628451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.386178\" y=\"92.726373\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.192063\" y=\"65.921645\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.646121\" y=\"67.827082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.295666\" y=\"73.868138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.981588\" y=\"81.497491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.834866\" y=\"57.255578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.896673\" y=\"56.665809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.227189\" y=\"72.549742\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.329422\" y=\"85.38564\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.058958\" y=\"58.074153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"178.342288\" y=\"51.205587\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.373088\" y=\"46.708364\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"77.803974\" y=\"111.673949\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.240795\" y=\"75.989104\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.312012\" y=\"67.739194\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.926694\" y=\"59.798297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.913672\" y=\"74.989388\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.635024\" y=\"59.375105\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.512233\" y=\"59.267597\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.543894\" y=\"93.854999\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.832725\" y=\"71.690158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.390046\" y=\"87.617628\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.727296\" y=\"63.623364\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.260721\" y=\"73.829216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.220665\" y=\"89.36582\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.38085\" y=\"94.878713\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.725452\" y=\"98.631002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.94471\" y=\"69.606532\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"73.676253\" y=\"77.322051\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.217505\" y=\"72.458828\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.958828\" y=\"44.551745\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.123908\" y=\"71.231531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.629155\" y=\"87.507944\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.86245\" y=\"89.154946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.219201\" y=\"115.023299\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"189.643748\" y=\"57.941606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.691932\" y=\"64.990028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"79.878438\" y=\"124.951583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.820831\" y=\"47.266292\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.795653\" y=\"82.798065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"185.46487\" y=\"84.905216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.289184\" y=\"63.342156\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.790243\" y=\"71.311502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.555683\" y=\"71.440978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"96.680579\" y=\"109.509315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.142542\" y=\"76.930463\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.204389\" y=\"81.979596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.270455\" y=\"45.388764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"37.81946\" y=\"96.679841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"187.724045\" y=\"39.170635\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.818021\" y=\"104.843924\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.548633\" y=\"136.669454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.098167\" y=\"64.485384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"69.900495\" y=\"92.242205\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.078741\" y=\"58.495525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.047477\" y=\"43.485036\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.94966\" y=\"66.785002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"170.966781\" y=\"75.943248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.77618\" y=\"105.039855\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.366653\" y=\"90.586554\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.319769\" y=\"70.239975\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.740655\" y=\"86.234712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.564353\" y=\"72.272405\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.289525\" y=\"42.120415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.977459\" y=\"52.733002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.326608\" y=\"91.534395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.793803\" y=\"78.277075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.637716\" y=\"80.007046\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"72.535262\" y=\"123.495815\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.666409\" y=\"87.647679\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.243464\" y=\"68.147087\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"79.233118\" y=\"77.973753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.615171\" y=\"102.953634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.83466\" y=\"48.117778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.245982\" y=\"79.685957\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"85.339264\" y=\"105.065753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.043811\" y=\"94.163776\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.807544\" y=\"39.249632\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.697482\" y=\"94.996263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.091272\" y=\"110.657126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.549356\" y=\"56.029453\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"86.928383\" y=\"95.454916\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.897108\" y=\"95.256836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.102496\" y=\"79.859375\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"51.276685\" y=\"86.897922\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.651787\" y=\"94.19315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.784394\" y=\"100.574648\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.524805\" y=\"95.633883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"61.405454\" y=\"77.128793\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"165.479099\" y=\"42.823713\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.107527\" y=\"71.69238\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"174.024353\" y=\"43.229075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.383267\" y=\"84.788153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.958005\" y=\"72.66032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.9598\" y=\"58.450722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.732142\" y=\"131.832798\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"204.588149\" y=\"54.265354\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.193145\" y=\"79.788226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.838601\" y=\"39.581108\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.481894\" y=\"74.271061\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.181891\" y=\"96.641912\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.217305\" y=\"95.322537\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.981023\" y=\"37.140992\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.457846\" y=\"88.381482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.444136\" y=\"82.87251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.320171\" y=\"114.644034\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.182927\" y=\"81.887664\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.052671\" y=\"110.831563\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.614091\" y=\"79.688158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.600058\" y=\"72.500684\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.438867\" y=\"64.647256\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.804829\" y=\"83.772278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"63.421576\" y=\"126.892836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.066561\" y=\"52.077508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.440322\" y=\"71.031701\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.984559\" y=\"77.309642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.146232\" y=\"95.714536\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.036364\" y=\"78.662995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.580275\" y=\"52.853989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.086729\" y=\"85.024525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.583032\" y=\"65.790707\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.297572\" y=\"73.972357\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"161.872947\" y=\"73.366803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.728672\" y=\"103.786181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.589504\" y=\"70.019699\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.80647\" y=\"46.796222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.874851\" y=\"71.131398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"170.34891\" y=\"67.727624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.207703\" y=\"87.823199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.000766\" y=\"74.458643\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"60.052055\" y=\"119.338468\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.077031\" y=\"65.114343\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.30747\" y=\"90.545777\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.660782\" y=\"32.072086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.63782\" y=\"89.646188\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"74.008351\" y=\"131.976622\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.802539\" y=\"37.519916\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.031993\" y=\"68.471924\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"160.842431\" y=\"58.213502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.530854\" y=\"67.209455\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.319874\" y=\"83.648026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.749716\" y=\"81.247013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.943817\" y=\"78.386436\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.952825\" y=\"110.099002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.80105\" y=\"79.870857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.17755\" y=\"86.82456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.775787\" y=\"55.800128\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.787785\" y=\"95.543365\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.680858\" y=\"80.716385\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.31618\" y=\"49.869361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"83.986793\" y=\"78.313592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.027008\" y=\"108.965791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.632561\" y=\"89.407648\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"86.120077\" y=\"102.732158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"55.340667\" y=\"130.289923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.168331\" y=\"77.297087\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.052556\" y=\"77.985982\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.276859\" y=\"86.539024\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.447145\" y=\"88.497173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.160475\" y=\"82.445164\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"77.770008\" y=\"100.566278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.059892\" y=\"78.2606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.837459\" y=\"104.95213\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.805963\" y=\"90.006435\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.199906\" y=\"66.676858\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.479051\" y=\"44.376892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.643194\" y=\"50.800963\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.651571\" y=\"73.130755\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.739921\" y=\"90.054365\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.782681\" y=\"88.832337\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.722082\" y=\"109.265351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.765036\" y=\"105.520126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.92917\" y=\"45.042519\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.462902\" y=\"71.352702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.305053\" y=\"87.712444\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.404515\" y=\"93.431903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"84.110943\" y=\"115.084394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.583832\" y=\"65.664837\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.929312\" y=\"41.543072\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.699533\" y=\"65.483171\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.61974\" y=\"73.541159\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"79.611058\" y=\"107.280884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.971819\" y=\"81.808232\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"86.09323\" y=\"92.773059\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"80.631611\" y=\"110.615348\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.394381\" y=\"87.620506\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.171816\" y=\"95.841866\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.954207\" y=\"67.122825\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.024508\" y=\"77.513579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"163.642053\" y=\"65.123268\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.571848\" y=\"108.43805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"187.924902\" y=\"59.570065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.405573\" y=\"71.318317\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.291421\" y=\"103.523987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.894751\" y=\"43.963427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.396273\" y=\"71.800816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.090681\" y=\"50.486663\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.573461\" y=\"80.491925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"72.203491\" y=\"101.020893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.981394\" y=\"103.960201\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.084978\" y=\"64.961187\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.747365\" y=\"108.101154\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.659146\" y=\"71.272436\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.896406\" y=\"54.533553\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.622954\" y=\"77.715356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.506828\" y=\"85.805685\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.689788\" y=\"84.457284\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.744492\" y=\"110.462091\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.914233\" y=\"40.894705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.029819\" y=\"69.718393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.924367\" y=\"99.022385\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.206793\" y=\"47.724193\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.371572\" y=\"94.62609\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.283811\" y=\"69.007238\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.098857\" y=\"115.545579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"187.707201\" y=\"50.701739\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.111841\" y=\"93.231596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.278095\" y=\"48.494835\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.721283\" y=\"60.52896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.206497\" y=\"115.579612\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.264923\" y=\"57.422106\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.301552\" y=\"48.033332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.042311\" y=\"92.460497\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"81.554385\" y=\"94.537197\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.620078\" y=\"105.885217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.920391\" y=\"89.998881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.870621\" y=\"57.369795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.159061\" y=\"109.391435\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.698184\" y=\"68.146646\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.944293\" y=\"77.863288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.880527\" y=\"82.309716\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.515502\" y=\"64.998791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.94588\" y=\"62.189196\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"82.297836\" y=\"90.072432\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.01675\" y=\"75.777629\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.402728\" y=\"88.600963\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.38606\" y=\"62.371521\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.955738\" y=\"81.635209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.671034\" y=\"54.280767\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.351852\" y=\"73.743823\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.858871\" y=\"70.005569\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.11235\" y=\"67.434763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.694098\" y=\"76.827061\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.895866\" y=\"83.246127\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.46799\" y=\"62.814925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.1394\" y=\"82.432944\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.65086\" y=\"66.571063\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.977175\" y=\"61.460029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.67534\" y=\"84.160395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.576162\" y=\"68.818434\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"178.764923\" y=\"52.552853\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.268663\" y=\"95.612473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.919849\" y=\"60.307027\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.769421\" y=\"65.64585\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.102148\" y=\"90.950681\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.715173\" y=\"67.75297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.335523\" y=\"53.050234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.15796\" y=\"106.433803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.824974\" y=\"49.907413\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.53108\" y=\"81.185502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.397239\" y=\"64.86224\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.153422\" y=\"63.739985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"177.608589\" y=\"101.59375\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.390429\" y=\"110.318736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.027687\" y=\"122.525807\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.667361\" y=\"38.326326\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.64613\" y=\"91.321178\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"96.587818\" y=\"77.393835\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.031757\" y=\"49.56985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.687921\" y=\"85.533263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.260207\" y=\"72.671207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"92.050953\" y=\"99.386596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.476967\" y=\"67.775845\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.306363\" y=\"74.056585\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"92.989877\" y=\"75.661508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"163.810489\" y=\"61.146314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.631908\" y=\"105.44496\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.028653\" y=\"37.429393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.080218\" y=\"78.800497\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.75805\" y=\"76.243697\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.333868\" y=\"65.434945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.884273\" y=\"95.744662\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.75585\" y=\"60.535636\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.694347\" y=\"87.970989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.355425\" y=\"86.192893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.322212\" y=\"57.788411\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"169.078373\" y=\"75.358756\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"203.677167\" y=\"35.551553\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.900537\" y=\"78.30334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.003074\" y=\"64.711556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.375884\" y=\"101.88973\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.776485\" y=\"97.819789\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.548848\" y=\"88.734081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"174.623095\" y=\"45.330227\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"166.504097\" y=\"44.209348\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.490532\" y=\"76.632356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"42.223604\" y=\"108.769978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"79.483809\" y=\"100.102314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.557705\" y=\"88.620482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.493029\" y=\"96.788656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.602751\" y=\"60.901465\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.314864\" y=\"93.607883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.405215\" y=\"74.933473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.2544\" y=\"82.22746\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.82136\" y=\"95.62631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.820357\" y=\"60.61157\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.426303\" y=\"81.496522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.750114\" y=\"41.516842\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.995442\" y=\"88.36295\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.801026\" y=\"70.030588\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.461677\" y=\"78.772412\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.195137\" y=\"69.940603\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.935805\" y=\"72.17007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"76.383706\" y=\"108.453568\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.861479\" y=\"66.977319\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.519279\" y=\"121.685772\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.620947\" y=\"96.364357\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.402655\" y=\"83.36262\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.037137\" y=\"77.685671\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.506589\" y=\"77.021255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"177.185268\" y=\"81.933449\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.590134\" y=\"56.89179\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.6819\" y=\"109.930138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.241482\" y=\"46.477058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.572872\" y=\"107.725896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.637728\" y=\"95.836344\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"212.651217\" y=\"25.80849\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.587829\" y=\"83.93642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"180.754959\" y=\"41.798879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.633346\" y=\"100.699816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.661397\" y=\"132.059178\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.076599\" y=\"61.119264\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.355169\" y=\"102.003628\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.63579\" y=\"90.938355\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"62.976754\" y=\"135.076353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.202629\" y=\"89.697253\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.238987\" y=\"84.102082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"168.109165\" y=\"70.643879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.793745\" y=\"77.271077\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.972281\" y=\"118.26173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.883808\" y=\"100.42625\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.039785\" y=\"85.449113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.66428\" y=\"91.51232\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.241492\" y=\"98.445219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.03768\" y=\"69.827219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"75.822165\" y=\"96.551888\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.904047\" y=\"69.991721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.273474\" y=\"77.144345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.75058\" y=\"53.943991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.731207\" y=\"42.491325\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.123343\" y=\"71.860096\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.473095\" y=\"71.452624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"76.20589\" y=\"87.64505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.625086\" y=\"59.370096\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.623662\" y=\"71.761607\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.872865\" y=\"59.617879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.328513\" y=\"76.742222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.067496\" y=\"104.341687\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.101\" y=\"68.026442\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"84.540093\" y=\"87.193492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.715822\" y=\"69.71948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.45679\" y=\"45.774082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.390465\" y=\"64.811021\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.321209\" y=\"54.048753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.308722\" y=\"47.273691\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.437076\" y=\"79.306596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.410571\" y=\"90.852565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.786144\" y=\"66.468719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.533711\" y=\"63.262394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.389089\" y=\"65.665216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.792984\" y=\"89.563288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.134847\" y=\"66.439287\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.283384\" y=\"83.170556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.321473\" y=\"65.386806\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.674786\" y=\"94.60237\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.015272\" y=\"77.253336\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.597825\" y=\"40.351655\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.524061\" y=\"79.915883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.986621\" y=\"52.793148\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.451529\" y=\"74.635042\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.319855\" y=\"91.09296\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.287857\" y=\"73.305529\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"81.69111\" y=\"88.123721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.736298\" y=\"93.357726\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.638866\" y=\"96.797956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"63.749778\" y=\"101.376634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.916784\" y=\"59.779791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.478063\" y=\"83.17462\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.579643\" y=\"58.26251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.260889\" y=\"93.280006\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.856746\" y=\"89.448882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.132326\" y=\"92.86561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.64914\" y=\"76.563584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"78.98032\" y=\"73.075454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.448037\" y=\"59.21978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.196027\" y=\"66.063946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.623498\" y=\"93.067459\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"167.48427\" y=\"74.32969\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.613633\" y=\"120.319759\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.849133\" y=\"89.083226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.136872\" y=\"21.716144\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.194044\" y=\"67.650078\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.50902\" y=\"65.223208\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.345405\" y=\"97.346334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.290961\" y=\"110.278113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.149373\" y=\"55.04702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.172144\" y=\"36.320377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.482255\" y=\"66.727421\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.525141\" y=\"54.699249\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.40025\" y=\"68.524397\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.578988\" y=\"18.152251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.351455\" y=\"96.415787\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.619062\" y=\"53.098791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.703068\" y=\"55.945706\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.422522\" y=\"67.417656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"179.246541\" y=\"50.437323\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.299476\" y=\"53.971836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.247584\" y=\"60.758656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.829639\" y=\"108.205526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.127188\" y=\"67.258656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.219419\" y=\"82.418834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.733263\" y=\"77.876968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.098952\" y=\"82.143424\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.306709\" y=\"57.152768\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.29035\" y=\"94.68598\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"56.441672\" y=\"112.619282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.18383\" y=\"84.338058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.610361\" y=\"105.269701\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.990516\" y=\"90.123526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.297022\" y=\"103.768415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.657461\" y=\"90.380013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.048586\" y=\"55.457805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.176953\" y=\"80.84138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"161.15855\" y=\"70.947599\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"188.818438\" y=\"23.162991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.81954\" y=\"77.873558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"52.788866\" y=\"105.443857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.073555\" y=\"91.711486\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.648184\" y=\"44.255994\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.24535\" y=\"95.849579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.719859\" y=\"83.283928\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.82831\" y=\"47.93496\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.600949\" y=\"41.384245\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"170.925208\" y=\"78.467352\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.491491\" y=\"50.069211\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.285578\" y=\"94.835505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.612509\" y=\"108.472892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.57265\" y=\"104.72846\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.8394\" y=\"106.281367\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.025283\" y=\"51.793366\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.112622\" y=\"70.717656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"90.392245\" y=\"98.065695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.588362\" y=\"93.409271\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.28\" y=\"91.783085\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.005108\" y=\"60.077816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.487075\" y=\"51.08775\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.931134\" y=\"70.340151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.782326\" y=\"64.663011\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.487126\" y=\"55.93901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.874491\" y=\"54.780247\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.387538\" y=\"88.241005\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.230036\" y=\"81.15877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.805315\" y=\"81.571363\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"175.518051\" y=\"62.661631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.912117\" y=\"69.693332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.50853\" y=\"74.384589\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.022979\" y=\"98.598832\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.308852\" y=\"66.33793\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.66247\" y=\"125.79795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.230846\" y=\"98.4751\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.927235\" y=\"64.56139\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.136891\" y=\"81.606658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.011061\" y=\"98.219326\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.433355\" y=\"94.831201\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"90.01999\" y=\"104.699339\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.124803\" y=\"89.41371\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.731162\" y=\"72.784708\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.449115\" y=\"87.411776\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.901989\" y=\"52.687565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.230845\" y=\"50.725829\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.264013\" y=\"65.130989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"174.363999\" y=\"63.986565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.755118\" y=\"80.834248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.336992\" y=\"81.052541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.442112\" y=\"68.298331\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.985402\" y=\"63.476082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.662602\" y=\"84.375522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.727325\" y=\"73.802402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"91.581023\" y=\"91.968214\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"183.538607\" y=\"35.232469\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.842907\" y=\"78.597462\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.752634\" y=\"70.788778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.254133\" y=\"59.685314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.991266\" y=\"90.993283\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"51.962785\" y=\"129.760231\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.49515\" y=\"95.79107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.077792\" y=\"49.856484\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.310112\" y=\"86.650945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.556629\" y=\"84.532026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.689037\" y=\"63.882353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.347151\" y=\"56.071804\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.809807\" y=\"91.749217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.976101\" y=\"88.082351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.36503\" y=\"105.130473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"175.369996\" y=\"51.890282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.0653\" y=\"58.570508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.694646\" y=\"59.913878\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.833458\" y=\"77.805222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.038152\" y=\"88.190008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.299748\" y=\"52.29818\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.303556\" y=\"74.407627\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.91774\" y=\"86.544145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"83.32546\" y=\"97.2812\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"209.389793\" y=\"47.401588\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"181.015184\" y=\"72.467508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"72.360497\" y=\"117.705185\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.733952\" y=\"77.578839\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.36438\" y=\"68.35539\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.414222\" y=\"67.610349\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.119107\" y=\"29.829656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"80.299656\" y=\"101.365519\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.623621\" y=\"65.258895\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.323999\" y=\"77.986457\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.074237\" y=\"22.041043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"161.23561\" y=\"82.919953\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"63.623552\" y=\"139.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.357694\" y=\"93.679042\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.611059\" y=\"110.310029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.936631\" y=\"96.225358\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.522297\" y=\"51.327124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.057859\" y=\"58.736199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.800353\" y=\"66.047748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.564327\" y=\"80.562145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.434737\" y=\"122.612181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.082975\" y=\"72.588527\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.615517\" y=\"68.419977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.593645\" y=\"69.203448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.359412\" y=\"99.604671\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.507215\" y=\"95.278895\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"91.779967\" y=\"116.960095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.826354\" y=\"62.502891\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.243687\" y=\"75.34703\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.302767\" y=\"65.876611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"175.021664\" y=\"59.436446\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.267938\" y=\"94.729298\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"171.014277\" y=\"65.936659\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.896302\" y=\"66.413173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.794339\" y=\"71.617763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.880567\" y=\"65.554642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"169.210858\" y=\"50.537598\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.656678\" y=\"60.66267\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.911634\" y=\"85.850677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.673002\" y=\"69.59409\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"189.161769\" y=\"33.39075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.753796\" y=\"84.740389\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.063714\" y=\"56.896367\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.889163\" y=\"80.144903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.337622\" y=\"78.820328\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.048405\" y=\"90.114192\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.60175\" y=\"90.689906\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.546441\" y=\"86.676935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.150959\" y=\"100.273606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.452988\" y=\"71.28935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.797849\" y=\"93.395327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.605712\" y=\"75.908799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.511792\" y=\"47.334452\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.202954\" y=\"42.681032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.34902\" y=\"68.254932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.52931\" y=\"121.483361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.118569\" y=\"92.04012\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.717182\" y=\"84.291729\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.564481\" y=\"80.507211\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.997267\" y=\"111.456825\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.925205\" y=\"70.558834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.319636\" y=\"99.113743\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.278791\" y=\"79.203896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"178.434161\" y=\"43.082933\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"167.558883\" y=\"49.999154\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.350653\" y=\"80.905868\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.014254\" y=\"53.759361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.995502\" y=\"57.926678\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"160.34066\" y=\"30.864672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.452077\" y=\"84.073393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.964594\" y=\"85.092948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.420073\" y=\"59.609608\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.2422\" y=\"85.599525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.279531\" y=\"37.233837\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.299046\" y=\"57.501901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.090431\" y=\"136.476002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.285742\" y=\"93.124352\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.883758\" y=\"79.8113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.341734\" y=\"62.819942\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.614272\" y=\"81.136541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.947694\" y=\"106.779282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.874459\" y=\"73.861437\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.434917\" y=\"107.285008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.587661\" y=\"86.318162\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.568218\" y=\"41.339427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.334003\" y=\"98.494541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.792341\" y=\"55.854203\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.765284\" y=\"74.743863\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"65.950443\" y=\"96.890186\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.953128\" y=\"68.410737\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.076785\" y=\"86.884353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"165.077753\" y=\"48.318827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.557638\" y=\"82.182124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.465336\" y=\"43.483263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.999096\" y=\"72.569612\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"175.658194\" y=\"72.806161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.614113\" y=\"47.114905\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"78.097028\" y=\"49.194621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.168313\" y=\"66.412408\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.900855\" y=\"105.564466\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.904687\" y=\"100.306264\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"90.283924\" y=\"106.950633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.055145\" y=\"64.954008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.513609\" y=\"90.1105\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.437905\" y=\"86.995488\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.146056\" y=\"62.85089\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.417844\" y=\"93.940841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"161.497704\" y=\"79.150901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.479509\" y=\"68.84641\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.86093\" y=\"101.662611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.037075\" y=\"49.77235\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.592107\" y=\"69.579363\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.298391\" y=\"111.892028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.540151\" y=\"60.302929\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.701447\" y=\"103.65314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.675451\" y=\"15.765491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.119625\" y=\"94.586921\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.41555\" y=\"54.787315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.166349\" y=\"83.67882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.124819\" y=\"68.62897\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.697529\" y=\"82.079448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.465559\" y=\"67.164617\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.395364\" y=\"97.354337\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.4787\" y=\"90.121634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.71934\" y=\"79.292481\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.647301\" y=\"61.17923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.39114\" y=\"64.295246\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"68.965886\" y=\"116.605219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.765768\" y=\"82.715272\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.540192\" y=\"92.86394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"83.89068\" y=\"70.888666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"165.89304\" y=\"13.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"176.577749\" y=\"69.149559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.099286\" y=\"42.032186\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"171.240875\" y=\"57.837107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.595161\" y=\"75.377153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"54.132348\" y=\"131.895592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.467119\" y=\"59.141719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.744611\" y=\"111.353278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.646477\" y=\"96.236795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.454028\" y=\"64.276207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.72858\" y=\"60.290799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"86.81705\" y=\"106.724808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.66873\" y=\"85.050771\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.426944\" y=\"107.254549\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.781012\" y=\"111.184544\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.073136\" y=\"95.462359\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"175.5756\" y=\"67.259161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.399948\" y=\"70.232714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.661228\" y=\"49.957704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.02515\" y=\"66.102736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.587138\" y=\"83.945404\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.828517\" y=\"77.177288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.246521\" y=\"76.923153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"85.757621\" y=\"90.314048\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.148795\" y=\"62.515236\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.402578\" y=\"59.281458\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"71.00132\" y=\"101.318345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"163.57908\" y=\"64.226513\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"73.297553\" y=\"102.041242\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.14116\" y=\"77.644053\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.532508\" y=\"91.387142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"215.364915\" y=\"27.810463\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.557131\" y=\"81.917821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.399975\" y=\"89.348764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.696899\" y=\"35.092983\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.216523\" y=\"65.048166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.750923\" y=\"43.871166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.567312\" y=\"75.364399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.841989\" y=\"76.088841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"174.497954\" y=\"72.693093\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"82.079833\" y=\"83.175531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.359196\" y=\"79.505546\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"86.410509\" y=\"100.975342\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"81.404638\" y=\"124.807206\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.355983\" y=\"90.983812\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.025712\" y=\"83.077619\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.753408\" y=\"83.761282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.473648\" y=\"87.596558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"76.848333\" y=\"84.604151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.54825\" y=\"116.228875\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"72.241611\" y=\"77.64884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.800053\" y=\"113.955505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.94458\" y=\"68.287306\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.352201\" y=\"71.528892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.151741\" y=\"74.031821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.390124\" y=\"98.097999\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.295013\" y=\"48.35415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.282461\" y=\"86.280172\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.137694\" y=\"67.597294\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.418614\" y=\"77.180758\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"180.585042\" y=\"64.412474\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.505276\" y=\"112.626968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.83676\" y=\"95.91145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"81.953483\" y=\"79.49606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.450492\" y=\"84.052712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.20357\" y=\"83.414741\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.473731\" y=\"75.428867\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.974924\" y=\"78.310834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.555073\" y=\"70.326748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.47176\" y=\"73.301386\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.135547\" y=\"71.147066\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.265214\" y=\"99.081935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.139364\" y=\"78.237334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.121391\" y=\"89.874683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.026376\" y=\"74.284852\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.496048\" y=\"72.372303\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.263738\" y=\"75.555399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"66.330597\" y=\"121.223819\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.496239\" y=\"80.050575\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"163.746725\" y=\"78.240407\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.019036\" y=\"75.147613\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.167031\" y=\"102.542952\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.733378\" y=\"87.033987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.758837\" y=\"45.301327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.225777\" y=\"91.822422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.013595\" y=\"76.642438\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.577436\" y=\"77.949601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.717064\" y=\"30.519615\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.419942\" y=\"73.579209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.874708\" y=\"82.110649\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.592761\" y=\"79.188468\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"70.614825\" y=\"104.574014\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.928618\" y=\"61.68454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"173.787735\" y=\"62.090174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.897787\" y=\"64.382054\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.262547\" y=\"114.576675\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.003667\" y=\"93.266282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.857955\" y=\"45.160321\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.470098\" y=\"104.21218\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.86453\" y=\"71.754109\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.791658\" y=\"68.087322\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.37824\" y=\"81.411749\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.522723\" y=\"50.130527\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.619915\" y=\"50.705691\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.740067\" y=\"63.967413\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.503223\" y=\"57.232677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.90262\" y=\"84.365181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.082842\" y=\"77.832046\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"73.714402\" y=\"113.094996\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.922321\" y=\"91.140991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.429953\" y=\"105.741195\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.251272\" y=\"68.392803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.652541\" y=\"75.12353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.281016\" y=\"90.649089\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.225874\" y=\"104.070657\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.851862\" y=\"63.468873\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.874801\" y=\"82.86794\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.361829\" y=\"85.608542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.679553\" y=\"97.206753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.433652\" y=\"68.260558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.707459\" y=\"56.226981\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.466984\" y=\"60.232185\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.211002\" y=\"51.873542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"191.749207\" y=\"18.103516\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.151989\" y=\"93.246023\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.586849\" y=\"73.027207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.664094\" y=\"43.075637\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"92.632218\" y=\"67.577574\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.688456\" y=\"79.029583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.443717\" y=\"119.915368\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.064883\" y=\"83.74487\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"166.324197\" y=\"76.370095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.687512\" y=\"92.48442\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"184.488892\" y=\"49.338792\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"74.158453\" y=\"100.184448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.142167\" y=\"97.096052\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.452225\" y=\"67.031251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.464654\" y=\"87.363325\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"180.956995\" y=\"21.562226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"169.849401\" y=\"69.816669\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.234793\" y=\"78.500167\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.43934\" y=\"89.430395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.511813\" y=\"91.456843\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.525078\" y=\"56.366234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.370516\" y=\"64.606874\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.840956\" y=\"78.651995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.986175\" y=\"72.41565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"67.812426\" y=\"107.662652\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.24277\" y=\"99.172621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.122348\" y=\"96.370217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.984574\" y=\"79.02333\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"78.10275\" y=\"89.016402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.469622\" y=\"104.754022\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.055326\" y=\"96.801986\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.311371\" y=\"111.927308\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.977943\" y=\"82.793202\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"181.183955\" y=\"41.859056\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.899333\" y=\"93.851658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.641859\" y=\"60.980031\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.884806\" y=\"74.145029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"82.031302\" y=\"94.163492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.943946\" y=\"68.159095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.227504\" y=\"102.06078\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.542706\" y=\"57.863059\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.00117\" y=\"85.641259\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.462926\" y=\"94.75956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.415666\" y=\"112.293427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.501266\" y=\"90.257794\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.875095\" y=\"65.223327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.522966\" y=\"83.79076\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.38404\" y=\"75.850764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"191.302369\" y=\"55.738297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.952036\" y=\"72.706857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"90.052766\" y=\"78.429072\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.100739\" y=\"73.384083\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.68414\" y=\"88.150926\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"83.949254\" y=\"84.380879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.488359\" y=\"89.189101\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.403712\" y=\"62.18428\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.634546\" y=\"71.018209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.618662\" y=\"70.038488\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.950225\" y=\"72.531255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.796374\" y=\"74.393081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.97434\" y=\"53.162821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.619682\" y=\"121.830153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.26606\" y=\"80.320939\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.049219\" y=\"64.345249\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.42358\" y=\"80.548704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.697011\" y=\"63.643561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.620693\" y=\"81.658512\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.167502\" y=\"101.152384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.36571\" y=\"66.060699\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.537929\" y=\"92.592949\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.695567\" y=\"67.56122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.542432\" y=\"90.036556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"168.065405\" y=\"57.539528\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.202409\" y=\"79.329016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.17291\" y=\"78.861112\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.472423\" y=\"83.921422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.067353\" y=\"75.450786\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.600733\" y=\"66.182709\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.687881\" y=\"98.983666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.388839\" y=\"65.131705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.364471\" y=\"69.319809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.523987\" y=\"78.456473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.684456\" y=\"51.867579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"66.500922\" y=\"82.685242\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.931686\" y=\"73.055611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.580351\" y=\"84.355827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.128055\" y=\"87.599534\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.042181\" y=\"93.319693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.098316\" y=\"67.56309\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.452956\" y=\"63.42464\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"181.400577\" y=\"48.451007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.510389\" y=\"55.90116\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.469543\" y=\"62.556877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.694968\" y=\"67.885119\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.093586\" y=\"77.585043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"85.199189\" y=\"87.156956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.044037\" y=\"58.183763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.598942\" y=\"82.54097\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.157904\" y=\"63.575948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.28948\" y=\"76.863967\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.132618\" y=\"99.133675\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.697074\" y=\"66.921095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"182.751259\" y=\"52.645248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.206545\" y=\"79.424332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.563205\" y=\"63.33256\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.903969\" y=\"39.476263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"85.87899\" y=\"86.515271\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.267502\" y=\"99.654722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.307719\" y=\"91.443661\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.555387\" y=\"93.766817\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.017868\" y=\"72.543665\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.969671\" y=\"96.980838\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.293017\" y=\"93.142453\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"78.994584\" y=\"130.32799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.427291\" y=\"37.928601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"166.354605\" y=\"62.978298\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.483096\" y=\"73.937807\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.54527\" y=\"88.439678\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.541587\" y=\"109.732608\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.425463\" y=\"97.713903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.188517\" y=\"51.397677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.721828\" y=\"69.78173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.177918\" y=\"71.655387\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.965602\" y=\"74.834836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"188.57917\" y=\"52.43887\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.583692\" y=\"78.713174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.018702\" y=\"70.531854\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.213885\" y=\"61.076881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.605197\" y=\"74.547729\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.640975\" y=\"52.674687\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.011495\" y=\"59.810942\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.194426\" y=\"61.533266\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.221769\" y=\"105.538605\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.302124\" y=\"83.827882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.453243\" y=\"73.022932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.00141\" y=\"72.99407\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.698996\" y=\"64.55689\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.138168\" y=\"83.376626\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.811148\" y=\"91.934398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.818379\" y=\"85.236683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.508163\" y=\"80.325857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.762443\" y=\"53.38592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.850859\" y=\"86.51086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.383111\" y=\"68.541043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"68.207159\" y=\"100.24009\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.417239\" y=\"118.103977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.672379\" y=\"90.561111\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.416054\" y=\"69.697515\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.346262\" y=\"62.456778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.383049\" y=\"94.957518\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.253293\" y=\"92.102869\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.880967\" y=\"66.853116\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"84.0285\" y=\"90.435422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.009441\" y=\"71.333254\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.573869\" y=\"103.614709\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.573603\" y=\"98.96007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.108641\" y=\"81.294635\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.700306\" y=\"81.23083\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"85.120846\" y=\"102.947303\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.863831\" y=\"79.235428\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"91.39912\" y=\"82.178295\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.719783\" y=\"91.059508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.136266\" y=\"86.045153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.852558\" y=\"65.405451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.931748\" y=\"69.00258\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"171.923474\" y=\"82.574475\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"81.203872\" y=\"115.920234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.399908\" y=\"89.551559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.549853\" y=\"77.133567\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.650045\" y=\"68.029976\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.900625\" y=\"84.591819\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.236454\" y=\"95.674044\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.441901\" y=\"83.951852\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"178.453651\" y=\"48.107719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"78.528815\" y=\"91.144692\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"84.272931\" y=\"77.966158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.235085\" y=\"101.867718\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.639236\" y=\"69.104578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.173343\" y=\"95.437832\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.640558\" y=\"91.398395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.366991\" y=\"82.985289\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.357063\" y=\"113.470475\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.19085\" y=\"87.582783\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.92588\" y=\"80.594545\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"163.507434\" y=\"75.882131\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.130443\" y=\"83.48542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.525102\" y=\"75.831255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"171.416936\" y=\"84.442152\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.333151\" y=\"66.885205\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.185721\" y=\"87.367559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"92.657561\" y=\"75.389946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.15855\" y=\"62.102534\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.341837\" y=\"89.780347\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.317039\" y=\"73.903159\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"71.70301\" y=\"115.759169\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.533778\" y=\"99.445677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.90197\" y=\"100.660773\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.346168\" y=\"95.951702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.431077\" y=\"91.992748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.271051\" y=\"93.511792\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.176293\" y=\"93.644631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"193.891924\" y=\"39.124589\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.574687\" y=\"89.347345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.69041\" y=\"69.862951\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.956908\" y=\"101.115803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.691024\" y=\"68.037402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m6ff9f381ac\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6ff9f381ac\" x=\"69.573382\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −2 -->\n",
       "      <g transform=\"translate(62.202288 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6ff9f381ac\" x=\"125.776441\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(122.595191 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6ff9f381ac\" x=\"181.979501\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(178.798251 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <defs>\n",
       "       <path id=\"m28622f4ef6\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m28622f4ef6\" x=\"28.942188\" y=\"125.71812\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- −5 -->\n",
       "      <g transform=\"translate(7.2 129.517339) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m28622f4ef6\" x=\"28.942188\" y=\"99.751174\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(15.579688 103.550393) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m28622f4ef6\" x=\"28.942188\" y=\"73.784228\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(15.579688 77.583446) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m28622f4ef6\" x=\"28.942188\" y=\"47.817281\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(9.217188 51.6165) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m28622f4ef6\" x=\"28.942188\" y=\"21.850335\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(9.217188 25.649554) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 28.942188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 224.242188 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 28.942188 7.2 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p4610e2cf3f\">\n",
       "   <rect x=\"28.942188\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘图，查看分布\n",
    "d2l.set_figsize()\n",
    "d2l.plt.scatter(features[:, (0)].detach().numpy(), \n",
    "                labels.detach().numpy(), 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2. <a id='toc8_1_2_'></a>[读取数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5976, -0.0429],\n",
      "        [ 0.1977, -0.1523],\n",
      "        [-0.5405,  0.9828],\n",
      "        [ 0.3401,  1.6607],\n",
      "        [ 0.2554, -0.0479],\n",
      "        [ 0.3899, -0.1485],\n",
      "        [-0.6512,  0.4294],\n",
      "        [-1.3002,  0.3497],\n",
      "        [ 0.4402, -0.2496],\n",
      "        [ 0.0964, -0.1336]]) \n",
      " tensor([[ 3.1606],\n",
      "        [ 5.1133],\n",
      "        [-0.2223],\n",
      "        [-0.7653],\n",
      "        [ 4.8709],\n",
      "        [ 5.4846],\n",
      "        [ 1.4428],\n",
      "        [ 0.3982],\n",
      "        [ 5.9351],\n",
      "        [ 4.8515]])\n"
     ]
    }
   ],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # 这些样本是随机读取的，没有特定的顺序\n",
    "    random.shuffle(indices)                                 # 把原来的indices顺序给打乱了\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "batch_size = 10\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.3. <a id='toc8_1_3_'></a>[初始化模型参数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.normal(mean=0, std=0.01, size=(2,1), requires_grad=True)\n",
    "b = torch.zeros(size=(1,), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.4. <a id='toc8_1_4_'></a>[定义模型](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b): \n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return torch.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.5. <a id='toc8_1_5_'></a>[定义损失函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):  \n",
    "    \"\"\"均方损失\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.6. <a id='toc8_1_6_'></a>[定义优化算法](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):  \n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.7. <a id='toc8_1_7_'></a>[训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000051\n",
      "epoch 2, loss 0.000056\n",
      "epoch 3, loss 0.000051\n",
      "epoch 4, loss 0.000050\n",
      "epoch 5, loss 0.000048\n",
      "epoch 6, loss 0.000052\n",
      "epoch 7, loss 0.000052\n",
      "epoch 8, loss 0.000049\n",
      "epoch 9, loss 0.000049\n",
      "epoch 10, loss 0.000049\n",
      "w的估计误差: tensor([-0.0010,  0.0004], grad_fn=<SubBackward0>)\n",
      "b的估计误差: tensor([-0.0013], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "num_epochs = 10\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y)  # X和y的小批量损失\n",
    "        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n",
    "        # 并以此计算关于[w,b]的梯度\n",
    "        l.sum().backward()\n",
    "        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n",
    "\n",
    "print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')\n",
    "print(f'b的估计误差: {true_b - b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. <a id='toc8_2_'></a>[现线性回归模型于训练过程-简洁实现](#toc0_)\n",
    "### 8.2.1. <a id='toc8_2_1_'></a>[虚拟数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2. <a id='toc8_2_2_'></a>[读取数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3. <a id='toc8_2_3_'></a>[定义模型](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn是神经网络的缩写\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.4. <a id='toc8_2_4_'></a>[初始化模型参数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.5. <a id='toc8_2_5_'></a>[定义损失函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.6. <a id='toc8_2_6_'></a>[定义优化算法](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "trainer = optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.7. <a id='toc8_2_7_'></a>[训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000298\n",
      "epoch 2, loss 0.000098\n",
      "epoch 3, loss 0.000099\n",
      "epoch 4, loss 0.000098\n",
      "epoch 5, loss 0.000100\n",
      "epoch 6, loss 0.000099\n",
      "epoch 7, loss 0.000099\n",
      "epoch 8, loss 0.000099\n",
      "epoch 9, loss 0.000100\n",
      "epoch 10, loss 0.000098\n",
      "w的估计误差： tensor([-0.0003,  0.0004])\n",
      "b的估计误差： tensor([-0.0004])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        y_hat = net(X)                  # 1. 计算y_hat\n",
    "        loss = loss_fn(y_hat ,y)        # 2. 计算loss值\n",
    "        trainer.zero_grad()\n",
    "        loss.backward()                 # 2. 求梯度           \n",
    "        trainer.step()                  # 3. 更新网络权重参数\n",
    "    train_loss = loss_fn(net(features), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {train_loss:f}')\n",
    "\n",
    "w = net[0].weight.data\n",
    "print('w的估计误差：', true_w - w.reshape(true_w.shape))\n",
    "b = net[0].bias.data\n",
    "print('b的估计误差：', true_b - b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.8. <a id='toc8_2_8_'></a>[参数保存](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"epoch\": num_epochs, \n",
    "        'mode_state_dict': net.state_dict(), \n",
    "        'opt_state_dict': trainer.state_dict(), \n",
    "        'loss': 'loss'\n",
    "    }, \n",
    "    'Pytorch_params/line_params.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.9. <a id='toc8_2_9_'></a>[重载](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0603])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32820/1977999358.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  check_point = torch.load('./Pytorch_params/line_params.pt')\n"
     ]
    }
   ],
   "source": [
    "check_point = torch.load('./Pytorch_params/line_params.pt')\n",
    "\n",
    "new_net = net = nn.Sequential(nn.Linear(2, 1))\n",
    "new_net.load_state_dict(check_point['mode_state_dict'])\n",
    "\n",
    "new_opt = optim.SGD(new_net.parameters(), lr=0.03)\n",
    "new_opt.load_state_dict(check_point['opt_state_dict'])\n",
    "\n",
    "# Stop BN、Dropout ...\n",
    "new_net.eval()\n",
    "\n",
    "# 停止计算梯度，节省运算和内存\n",
    "with torch.no_grad():\n",
    "    pre = new_net(torch.Tensor([3.0, 2.1]))\n",
    "    print(pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. <a id='toc8_3_'></a>[专题-模型定义（计算预测值）](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1. <a id='toc8_3_1_'></a>[torch.nn模块](#toc0_)\n",
    "```shell\n",
    "1. 简单、快速，但不够灵活\n",
    "```\n",
    "```shell\n",
    "优点：\n",
    "    一般，pytorch的nn.Sequentail类就比较方便的快速构建神经网络的框架；\n",
    "    同时，nn也包含了很多完整的神经网络如：CNN、RNN等；\n",
    "缺点：\n",
    "    高度封装，需要复杂的自定义神经网络时就不适用了。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(786, 256), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(256, 256), \n",
    "    nn.Tanh(),\n",
    "    nn.Linear(256, 10), \n",
    "    nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2. <a id='toc8_3_2_'></a>[自定义-块](#toc0_)\n",
    "```shell\n",
    "2. 灵活，但麻烦\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2.1. <a id='toc8_3_2_1_'></a>[自定义块](#toc0_)\n",
    "\n",
    "* 从编程的角度看：块就是Class\n",
    "\n",
    "* `nn.Module`会自动调用`forward()`方法，我们也可以重写该方法，从而实现更加灵活的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''定义每个块或层'''\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''正向传播'''\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2.2. <a id='toc8_3_2_2_'></a>[顺序块](#toc0_)\n",
    "```\n",
    "Sequential就是顺序块，这里我们自己从头实现一边Sequential这个方法\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Sequential()\n",
    "\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "\n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2.3. <a id='toc8_3_2_3_'></a>[效率](#toc0_)\n",
    "```shell\n",
    "1. 一个块可以由许多层组成；一个块可以由许多块组成。\n",
    "2. 块可以包含代码。\n",
    "3. 块负责大量的内部处理，包括参数初始化和反向传播。\n",
    "4. 层和块的顺序连接由Sequential块处理。\n",
    "```\n",
    "```shell\n",
    "读者可能会开始担心操作效率的问题。 毕竟，我们在一个高性能的深度学习库中进行了大量的字典查找、 代码执行和许多其他的Python代码。 Python的问题全局解释器锁 是众所周知的。 在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.3. <a id='toc8_3_3_'></a>[参数管理](#toc0_)\n",
    "\n",
    "* 其实可以将`nn.Sequential`视为Python的`list数据结构`，`按顺序`储存神经网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2042],\n",
       "        [-0.1571]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 8), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.3.1. <a id='toc8_3_3_1_'></a>[参数访问](#toc0_)\n",
    "\n",
    "* 我们从已有模型中访问参数；\n",
    "\n",
    "* 当通过 `Sequential类` 定义模型时，我们可以通过 `索引 (下标)` 来访问模型的任意层；\n",
    "\n",
    "* `自定义的重载nn.Module` 的layer1、layer2等等，需要net`.`layer1或net`.`layer2方式进行调用；\n",
    "\n",
    "* 这就像模型是一个列表一样，每层的参数都在其属性中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net # nn.Sequential类，可以直接用下标进行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=4, out_features=8, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=8, out_features=1, bias=True))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0], net[1], net[2] # nn.Sequential类，可以直接用下标进行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4, out_features=8, bias=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.4562, -0.3295,  0.2082,  0.0261],\n",
       "                      [ 0.1554, -0.3213,  0.0664,  0.0268],\n",
       "                      [-0.0912, -0.3404,  0.1334,  0.1549],\n",
       "                      [ 0.1729,  0.3674, -0.3309, -0.1862],\n",
       "                      [-0.2319, -0.2233, -0.4803,  0.2378],\n",
       "                      [ 0.0542,  0.1492,  0.0696,  0.0975],\n",
       "                      [-0.1176, -0.0453,  0.1025, -0.4154],\n",
       "                      [-0.0219,  0.3421, -0.0907, -0.1268]])),\n",
       "             ('bias',\n",
       "              tensor([0.1891, 0.3493, 0.4254, 0.4983, 0.3337, 0.0840, 0.3323, 0.1119]))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=1, bias=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n输出的结果告诉我们一些重要的事情： \\n    首先，这个全连接层包含两个参数，分别是该层的权重和偏置。 \\n    两者都存储为单精度浮点数（float32）。 \\n    注意，参数名称允许唯一标识每个参数，即使在包含数百个层的网络中也是如此。\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].state_dict()\n",
    "'''\n",
    "输出的结果告诉我们一些重要的事情： \n",
    "    首先，这个全连接层包含两个参数，分别是该层的权重和偏置。 \n",
    "    两者都存储为单精度浮点数（float32）。 \n",
    "    注意，参数名称允许唯一标识每个参数，即使在包含数百个层的网络中也是如此。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0815, -0.1555, -0.1977, -0.1848, -0.0943, -0.3376, -0.1224,  0.1511]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0815, -0.1555, -0.1977, -0.1848, -0.0943, -0.3376, -0.1224,  0.1511]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.data # 访问目标参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.1018], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1018])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].bias.data # 访问目标参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.4562, -0.3295,  0.2082,  0.0261],\n",
       "                      [ 0.1554, -0.3213,  0.0664,  0.0268],\n",
       "                      [-0.0912, -0.3404,  0.1334,  0.1549],\n",
       "                      [ 0.1729,  0.3674, -0.3309, -0.1862],\n",
       "                      [-0.2319, -0.2233, -0.4803,  0.2378],\n",
       "                      [ 0.0542,  0.1492,  0.0696,  0.0975],\n",
       "                      [-0.1176, -0.0453,  0.1025, -0.4154],\n",
       "                      [-0.0219,  0.3421, -0.0907, -0.1268]])),\n",
       "             ('0.bias',\n",
       "              tensor([0.1891, 0.3493, 0.4254, 0.4983, 0.3337, 0.0840, 0.3323, 0.1119])),\n",
       "             ('2.weight',\n",
       "              tensor([[-0.0815, -0.1555, -0.1977, -0.1848, -0.0943, -0.3376, -0.1224,  0.1511]])),\n",
       "             ('2.bias', tensor([0.1018]))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以直接输出神经网络的所有层参数信息，net[1]是relu激活函数，没有参数，所以就显示无\n",
    "# 后续，torch.save(net.state_dict(), 'Pytorch_datasets/net_params)\n",
    "net.state_dict() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.3.2. <a id='toc8_3_3_2_'></a>[参数初始化](#toc0_)\n",
    "\n",
    "* 初始化，主要是为了不要再一开始训练就炸掉了，其实不用太迷信了。\n",
    "\n",
    "* 默认情况下，PyTorch会根据一个范围均匀地初始化权重和偏置矩阵， 这个范围是根据输入和输出维度计算出的。 \n",
    "\n",
    "* PyTorch的nn.init模块提供了多种预置初始化方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.3.3.2.1. <a id='toc8_3_3_2_1_'></a>[内置初始化](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = net[0]\n",
    "nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.3.3.2.2. <a id='toc8_3_3_2_2_'></a>[自定义初始化](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.3.3.2.3. <a id='toc8_3_3_2_3_'></a>[参数绑定](#toc0_)\n",
    "```\n",
    "有时我们希望在多个层间共享参数： 我们可以定义一个稠密层，然后使用它的参数来设置另一个层的参数。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# 我们需要给共享层一个名称，以便可以引用它的参数\n",
    "shared = nn.Linear(8, 8)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 8), \n",
    "    nn.ReLU(),\n",
    "    shared, \n",
    "    nn.ReLU(),\n",
    "    shared, \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "net(X)\n",
    "\n",
    "# 检查参数是否相同\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "\n",
    "net[2].weight.data[0, 0] = 100\n",
    "\n",
    "# 确保它们实际上是同一个对象，而不只是有相同的值\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.4. <a id='toc8_3_4_'></a>[自定义-层](#toc0_)\n",
    "```shell\n",
    "深度学习成功背后的一个因素是神经网络的灵活性： \n",
    "我们可以用创造性的方式组合不同的层，从而设计出适用于各种任务的架构。 \n",
    "例如，研究人员发明了专门用于处理图像、文本、序列数据和执行动态规划的层。 \n",
    "有时我们会遇到或要自己发明一个现在在深度学习框架中还不存在的层。 \n",
    "在这些情况下，必须构建自定义层。本节将展示如何构建自定义层。\n",
    "```\n",
    "```shell\n",
    "块和层其实并无本质的区别，因为都是torch.nn.Module的子类\n",
    "\n",
    "e.g. \n",
    "    全连接层（FC）\n",
    "    池化层（Pooling）\n",
    "    BN层\n",
    "    Dropout层\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.4.1. <a id='toc8_3_4_1_'></a>[不带参数的层](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  0.,  1.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()\n",
    "    \n",
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-9.3132e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在，我们可以将层作为组件合并到更复杂的模型中。\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(8, 128), \n",
    "    CenteredLayer()\n",
    ")\n",
    "\n",
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.4.2. <a id='toc8_3_4_2_'></a>[带参数的层](#toc0_)\n",
    "\n",
    "用到`nn.Parameter()`可以将参数加入神经网络中，便于自动管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000],\n",
       "        [0.1466, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units)) \n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)\n",
    "    \n",
    "linear = MyLinear(5, 3)\n",
    "# linear.weight\n",
    "\n",
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们还可以使用自定义层构建模型，就像使用内置的全连接层一样使用自定义层。\n",
    "net = nn.Sequential(\n",
    "    MyLinear(64, 8), \n",
    "    MyLinear(8, 1)\n",
    ")\n",
    "\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4. <a id='toc8_4_'></a>[专题-损失函数](#toc0_)\n",
    "- 损失函数的输入是 (output, target) ，即网络输出和真实标签对的数据，然后返回一个数值表示网络输出和真实标签的差距。\n",
    "\n",
    "  1. 均方误差\n",
    "\n",
    "  2. 交叉熵\n",
    "  \n",
    "  3. 自定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.1. <a id='toc8_4_1_'></a>[均方误差](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.2. <a id='toc8_4_2_'></a>[交叉熵](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.3. <a id='toc8_4_3_'></a>[自定义](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y, y_hat):\n",
    "    '''例如真实值于预测值之差'''\n",
    "    error_values = y - y_hat\n",
    "    return error_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5. <a id='toc8_5_'></a>[专题-反向传播（求梯度）](#toc0_)\n",
    "```\n",
    "求梯度（求偏导数）\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 见autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6. <a id='toc8_6_'></a>[专题-更新权重（优化算法）](#toc0_)\n",
    "```\n",
    "优化算法\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.1. <a id='toc8_6_1_'></a>[小批量梯度下降（SGD）](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.SGD(params=net.parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.2. <a id='toc8_6_2_'></a>[adam](#toc0_)\n",
    "```shell\n",
    "Adam对lr不敏感\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.Adam(params=net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.3. <a id='toc8_6_3_'></a>[RMSprop](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSprop (\n",
       "Parameter Group 0\n",
       "    alpha: 0.99\n",
       "    centered: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.RMSprop(params=net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7. <a id='toc8_7_'></a>[专题-训练](#toc0_)\n",
    "\n",
    "![Train step via pure PyTorch](./Pytorch_Pictures/PyTorch_graphacial_demo/Train_step_via_pure_PyTorch.jpg)\n",
    "\n",
    "```shell\n",
    "训练的模板代码\n",
    "```\n",
    "```sehll\n",
    "net.train():\n",
    "    启用 Batch Normalization 和 Dropout。\n",
    "    如果模型中有BN层(Batch Normalization）和Dropout，需要在训练时添加model.train()\n",
    "    model.train()作用： \n",
    "                        对BN层，保证BN层能够用到每一批数据的均值和方差，并进行计算更新；\n",
    "                        对于Dropout，model.train()是随机取一部分网络连接来训练更新参数。\n",
    "\n",
    "net.eval()\n",
    "    不启用 Batch Normalization 和 Dropout。\n",
    "    如果模型中有BN层(Batch Normalization）和Dropout，在测试时添加model.eval()。\n",
    "    model.eval()是保证BN层直接利用之前训练阶段得到的均值和方差，即测试过程中要保证BN层的均值和方差不变；\n",
    "                        对于Dropout，model.eval()是利用到了所有网络连接，即不进行随机舍弃神经元。\n",
    "                        \n",
    "with torch.no_grad():\n",
    "    pass\n",
    "\n",
    "    无论是train() 还是eval() 模式，各层的gradient计算和存储都在进行且完全一致。\n",
    "    而with torch.no_grad()则主要是用于停止autograd模块的工作，以起到加速和节省显存的作用。\n",
    "    它的作用是将该with语句包裹起来的部分停止梯度的更新，从而节省了GPU算力和显存，但是并不会影响dropout和BN层的行为。\n",
    "    若想节约算力，可在test阶段带上torch.no_grad()，示例代码：\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 3659860.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Pytorch_datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 119645.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Pytorch_datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 912416.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Pytorch_datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 17224709.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Pytorch_datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 数据准备\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "# import torch.nn.functional as F \n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 256), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10), \n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.network(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程封装\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "import IPython.display as display\n",
    "import os\n",
    "\n",
    "def train_steps(\n",
    "        epochs, \n",
    "        train_dataset, \n",
    "        train_iter, \n",
    "        test_dataset, \n",
    "        net, \n",
    "        loss_fn, \n",
    "        opt, \n",
    "        device, \n",
    "        train_figure = False, \n",
    "        resume = False, \n",
    "        PATH = 'Pytorch_params/weights'\n",
    "    ):\n",
    "    '''\n",
    "    参数记录:\n",
    "            epochs = epochs                         # epoch\n",
    "            train_dataset = train_dataset           # 全部train数据集\n",
    "            train_iter = train_iter                 # batch之后的train数据集\n",
    "            test_dataset = test_dataset             # 全部test数据集\n",
    "            net = net                               # 网络模型\n",
    "            loss_fn = loss_fn                       # 损失函数\n",
    "            opt = opt                               # 优化器\n",
    "            device = device                         # device GPU/CPU\n",
    "            train_figure = False                    # 可视化训练过程\n",
    "            resume = False                          # 断点续训\n",
    "    '''\n",
    "    # 拷贝数据和模型到device上\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    ## 数据\n",
    "    train_all_data_gpu = train_dataset.data.to(device)                                      # .to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)                                # .to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)                                        # .to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)                                  # .to(device)\n",
    "    ## 模型\n",
    "    net.to(device)                                                                          # .to(device)\n",
    "\n",
    "    def dl_plot(epochs:int, epoch_list:list, train_loss_list:list, train_acc_list:list, test_acc_list:list):\n",
    "        '''绘图'''\n",
    "        plt.rcParams['font.sans-serif']=['Times new roman', 'Arial', 'KaiTi']\n",
    "        plt.style.context(['ggplot', 'seaborn'])\n",
    "        \n",
    "        plt.close()\n",
    "        fig = plt.figure(figsize=(3.0, 3.0))\n",
    "\n",
    "        # for y, label in zip([train_loss_list, train_acc_list, test_acc_list], ['train_loss', 'train_acc', 'test_acc']):\n",
    "        for y, label in zip([train_acc_list, test_acc_list], ['train_acc', 'test_acc']):\n",
    "            plt.plot(epoch_list, y, label=label)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.xlim((1, epochs))\n",
    "        plt.ylabel('Values')\n",
    "        plt.ylim((0, 1))\n",
    "        plt.yticks(torch.arange(0, 1, 0.05).numpy())\n",
    "        # plt.tight_layout()\n",
    "\n",
    "        display.display(fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    epoch_list = []\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "    best_test_acc = 0\n",
    "\n",
    "    # 断点续训\n",
    "    start_epoch = 0\n",
    "    if resume:\n",
    "        if os.path.isfile(PATH+'/last.pt'):\n",
    "            check_point = torch.load(PATH+'/last.pt')\n",
    "            start_epoch = check_point['epoch']\n",
    "            net.load_state_dict(check_point['model_state_dict'])\n",
    "            opt.load_state_dict(check_point['opt_state_dict'])\n",
    "        else:\n",
    "            print(f'没有训练记录。')\n",
    "        \n",
    "    print('start_epoch: ', start_epoch)\n",
    "    for epoch in range(start_epoch, epochs, 1):\n",
    "        net.train()                             # 训练模式\n",
    "        epoch_list.append(epoch+1)\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   ## 复制到device（GPU/CPU）上                    # .to(device)\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            y_hat = net(X)                      # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)            # 计算loss\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            loss.backward()                     # 计算梯度\n",
    "            opt.step()                          # 更新网络参数\n",
    "\n",
    "        net.eval()                              # 切换至评估模式\n",
    "                                                # 模型默认是net.train()\n",
    "                                                # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                                                # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad():                   # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            train_loss_list.append(train_loss.item())\n",
    "            # print(train_loss)\n",
    "\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) \n",
    "            train_acc_list.append(train_acc.item())\n",
    "            # print(train_acc)\n",
    "\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp))\n",
    "            test_acc_list.append(test_acc.item())\n",
    "            # print(test_acc)\n",
    "\n",
    "            if train_figure:\n",
    "                if epoch % 1 == 0:\n",
    "                    dl_plot(epochs, epoch_list, train_loss_list, train_acc_list, test_acc_list)\n",
    "            else:\n",
    "                print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "        # 保存权重参数：last.pt和best.pt\n",
    "        torch.save({'epoch':epoch, 'model_state_dict':net.state_dict(), 'opt_state_dict':opt.state_dict(), 'loss':test_acc}, PATH+'/last.pt') \n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            torch.save({'epoch':epoch, 'model_state_dict':net.state_dict(), 'opt_state_dict':opt.state_dict(), 'loss':test_acc}, PATH+'/best.pt') \n",
    "\n",
    "    stop = time.time()\n",
    "    print('='*100)\n",
    "    print(f\"耗时： {stop - start} seconds.\")\n",
    "    return (train_loss, train_acc, test_acc)\n",
    "    # return (epoch_list, train_loss_list, train_acc_list, test_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程封装\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "import IPython.display as display\n",
    "import os\n",
    "\n",
    "def training_step(\n",
    "        epochs, \n",
    "        train_dataset, \n",
    "        train_iter, \n",
    "        test_dataset, \n",
    "        net, \n",
    "        loss_fn, \n",
    "        opt, \n",
    "        device, \n",
    "        train_figure = False, \n",
    "        resume = False, \n",
    "        PATH = 'Pytorch_params/weights'):\n",
    "    '''\n",
    "    训练过程\n",
    "    params:\n",
    "            epochs = epochs                         # epoch\n",
    "            train_dataset = train_dataset           # 全部train数据集\n",
    "            train_iter = train_iter                 # batch之后的train数据集\n",
    "            test_dataset = test_dataset             # 全部test数据集\n",
    "            net = net                               # 网络模型\n",
    "            loss_fn = loss_fn                       # 损失函数\n",
    "            opt = opt                               # 优化器\n",
    "            device = device                         # device GPU/CPU\n",
    "            train_figure = False                    # 可视化训练过程\n",
    "            resume = False                          # 断点续训\n",
    "    return:\n",
    "            tra_loss, val_loss, val_acc, test_loss, test_acc\n",
    "    '''\n",
    "    # 拷贝数据和模型到device上\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    ## 数据\n",
    "    train_all_data_gpu = train_dataset.data.to(device)                                      # .to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)                                # .to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)                                        # .to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)                                  # .to(device)\n",
    "    ## 模型\n",
    "    net.to(device)                                                                          # .to(device)\n",
    "\n",
    "    def dl_plot(epochs:int, epoch_list:list, train_loss_list:list, train_acc_list:list, test_acc_list:list):\n",
    "        '''绘图'''\n",
    "        plt.rcParams['font.sans-serif']=['Times new roman', 'Arial', 'KaiTi']\n",
    "        plt.style.context(['ggplot', 'seaborn'])\n",
    "        \n",
    "        plt.close()\n",
    "        fig = plt.figure(figsize=(3.0, 3.0))\n",
    "\n",
    "        # for y, label in zip([train_loss_list, train_acc_list, test_acc_list], ['train_loss', 'train_acc', 'test_acc']):\n",
    "        for y, label in zip([train_acc_list, test_acc_list], ['train_acc', 'test_acc']):\n",
    "            plt.plot(epoch_list, y, label=label)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.xlim((1, epochs))\n",
    "        plt.ylabel('Values')\n",
    "        plt.ylim((0, 1))\n",
    "        plt.yticks(torch.arange(0, 1, 0.05).numpy())\n",
    "        # plt.tight_layout()\n",
    "\n",
    "        display.display(fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    epoch_list = []\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "    best_test_acc = 0\n",
    "\n",
    "    # 断点续训\n",
    "    start_epoch = 0\n",
    "    if resume:\n",
    "        if os.path.isfile(PATH+'/last.pt'):\n",
    "            check_point = torch.load(PATH+'/last.pt')\n",
    "            start_epoch = check_point['epoch']\n",
    "            net.load_state_dict(check_point['model_state_dict'])\n",
    "            opt.load_state_dict(check_point['opt_state_dict'])\n",
    "        else:\n",
    "            print(f'没有训练记录。')\n",
    "        \n",
    "    print('start_epoch: ', start_epoch)\n",
    "    for epoch in range(start_epoch, epochs, 1):\n",
    "        net.train()                             # 训练模式\n",
    "        epoch_list.append(epoch+1)\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   ## 复制到device（GPU/CPU）上                    # .to(device)\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            y_hat = net(X)                      # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)            # 计算loss\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            loss.backward()                     # 计算梯度\n",
    "            opt.step()                          # 更新网络参数\n",
    "\n",
    "        net.eval()                              # 切换至评估模式\n",
    "                                                # 模型默认是net.train()\n",
    "                                                # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                                                # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad():                   # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            train_loss_list.append(train_loss.item())\n",
    "            # print(train_loss)\n",
    "\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) \n",
    "            train_acc_list.append(train_acc.item())\n",
    "            # print(train_acc)\n",
    "\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp))\n",
    "            test_acc_list.append(test_acc.item())\n",
    "            # print(test_acc)\n",
    "\n",
    "            if train_figure:\n",
    "                if epoch % 1 == 0:\n",
    "                    dl_plot(epochs, epoch_list, train_loss_list, train_acc_list, test_acc_list)\n",
    "            else:\n",
    "                print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "        # 保存权重参数：last.pt和best.pt\n",
    "        torch.save({'epoch':epoch, 'model_state_dict':net.state_dict(), 'opt_state_dict':opt.state_dict(), 'loss':test_acc}, PATH+'/last.pt') \n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            torch.save({'epoch':epoch, 'model_state_dict':net.state_dict(), 'opt_state_dict':opt.state_dict(), 'loss':test_acc}, PATH+'/best.pt') \n",
    "\n",
    "    stop = time.time()\n",
    "    print('='*100)\n",
    "    print(f\"耗时： {stop - start} seconds.\")\n",
    "    return (train_loss, train_acc, test_acc)\n",
    "    # return (epoch_list, train_loss_list, train_acc_list, test_acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.1. <a id='toc8_7_1_'></a>[开始训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 59.95664095878601 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.7594, device='cuda:0'),\n",
       " tensor(0.7902, device='cuda:0'),\n",
       " tensor(0.8000, device='cuda:0'))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 开始训练\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.01)\n",
    "\n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device, \n",
    "    train_figure=True, \n",
    "    resume = False, \n",
    "    PATH = './Pytorch_params/weights'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32820/198423743.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best = torch.load('./Pytorch_params/weights/best.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9,\n",
       " tensor(0.8000, device='cuda:0'),\n",
       " OrderedDict([('network.1.weight',\n",
       "               tensor([[-0.0241, -0.0069,  0.0088,  ..., -0.0267, -0.0129, -0.0065],\n",
       "                       [ 0.0302, -0.0323,  0.0237,  ..., -0.0168,  0.0240,  0.0341],\n",
       "                       [-0.0151,  0.0176, -0.0027,  ...,  0.0083, -0.0131,  0.0065],\n",
       "                       ...,\n",
       "                       [ 0.0030,  0.0136, -0.0048,  ..., -0.0145, -0.0219, -0.0337],\n",
       "                       [-0.0136, -0.0261,  0.0065,  ..., -0.0004,  0.0057,  0.0013],\n",
       "                       [-0.0356, -0.0046, -0.0026,  ..., -0.0298,  0.0247,  0.0137]],\n",
       "                      device='cuda:0')),\n",
       "              ('network.1.bias',\n",
       "               tensor([ 3.9702e-02,  3.4285e-02,  4.3656e-02, -7.5687e-04,  4.5628e-02,\n",
       "                       -1.5764e-03,  9.1527e-03,  1.2884e-02,  5.1464e-02,  1.3203e-02,\n",
       "                        3.2777e-02,  2.3281e-02, -7.0645e-07, -2.0750e-02,  1.0967e-02,\n",
       "                        1.6538e-02, -3.8702e-02,  1.7775e-02,  4.1511e-02,  1.2678e-02,\n",
       "                        2.1664e-02, -2.0623e-02,  3.2701e-02,  2.3492e-02,  4.9457e-03,\n",
       "                        3.9780e-02, -1.1985e-02,  4.2158e-02,  5.6506e-02,  2.7593e-02,\n",
       "                        9.5884e-03,  2.4593e-02,  5.3445e-03,  1.0407e-02, -2.9220e-02,\n",
       "                       -7.0291e-03,  1.5674e-02, -1.9235e-02,  2.1151e-02,  2.2816e-02,\n",
       "                        7.4965e-03,  5.0568e-02, -8.6301e-03, -1.1696e-02,  1.7590e-02,\n",
       "                        5.1232e-02, -1.1965e-02,  3.1024e-02,  3.3625e-02,  1.2786e-02,\n",
       "                        2.7856e-02,  2.0230e-02,  1.9761e-02,  4.9548e-02,  4.0749e-02,\n",
       "                        1.2994e-02,  5.2624e-02,  2.0533e-02,  2.9313e-02,  6.8340e-03,\n",
       "                       -2.8082e-02,  1.5062e-02, -3.0884e-02, -2.3156e-02, -2.2881e-03,\n",
       "                        2.6252e-03, -3.0055e-02, -1.5311e-02,  3.1937e-02,  3.6528e-02,\n",
       "                        3.3189e-02, -1.0149e-02,  2.0503e-02, -1.4367e-02,  4.2755e-02,\n",
       "                       -1.9800e-02, -1.1765e-02,  3.1096e-02,  2.9567e-02, -2.6079e-02,\n",
       "                        2.4057e-02,  2.8671e-02,  6.5098e-03,  1.6217e-02,  1.6545e-02,\n",
       "                        1.9598e-02,  3.9184e-02, -1.1046e-02,  6.2070e-03,  3.1246e-02,\n",
       "                        9.4902e-03,  3.0827e-02, -1.2420e-02, -1.8113e-02, -7.5191e-03,\n",
       "                       -2.3051e-02,  1.2938e-02, -1.2393e-02, -2.3524e-02, -9.9774e-03,\n",
       "                        8.9223e-03,  3.3172e-02,  3.3347e-02,  1.9719e-02, -5.4457e-03,\n",
       "                        1.0521e-02, -2.5926e-03,  3.6220e-03, -8.9649e-03,  3.5096e-03,\n",
       "                        3.9662e-02,  8.8037e-03,  2.5711e-02, -6.7204e-03, -8.7729e-03,\n",
       "                        1.3268e-02,  2.2215e-02, -7.2406e-03,  1.6775e-03, -1.3178e-02,\n",
       "                        2.2741e-02, -1.6813e-02,  6.5540e-03,  4.7898e-02,  1.7329e-02,\n",
       "                       -1.8237e-02,  2.3492e-02, -2.1715e-02,  3.1797e-02, -2.3865e-03,\n",
       "                        1.9146e-03,  2.0191e-02,  2.1575e-02, -5.3633e-03,  1.5864e-02,\n",
       "                        4.8251e-02, -1.8978e-03, -2.8512e-03,  3.3479e-02,  3.3359e-02,\n",
       "                       -2.1005e-02,  1.0200e-04, -2.5433e-02, -8.3805e-03,  5.2502e-02,\n",
       "                       -2.7321e-02,  6.5998e-02,  8.3883e-03,  2.5566e-02,  8.6262e-03,\n",
       "                       -2.2832e-02,  4.9074e-02, -2.7729e-02, -6.6179e-03,  3.1971e-02,\n",
       "                        4.1276e-02, -2.6954e-02, -9.3661e-03, -6.8694e-03,  1.2666e-02,\n",
       "                       -1.8432e-02, -3.2942e-02,  3.6010e-02,  1.3340e-02,  1.3230e-02,\n",
       "                        1.2177e-03, -4.0268e-03,  2.4358e-02, -1.4252e-02,  1.7725e-02,\n",
       "                        1.4390e-02,  4.5555e-02,  4.3820e-03, -9.9201e-03,  2.5283e-03,\n",
       "                       -1.3692e-02, -3.6250e-02,  2.1885e-03,  3.5891e-02,  2.4769e-02,\n",
       "                        9.7989e-03,  4.4549e-02,  1.1250e-02,  2.9513e-04, -8.4876e-03,\n",
       "                       -1.0764e-02, -5.3896e-03,  3.9276e-02,  3.1027e-02,  1.1406e-02,\n",
       "                        3.0260e-02,  1.2267e-02,  4.6958e-03,  3.7215e-02,  3.9977e-02,\n",
       "                        3.3820e-02, -1.0931e-02,  1.0565e-02,  1.1181e-02, -1.3401e-02,\n",
       "                        3.6825e-02,  4.5035e-02, -2.7077e-02, -2.0625e-02, -1.2974e-02,\n",
       "                       -2.3754e-02,  3.1041e-02,  4.6583e-02,  5.2671e-02, -1.2074e-02,\n",
       "                       -1.2163e-02, -2.2311e-02, -1.4121e-02, -2.3022e-02,  1.5178e-02,\n",
       "                        2.2413e-02,  2.1362e-02, -1.1371e-02, -2.4531e-02,  3.2458e-02,\n",
       "                        2.1671e-02,  3.3461e-02,  6.0620e-03,  2.3813e-02,  4.7138e-02,\n",
       "                       -3.1214e-02, -2.6454e-03, -2.5188e-02,  3.4154e-02,  2.0549e-02,\n",
       "                       -9.4273e-03,  2.9883e-02, -8.0837e-03,  4.4898e-02,  5.3602e-03,\n",
       "                       -2.3646e-02,  2.8702e-02,  2.7271e-02,  5.5416e-02, -2.3502e-02,\n",
       "                        1.4266e-02, -4.1066e-02,  3.4123e-02,  2.6651e-02,  3.1687e-02,\n",
       "                        2.6590e-02, -3.7192e-03,  2.8239e-02,  5.7477e-03, -2.0121e-02,\n",
       "                        5.4461e-03,  3.0526e-02, -9.5012e-03,  2.7479e-02, -2.8464e-02,\n",
       "                        4.6071e-02], device='cuda:0')),\n",
       "              ('network.3.weight',\n",
       "               tensor([[-0.0505, -0.1163, -0.0902,  ..., -0.0762,  0.0453,  0.0470],\n",
       "                       [ 0.0724,  0.1765,  0.0936,  ..., -0.0425,  0.0104, -0.0149],\n",
       "                       [-0.0884, -0.0270,  0.0364,  ..., -0.0410, -0.0254, -0.0206],\n",
       "                       ...,\n",
       "                       [-0.0540,  0.0514, -0.1432,  ..., -0.1346, -0.0148,  0.1571],\n",
       "                       [ 0.0946,  0.0494,  0.0184,  ...,  0.0630,  0.0512, -0.0797],\n",
       "                       [ 0.0776,  0.0689, -0.0066,  ..., -0.0522,  0.0436, -0.0084]],\n",
       "                      device='cuda:0')),\n",
       "              ('network.3.bias',\n",
       "               tensor([-0.0526,  0.1243, -0.0987,  0.0301,  0.0522, -0.0409,  0.0423,  0.0652,\n",
       "                       -0.1231,  0.0462], device='cuda:0'))]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = torch.load('./Pytorch_params/weights/best.pt')\n",
    "best['epoch'], best['loss'], best['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 70.18707489967346 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.7867), tensor(0.7317), tensor(0.7402))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 再试一次，会不会造成net的parameter的累加，结果表明不会\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()   \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.01)  \n",
    "    \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device, \n",
    "            train_figure=True, \n",
    "            resume = False\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.2. <a id='toc8_7_2_'></a>[自己探索](#toc0_)\n",
    "#### 8.7.2.1. <a id='toc8_7_2_1_'></a>[lr的影响](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 69.80070853233337 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.4991), tensor(0.9673), tensor(0.9614))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()      \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device, \n",
    "    train_figure=True\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.7.2.2. <a id='toc8_7_2_2_'></a>[不同模型的效率](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 87.9712917804718 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.4962), tensor(0.9704), tensor(0.9643))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"335.982812pt\" height=\"265.325625pt\" viewBox=\"0 0 335.982812 265.325625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-04-25T11:13:04.145402</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 265.325625 \n",
       "L 335.982812 265.325625 \n",
       "L 335.982812 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "L 44.782812 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 44.782812 228.96 \n",
       "L 44.782812 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m92953bacde\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"44.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(42.282812 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-31\" d=\"M 750 3822 \n",
       "L 1781 4325 \n",
       "L 1884 4325 \n",
       "L 1884 747 \n",
       "Q 1884 391 1914 303 \n",
       "Q 1944 216 2037 169 \n",
       "Q 2131 122 2419 116 \n",
       "L 2419 0 \n",
       "L 825 0 \n",
       "L 825 116 \n",
       "Q 1125 122 1212 167 \n",
       "Q 1300 213 1334 289 \n",
       "Q 1369 366 1369 747 \n",
       "L 1369 3034 \n",
       "Q 1369 3497 1338 3628 \n",
       "Q 1316 3728 1258 3775 \n",
       "Q 1200 3822 1119 3822 \n",
       "Q 1003 3822 797 3725 \n",
       "L 750 3822 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 75.782813 228.96 \n",
       "L 75.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"75.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(73.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-32\" d=\"M 2934 816 \n",
       "L 2638 0 \n",
       "L 138 0 \n",
       "L 138 116 \n",
       "Q 1241 1122 1691 1759 \n",
       "Q 2141 2397 2141 2925 \n",
       "Q 2141 3328 1894 3587 \n",
       "Q 1647 3847 1303 3847 \n",
       "Q 991 3847 742 3664 \n",
       "Q 494 3481 375 3128 \n",
       "L 259 3128 \n",
       "Q 338 3706 661 4015 \n",
       "Q 984 4325 1469 4325 \n",
       "Q 1984 4325 2329 3994 \n",
       "Q 2675 3663 2675 3213 \n",
       "Q 2675 2891 2525 2569 \n",
       "Q 2294 2063 1775 1497 \n",
       "Q 997 647 803 472 \n",
       "L 1909 472 \n",
       "Q 2247 472 2383 497 \n",
       "Q 2519 522 2628 598 \n",
       "Q 2738 675 2819 816 \n",
       "L 2934 816 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 106.782813 228.96 \n",
       "L 106.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"106.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 3 -->\n",
       "      <g transform=\"translate(104.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-33\" d=\"M 325 3431 \n",
       "Q 506 3859 782 4092 \n",
       "Q 1059 4325 1472 4325 \n",
       "Q 1981 4325 2253 3994 \n",
       "Q 2459 3747 2459 3466 \n",
       "Q 2459 3003 1878 2509 \n",
       "Q 2269 2356 2469 2072 \n",
       "Q 2669 1788 2669 1403 \n",
       "Q 2669 853 2319 450 \n",
       "Q 1863 -75 997 -75 \n",
       "Q 569 -75 414 31 \n",
       "Q 259 138 259 259 \n",
       "Q 259 350 332 419 \n",
       "Q 406 488 509 488 \n",
       "Q 588 488 669 463 \n",
       "Q 722 447 909 348 \n",
       "Q 1097 250 1169 231 \n",
       "Q 1284 197 1416 197 \n",
       "Q 1734 197 1970 444 \n",
       "Q 2206 691 2206 1028 \n",
       "Q 2206 1275 2097 1509 \n",
       "Q 2016 1684 1919 1775 \n",
       "Q 1784 1900 1550 2001 \n",
       "Q 1316 2103 1072 2103 \n",
       "L 972 2103 \n",
       "L 972 2197 \n",
       "Q 1219 2228 1467 2375 \n",
       "Q 1716 2522 1828 2728 \n",
       "Q 1941 2934 1941 3181 \n",
       "Q 1941 3503 1739 3701 \n",
       "Q 1538 3900 1238 3900 \n",
       "Q 753 3900 428 3381 \n",
       "L 325 3431 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 137.782813 228.96 \n",
       "L 137.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"137.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(135.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-34\" d=\"M 2978 1563 \n",
       "L 2978 1119 \n",
       "L 2409 1119 \n",
       "L 2409 0 \n",
       "L 1894 0 \n",
       "L 1894 1119 \n",
       "L 100 1119 \n",
       "L 100 1519 \n",
       "L 2066 4325 \n",
       "L 2409 4325 \n",
       "L 2409 1563 \n",
       "L 2978 1563 \n",
       "z\n",
       "M 1894 1563 \n",
       "L 1894 3666 \n",
       "L 406 1563 \n",
       "L 1894 1563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 168.782813 228.96 \n",
       "L 168.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"168.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(166.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-35\" d=\"M 2778 4238 \n",
       "L 2534 3706 \n",
       "L 1259 3706 \n",
       "L 981 3138 \n",
       "Q 1809 3016 2294 2522 \n",
       "Q 2709 2097 2709 1522 \n",
       "Q 2709 1188 2573 903 \n",
       "Q 2438 619 2231 419 \n",
       "Q 2025 219 1772 97 \n",
       "Q 1413 -75 1034 -75 \n",
       "Q 653 -75 479 54 \n",
       "Q 306 184 306 341 \n",
       "Q 306 428 378 495 \n",
       "Q 450 563 559 563 \n",
       "Q 641 563 702 538 \n",
       "Q 763 513 909 409 \n",
       "Q 1144 247 1384 247 \n",
       "Q 1750 247 2026 523 \n",
       "Q 2303 800 2303 1197 \n",
       "Q 2303 1581 2056 1914 \n",
       "Q 1809 2247 1375 2428 \n",
       "Q 1034 2569 447 2591 \n",
       "L 1259 4238 \n",
       "L 2778 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 199.782813 228.96 \n",
       "L 199.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"199.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(197.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-36\" d=\"M 2869 4325 \n",
       "L 2869 4209 \n",
       "Q 2456 4169 2195 4045 \n",
       "Q 1934 3922 1679 3669 \n",
       "Q 1425 3416 1258 3105 \n",
       "Q 1091 2794 978 2366 \n",
       "Q 1428 2675 1881 2675 \n",
       "Q 2316 2675 2634 2325 \n",
       "Q 2953 1975 2953 1425 \n",
       "Q 2953 894 2631 456 \n",
       "Q 2244 -75 1606 -75 \n",
       "Q 1172 -75 869 213 \n",
       "Q 275 772 275 1663 \n",
       "Q 275 2231 503 2743 \n",
       "Q 731 3256 1154 3653 \n",
       "Q 1578 4050 1965 4187 \n",
       "Q 2353 4325 2688 4325 \n",
       "L 2869 4325 \n",
       "z\n",
       "M 925 2138 \n",
       "Q 869 1716 869 1456 \n",
       "Q 869 1156 980 804 \n",
       "Q 1091 453 1309 247 \n",
       "Q 1469 100 1697 100 \n",
       "Q 1969 100 2183 356 \n",
       "Q 2397 613 2397 1088 \n",
       "Q 2397 1622 2184 2012 \n",
       "Q 1972 2403 1581 2403 \n",
       "Q 1463 2403 1327 2353 \n",
       "Q 1191 2303 925 2138 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 230.782813 228.96 \n",
       "L 230.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"230.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 7 -->\n",
       "      <g transform=\"translate(228.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-37\" d=\"M 644 4238 \n",
       "L 2916 4238 \n",
       "L 2916 4119 \n",
       "L 1503 -88 \n",
       "L 1153 -88 \n",
       "L 2419 3728 \n",
       "L 1253 3728 \n",
       "Q 900 3728 750 3644 \n",
       "Q 488 3500 328 3200 \n",
       "L 238 3234 \n",
       "L 644 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-37\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 261.782812 228.96 \n",
       "L 261.782812 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"261.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(259.282812 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-38\" d=\"M 1228 2134 \n",
       "Q 725 2547 579 2797 \n",
       "Q 434 3047 434 3316 \n",
       "Q 434 3728 753 4026 \n",
       "Q 1072 4325 1600 4325 \n",
       "Q 2113 4325 2425 4047 \n",
       "Q 2738 3769 2738 3413 \n",
       "Q 2738 3175 2569 2928 \n",
       "Q 2400 2681 1866 2347 \n",
       "Q 2416 1922 2594 1678 \n",
       "Q 2831 1359 2831 1006 \n",
       "Q 2831 559 2490 242 \n",
       "Q 2150 -75 1597 -75 \n",
       "Q 994 -75 656 303 \n",
       "Q 388 606 388 966 \n",
       "Q 388 1247 577 1523 \n",
       "Q 766 1800 1228 2134 \n",
       "z\n",
       "M 1719 2469 \n",
       "Q 2094 2806 2194 3001 \n",
       "Q 2294 3197 2294 3444 \n",
       "Q 2294 3772 2109 3958 \n",
       "Q 1925 4144 1606 4144 \n",
       "Q 1288 4144 1088 3959 \n",
       "Q 888 3775 888 3528 \n",
       "Q 888 3366 970 3203 \n",
       "Q 1053 3041 1206 2894 \n",
       "L 1719 2469 \n",
       "z\n",
       "M 1375 2016 \n",
       "Q 1116 1797 991 1539 \n",
       "Q 866 1281 866 981 \n",
       "Q 866 578 1086 336 \n",
       "Q 1306 94 1647 94 \n",
       "Q 1984 94 2187 284 \n",
       "Q 2391 475 2391 747 \n",
       "Q 2391 972 2272 1150 \n",
       "Q 2050 1481 1375 2016 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 292.782812 228.96 \n",
       "L 292.782812 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"292.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 9 -->\n",
       "      <g transform=\"translate(290.282812 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-39\" d=\"M 338 -88 \n",
       "L 338 28 \n",
       "Q 744 34 1094 217 \n",
       "Q 1444 400 1770 856 \n",
       "Q 2097 1313 2225 1859 \n",
       "Q 1734 1544 1338 1544 \n",
       "Q 891 1544 572 1889 \n",
       "Q 253 2234 253 2806 \n",
       "Q 253 3363 572 3797 \n",
       "Q 956 4325 1575 4325 \n",
       "Q 2097 4325 2469 3894 \n",
       "Q 2925 3359 2925 2575 \n",
       "Q 2925 1869 2578 1258 \n",
       "Q 2231 647 1613 244 \n",
       "Q 1109 -88 516 -88 \n",
       "L 338 -88 \n",
       "z\n",
       "M 2275 2091 \n",
       "Q 2331 2497 2331 2741 \n",
       "Q 2331 3044 2228 3395 \n",
       "Q 2125 3747 1936 3934 \n",
       "Q 1747 4122 1506 4122 \n",
       "Q 1228 4122 1018 3872 \n",
       "Q 809 3622 809 3128 \n",
       "Q 809 2469 1088 2097 \n",
       "Q 1291 1828 1588 1828 \n",
       "Q 1731 1828 1928 1897 \n",
       "Q 2125 1966 2275 2091 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-39\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"323.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(318.782812 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-30\" d=\"M 231 2094 \n",
       "Q 231 2819 450 3342 \n",
       "Q 669 3866 1031 4122 \n",
       "Q 1313 4325 1613 4325 \n",
       "Q 2100 4325 2488 3828 \n",
       "Q 2972 3213 2972 2159 \n",
       "Q 2972 1422 2759 906 \n",
       "Q 2547 391 2217 158 \n",
       "Q 1888 -75 1581 -75 \n",
       "Q 975 -75 572 641 \n",
       "Q 231 1244 231 2094 \n",
       "z\n",
       "M 844 2016 \n",
       "Q 844 1141 1059 588 \n",
       "Q 1238 122 1591 122 \n",
       "Q 1759 122 1940 273 \n",
       "Q 2122 425 2216 781 \n",
       "Q 2359 1319 2359 2297 \n",
       "Q 2359 3022 2209 3506 \n",
       "Q 2097 3866 1919 4016 \n",
       "Q 1791 4119 1609 4119 \n",
       "Q 1397 4119 1231 3928 \n",
       "Q 1006 3669 925 3112 \n",
       "Q 844 2556 844 2016 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_11\">\n",
       "     <!-- Epoch -->\n",
       "     <g transform=\"translate(171.509375 255.986562) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-45\" d=\"M 1338 4006 \n",
       "L 1338 2331 \n",
       "L 2269 2331 \n",
       "Q 2631 2331 2753 2441 \n",
       "Q 2916 2584 2934 2947 \n",
       "L 3050 2947 \n",
       "L 3050 1472 \n",
       "L 2934 1472 \n",
       "Q 2891 1781 2847 1869 \n",
       "Q 2791 1978 2662 2040 \n",
       "Q 2534 2103 2269 2103 \n",
       "L 1338 2103 \n",
       "L 1338 706 \n",
       "Q 1338 425 1363 364 \n",
       "Q 1388 303 1450 267 \n",
       "Q 1513 231 1688 231 \n",
       "L 2406 231 \n",
       "Q 2766 231 2928 281 \n",
       "Q 3091 331 3241 478 \n",
       "Q 3434 672 3638 1063 \n",
       "L 3763 1063 \n",
       "L 3397 0 \n",
       "L 131 0 \n",
       "L 131 116 \n",
       "L 281 116 \n",
       "Q 431 116 566 188 \n",
       "Q 666 238 702 338 \n",
       "Q 738 438 738 747 \n",
       "L 738 3500 \n",
       "Q 738 3903 656 3997 \n",
       "Q 544 4122 281 4122 \n",
       "L 131 4122 \n",
       "L 131 4238 \n",
       "L 3397 4238 \n",
       "L 3444 3309 \n",
       "L 3322 3309 \n",
       "Q 3256 3644 3176 3769 \n",
       "Q 3097 3894 2941 3959 \n",
       "Q 2816 4006 2500 4006 \n",
       "L 1338 4006 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-70\" d=\"M -6 2578 \n",
       "L 875 2934 \n",
       "L 994 2934 \n",
       "L 994 2266 \n",
       "Q 1216 2644 1439 2795 \n",
       "Q 1663 2947 1909 2947 \n",
       "Q 2341 2947 2628 2609 \n",
       "Q 2981 2197 2981 1534 \n",
       "Q 2981 794 2556 309 \n",
       "Q 2206 -88 1675 -88 \n",
       "Q 1444 -88 1275 -22 \n",
       "Q 1150 25 994 166 \n",
       "L 994 -706 \n",
       "Q 994 -1000 1030 -1079 \n",
       "Q 1066 -1159 1155 -1206 \n",
       "Q 1244 -1253 1478 -1253 \n",
       "L 1478 -1369 \n",
       "L -22 -1369 \n",
       "L -22 -1253 \n",
       "L 56 -1253 \n",
       "Q 228 -1256 350 -1188 \n",
       "Q 409 -1153 442 -1076 \n",
       "Q 475 -1000 475 -688 \n",
       "L 475 2019 \n",
       "Q 475 2297 450 2372 \n",
       "Q 425 2447 370 2484 \n",
       "Q 316 2522 222 2522 \n",
       "Q 147 2522 31 2478 \n",
       "L -6 2578 \n",
       "z\n",
       "M 994 2081 \n",
       "L 994 1013 \n",
       "Q 994 666 1022 556 \n",
       "Q 1066 375 1236 237 \n",
       "Q 1406 100 1666 100 \n",
       "Q 1978 100 2172 344 \n",
       "Q 2425 663 2425 1241 \n",
       "Q 2425 1897 2138 2250 \n",
       "Q 1938 2494 1663 2494 \n",
       "Q 1513 2494 1366 2419 \n",
       "Q 1253 2363 994 2081 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6f\" d=\"M 1600 2947 \n",
       "Q 2250 2947 2644 2453 \n",
       "Q 2978 2031 2978 1484 \n",
       "Q 2978 1100 2793 706 \n",
       "Q 2609 313 2286 112 \n",
       "Q 1963 -88 1566 -88 \n",
       "Q 919 -88 538 428 \n",
       "Q 216 863 216 1403 \n",
       "Q 216 1797 411 2186 \n",
       "Q 606 2575 925 2761 \n",
       "Q 1244 2947 1600 2947 \n",
       "z\n",
       "M 1503 2744 \n",
       "Q 1338 2744 1170 2645 \n",
       "Q 1003 2547 900 2300 \n",
       "Q 797 2053 797 1666 \n",
       "Q 797 1041 1045 587 \n",
       "Q 1294 134 1700 134 \n",
       "Q 2003 134 2200 384 \n",
       "Q 2397 634 2397 1244 \n",
       "Q 2397 2006 2069 2444 \n",
       "Q 1847 2744 1503 2744 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-63\" d=\"M 2631 1088 \n",
       "Q 2516 522 2178 217 \n",
       "Q 1841 -88 1431 -88 \n",
       "Q 944 -88 581 321 \n",
       "Q 219 731 219 1428 \n",
       "Q 219 2103 620 2525 \n",
       "Q 1022 2947 1584 2947 \n",
       "Q 2006 2947 2278 2723 \n",
       "Q 2550 2500 2550 2259 \n",
       "Q 2550 2141 2473 2067 \n",
       "Q 2397 1994 2259 1994 \n",
       "Q 2075 1994 1981 2113 \n",
       "Q 1928 2178 1911 2362 \n",
       "Q 1894 2547 1784 2644 \n",
       "Q 1675 2738 1481 2738 \n",
       "Q 1169 2738 978 2506 \n",
       "Q 725 2200 725 1697 \n",
       "Q 725 1184 976 792 \n",
       "Q 1228 400 1656 400 \n",
       "Q 1963 400 2206 609 \n",
       "Q 2378 753 2541 1131 \n",
       "L 2631 1088 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-68\" d=\"M 1041 4444 \n",
       "L 1041 2350 \n",
       "Q 1388 2731 1591 2839 \n",
       "Q 1794 2947 1997 2947 \n",
       "Q 2241 2947 2416 2812 \n",
       "Q 2591 2678 2675 2391 \n",
       "Q 2734 2191 2734 1659 \n",
       "L 2734 647 \n",
       "Q 2734 375 2778 275 \n",
       "Q 2809 200 2884 156 \n",
       "Q 2959 113 3159 113 \n",
       "L 3159 0 \n",
       "L 1753 0 \n",
       "L 1753 113 \n",
       "L 1819 113 \n",
       "Q 2019 113 2097 173 \n",
       "Q 2175 234 2206 353 \n",
       "Q 2216 403 2216 647 \n",
       "L 2216 1659 \n",
       "Q 2216 2128 2167 2275 \n",
       "Q 2119 2422 2012 2495 \n",
       "Q 1906 2569 1756 2569 \n",
       "Q 1603 2569 1437 2487 \n",
       "Q 1272 2406 1041 2159 \n",
       "L 1041 647 \n",
       "Q 1041 353 1073 281 \n",
       "Q 1106 209 1195 161 \n",
       "Q 1284 113 1503 113 \n",
       "L 1503 0 \n",
       "L 84 0 \n",
       "L 84 113 \n",
       "Q 275 113 384 172 \n",
       "Q 447 203 484 290 \n",
       "Q 522 378 522 647 \n",
       "L 522 3238 \n",
       "Q 522 3728 498 3840 \n",
       "Q 475 3953 426 3993 \n",
       "Q 378 4034 297 4034 \n",
       "Q 231 4034 84 3984 \n",
       "L 41 4094 \n",
       "L 897 4444 \n",
       "L 1041 4444 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-45\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-70\" x=\"61.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6f\" x=\"111.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"161.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-68\" x=\"205.46875\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <defs>\n",
       "       <path id=\"m2ec95d50d3\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.00 -->\n",
       "      <g transform=\"translate(20.282812 232.431875) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-2e\" d=\"M 800 606 \n",
       "Q 947 606 1047 504 \n",
       "Q 1147 403 1147 259 \n",
       "Q 1147 116 1045 14 \n",
       "Q 944 -88 800 -88 \n",
       "Q 656 -88 554 14 \n",
       "Q 453 116 453 259 \n",
       "Q 453 406 554 506 \n",
       "Q 656 606 800 606 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 44.782812 217.872 \n",
       "L 323.782812 217.872 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"217.872\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.05 -->\n",
       "      <g transform=\"translate(20.282812 221.343875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path d=\"M 44.782812 206.784 \n",
       "L 323.782812 206.784 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_26\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"206.784\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.282812 210.255875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path d=\"M 44.782812 195.695999 \n",
       "L 323.782812 195.695999 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_28\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"195.695999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.282812 199.167874) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <path d=\"M 44.782812 184.607999 \n",
       "L 323.782812 184.607999 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_30\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"184.607999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 0.20 -->\n",
       "      <g transform=\"translate(20.282812 188.079874) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_31\">\n",
       "      <path d=\"M 44.782812 173.52 \n",
       "L 323.782812 173.52 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_32\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"173.52\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 0.25 -->\n",
       "      <g transform=\"translate(20.282812 176.991875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_33\">\n",
       "      <path d=\"M 44.782812 162.431997 \n",
       "L 323.782812 162.431997 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_34\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"162.431997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- 0.30 -->\n",
       "      <g transform=\"translate(20.282812 165.903872) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_35\">\n",
       "      <path d=\"M 44.782812 151.344001 \n",
       "L 323.782812 151.344001 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_36\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"151.344001\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 0.35 -->\n",
       "      <g transform=\"translate(20.282812 154.815876) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_37\">\n",
       "      <path d=\"M 44.782812 140.255999 \n",
       "L 323.782812 140.255999 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_38\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"140.255999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_20\">\n",
       "      <!-- 0.40 -->\n",
       "      <g transform=\"translate(20.282812 143.727874) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-34\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_39\">\n",
       "      <path d=\"M 44.782812 129.167996 \n",
       "L 323.782812 129.167996 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_40\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"129.167996\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_21\">\n",
       "      <!-- 0.45 -->\n",
       "      <g transform=\"translate(20.282812 132.639871) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-34\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_11\">\n",
       "     <g id=\"line2d_41\">\n",
       "      <path d=\"M 44.782812 118.08 \n",
       "L 323.782812 118.08 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_42\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"118.08\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_22\">\n",
       "      <!-- 0.50 -->\n",
       "      <g transform=\"translate(20.282812 121.551875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_12\">\n",
       "     <g id=\"line2d_43\">\n",
       "      <path d=\"M 44.782812 106.991997 \n",
       "L 323.782812 106.991997 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_44\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"106.991997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_23\">\n",
       "      <!-- 0.55 -->\n",
       "      <g transform=\"translate(20.282812 110.463872) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_13\">\n",
       "     <g id=\"line2d_45\">\n",
       "      <path d=\"M 44.782812 95.903995 \n",
       "L 323.782812 95.903995 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_46\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"95.903995\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_24\">\n",
       "      <!-- 0.60 -->\n",
       "      <g transform=\"translate(20.282812 99.37587) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-36\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_14\">\n",
       "     <g id=\"line2d_47\">\n",
       "      <path d=\"M 44.782812 84.816005 \n",
       "L 323.782812 84.816005 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_48\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"84.816005\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_25\">\n",
       "      <!-- 0.65 -->\n",
       "      <g transform=\"translate(20.282812 88.28788) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-36\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_15\">\n",
       "     <g id=\"line2d_49\">\n",
       "      <path d=\"M 44.782812 73.728003 \n",
       "L 323.782812 73.728003 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_50\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"73.728003\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_26\">\n",
       "      <!-- 0.70 -->\n",
       "      <g transform=\"translate(20.282812 77.199878) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-37\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_16\">\n",
       "     <g id=\"line2d_51\">\n",
       "      <path d=\"M 44.782812 62.64 \n",
       "L 323.782812 62.64 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_52\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"62.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_27\">\n",
       "      <!-- 0.75 -->\n",
       "      <g transform=\"translate(20.282812 66.111875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-37\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_17\">\n",
       "     <g id=\"line2d_53\">\n",
       "      <path d=\"M 44.782812 51.551997 \n",
       "L 323.782812 51.551997 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_54\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"51.551997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_28\">\n",
       "      <!-- 0.80 -->\n",
       "      <g transform=\"translate(20.282812 55.023872) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-38\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_18\">\n",
       "     <g id=\"line2d_55\">\n",
       "      <path d=\"M 44.782812 40.463995 \n",
       "L 323.782812 40.463995 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_56\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"40.463995\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_29\">\n",
       "      <!-- 0.85 -->\n",
       "      <g transform=\"translate(20.282812 43.93587) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-38\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_19\">\n",
       "     <g id=\"line2d_57\">\n",
       "      <path d=\"M 44.782812 29.376005 \n",
       "L 323.782812 29.376005 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_58\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"29.376005\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_30\">\n",
       "      <!-- 0.90 -->\n",
       "      <g transform=\"translate(20.282812 32.84788) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-39\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_20\">\n",
       "     <g id=\"line2d_59\">\n",
       "      <path d=\"M 44.782812 18.288003 \n",
       "L 323.782812 18.288003 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_60\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"18.288003\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_31\">\n",
       "      <!-- 0.95 -->\n",
       "      <g transform=\"translate(20.282812 21.759878) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-39\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_32\">\n",
       "     <!-- Values -->\n",
       "     <g transform=\"translate(14.14375 131.408906) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-56\" d=\"M 4544 4238 \n",
       "L 4544 4122 \n",
       "Q 4319 4081 4203 3978 \n",
       "Q 4038 3825 3909 3509 \n",
       "L 2431 -97 \n",
       "L 2316 -97 \n",
       "L 728 3556 \n",
       "Q 606 3838 556 3900 \n",
       "Q 478 3997 364 4051 \n",
       "Q 250 4106 56 4122 \n",
       "L 56 4238 \n",
       "L 1788 4238 \n",
       "L 1788 4122 \n",
       "Q 1494 4094 1406 4022 \n",
       "Q 1319 3950 1319 3838 \n",
       "Q 1319 3681 1463 3350 \n",
       "L 2541 866 \n",
       "L 3541 3319 \n",
       "Q 3688 3681 3688 3822 \n",
       "Q 3688 3913 3597 3995 \n",
       "Q 3506 4078 3291 4113 \n",
       "Q 3275 4116 3238 4122 \n",
       "L 3238 4238 \n",
       "L 4544 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-61\" d=\"M 1822 413 \n",
       "Q 1381 72 1269 19 \n",
       "Q 1100 -59 909 -59 \n",
       "Q 613 -59 420 144 \n",
       "Q 228 347 228 678 \n",
       "Q 228 888 322 1041 \n",
       "Q 450 1253 767 1440 \n",
       "Q 1084 1628 1822 1897 \n",
       "L 1822 2009 \n",
       "Q 1822 2438 1686 2597 \n",
       "Q 1550 2756 1291 2756 \n",
       "Q 1094 2756 978 2650 \n",
       "Q 859 2544 859 2406 \n",
       "L 866 2225 \n",
       "Q 866 2081 792 2003 \n",
       "Q 719 1925 600 1925 \n",
       "Q 484 1925 411 2006 \n",
       "Q 338 2088 338 2228 \n",
       "Q 338 2497 613 2722 \n",
       "Q 888 2947 1384 2947 \n",
       "Q 1766 2947 2009 2819 \n",
       "Q 2194 2722 2281 2516 \n",
       "Q 2338 2381 2338 1966 \n",
       "L 2338 994 \n",
       "Q 2338 584 2353 492 \n",
       "Q 2369 400 2405 369 \n",
       "Q 2441 338 2488 338 \n",
       "Q 2538 338 2575 359 \n",
       "Q 2641 400 2828 588 \n",
       "L 2828 413 \n",
       "Q 2478 -56 2159 -56 \n",
       "Q 2006 -56 1915 50 \n",
       "Q 1825 156 1822 413 \n",
       "z\n",
       "M 1822 616 \n",
       "L 1822 1706 \n",
       "Q 1350 1519 1213 1441 \n",
       "Q 966 1303 859 1153 \n",
       "Q 753 1003 753 825 \n",
       "Q 753 600 887 451 \n",
       "Q 1022 303 1197 303 \n",
       "Q 1434 303 1822 616 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6c\" d=\"M 1184 4444 \n",
       "L 1184 647 \n",
       "Q 1184 378 1223 290 \n",
       "Q 1263 203 1344 158 \n",
       "Q 1425 113 1647 113 \n",
       "L 1647 0 \n",
       "L 244 0 \n",
       "L 244 113 \n",
       "Q 441 113 512 153 \n",
       "Q 584 194 625 287 \n",
       "Q 666 381 666 647 \n",
       "L 666 3247 \n",
       "Q 666 3731 644 3842 \n",
       "Q 622 3953 573 3993 \n",
       "Q 525 4034 450 4034 \n",
       "Q 369 4034 244 3984 \n",
       "L 191 4094 \n",
       "L 1044 4444 \n",
       "L 1184 4444 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-75\" d=\"M 2709 2863 \n",
       "L 2709 1128 \n",
       "Q 2709 631 2732 520 \n",
       "Q 2756 409 2807 365 \n",
       "Q 2859 322 2928 322 \n",
       "Q 3025 322 3147 375 \n",
       "L 3191 266 \n",
       "L 2334 -88 \n",
       "L 2194 -88 \n",
       "L 2194 519 \n",
       "Q 1825 119 1631 15 \n",
       "Q 1438 -88 1222 -88 \n",
       "Q 981 -88 804 51 \n",
       "Q 628 191 559 409 \n",
       "Q 491 628 491 1028 \n",
       "L 491 2306 \n",
       "Q 491 2509 447 2587 \n",
       "Q 403 2666 317 2708 \n",
       "Q 231 2750 6 2747 \n",
       "L 6 2863 \n",
       "L 1009 2863 \n",
       "L 1009 947 \n",
       "Q 1009 547 1148 422 \n",
       "Q 1288 297 1484 297 \n",
       "Q 1619 297 1789 381 \n",
       "Q 1959 466 2194 703 \n",
       "L 2194 2325 \n",
       "Q 2194 2569 2105 2655 \n",
       "Q 2016 2741 1734 2747 \n",
       "L 1734 2863 \n",
       "L 2709 2863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-65\" d=\"M 681 1784 \n",
       "Q 678 1147 991 784 \n",
       "Q 1303 422 1725 422 \n",
       "Q 2006 422 2214 576 \n",
       "Q 2422 731 2563 1106 \n",
       "L 2659 1044 \n",
       "Q 2594 616 2278 264 \n",
       "Q 1963 -88 1488 -88 \n",
       "Q 972 -88 605 314 \n",
       "Q 238 716 238 1394 \n",
       "Q 238 2128 614 2539 \n",
       "Q 991 2950 1559 2950 \n",
       "Q 2041 2950 2350 2633 \n",
       "Q 2659 2316 2659 1784 \n",
       "L 681 1784 \n",
       "z\n",
       "M 681 1966 \n",
       "L 2006 1966 \n",
       "Q 1991 2241 1941 2353 \n",
       "Q 1863 2528 1708 2628 \n",
       "Q 1553 2728 1384 2728 \n",
       "Q 1125 2728 920 2526 \n",
       "Q 716 2325 681 1966 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-73\" d=\"M 2050 2947 \n",
       "L 2050 1972 \n",
       "L 1947 1972 \n",
       "Q 1828 2431 1642 2597 \n",
       "Q 1456 2763 1169 2763 \n",
       "Q 950 2763 815 2647 \n",
       "Q 681 2531 681 2391 \n",
       "Q 681 2216 781 2091 \n",
       "Q 878 1963 1175 1819 \n",
       "L 1631 1597 \n",
       "Q 2266 1288 2266 781 \n",
       "Q 2266 391 1970 151 \n",
       "Q 1675 -88 1309 -88 \n",
       "Q 1047 -88 709 6 \n",
       "Q 606 38 541 38 \n",
       "Q 469 38 428 -44 \n",
       "L 325 -44 \n",
       "L 325 978 \n",
       "L 428 978 \n",
       "Q 516 541 762 319 \n",
       "Q 1009 97 1316 97 \n",
       "Q 1531 97 1667 223 \n",
       "Q 1803 350 1803 528 \n",
       "Q 1803 744 1651 891 \n",
       "Q 1500 1038 1047 1263 \n",
       "Q 594 1488 453 1669 \n",
       "Q 313 1847 313 2119 \n",
       "Q 313 2472 555 2709 \n",
       "Q 797 2947 1181 2947 \n",
       "Q 1350 2947 1591 2875 \n",
       "Q 1750 2828 1803 2828 \n",
       "Q 1853 2828 1881 2850 \n",
       "Q 1909 2872 1947 2947 \n",
       "L 2050 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-56\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"61.091797\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6c\" x=\"105.476562\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-75\" x=\"133.259766\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-65\" x=\"183.259766\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-73\" x=\"227.644531\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_61\">\n",
       "    <path d=\"M 44.782812 41.894346 \n",
       "L 75.782813 24.622945 \n",
       "L 106.782813 21.26698 \n",
       "L 137.782813 20.35407 \n",
       "L 168.782813 18.262122 \n",
       "L 199.782813 17.020271 \n",
       "L 230.782813 15.996477 \n",
       "L 261.782812 14.891379 \n",
       "L 292.782812 14.248274 \n",
       "L 323.782812 13.753012 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_62\">\n",
       "    <path d=\"M 44.782812 40.707932 \n",
       "L 75.782813 24.031588 \n",
       "L 106.782813 21.614399 \n",
       "L 137.782813 21.126526 \n",
       "L 168.782813 18.975454 \n",
       "L 199.782813 18.177117 \n",
       "L 230.782813 17.134844 \n",
       "L 261.782812 16.136931 \n",
       "L 292.782812 15.693403 \n",
       "L 323.782812 15.116837 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 44.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 44.782812 7.2 \n",
       "L 323.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 51.782812 223.96 \n",
       "L 120.425 223.96 \n",
       "Q 122.425 223.96 122.425 221.96 \n",
       "L 122.425 194.644375 \n",
       "Q 122.425 192.644375 120.425 192.644375 \n",
       "L 51.782812 192.644375 \n",
       "Q 49.782812 192.644375 49.782812 194.644375 \n",
       "L 49.782812 221.96 \n",
       "Q 49.782812 223.96 51.782812 223.96 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_63\">\n",
       "     <path d=\"M 53.782812 200.144375 \n",
       "L 63.782812 200.144375 \n",
       "L 73.782813 200.144375 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_33\">\n",
       "     <!-- train_acc -->\n",
       "     <g transform=\"translate(81.782813 203.644375) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-74\" d=\"M 1031 3803 \n",
       "L 1031 2863 \n",
       "L 1700 2863 \n",
       "L 1700 2644 \n",
       "L 1031 2644 \n",
       "L 1031 788 \n",
       "Q 1031 509 1111 412 \n",
       "Q 1191 316 1316 316 \n",
       "Q 1419 316 1516 380 \n",
       "Q 1613 444 1666 569 \n",
       "L 1788 569 \n",
       "Q 1678 263 1478 108 \n",
       "Q 1278 -47 1066 -47 \n",
       "Q 922 -47 784 33 \n",
       "Q 647 113 581 261 \n",
       "Q 516 409 516 719 \n",
       "L 516 2644 \n",
       "L 63 2644 \n",
       "L 63 2747 \n",
       "Q 234 2816 414 2980 \n",
       "Q 594 3144 734 3369 \n",
       "Q 806 3488 934 3803 \n",
       "L 1031 3803 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-72\" d=\"M 1038 2947 \n",
       "L 1038 2303 \n",
       "Q 1397 2947 1775 2947 \n",
       "Q 1947 2947 2059 2842 \n",
       "Q 2172 2738 2172 2600 \n",
       "Q 2172 2478 2090 2393 \n",
       "Q 2009 2309 1897 2309 \n",
       "Q 1788 2309 1652 2417 \n",
       "Q 1516 2525 1450 2525 \n",
       "Q 1394 2525 1328 2463 \n",
       "Q 1188 2334 1038 2041 \n",
       "L 1038 669 \n",
       "Q 1038 431 1097 309 \n",
       "Q 1138 225 1241 169 \n",
       "Q 1344 113 1538 113 \n",
       "L 1538 0 \n",
       "L 72 0 \n",
       "L 72 113 \n",
       "Q 291 113 397 181 \n",
       "Q 475 231 506 341 \n",
       "Q 522 394 522 644 \n",
       "L 522 1753 \n",
       "Q 522 2253 501 2348 \n",
       "Q 481 2444 426 2487 \n",
       "Q 372 2531 291 2531 \n",
       "Q 194 2531 72 2484 \n",
       "L 41 2597 \n",
       "L 906 2947 \n",
       "L 1038 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-69\" d=\"M 928 4444 \n",
       "Q 1059 4444 1151 4351 \n",
       "Q 1244 4259 1244 4128 \n",
       "Q 1244 3997 1151 3903 \n",
       "Q 1059 3809 928 3809 \n",
       "Q 797 3809 703 3903 \n",
       "Q 609 3997 609 4128 \n",
       "Q 609 4259 701 4351 \n",
       "Q 794 4444 928 4444 \n",
       "z\n",
       "M 1188 2947 \n",
       "L 1188 647 \n",
       "Q 1188 378 1227 289 \n",
       "Q 1266 200 1342 156 \n",
       "Q 1419 113 1622 113 \n",
       "L 1622 0 \n",
       "L 231 0 \n",
       "L 231 113 \n",
       "Q 441 113 512 153 \n",
       "Q 584 194 626 287 \n",
       "Q 669 381 669 647 \n",
       "L 669 1750 \n",
       "Q 669 2216 641 2353 \n",
       "Q 619 2453 572 2492 \n",
       "Q 525 2531 444 2531 \n",
       "Q 356 2531 231 2484 \n",
       "L 188 2597 \n",
       "L 1050 2947 \n",
       "L 1188 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6e\" d=\"M 1034 2341 \n",
       "Q 1538 2947 1994 2947 \n",
       "Q 2228 2947 2397 2830 \n",
       "Q 2566 2713 2666 2444 \n",
       "Q 2734 2256 2734 1869 \n",
       "L 2734 647 \n",
       "Q 2734 375 2778 278 \n",
       "Q 2813 200 2889 156 \n",
       "Q 2966 113 3172 113 \n",
       "L 3172 0 \n",
       "L 1756 0 \n",
       "L 1756 113 \n",
       "L 1816 113 \n",
       "Q 2016 113 2095 173 \n",
       "Q 2175 234 2206 353 \n",
       "Q 2219 400 2219 647 \n",
       "L 2219 1819 \n",
       "Q 2219 2209 2117 2386 \n",
       "Q 2016 2563 1775 2563 \n",
       "Q 1403 2563 1034 2156 \n",
       "L 1034 647 \n",
       "Q 1034 356 1069 288 \n",
       "Q 1113 197 1189 155 \n",
       "Q 1266 113 1500 113 \n",
       "L 1500 0 \n",
       "L 84 0 \n",
       "L 84 113 \n",
       "L 147 113 \n",
       "Q 366 113 442 223 \n",
       "Q 519 334 519 647 \n",
       "L 519 1709 \n",
       "Q 519 2225 495 2337 \n",
       "Q 472 2450 423 2490 \n",
       "Q 375 2531 294 2531 \n",
       "Q 206 2531 84 2484 \n",
       "L 38 2597 \n",
       "L 900 2947 \n",
       "L 1034 2947 \n",
       "L 1034 2341 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-5f\" d=\"M 3256 -1381 \n",
       "L -53 -1381 \n",
       "L -53 -1119 \n",
       "L 3256 -1119 \n",
       "L 3256 -1381 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-72\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"61.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-69\" x=\"105.46875\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6e\" x=\"133.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-5f\" x=\"183.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"233.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"277.636719\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"322.021484\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_64\">\n",
       "     <path d=\"M 53.782812 214.302187 \n",
       "L 63.782812 214.302187 \n",
       "L 73.782813 214.302187 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_34\">\n",
       "     <!-- test_acc -->\n",
       "     <g transform=\"translate(81.782813 217.802187) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-65\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-73\" x=\"72.167969\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\" x=\"111.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-5f\" x=\"138.867188\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"188.867188\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"233.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"277.636719\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p21d23a3a71\">\n",
       "   <rect x=\"44.782812\" y=\"7.2\" width=\"279\" height=\"221.76\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_acc一直在92%左右，如何才能提高？\n",
    "# 使用CNN会好一点吗？\n",
    "# 我们来试一试：\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 10), nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net1()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device, \n",
    "    train_figure=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 210.56247329711914 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.4977), tensor(0.9650), tensor(0.9571))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"335.982812pt\" height=\"265.325625pt\" viewBox=\"0 0 335.982812 265.325625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-04-25T11:16:47.537576</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 265.325625 \n",
       "L 335.982812 265.325625 \n",
       "L 335.982812 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "L 44.782812 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 83.265571 228.96 \n",
       "L 83.265571 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"mc04ace902a\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"83.265571\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(80.765571 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-35\" d=\"M 2778 4238 \n",
       "L 2534 3706 \n",
       "L 1259 3706 \n",
       "L 981 3138 \n",
       "Q 1809 3016 2294 2522 \n",
       "Q 2709 2097 2709 1522 \n",
       "Q 2709 1188 2573 903 \n",
       "Q 2438 619 2231 419 \n",
       "Q 2025 219 1772 97 \n",
       "Q 1413 -75 1034 -75 \n",
       "Q 653 -75 479 54 \n",
       "Q 306 184 306 341 \n",
       "Q 306 428 378 495 \n",
       "Q 450 563 559 563 \n",
       "Q 641 563 702 538 \n",
       "Q 763 513 909 409 \n",
       "Q 1144 247 1384 247 \n",
       "Q 1750 247 2026 523 \n",
       "Q 2303 800 2303 1197 \n",
       "Q 2303 1581 2056 1914 \n",
       "Q 1809 2247 1375 2428 \n",
       "Q 1034 2569 447 2591 \n",
       "L 1259 4238 \n",
       "L 2778 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 131.369019 228.96 \n",
       "L 131.369019 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"131.369019\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(126.369019 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-31\" d=\"M 750 3822 \n",
       "L 1781 4325 \n",
       "L 1884 4325 \n",
       "L 1884 747 \n",
       "Q 1884 391 1914 303 \n",
       "Q 1944 216 2037 169 \n",
       "Q 2131 122 2419 116 \n",
       "L 2419 0 \n",
       "L 825 0 \n",
       "L 825 116 \n",
       "Q 1125 122 1212 167 \n",
       "Q 1300 213 1334 289 \n",
       "Q 1369 366 1369 747 \n",
       "L 1369 3034 \n",
       "Q 1369 3497 1338 3628 \n",
       "Q 1316 3728 1258 3775 \n",
       "Q 1200 3822 1119 3822 \n",
       "Q 1003 3822 797 3725 \n",
       "L 750 3822 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"TimesNewRomanPSMT-30\" d=\"M 231 2094 \n",
       "Q 231 2819 450 3342 \n",
       "Q 669 3866 1031 4122 \n",
       "Q 1313 4325 1613 4325 \n",
       "Q 2100 4325 2488 3828 \n",
       "Q 2972 3213 2972 2159 \n",
       "Q 2972 1422 2759 906 \n",
       "Q 2547 391 2217 158 \n",
       "Q 1888 -75 1581 -75 \n",
       "Q 975 -75 572 641 \n",
       "Q 231 1244 231 2094 \n",
       "z\n",
       "M 844 2016 \n",
       "Q 844 1141 1059 588 \n",
       "Q 1238 122 1591 122 \n",
       "Q 1759 122 1940 273 \n",
       "Q 2122 425 2216 781 \n",
       "Q 2359 1319 2359 2297 \n",
       "Q 2359 3022 2209 3506 \n",
       "Q 2097 3866 1919 4016 \n",
       "Q 1791 4119 1609 4119 \n",
       "Q 1397 4119 1231 3928 \n",
       "Q 1006 3669 925 3112 \n",
       "Q 844 2556 844 2016 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 179.472468 228.96 \n",
       "L 179.472468 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"179.472468\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(174.472468 242.90375) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 227.575916 228.96 \n",
       "L 227.575916 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"227.575916\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(222.575916 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-32\" d=\"M 2934 816 \n",
       "L 2638 0 \n",
       "L 138 0 \n",
       "L 138 116 \n",
       "Q 1241 1122 1691 1759 \n",
       "Q 2141 2397 2141 2925 \n",
       "Q 2141 3328 1894 3587 \n",
       "Q 1647 3847 1303 3847 \n",
       "Q 991 3847 742 3664 \n",
       "Q 494 3481 375 3128 \n",
       "L 259 3128 \n",
       "Q 338 3706 661 4015 \n",
       "Q 984 4325 1469 4325 \n",
       "Q 1984 4325 2329 3994 \n",
       "Q 2675 3663 2675 3213 \n",
       "Q 2675 2891 2525 2569 \n",
       "Q 2294 2063 1775 1497 \n",
       "Q 997 647 803 472 \n",
       "L 1909 472 \n",
       "Q 2247 472 2383 497 \n",
       "Q 2519 522 2628 598 \n",
       "Q 2738 675 2819 816 \n",
       "L 2934 816 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 275.679364 228.96 \n",
       "L 275.679364 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"275.679364\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(270.679364 242.90375) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"323.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 30 -->\n",
       "      <g transform=\"translate(318.782812 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-33\" d=\"M 325 3431 \n",
       "Q 506 3859 782 4092 \n",
       "Q 1059 4325 1472 4325 \n",
       "Q 1981 4325 2253 3994 \n",
       "Q 2459 3747 2459 3466 \n",
       "Q 2459 3003 1878 2509 \n",
       "Q 2269 2356 2469 2072 \n",
       "Q 2669 1788 2669 1403 \n",
       "Q 2669 853 2319 450 \n",
       "Q 1863 -75 997 -75 \n",
       "Q 569 -75 414 31 \n",
       "Q 259 138 259 259 \n",
       "Q 259 350 332 419 \n",
       "Q 406 488 509 488 \n",
       "Q 588 488 669 463 \n",
       "Q 722 447 909 348 \n",
       "Q 1097 250 1169 231 \n",
       "Q 1284 197 1416 197 \n",
       "Q 1734 197 1970 444 \n",
       "Q 2206 691 2206 1028 \n",
       "Q 2206 1275 2097 1509 \n",
       "Q 2016 1684 1919 1775 \n",
       "Q 1784 1900 1550 2001 \n",
       "Q 1316 2103 1072 2103 \n",
       "L 972 2103 \n",
       "L 972 2197 \n",
       "Q 1219 2228 1467 2375 \n",
       "Q 1716 2522 1828 2728 \n",
       "Q 1941 2934 1941 3181 \n",
       "Q 1941 3503 1739 3701 \n",
       "Q 1538 3900 1238 3900 \n",
       "Q 753 3900 428 3381 \n",
       "L 325 3431 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Epoch -->\n",
       "     <g transform=\"translate(171.509375 255.986562) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-45\" d=\"M 1338 4006 \n",
       "L 1338 2331 \n",
       "L 2269 2331 \n",
       "Q 2631 2331 2753 2441 \n",
       "Q 2916 2584 2934 2947 \n",
       "L 3050 2947 \n",
       "L 3050 1472 \n",
       "L 2934 1472 \n",
       "Q 2891 1781 2847 1869 \n",
       "Q 2791 1978 2662 2040 \n",
       "Q 2534 2103 2269 2103 \n",
       "L 1338 2103 \n",
       "L 1338 706 \n",
       "Q 1338 425 1363 364 \n",
       "Q 1388 303 1450 267 \n",
       "Q 1513 231 1688 231 \n",
       "L 2406 231 \n",
       "Q 2766 231 2928 281 \n",
       "Q 3091 331 3241 478 \n",
       "Q 3434 672 3638 1063 \n",
       "L 3763 1063 \n",
       "L 3397 0 \n",
       "L 131 0 \n",
       "L 131 116 \n",
       "L 281 116 \n",
       "Q 431 116 566 188 \n",
       "Q 666 238 702 338 \n",
       "Q 738 438 738 747 \n",
       "L 738 3500 \n",
       "Q 738 3903 656 3997 \n",
       "Q 544 4122 281 4122 \n",
       "L 131 4122 \n",
       "L 131 4238 \n",
       "L 3397 4238 \n",
       "L 3444 3309 \n",
       "L 3322 3309 \n",
       "Q 3256 3644 3176 3769 \n",
       "Q 3097 3894 2941 3959 \n",
       "Q 2816 4006 2500 4006 \n",
       "L 1338 4006 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-70\" d=\"M -6 2578 \n",
       "L 875 2934 \n",
       "L 994 2934 \n",
       "L 994 2266 \n",
       "Q 1216 2644 1439 2795 \n",
       "Q 1663 2947 1909 2947 \n",
       "Q 2341 2947 2628 2609 \n",
       "Q 2981 2197 2981 1534 \n",
       "Q 2981 794 2556 309 \n",
       "Q 2206 -88 1675 -88 \n",
       "Q 1444 -88 1275 -22 \n",
       "Q 1150 25 994 166 \n",
       "L 994 -706 \n",
       "Q 994 -1000 1030 -1079 \n",
       "Q 1066 -1159 1155 -1206 \n",
       "Q 1244 -1253 1478 -1253 \n",
       "L 1478 -1369 \n",
       "L -22 -1369 \n",
       "L -22 -1253 \n",
       "L 56 -1253 \n",
       "Q 228 -1256 350 -1188 \n",
       "Q 409 -1153 442 -1076 \n",
       "Q 475 -1000 475 -688 \n",
       "L 475 2019 \n",
       "Q 475 2297 450 2372 \n",
       "Q 425 2447 370 2484 \n",
       "Q 316 2522 222 2522 \n",
       "Q 147 2522 31 2478 \n",
       "L -6 2578 \n",
       "z\n",
       "M 994 2081 \n",
       "L 994 1013 \n",
       "Q 994 666 1022 556 \n",
       "Q 1066 375 1236 237 \n",
       "Q 1406 100 1666 100 \n",
       "Q 1978 100 2172 344 \n",
       "Q 2425 663 2425 1241 \n",
       "Q 2425 1897 2138 2250 \n",
       "Q 1938 2494 1663 2494 \n",
       "Q 1513 2494 1366 2419 \n",
       "Q 1253 2363 994 2081 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6f\" d=\"M 1600 2947 \n",
       "Q 2250 2947 2644 2453 \n",
       "Q 2978 2031 2978 1484 \n",
       "Q 2978 1100 2793 706 \n",
       "Q 2609 313 2286 112 \n",
       "Q 1963 -88 1566 -88 \n",
       "Q 919 -88 538 428 \n",
       "Q 216 863 216 1403 \n",
       "Q 216 1797 411 2186 \n",
       "Q 606 2575 925 2761 \n",
       "Q 1244 2947 1600 2947 \n",
       "z\n",
       "M 1503 2744 \n",
       "Q 1338 2744 1170 2645 \n",
       "Q 1003 2547 900 2300 \n",
       "Q 797 2053 797 1666 \n",
       "Q 797 1041 1045 587 \n",
       "Q 1294 134 1700 134 \n",
       "Q 2003 134 2200 384 \n",
       "Q 2397 634 2397 1244 \n",
       "Q 2397 2006 2069 2444 \n",
       "Q 1847 2744 1503 2744 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-63\" d=\"M 2631 1088 \n",
       "Q 2516 522 2178 217 \n",
       "Q 1841 -88 1431 -88 \n",
       "Q 944 -88 581 321 \n",
       "Q 219 731 219 1428 \n",
       "Q 219 2103 620 2525 \n",
       "Q 1022 2947 1584 2947 \n",
       "Q 2006 2947 2278 2723 \n",
       "Q 2550 2500 2550 2259 \n",
       "Q 2550 2141 2473 2067 \n",
       "Q 2397 1994 2259 1994 \n",
       "Q 2075 1994 1981 2113 \n",
       "Q 1928 2178 1911 2362 \n",
       "Q 1894 2547 1784 2644 \n",
       "Q 1675 2738 1481 2738 \n",
       "Q 1169 2738 978 2506 \n",
       "Q 725 2200 725 1697 \n",
       "Q 725 1184 976 792 \n",
       "Q 1228 400 1656 400 \n",
       "Q 1963 400 2206 609 \n",
       "Q 2378 753 2541 1131 \n",
       "L 2631 1088 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-68\" d=\"M 1041 4444 \n",
       "L 1041 2350 \n",
       "Q 1388 2731 1591 2839 \n",
       "Q 1794 2947 1997 2947 \n",
       "Q 2241 2947 2416 2812 \n",
       "Q 2591 2678 2675 2391 \n",
       "Q 2734 2191 2734 1659 \n",
       "L 2734 647 \n",
       "Q 2734 375 2778 275 \n",
       "Q 2809 200 2884 156 \n",
       "Q 2959 113 3159 113 \n",
       "L 3159 0 \n",
       "L 1753 0 \n",
       "L 1753 113 \n",
       "L 1819 113 \n",
       "Q 2019 113 2097 173 \n",
       "Q 2175 234 2206 353 \n",
       "Q 2216 403 2216 647 \n",
       "L 2216 1659 \n",
       "Q 2216 2128 2167 2275 \n",
       "Q 2119 2422 2012 2495 \n",
       "Q 1906 2569 1756 2569 \n",
       "Q 1603 2569 1437 2487 \n",
       "Q 1272 2406 1041 2159 \n",
       "L 1041 647 \n",
       "Q 1041 353 1073 281 \n",
       "Q 1106 209 1195 161 \n",
       "Q 1284 113 1503 113 \n",
       "L 1503 0 \n",
       "L 84 0 \n",
       "L 84 113 \n",
       "Q 275 113 384 172 \n",
       "Q 447 203 484 290 \n",
       "Q 522 378 522 647 \n",
       "L 522 3238 \n",
       "Q 522 3728 498 3840 \n",
       "Q 475 3953 426 3993 \n",
       "Q 378 4034 297 4034 \n",
       "Q 231 4034 84 3984 \n",
       "L 41 4094 \n",
       "L 897 4444 \n",
       "L 1041 4444 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-45\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-70\" x=\"61.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6f\" x=\"111.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"161.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-68\" x=\"205.46875\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <defs>\n",
       "       <path id=\"mcd123fd2b1\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.00 -->\n",
       "      <g transform=\"translate(20.282812 232.431875) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-2e\" d=\"M 800 606 \n",
       "Q 947 606 1047 504 \n",
       "Q 1147 403 1147 259 \n",
       "Q 1147 116 1045 14 \n",
       "Q 944 -88 800 -88 \n",
       "Q 656 -88 554 14 \n",
       "Q 453 116 453 259 \n",
       "Q 453 406 554 506 \n",
       "Q 656 606 800 606 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 44.782812 217.872 \n",
       "L 323.782812 217.872 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"217.872\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.05 -->\n",
       "      <g transform=\"translate(20.282812 221.343875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 44.782812 206.784 \n",
       "L 323.782812 206.784 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"206.784\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.282812 210.255875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 44.782812 195.695999 \n",
       "L 323.782812 195.695999 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"195.695999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.282812 199.167874) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 44.782812 184.607999 \n",
       "L 323.782812 184.607999 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"184.607999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.20 -->\n",
       "      <g transform=\"translate(20.282812 188.079874) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 44.782812 173.52 \n",
       "L 323.782812 173.52 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"173.52\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.25 -->\n",
       "      <g transform=\"translate(20.282812 176.991875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path d=\"M 44.782812 162.431997 \n",
       "L 323.782812 162.431997 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_26\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"162.431997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.30 -->\n",
       "      <g transform=\"translate(20.282812 165.903872) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path d=\"M 44.782812 151.344001 \n",
       "L 323.782812 151.344001 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_28\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"151.344001\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.35 -->\n",
       "      <g transform=\"translate(20.282812 154.815876) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <path d=\"M 44.782812 140.255999 \n",
       "L 323.782812 140.255999 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_30\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"140.255999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 0.40 -->\n",
       "      <g transform=\"translate(20.282812 143.727874) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-34\" d=\"M 2978 1563 \n",
       "L 2978 1119 \n",
       "L 2409 1119 \n",
       "L 2409 0 \n",
       "L 1894 0 \n",
       "L 1894 1119 \n",
       "L 100 1119 \n",
       "L 100 1519 \n",
       "L 2066 4325 \n",
       "L 2409 4325 \n",
       "L 2409 1563 \n",
       "L 2978 1563 \n",
       "z\n",
       "M 1894 1563 \n",
       "L 1894 3666 \n",
       "L 406 1563 \n",
       "L 1894 1563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-34\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_31\">\n",
       "      <path d=\"M 44.782812 129.167996 \n",
       "L 323.782812 129.167996 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_32\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"129.167996\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 0.45 -->\n",
       "      <g transform=\"translate(20.282812 132.639871) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-34\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_11\">\n",
       "     <g id=\"line2d_33\">\n",
       "      <path d=\"M 44.782812 118.08 \n",
       "L 323.782812 118.08 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_34\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"118.08\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- 0.50 -->\n",
       "      <g transform=\"translate(20.282812 121.551875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_12\">\n",
       "     <g id=\"line2d_35\">\n",
       "      <path d=\"M 44.782812 106.991997 \n",
       "L 323.782812 106.991997 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_36\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"106.991997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 0.55 -->\n",
       "      <g transform=\"translate(20.282812 110.463872) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_13\">\n",
       "     <g id=\"line2d_37\">\n",
       "      <path d=\"M 44.782812 95.903995 \n",
       "L 323.782812 95.903995 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_38\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"95.903995\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_20\">\n",
       "      <!-- 0.60 -->\n",
       "      <g transform=\"translate(20.282812 99.37587) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-36\" d=\"M 2869 4325 \n",
       "L 2869 4209 \n",
       "Q 2456 4169 2195 4045 \n",
       "Q 1934 3922 1679 3669 \n",
       "Q 1425 3416 1258 3105 \n",
       "Q 1091 2794 978 2366 \n",
       "Q 1428 2675 1881 2675 \n",
       "Q 2316 2675 2634 2325 \n",
       "Q 2953 1975 2953 1425 \n",
       "Q 2953 894 2631 456 \n",
       "Q 2244 -75 1606 -75 \n",
       "Q 1172 -75 869 213 \n",
       "Q 275 772 275 1663 \n",
       "Q 275 2231 503 2743 \n",
       "Q 731 3256 1154 3653 \n",
       "Q 1578 4050 1965 4187 \n",
       "Q 2353 4325 2688 4325 \n",
       "L 2869 4325 \n",
       "z\n",
       "M 925 2138 \n",
       "Q 869 1716 869 1456 \n",
       "Q 869 1156 980 804 \n",
       "Q 1091 453 1309 247 \n",
       "Q 1469 100 1697 100 \n",
       "Q 1969 100 2183 356 \n",
       "Q 2397 613 2397 1088 \n",
       "Q 2397 1622 2184 2012 \n",
       "Q 1972 2403 1581 2403 \n",
       "Q 1463 2403 1327 2353 \n",
       "Q 1191 2303 925 2138 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-36\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_14\">\n",
       "     <g id=\"line2d_39\">\n",
       "      <path d=\"M 44.782812 84.816005 \n",
       "L 323.782812 84.816005 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_40\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"84.816005\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_21\">\n",
       "      <!-- 0.65 -->\n",
       "      <g transform=\"translate(20.282812 88.28788) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-36\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_15\">\n",
       "     <g id=\"line2d_41\">\n",
       "      <path d=\"M 44.782812 73.728003 \n",
       "L 323.782812 73.728003 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_42\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"73.728003\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_22\">\n",
       "      <!-- 0.70 -->\n",
       "      <g transform=\"translate(20.282812 77.199878) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-37\" d=\"M 644 4238 \n",
       "L 2916 4238 \n",
       "L 2916 4119 \n",
       "L 1503 -88 \n",
       "L 1153 -88 \n",
       "L 2419 3728 \n",
       "L 1253 3728 \n",
       "Q 900 3728 750 3644 \n",
       "Q 488 3500 328 3200 \n",
       "L 238 3234 \n",
       "L 644 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-37\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_16\">\n",
       "     <g id=\"line2d_43\">\n",
       "      <path d=\"M 44.782812 62.64 \n",
       "L 323.782812 62.64 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_44\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"62.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_23\">\n",
       "      <!-- 0.75 -->\n",
       "      <g transform=\"translate(20.282812 66.111875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-37\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_17\">\n",
       "     <g id=\"line2d_45\">\n",
       "      <path d=\"M 44.782812 51.551997 \n",
       "L 323.782812 51.551997 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_46\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"51.551997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_24\">\n",
       "      <!-- 0.80 -->\n",
       "      <g transform=\"translate(20.282812 55.023872) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-38\" d=\"M 1228 2134 \n",
       "Q 725 2547 579 2797 \n",
       "Q 434 3047 434 3316 \n",
       "Q 434 3728 753 4026 \n",
       "Q 1072 4325 1600 4325 \n",
       "Q 2113 4325 2425 4047 \n",
       "Q 2738 3769 2738 3413 \n",
       "Q 2738 3175 2569 2928 \n",
       "Q 2400 2681 1866 2347 \n",
       "Q 2416 1922 2594 1678 \n",
       "Q 2831 1359 2831 1006 \n",
       "Q 2831 559 2490 242 \n",
       "Q 2150 -75 1597 -75 \n",
       "Q 994 -75 656 303 \n",
       "Q 388 606 388 966 \n",
       "Q 388 1247 577 1523 \n",
       "Q 766 1800 1228 2134 \n",
       "z\n",
       "M 1719 2469 \n",
       "Q 2094 2806 2194 3001 \n",
       "Q 2294 3197 2294 3444 \n",
       "Q 2294 3772 2109 3958 \n",
       "Q 1925 4144 1606 4144 \n",
       "Q 1288 4144 1088 3959 \n",
       "Q 888 3775 888 3528 \n",
       "Q 888 3366 970 3203 \n",
       "Q 1053 3041 1206 2894 \n",
       "L 1719 2469 \n",
       "z\n",
       "M 1375 2016 \n",
       "Q 1116 1797 991 1539 \n",
       "Q 866 1281 866 981 \n",
       "Q 866 578 1086 336 \n",
       "Q 1306 94 1647 94 \n",
       "Q 1984 94 2187 284 \n",
       "Q 2391 475 2391 747 \n",
       "Q 2391 972 2272 1150 \n",
       "Q 2050 1481 1375 2016 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-38\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_18\">\n",
       "     <g id=\"line2d_47\">\n",
       "      <path d=\"M 44.782812 40.463995 \n",
       "L 323.782812 40.463995 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_48\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"40.463995\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_25\">\n",
       "      <!-- 0.85 -->\n",
       "      <g transform=\"translate(20.282812 43.93587) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-38\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_19\">\n",
       "     <g id=\"line2d_49\">\n",
       "      <path d=\"M 44.782812 29.376005 \n",
       "L 323.782812 29.376005 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_50\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"29.376005\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_26\">\n",
       "      <!-- 0.90 -->\n",
       "      <g transform=\"translate(20.282812 32.84788) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-39\" d=\"M 338 -88 \n",
       "L 338 28 \n",
       "Q 744 34 1094 217 \n",
       "Q 1444 400 1770 856 \n",
       "Q 2097 1313 2225 1859 \n",
       "Q 1734 1544 1338 1544 \n",
       "Q 891 1544 572 1889 \n",
       "Q 253 2234 253 2806 \n",
       "Q 253 3363 572 3797 \n",
       "Q 956 4325 1575 4325 \n",
       "Q 2097 4325 2469 3894 \n",
       "Q 2925 3359 2925 2575 \n",
       "Q 2925 1869 2578 1258 \n",
       "Q 2231 647 1613 244 \n",
       "Q 1109 -88 516 -88 \n",
       "L 338 -88 \n",
       "z\n",
       "M 2275 2091 \n",
       "Q 2331 2497 2331 2741 \n",
       "Q 2331 3044 2228 3395 \n",
       "Q 2125 3747 1936 3934 \n",
       "Q 1747 4122 1506 4122 \n",
       "Q 1228 4122 1018 3872 \n",
       "Q 809 3622 809 3128 \n",
       "Q 809 2469 1088 2097 \n",
       "Q 1291 1828 1588 1828 \n",
       "Q 1731 1828 1928 1897 \n",
       "Q 2125 1966 2275 2091 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-39\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_20\">\n",
       "     <g id=\"line2d_51\">\n",
       "      <path d=\"M 44.782812 18.288003 \n",
       "L 323.782812 18.288003 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_52\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"18.288003\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_27\">\n",
       "      <!-- 0.95 -->\n",
       "      <g transform=\"translate(20.282812 21.759878) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-39\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_28\">\n",
       "     <!-- Values -->\n",
       "     <g transform=\"translate(14.14375 131.408906) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-56\" d=\"M 4544 4238 \n",
       "L 4544 4122 \n",
       "Q 4319 4081 4203 3978 \n",
       "Q 4038 3825 3909 3509 \n",
       "L 2431 -97 \n",
       "L 2316 -97 \n",
       "L 728 3556 \n",
       "Q 606 3838 556 3900 \n",
       "Q 478 3997 364 4051 \n",
       "Q 250 4106 56 4122 \n",
       "L 56 4238 \n",
       "L 1788 4238 \n",
       "L 1788 4122 \n",
       "Q 1494 4094 1406 4022 \n",
       "Q 1319 3950 1319 3838 \n",
       "Q 1319 3681 1463 3350 \n",
       "L 2541 866 \n",
       "L 3541 3319 \n",
       "Q 3688 3681 3688 3822 \n",
       "Q 3688 3913 3597 3995 \n",
       "Q 3506 4078 3291 4113 \n",
       "Q 3275 4116 3238 4122 \n",
       "L 3238 4238 \n",
       "L 4544 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-61\" d=\"M 1822 413 \n",
       "Q 1381 72 1269 19 \n",
       "Q 1100 -59 909 -59 \n",
       "Q 613 -59 420 144 \n",
       "Q 228 347 228 678 \n",
       "Q 228 888 322 1041 \n",
       "Q 450 1253 767 1440 \n",
       "Q 1084 1628 1822 1897 \n",
       "L 1822 2009 \n",
       "Q 1822 2438 1686 2597 \n",
       "Q 1550 2756 1291 2756 \n",
       "Q 1094 2756 978 2650 \n",
       "Q 859 2544 859 2406 \n",
       "L 866 2225 \n",
       "Q 866 2081 792 2003 \n",
       "Q 719 1925 600 1925 \n",
       "Q 484 1925 411 2006 \n",
       "Q 338 2088 338 2228 \n",
       "Q 338 2497 613 2722 \n",
       "Q 888 2947 1384 2947 \n",
       "Q 1766 2947 2009 2819 \n",
       "Q 2194 2722 2281 2516 \n",
       "Q 2338 2381 2338 1966 \n",
       "L 2338 994 \n",
       "Q 2338 584 2353 492 \n",
       "Q 2369 400 2405 369 \n",
       "Q 2441 338 2488 338 \n",
       "Q 2538 338 2575 359 \n",
       "Q 2641 400 2828 588 \n",
       "L 2828 413 \n",
       "Q 2478 -56 2159 -56 \n",
       "Q 2006 -56 1915 50 \n",
       "Q 1825 156 1822 413 \n",
       "z\n",
       "M 1822 616 \n",
       "L 1822 1706 \n",
       "Q 1350 1519 1213 1441 \n",
       "Q 966 1303 859 1153 \n",
       "Q 753 1003 753 825 \n",
       "Q 753 600 887 451 \n",
       "Q 1022 303 1197 303 \n",
       "Q 1434 303 1822 616 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6c\" d=\"M 1184 4444 \n",
       "L 1184 647 \n",
       "Q 1184 378 1223 290 \n",
       "Q 1263 203 1344 158 \n",
       "Q 1425 113 1647 113 \n",
       "L 1647 0 \n",
       "L 244 0 \n",
       "L 244 113 \n",
       "Q 441 113 512 153 \n",
       "Q 584 194 625 287 \n",
       "Q 666 381 666 647 \n",
       "L 666 3247 \n",
       "Q 666 3731 644 3842 \n",
       "Q 622 3953 573 3993 \n",
       "Q 525 4034 450 4034 \n",
       "Q 369 4034 244 3984 \n",
       "L 191 4094 \n",
       "L 1044 4444 \n",
       "L 1184 4444 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-75\" d=\"M 2709 2863 \n",
       "L 2709 1128 \n",
       "Q 2709 631 2732 520 \n",
       "Q 2756 409 2807 365 \n",
       "Q 2859 322 2928 322 \n",
       "Q 3025 322 3147 375 \n",
       "L 3191 266 \n",
       "L 2334 -88 \n",
       "L 2194 -88 \n",
       "L 2194 519 \n",
       "Q 1825 119 1631 15 \n",
       "Q 1438 -88 1222 -88 \n",
       "Q 981 -88 804 51 \n",
       "Q 628 191 559 409 \n",
       "Q 491 628 491 1028 \n",
       "L 491 2306 \n",
       "Q 491 2509 447 2587 \n",
       "Q 403 2666 317 2708 \n",
       "Q 231 2750 6 2747 \n",
       "L 6 2863 \n",
       "L 1009 2863 \n",
       "L 1009 947 \n",
       "Q 1009 547 1148 422 \n",
       "Q 1288 297 1484 297 \n",
       "Q 1619 297 1789 381 \n",
       "Q 1959 466 2194 703 \n",
       "L 2194 2325 \n",
       "Q 2194 2569 2105 2655 \n",
       "Q 2016 2741 1734 2747 \n",
       "L 1734 2863 \n",
       "L 2709 2863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-65\" d=\"M 681 1784 \n",
       "Q 678 1147 991 784 \n",
       "Q 1303 422 1725 422 \n",
       "Q 2006 422 2214 576 \n",
       "Q 2422 731 2563 1106 \n",
       "L 2659 1044 \n",
       "Q 2594 616 2278 264 \n",
       "Q 1963 -88 1488 -88 \n",
       "Q 972 -88 605 314 \n",
       "Q 238 716 238 1394 \n",
       "Q 238 2128 614 2539 \n",
       "Q 991 2950 1559 2950 \n",
       "Q 2041 2950 2350 2633 \n",
       "Q 2659 2316 2659 1784 \n",
       "L 681 1784 \n",
       "z\n",
       "M 681 1966 \n",
       "L 2006 1966 \n",
       "Q 1991 2241 1941 2353 \n",
       "Q 1863 2528 1708 2628 \n",
       "Q 1553 2728 1384 2728 \n",
       "Q 1125 2728 920 2526 \n",
       "Q 716 2325 681 1966 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-73\" d=\"M 2050 2947 \n",
       "L 2050 1972 \n",
       "L 1947 1972 \n",
       "Q 1828 2431 1642 2597 \n",
       "Q 1456 2763 1169 2763 \n",
       "Q 950 2763 815 2647 \n",
       "Q 681 2531 681 2391 \n",
       "Q 681 2216 781 2091 \n",
       "Q 878 1963 1175 1819 \n",
       "L 1631 1597 \n",
       "Q 2266 1288 2266 781 \n",
       "Q 2266 391 1970 151 \n",
       "Q 1675 -88 1309 -88 \n",
       "Q 1047 -88 709 6 \n",
       "Q 606 38 541 38 \n",
       "Q 469 38 428 -44 \n",
       "L 325 -44 \n",
       "L 325 978 \n",
       "L 428 978 \n",
       "Q 516 541 762 319 \n",
       "Q 1009 97 1316 97 \n",
       "Q 1531 97 1667 223 \n",
       "Q 1803 350 1803 528 \n",
       "Q 1803 744 1651 891 \n",
       "Q 1500 1038 1047 1263 \n",
       "Q 594 1488 453 1669 \n",
       "Q 313 1847 313 2119 \n",
       "Q 313 2472 555 2709 \n",
       "Q 797 2947 1181 2947 \n",
       "Q 1350 2947 1591 2875 \n",
       "Q 1750 2828 1803 2828 \n",
       "Q 1853 2828 1881 2850 \n",
       "Q 1909 2872 1947 2947 \n",
       "L 2050 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-56\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"61.091797\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6c\" x=\"105.476562\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-75\" x=\"133.259766\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-65\" x=\"183.259766\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-73\" x=\"227.644531\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_53\">\n",
       "    <path d=\"M 44.782812 27.317327 \n",
       "L 54.403502 23.913314 \n",
       "L 64.024192 23.163025 \n",
       "L 73.644881 21.640267 \n",
       "L 83.265571 20.716268 \n",
       "L 92.886261 20.383626 \n",
       "L 102.50695 19.07895 \n",
       "L 112.12764 18.720427 \n",
       "L 121.74833 18.398875 \n",
       "L 131.369019 17.707722 \n",
       "L 140.989709 18.288003 \n",
       "L 150.610399 17.219862 \n",
       "L 160.231088 16.84286 \n",
       "L 169.851778 16.813292 \n",
       "L 179.472468 16.550876 \n",
       "L 189.093157 16.354987 \n",
       "L 198.713847 16.84286 \n",
       "L 208.334537 16.32173 \n",
       "L 217.955226 16.107362 \n",
       "L 227.575916 16.151708 \n",
       "L 237.196606 15.778421 \n",
       "L 246.817295 16.007567 \n",
       "L 256.437985 15.815378 \n",
       "L 266.058675 15.545574 \n",
       "L 275.679364 15.353372 \n",
       "L 285.300054 15.368163 \n",
       "L 294.920744 15.04661 \n",
       "L 304.541433 15.334893 \n",
       "L 314.162123 15.212931 \n",
       "L 323.782812 14.965294 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_54\">\n",
       "    <path d=\"M 44.782812 27.114048 \n",
       "L 54.403502 23.499355 \n",
       "L 64.024192 23.299778 \n",
       "L 73.644881 21.547874 \n",
       "L 83.265571 20.727358 \n",
       "L 92.886261 21.281757 \n",
       "L 102.50695 19.951201 \n",
       "L 112.12764 19.662918 \n",
       "L 121.74833 19.24157 \n",
       "L 131.369019 18.642811 \n",
       "L 140.989709 19.552033 \n",
       "L 150.610399 18.376708 \n",
       "L 160.231088 18.044066 \n",
       "L 169.851778 18.376708 \n",
       "L 179.472468 18.110592 \n",
       "L 189.093157 17.511846 \n",
       "L 198.713847 17.999706 \n",
       "L 208.334537 17.866655 \n",
       "L 217.955226 17.711423 \n",
       "L 227.575916 17.866655 \n",
       "L 237.196606 17.090498 \n",
       "L 246.817295 17.711423 \n",
       "L 256.437985 17.777949 \n",
       "L 266.058675 17.445307 \n",
       "L 275.679364 16.735676 \n",
       "L 285.300054 17.334435 \n",
       "L 294.920744 16.447393 \n",
       "L 304.541433 16.868741 \n",
       "L 314.162123 17.068319 \n",
       "L 323.782812 16.71351 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 44.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 44.782812 7.2 \n",
       "L 323.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 51.782812 223.96 \n",
       "L 120.425 223.96 \n",
       "Q 122.425 223.96 122.425 221.96 \n",
       "L 122.425 194.644375 \n",
       "Q 122.425 192.644375 120.425 192.644375 \n",
       "L 51.782812 192.644375 \n",
       "Q 49.782812 192.644375 49.782812 194.644375 \n",
       "L 49.782812 221.96 \n",
       "Q 49.782812 223.96 51.782812 223.96 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_55\">\n",
       "     <path d=\"M 53.782812 200.144375 \n",
       "L 63.782812 200.144375 \n",
       "L 73.782813 200.144375 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_29\">\n",
       "     <!-- train_acc -->\n",
       "     <g transform=\"translate(81.782813 203.644375) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-74\" d=\"M 1031 3803 \n",
       "L 1031 2863 \n",
       "L 1700 2863 \n",
       "L 1700 2644 \n",
       "L 1031 2644 \n",
       "L 1031 788 \n",
       "Q 1031 509 1111 412 \n",
       "Q 1191 316 1316 316 \n",
       "Q 1419 316 1516 380 \n",
       "Q 1613 444 1666 569 \n",
       "L 1788 569 \n",
       "Q 1678 263 1478 108 \n",
       "Q 1278 -47 1066 -47 \n",
       "Q 922 -47 784 33 \n",
       "Q 647 113 581 261 \n",
       "Q 516 409 516 719 \n",
       "L 516 2644 \n",
       "L 63 2644 \n",
       "L 63 2747 \n",
       "Q 234 2816 414 2980 \n",
       "Q 594 3144 734 3369 \n",
       "Q 806 3488 934 3803 \n",
       "L 1031 3803 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-72\" d=\"M 1038 2947 \n",
       "L 1038 2303 \n",
       "Q 1397 2947 1775 2947 \n",
       "Q 1947 2947 2059 2842 \n",
       "Q 2172 2738 2172 2600 \n",
       "Q 2172 2478 2090 2393 \n",
       "Q 2009 2309 1897 2309 \n",
       "Q 1788 2309 1652 2417 \n",
       "Q 1516 2525 1450 2525 \n",
       "Q 1394 2525 1328 2463 \n",
       "Q 1188 2334 1038 2041 \n",
       "L 1038 669 \n",
       "Q 1038 431 1097 309 \n",
       "Q 1138 225 1241 169 \n",
       "Q 1344 113 1538 113 \n",
       "L 1538 0 \n",
       "L 72 0 \n",
       "L 72 113 \n",
       "Q 291 113 397 181 \n",
       "Q 475 231 506 341 \n",
       "Q 522 394 522 644 \n",
       "L 522 1753 \n",
       "Q 522 2253 501 2348 \n",
       "Q 481 2444 426 2487 \n",
       "Q 372 2531 291 2531 \n",
       "Q 194 2531 72 2484 \n",
       "L 41 2597 \n",
       "L 906 2947 \n",
       "L 1038 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-69\" d=\"M 928 4444 \n",
       "Q 1059 4444 1151 4351 \n",
       "Q 1244 4259 1244 4128 \n",
       "Q 1244 3997 1151 3903 \n",
       "Q 1059 3809 928 3809 \n",
       "Q 797 3809 703 3903 \n",
       "Q 609 3997 609 4128 \n",
       "Q 609 4259 701 4351 \n",
       "Q 794 4444 928 4444 \n",
       "z\n",
       "M 1188 2947 \n",
       "L 1188 647 \n",
       "Q 1188 378 1227 289 \n",
       "Q 1266 200 1342 156 \n",
       "Q 1419 113 1622 113 \n",
       "L 1622 0 \n",
       "L 231 0 \n",
       "L 231 113 \n",
       "Q 441 113 512 153 \n",
       "Q 584 194 626 287 \n",
       "Q 669 381 669 647 \n",
       "L 669 1750 \n",
       "Q 669 2216 641 2353 \n",
       "Q 619 2453 572 2492 \n",
       "Q 525 2531 444 2531 \n",
       "Q 356 2531 231 2484 \n",
       "L 188 2597 \n",
       "L 1050 2947 \n",
       "L 1188 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6e\" d=\"M 1034 2341 \n",
       "Q 1538 2947 1994 2947 \n",
       "Q 2228 2947 2397 2830 \n",
       "Q 2566 2713 2666 2444 \n",
       "Q 2734 2256 2734 1869 \n",
       "L 2734 647 \n",
       "Q 2734 375 2778 278 \n",
       "Q 2813 200 2889 156 \n",
       "Q 2966 113 3172 113 \n",
       "L 3172 0 \n",
       "L 1756 0 \n",
       "L 1756 113 \n",
       "L 1816 113 \n",
       "Q 2016 113 2095 173 \n",
       "Q 2175 234 2206 353 \n",
       "Q 2219 400 2219 647 \n",
       "L 2219 1819 \n",
       "Q 2219 2209 2117 2386 \n",
       "Q 2016 2563 1775 2563 \n",
       "Q 1403 2563 1034 2156 \n",
       "L 1034 647 \n",
       "Q 1034 356 1069 288 \n",
       "Q 1113 197 1189 155 \n",
       "Q 1266 113 1500 113 \n",
       "L 1500 0 \n",
       "L 84 0 \n",
       "L 84 113 \n",
       "L 147 113 \n",
       "Q 366 113 442 223 \n",
       "Q 519 334 519 647 \n",
       "L 519 1709 \n",
       "Q 519 2225 495 2337 \n",
       "Q 472 2450 423 2490 \n",
       "Q 375 2531 294 2531 \n",
       "Q 206 2531 84 2484 \n",
       "L 38 2597 \n",
       "L 900 2947 \n",
       "L 1034 2947 \n",
       "L 1034 2341 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-5f\" d=\"M 3256 -1381 \n",
       "L -53 -1381 \n",
       "L -53 -1119 \n",
       "L 3256 -1119 \n",
       "L 3256 -1381 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-72\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"61.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-69\" x=\"105.46875\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6e\" x=\"133.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-5f\" x=\"183.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"233.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"277.636719\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"322.021484\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_56\">\n",
       "     <path d=\"M 53.782812 214.302187 \n",
       "L 63.782812 214.302187 \n",
       "L 73.782813 214.302187 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_30\">\n",
       "     <!-- test_acc -->\n",
       "     <g transform=\"translate(81.782813 217.802187) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-65\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-73\" x=\"72.167969\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\" x=\"111.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-5f\" x=\"138.867188\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"188.867188\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"233.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"277.636719\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pef7e57143d\">\n",
       "   <rect x=\"44.782812\" y=\"7.2\" width=\"279\" height=\"221.76\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 开始训练\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.network = nn.Sequential(nn.Flatten(),\n",
    "        #                              nn.Linear(28*28, 2**5), nn.ReLU(),\n",
    "        #                              nn.Linear(2**5, 10), nn.Softmax())\n",
    "        self.num_hidden = 2**5\n",
    "        self.layer1 = nn.Flatten()\n",
    "        self.layer2 = nn.Linear(28*28, self.num_hidden)\n",
    "        self.layer3 = nn.Linear(self.num_hidden, self.num_hidden)\n",
    "        self.ac = nn.ReLU()\n",
    "        # self.ac = nn.Tanh()\n",
    "        self.dp = nn.Dropout()\n",
    "        self.bn = nn.BatchNorm1d(self.num_hidden)\n",
    "        self.layer4 = nn.Linear(self.num_hidden, 10)\n",
    "        self.layer5 = nn.Softmax()\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        y = self.layer1(X)\n",
    "        y = self.layer2(y)\n",
    "        \n",
    "        for i in range(2):\n",
    "            y = y + self.dp(self.ac(self.bn(self.layer3(y))))\n",
    "                   \n",
    "        y = self.layer4(y)\n",
    "        y = self.layer5(y)\n",
    "        return y\n",
    "\n",
    "net = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)\n",
    "\n",
    "train_steps(\n",
    "    epochs=30, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device, \n",
    "    train_figure=True\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.3. <a id='toc8_7_3_'></a>[K折交叉验证](#toc0_)\n",
    "- 简述：把数据分成K份，分别只取1份做Test_data，（K-1）做Train_data，做K次，计算Test_acc的平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1 # k必须大于1\n",
    "    fold_size = X.shape[0] // k # 窗口大小：X一维数据长度除以k向下取整数\n",
    "    print('fold_size: ', fold_size)\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size) # 切片范围 (窗口大小)\n",
    "        print(idx)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat([X_train, X_part], 0)\n",
    "            y_train = torch.cat([y_train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14]]),\n",
       " tensor([[  0,  -1,  -2],\n",
       "         [ -3,  -4,  -5],\n",
       "         [ -6,  -7,  -8],\n",
       "         [ -9, -10, -11],\n",
       "         [-12, -13, -14]]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(15).reshape(5, 3)\n",
    "y = torch.negative(torch.arange(15).reshape(5, 3))\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_size:  2\n",
      "slice(0, 2, None)\n",
      "slice(2, 4, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[ 0, -1, -2],\n",
       "         [-3, -4, -5]]),\n",
       " tensor([[ 6,  7,  8],\n",
       "         [ 9, 10, 11]]),\n",
       " tensor([[ -6,  -7,  -8],\n",
       "         [ -9, -10, -11]]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_k_fold_data(2, 1, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8. <a id='toc8_8_'></a>[可视化训练过程](#toc0_)\n",
    "* 清理上一次\n",
    "    * figure plt.clf() # 只是清理figure内容\n",
    "    * figure `plt.colse()` # 关闭（释放）figure\n",
    "    * axes plt.cla() # 只是清理axes内容\n",
    "* 绘图plot\n",
    "* 用jupyter的display来显示\n",
    "* 保持yupyter上的display直至下一次展示再清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印图片耗时： 2.1650073528289795 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def dl_plot(x, y):\n",
    "    '''再jupyter中持续刷新展示图片'''\n",
    "    plt.close()                                 # close figure （推荐）\n",
    "    fig = plt.figure(figsize=(3.5, 2.5))\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "\n",
    "    # plt.show()                                # 普通展示\n",
    "    display.display(fig)                        # 在jupyter中展示 （推荐）\n",
    "    display.clear_output(wait=True)             # 等待 （必须）\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(50):\n",
    "    x = torch.arange(0, epoch+1, 0.1)\n",
    "    y = torch.sin(x)\n",
    "    if epoch % 2 == 0:\n",
    "        dl_plot(x, y)\n",
    "stop = time.time()\n",
    "print(f\"打印图片耗时： {stop - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10: \t train_loss=0.8999999761581421 \t train_acc=0.7833268642425537\n",
      "2/10: \t train_loss=1.899999976158142 \t train_acc=0.9463000893592834\n",
      "3/10: \t train_loss=2.9000000953674316 \t train_acc=0.23924924433231354\n",
      "4/10: \t train_loss=3.9000000953674316 \t train_acc=-0.6877662539482117\n",
      "5/10: \t train_loss=4.900000095367432 \t train_acc=-0.9824525713920593\n",
      "6/10: \t train_loss=5.900000095367432 \t train_acc=-0.37387657165527344\n",
      "7/10: \t train_loss=6.900000095367432 \t train_acc=0.5784398317337036\n",
      "8/10: \t train_loss=7.899999618530273 \t train_acc=0.9989413619041443\n",
      "9/10: \t train_loss=8.899999618530273 \t train_acc=0.5010212063789368\n",
      "10/10: \t train_loss=9.899999618530273 \t train_acc=-0.4575355648994446\n",
      "打印数值耗时： 0.0011034011840820312 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(10):\n",
    "    x = torch.arange(0, epoch+1, 0.1)\n",
    "    y = torch.sin(x)\n",
    "    # dl_plot(x, y)\n",
    "    print(f\"{epoch+1}/{10}: \\t train_loss={x[-1]} \\t train_acc={y[-1]}\")\n",
    "    \n",
    "stop = time.time()\n",
    "print(f\"打印数值耗时： {stop - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. <a id='toc9_'></a>[在 GPU 上训练](#toc0_)\n",
    "```shell\n",
    "要实行运算的Tensor必须在同一张GPU卡上：\n",
    "```\n",
    "\n",
    "|操作|函数|\n",
    "|:-|:-|\n",
    "|1. 张量传到GPU上 |x_gpu = x.to('cuda:0')|\n",
    "|2. 神经网络传到GPU上|net = net.to('cuda:0')|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. <a id='toc9_1_'></a>[查看GPU配置](#toc0_)\n",
    "```shell\n",
    "都在torch.cuda.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 是否有可用的GPU\n",
    "torch.cuda.is_available()           \n",
    "# True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可用的GPU数量\n",
    "torch.cuda.device_count()     \n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA A100-SXM4-40GB'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回gpu名字，设备索引默认从0开始；\n",
    "torch.cuda.get_device_name(0)\n",
    "# \"Tesla T4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回当前设备索引；\n",
    "torch.cuda.current_device()\n",
    "# 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单机2卡: ['NVIDIA A100-SXM4-40GB', 'NVIDIA A100-SXM4-40GB']\n"
     ]
    }
   ],
   "source": [
    "def check_device():\n",
    "    '''判断是否有GPU，并列出GPU的代号/名称'''\n",
    "    if torch.cuda.is_available(): # 判断是否支持cuda/GPU\n",
    "        gpu_num = torch.cuda.device_count() # cuda/GPU计数\n",
    "        if gpu_num == 1:\n",
    "            print(f\"单机单卡: {[torch.cuda.get_device_name(gpu_name) for gpu_name in range(gpu_num)]}\")\n",
    "        else:\n",
    "            print(f\"单机{gpu_num}卡: {[torch.cuda.get_device_name(gpu_name) for gpu_name in range(gpu_num)]}\")\n",
    "    else:\n",
    "        print(f\"只有CPU\")\n",
    "    return None \n",
    "\n",
    "check_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cuda:0', 'cuda:1']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = [ 'cpu' if not torch.cuda.is_available() else ]\n",
    "device = [f'cuda:{i}' for i in range(torch.cuda.device_count())] if torch.cuda.is_available() else ['cpu']\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. <a id='toc9_2_'></a>[单机单卡（GPU）](#toc0_)\n",
    "```\n",
    "所有的张量必须存在于同一个设备上（同一个CPU或同一个GPU），才能正确计算，否则可能会出现异常错误。\n",
    "    1、模型上GPU：model.cuda() 或 model.to(device)   \n",
    "    2、数据上GPU：data_gpu = data.cuda() 或 data_gpu = data.to(device)   \n",
    "    3、输出下GPU：output = model(data)  output.detach().cpu().numpy()，\n",
    "```\n",
    "|对象|方法一|方法二|\n",
    "|:-|:-|:-|\n",
    "|模型上GPU：|model.cuda()|model.`to(device)`|\n",
    "|数据上GPU：|data.cuda()|data.`to(device)`|\n",
    "|输出下GPU：|output=model(data)|output`.detach().cpu().numpy()`|\n",
    "||解释：||\n",
    "||output`.detach()`|将变量output从计算图中分离，使其不具有梯度，不进行反向传播|\n",
    "||`.cpu()`|将GPU数据转CPU|\n",
    "||.numpy()|将Tensor转numpy|\n",
    "||`.item()`|将Tensor转为python数值|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.]]),\n",
       " tensor([[1.],\n",
       "         [1.]]),\n",
       " device(type='cpu'),\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x = torch.ones((2, 1))\n",
    "y = torch.ones((2, 1))\n",
    "x, y, x.device, y.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.]], device='cuda:0'),\n",
       " tensor([[1.],\n",
       "         [1.]], device='cuda:0'),\n",
       " device(type='cuda', index=0),\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x.to(device)\n",
    "y1 = y.to(device)\n",
    "x1, y1, x1.device, y1.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3. <a id='toc9_3_'></a>[单机多卡（GPU）](#toc0_)\n",
    "\n",
    "目前PyTorch的单机多卡训练，主要有两种方式：\n",
    "\n",
    "|方法|函数|注释|\n",
    "|:-|:-|:-|\n",
    "|第一种：|torch.nn.`DataParallel`(module=net, device_ids=[0, 1], output_device=[0])|# 单机两卡|\n",
    "|第二种：|torch.nn.parallel.`DistributedDataParallel`()|# 单机多卡、多机多卡|\n",
    "\n",
    "\n",
    "DataParallel (DP) 和 DistributedDataParallel (DDP) 都是用于在多GPU上进行训练的工具，但它们有一些关键的区别：\n",
    "\n",
    "1. **目标环境：**\n",
    "   - `DataParallel` 适用于单机多卡的情况，通过将模型复制到每个GPU上，每个GPU计算不同的批次，最后通过梯度累积或平均来更新模型参数。\n",
    "   - `DistributedDataParallel` 适用于分布式环境，可以在单机或多台机器上的多个GPU上运行，每个GPU计算不同的批次，并通过分布式通信来同步梯度和更新模型参数。\n",
    "\n",
    "2. **通信方式：**\n",
    "   - `DataParallel` 使用单个进程内的多个GPU，通信相对较简单，仅涉及到进程内的数据传输。\n",
    "   - `DistributedDataParallel` 通过分布式通信协议，如NCCL或Gloo，实现跨进程和可能跨机器的通信，因此需要更复杂的设置。\n",
    "\n",
    "3. **启动方式：**\n",
    "   - `DataParallel` 只需在模型实例上调用 `nn.DataParallel(model)` 即可。\n",
    "   - `DistributedDataParallel` 需要在训练脚本中设置分布式环境变量，如`torch.distributed.launch` 或手动设置`os.environ`。\n",
    "\n",
    "4. **维护性：**\n",
    "   - `DataParallel` 更容易使用，因为它不涉及复杂的分布式设置。\n",
    "   - `DistributedDataParallel` 适用于更复杂的分布式场景，但需要更多的设置和管理。\n",
    "\n",
    "在单机多卡的情况下，如果简单性和易用性是首要考虑的因素，可以使用 DataParallel。在需要更高级的分布式设置时，或者在多机多卡的环境中，DistributedDataParallel 提供了更大的灵活性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.1. <a id='toc9_3_1_'></a>[DP](#toc0_)\n",
    "```shell\n",
    "单机多线程\n",
    "```\n",
    "```python\n",
    "详解\n",
    "torch.nn.DataParallel(module, device_ids, output_device)  \n",
    "\n",
    "Parameters\n",
    "    module (Module) – module to be parallelized                                                 # 神经网络\n",
    "    device_ids (list of int or torch.device) – CUDA devices (default: all devices)              # 默认使用所用GPU\n",
    "    output_device (int or torch.device) – device location of output (default: device_ids[0])    # 在cuda:0上进行参数分配、计算、汇总、更新\n",
    "Variables\n",
    "    module (Module) – the module to be parallelized\n",
    "    \n",
    "1. 有一个前提: net模型被复制到cuda:[0, 1, 2等等]上，但是X, y必须提前在cuda:0上，而不能在cuda:1、cuda:2等等上；\n",
    "2. 那如果cuda:0有其他人占满了，怎么办？那就需要手动指定其他GPU为cuda:0了：\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"      # 一定一定要放在所有访问显卡的代码之前，否则则无效，给我困扰了好一段时间才发现了。我之前看到有一个说法是放到import os之后并且在import torch之前。\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2, 3\"         # 只识别2、3而抛弃了其他GPU，把2当成pytorch逻辑上的cuda:0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Runing on cuda:0 \n",
      " ====================================================================================================\n",
      "epoch 1/10: train_loss=1.5717055797576904, train_acc=90.85833740234375, test_acc=90.91999816894531\n",
      "epoch 2/10: train_loss=1.5450035333633423, train_acc=92.63500213623047, test_acc=92.77999877929688\n",
      "epoch 3/10: train_loss=1.5318394899368286, train_acc=93.75666809082031, test_acc=93.83999633789062\n",
      "epoch 4/10: train_loss=1.5233505964279175, train_acc=94.5, test_acc=94.18000030517578\n",
      "epoch 5/10: train_loss=1.5167455673217773, train_acc=95.13500213623047, test_acc=94.83999633789062\n",
      "epoch 6/10: train_loss=1.5123507976531982, train_acc=95.55833435058594, test_acc=95.25\n",
      "epoch 7/10: train_loss=1.5058631896972656, train_acc=96.14500427246094, test_acc=95.44000244140625\n",
      "epoch 8/10: train_loss=1.502568006515503, train_acc=96.41999816894531, test_acc=95.80000305175781\n",
      "epoch 9/10: train_loss=1.4993404150009155, train_acc=96.69999694824219, test_acc=96.18000030517578\n",
      "epoch 10/10: train_loss=1.4963492155075073, train_acc=97.02667236328125, test_acc=96.30000305175781\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 5.24815821647644 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, batch_size=128,  shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 10), nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "    print('='*100, '\\n', f\"Runing on {device}\", '\\n','='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net = nn.DataParallel(module=net)\n",
    "    # net = nn.DataParallel(module=net, device_ids=[0, 1], output_device=[0]) # 多GPU并行计算，等价于net = nn.DataParallel(module=net)\n",
    "    net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.2. <a id='toc9_3_2_'></a>[DDP](#toc0_)\n",
    "```shell\n",
    "1. 与 DataParallel 的单进程控制多 GPU 不同，在 distributed 的帮助下，我们只需要编写一份代码，torch 就会自动将其分配给 \n",
    " 个进程，分别在 n 个 GPU 上运行。\n",
    "2. 单机多进程\n",
    "```\n",
    "```python\n",
    "详解\n",
    "torch.nn.parallel.DistributedDataParallel(module, device_ids, output_device)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import os \n",
    "\n",
    "def ddp_setup(rank, world_size):\n",
    "    '''\n",
    "    Args:\n",
    "        rank: unique identifier of each process\n",
    "        world_size: Total number of process\n",
    "    '''\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12357\"\n",
    "    dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3.2.1. <a id='toc9_3_2_1_'></a>[在colab上测试可用](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.multiprocessing import Process\n",
    "import os\n",
    "\n",
    "# 定义卷积神经网络模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train(local_rank, world_size):\n",
    "  \n",
    "  os.environ[\"MASTER_PORT\"] = \"12357\"\n",
    "  os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "\n",
    "  # 设置每个进程的GPU\n",
    "  torch.cuda.set_device(local_rank)\n",
    "  device = torch.device(\"cuda\", local_rank)\n",
    "\n",
    "  # 初始化进程组\n",
    "  dist.init_process_group(backend='nccl', world_size=world_size, rank=local_rank)\n",
    "\n",
    "  # 数据预处理和加载\n",
    "  transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "  trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "  # 使用DistributedSampler来对数据进行分布式采样\n",
    "  train_sampler = torch.utils.data.distributed.DistributedSampler(trainset)\n",
    "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=False, sampler=train_sampler)\n",
    "\n",
    "  # 创建CNN模型实例，并放入多个GPU上\n",
    "  model = CNN().to(device)\n",
    "  model = nn.parallel.DistributedDataParallel(model, device_ids=[local_rank])\n",
    "\n",
    "  # 定义损失函数和优化器\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "  # 训练模型\n",
    "  num_epochs = 5\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "      model.train()\n",
    "      running_loss = 0.0\n",
    "\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "          inputs, labels = data\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          running_loss += loss.item()\n",
    "\n",
    "      print(f\"Local Rank {local_rank}, Epoch {epoch + 1}/{num_epochs}, Training Loss: {running_loss / len(trainloader):.4f}\")\n",
    "\n",
    "  dist.destroy_process_group()\n",
    "\n",
    "# Process格式：\n",
    "if __name__ == \"__main__\":\n",
    "  # size = torch.cuda.device_count()\n",
    "  size = 10\n",
    "  processes = []\n",
    "  world_size = 1\n",
    "  for rank in range(size):\n",
    "      p = Process(target=train, args=(rank, world_size))\n",
    "      p.start()\n",
    "      processes.append(p)\n",
    "\n",
    "  for p in processes:\n",
    "      p.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4. <a id='toc9_4_'></a>[多机多卡（GPU）- 分布式训练](#toc0_)\n",
    "```shell\n",
    "目前PyTorch的多机多卡训练，主要有两种方式：   \n",
    "    1. torch.nn.parallel.DistributedDataParallel()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. <a id='toc10_'></a>[模型和参数的保存与加载](#toc0_)\n",
    "\n",
    "* torch.save( 张量名, 位置 )\n",
    "\n",
    "* 张量名称 = torch.load( 位置 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1. <a id='toc10_1_'></a>[加载和保存-张量](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.ones((3, 5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save()\n",
    "torch.save(x, './Pytorch_params/x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.load()\n",
    "x1 = torch.load('./Pytorch_params/x-file')\n",
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2. <a id='toc10_2_'></a>[加载和保存-模型参数](#toc0_)\n",
    "```shell\n",
    "保存单个权重向量（或其他张量）确实有用， 但是如果我们想保存整个模型，并在以后加载它们， 单独保存每个向量则会变得很麻烦。 毕竟，我们可能有数百个参数散布在各处。 因此，深度学习框架提供了内置函数来保存和加载整个网络。 需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。 例如，如果我们有一个3层多层感知机，我们需要单独指定架构。 因为模型本身可以包含任意代码，所以模型本身难以序列化。 因此，为了恢复模型，我们需要用代码生成架构， 然后从磁盘加载参数。\n",
    "```\n",
    "```shell\n",
    "1. save和load函数可用于张量对象的文件读写。\n",
    "2. 我们可以通过参数字典保存和加载网络的全部参数。\n",
    "3. 保存架构必须在代码中完成，而不是在参数中完成。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save()\n",
    "# 接下来，我们将模型的参数存储在一个叫做“mlp.params”的文件中。\n",
    "torch.save(net.state_dict(), './Pytorch_params/mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.load()\n",
    "# 为了恢复模型，我们实例化了原始多层感知机模型的一个备份。 \n",
    "# 这里我们不需要随机初始化模型参数，而是直接读取文件中存储的参数。\n",
    "net_params = torch.load('./Pytorch_params/mlp.params')\n",
    "clone = MLP()\n",
    "\n",
    "clone.load_state_dict(net_params)\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 完整的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存\n",
    "torch.save(\n",
    "    {\n",
    "        'epoch': '10', \n",
    "        'model_state_dict': net.state_dict(), \n",
    "        # 'opt_state_dict': opt.state_dict(), \n",
    "        'loss': 'loss'\n",
    "    }, \n",
    "    './Pytorch_params/test.pt'\n",
    ")\n",
    "\n",
    "# 重载\n",
    "check_point = torch.load('./Pytorch_params/test.pt')\n",
    "\n",
    "check_point['model_state_dict']\n",
    "check_point['loss']\n",
    "check_point['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. <a id='toc11_'></a>[神经网络类型](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. <a id='toc11_1_'></a>[CNN](#toc0_)\n",
    "\n",
    "CBAPD: 卷积，批量归一化，激活，池化，丢弃\n",
    "\n",
    "卷积层就是特征提取，随后将特征传入FC（全连接层）；\n",
    "\n",
    "卷积本身是线性的，但是经过激活函数后可以编程非线性的。\n",
    "\n",
    "### 11.1.1. <a id='toc11_1_1_'></a>[概述](#toc0_)\n",
    "\n",
    "- 为什么要用CNN？\n",
    "  - 利用MLP处理图片像素矩阵，太占内存\n",
    "  - 解决办法，顶层设计一个新的算法具备如下特点：\n",
    "    - 局部性\n",
    "    - 平移不变性\n",
    "  - 刚好来自“信号处理中的卷积”符合此类特征：\n",
    "    - 局部性 （固定/通用的卷积核）\n",
    "    - 平移不变性 （特征图在整个图片的位置不固定，可以平移）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.2. <a id='toc11_1_2_'></a>[简单CNN](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2.1. <a id='toc11_1_2_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11.1.2.1.1. <a id='toc11_1_2_1_1_'></a>[卷积计算过程](#toc0_)\n",
    "\n",
    " <img src=\"./Pytorch_Pictures/convolution/conv.gif\" width = \"500\" height = \"300\" alt=\"图片名称\" align=center />\n",
    "\n",
    "- 内积后求和\n",
    "\n",
    "- 输出大小：(Xh - Kh + 1, Xw - Kw + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def cov2d(X, kernel)-> torch.Tensor:\n",
    "    '''\n",
    "    手写二维convolution计算过程 (二维互关运算)\n",
    "\n",
    "    Args: \n",
    "        X (2d): 输入图片像素矩阵\n",
    "        kernel (int): 卷积核\n",
    "\n",
    "    Return: \n",
    "        Y: 卷积计算结果\n",
    "    '''\n",
    "\n",
    "    h, w = kernel.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))   # 输出形状，暂时用0填充\n",
    "    # print(Y)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * kernel).sum()      # X取子集 * kernel 最后在求和\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.],\n",
       "        [6., 7., 8.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(9, dtype=torch.float32).reshape(3, 3)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = torch.arange(4, dtype=torch.float32).reshape(2, 2)\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov2d(X=X, kernel=kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11.1.2.1.2. <a id='toc11_1_2_1_2_'></a>[从头卷积层](#toc0_)\n",
    "- 卷积层对输入和卷积核进行互关运算，并添加偏置；\n",
    "- 所以卷积层中两个被训练的参数是卷积核与偏置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Cov2d(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return cov2d(X, self.weight) + self.bias                   # 将conv2d计算添加进来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.9126,  5.9625],\n",
       "        [10.0622, 12.1121]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov2d1 = Cov2d(kernel_size=(2, 2))\n",
    "cov2d1(X=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2.2. <a id='toc11_1_2_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0601,  0.0402],\n",
       "          [ 0.2407,  0.3410]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "conv2d = nn.Conv2d(\n",
    "    in_channels = 1, \n",
    "    out_channels = 1, \n",
    "    kernel_size = (2, 2), \n",
    "    bias = True\n",
    ")\n",
    "\n",
    "# nn.Conv2d的输入和输出都是：批量大小、通道数、高度和宽度\n",
    "conv2d(X.reshape((1,1,3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2.3. <a id='toc11_1_2_3_'></a>[填充和步幅](#toc0_)\n",
    "\n",
    "- 填充 (padding)\n",
    "\n",
    "  - 输出大小：(Xh - Kh + Ph + 1, Xw - Kw + Pw + 1)\n",
    "\n",
    "  - 一般情况下Kh和Kw为奇数(1,3,5,7) 可得 (输入和输出形状一致)：\n",
    "\n",
    "    - Ph设置为：Kh - 1\n",
    "\n",
    "    - Pw设置为：Kw - 1\n",
    "\n",
    "  - padding填写时写一半 (输入和输出形状一致)：\n",
    "    - padding = (Ph/2, Pw/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.],\n",
       "         [6., 7., 8.]]),\n",
       " torch.Size([1, 1, 3, 3]),\n",
       " tensor([[[[-0.3299, -0.8171,  0.1535],\n",
       "           [-1.3427, -2.3634, -0.2771],\n",
       "           [-1.2391, -2.3088, -2.5213]]]], grad_fn=<ConvolutionBackward0>),\n",
       " torch.Size([1, 1, 3, 3]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "conv2d1 = nn.Conv2d(\n",
    "    in_channels = 1, \n",
    "    out_channels = 1, \n",
    "    kernel_size = (3, 3), \n",
    "    bias = True, \n",
    "    padding = (1, 1),           # ((3 - 1)/2, (3 - 1)/2)\n",
    "    stride = 1\n",
    ")\n",
    "\n",
    "# nn.Conv2d的输入和输出都是：批量大小、通道数、高度和宽度\n",
    "X = torch.arange(9, dtype=torch.float32).reshape(3, 3)\n",
    "Y = conv2d1(X.reshape((1,1,3,3)))\n",
    "X, X.reshape((1,1,3,3)).shape, Y, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 步幅 (stride)\n",
    "\n",
    "  - 输出大小为：( (Xh - Kh + Ph + Sh)/Sh, (Xw - Kw + Pw + Sw)/Sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11., 12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19., 20., 21., 22., 23.],\n",
       "         [24., 25., 26., 27., 28., 29., 30., 31.],\n",
       "         [32., 33., 34., 35., 36., 37., 38., 39.],\n",
       "         [40., 41., 42., 43., 44., 45., 46., 47.],\n",
       "         [48., 49., 50., 51., 52., 53., 54., 55.],\n",
       "         [56., 57., 58., 59., 60., 61., 62., 63.]]),\n",
       " torch.Size([1, 1, 8, 8]),\n",
       " tensor([[[[  0.4318,  -2.9064,  -3.9838,  -5.0611],\n",
       "           [ -3.0204, -13.3529, -14.7837, -16.2145],\n",
       "           [ -6.1843, -24.7991, -26.2299, -27.6607],\n",
       "           [ -9.3481, -36.2454, -37.6762, -39.1069]]]],\n",
       "        grad_fn=<ConvolutionBackward0>),\n",
       " torch.Size([1, 1, 4, 4]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "conv2d1 = nn.Conv2d(\n",
    "    in_channels = 1, \n",
    "    out_channels = 1, \n",
    "    kernel_size = (3, 3), \n",
    "    bias = True, \n",
    "    padding = (1, 1),           # ((3 - 1)/2, (3 - 1)/2)\n",
    "    stride = 2                  # (8 - 3 + 1 + 2 )/2 = 4\n",
    ")\n",
    "\n",
    "# nn.Conv2d的输入和输出都是：批量大小、通道数、高度和宽度\n",
    "X = torch.arange(64, dtype=torch.float32).reshape(8, 8)\n",
    "Y = conv2d1(X.reshape((1,1,8,8)))\n",
    "X, X.reshape((1,1,8,8)).shape, Y, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2.4. <a id='toc11_1_2_4_'></a>[多输入和多输出通道](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11., 12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19., 20., 21., 22., 23.],\n",
       "         [24., 25., 26., 27., 28., 29., 30., 31.],\n",
       "         [32., 33., 34., 35., 36., 37., 38., 39.],\n",
       "         [40., 41., 42., 43., 44., 45., 46., 47.],\n",
       "         [48., 49., 50., 51., 52., 53., 54., 55.],\n",
       "         [56., 57., 58., 59., 60., 61., 62., 63.]]),\n",
       " torch.Size([1, 1, 8, 8]),\n",
       " tensor([[[[ -3.1349,  -3.0231,  -4.5567,  -6.0904],\n",
       "           [-15.0264, -16.0034, -17.6924, -19.3814],\n",
       "           [-26.5322, -29.5155, -31.2045, -32.8935],\n",
       "           [-38.0381, -43.0276, -44.7166, -46.4056]],\n",
       " \n",
       "          [[  1.8246,   4.3984,   5.4487,   6.4991],\n",
       "           [  0.2586,  11.0692,  11.8181,  12.5670],\n",
       "           [ -1.3924,  17.0604,  17.8093,  18.5582],\n",
       "           [ -3.0434,  23.0516,  23.8005,  24.5494]],\n",
       " \n",
       "          [[ -3.0677,  -2.4633,  -2.2421,  -2.0210],\n",
       "           [-12.1480,  -5.0198,  -5.5860,  -6.1523],\n",
       "           [-24.6482,  -9.5497, -10.1159, -10.6822],\n",
       "           [-37.1485, -14.0796, -14.6459, -15.2121]]]],\n",
       "        grad_fn=<ConvolutionBackward0>),\n",
       " torch.Size([1, 3, 4, 4]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "conv2d1 = nn.Conv2d(\n",
    "    in_channels = 1, \n",
    "    out_channels = 3, \n",
    "    kernel_size = (3, 3), \n",
    "    bias = True, \n",
    "    padding = (1, 1),           # ((3 - 1)/2, (3 - 1)/2)\n",
    "    stride = 2                  # (8 - 3 + 1 + 2 )/2 = 4\n",
    ")\n",
    "\n",
    "# nn.Conv2d的输入和输出都是：批量大小、通道数、高度和宽度\n",
    "X = torch.arange(64, dtype=torch.float32).reshape(8, 8)\n",
    "Y = conv2d1(X.reshape((1,1,8,8)))\n",
    "X, X.reshape((1,1,8,8)).shape, Y, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2.5. <a id='toc11_1_2_5_'></a>[Pooling (汇聚层)](#toc0_)\n",
    "\n",
    "- pooling层不包含参数\n",
    "\n",
    "\n",
    "##### 11.1.2.5.1. <a id='toc11_1_2_5_1_'></a>[平均Pooling](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AvgPool2d(kernel_size=(2, 2), stride=1, padding=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "nn.AvgPool2d(\n",
    "    kernel_size = (2, 2), \n",
    "    padding = 0, \n",
    "    stride = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11.1.2.5.2. <a id='toc11_1_2_5_2_'></a>[最大Pooling](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool2d(kernel_size=(2, 2), stride=1, padding=0, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "nn.MaxPool2d(\n",
    "    kernel_size = (2, 2), \n",
    "    padding = 0, \n",
    "    stride = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.3. <a id='toc11_1_3_'></a>[LeNet](#toc0_)\n",
    "\n",
    "- 最早被Yann LeCun用来识别手写数字的算法\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/convolution/LeNet.jpg\" width = \"700\" height = \"300\" alt=\"图片名称\" align=center >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1736, -0.2433,  0.1071,  0.7213, -0.1392,  0.1065,  0.1411,  0.4583,\n",
       "          0.1942,  0.0054]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), \n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5), \n",
    "            nn.Sigmoid(), \n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(16 * 5 * 5, 120), \n",
    "            nn.Sigmoid(), \n",
    "            nn.Linear(120, 84), \n",
    "            nn.Sigmoid(), \n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "lenet = LeNet()\n",
    "\n",
    "X = torch.arange(28*28, dtype=torch.float32).reshape((1, 1, 28, 28))\n",
    "# X = torch.rand(size=(1,1,28,28), dtype=torch.float32)\n",
    "# X.shape\n",
    "lenet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.4. <a id='toc11_1_4_'></a>[AlexNet](#toc0_)\n",
    "\n",
    "- 第一个在大规模视觉比赛 (ImageNet) 中战胜传统给算法 (如支持向量机 supportvectormachines) 的**大型神经网络**\n",
    "\n",
    "- 证明算法学习的特征可以超越手动设计的特征\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/convolution/AlexNet.jpg\" width = \"500\" height = \"700\" alt=\"图片名称\" align=center >  \n",
    "\n",
    "- LeNet VS AlexNet：\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/convolution/LeNetVSAlexNet.jpg\" width = \"1000\" height = \"300\" alt=\"图片名称\" align=center >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import AlexNet\n",
    "\n",
    "alexnet = AlexNet()\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.5. <a id='toc11_1_5_'></a>[VGG](#toc0_)\n",
    "\n",
    "- 利用重复的神经网络块\n",
    "\n",
    "  - 卷积层，如Conv2d()\n",
    "  - 非线性激活，如nn.Relu()\n",
    "  - 汇聚层，如nn.MaxPooling()\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/convolution/VGG.jpg\" width = \"500\" height = \"500\" alt=\"图片名称\" align=center >  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模块设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (5): Flatten(start_dim=1, end_dim=-1)\n",
       "  (6): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Dropout(p=0.5, inplace=False)\n",
       "  (9): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.5, inplace=False)\n",
       "  (12): Linear(in_features=4096, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "conv_arch = (\n",
    "    (1, 64), \n",
    "    (1, 128), \n",
    "    (2, 256), \n",
    "    (2, 512), \n",
    "    (2, 512)\n",
    ")\n",
    "\n",
    "def vgg(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    # 卷积部分\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "        \n",
    "    return nn.Sequential(\n",
    "        *conv_blks, \n",
    "        nn.Flatten(), \n",
    "        # 全连接部分\n",
    "        nn.Linear(out_channels*7*7, 4096), \n",
    "        nn.ReLU(), \n",
    "        nn.Dropout(p=0.5), \n",
    "        nn.Linear(4096, 4096), \n",
    "        nn.ReLU(), \n",
    "        nn.Dropout(p=0.5), \n",
    "        nn.Linear(4096, 10)\n",
    "    )\n",
    "\n",
    "net = vgg(conv_arch)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vgg11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import vgg11\n",
    "\n",
    "vgg = vgg11()\n",
    "vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.6. <a id='toc11_1_6_'></a>[NiN](#toc0_)\n",
    "\n",
    "- 使用1 x 1卷积层来替代全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.7. <a id='toc11_1_7_'></a>[GoogLeNet](#toc0_)\n",
    "\n",
    "- 2014年的ImageNet挑战赛中，GoogLeNet大放异彩；\n",
    "\n",
    "- 解决了到底选多大的卷积核的问题？结论是：使用不同大小的卷积核组合更加有利。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.8. <a id='toc11_1_8_'></a>[批量规范化](#toc0_)\n",
    "\n",
    "- batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BatchNorm2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.9. <a id='toc11_1_9_'></a>[ResNet](#toc0_)\n",
    "```shell\n",
    "如果，CNN只需要弄懂一个神经网络模型的话，那就是ResNet。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.9.1. <a id='toc11_1_9_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.LSTM(), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet34 \n",
    "\n",
    "resnet = resnet34()\n",
    "resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2. <a id='toc11_2_'></a>[序列数据](#toc0_)\n",
    "### 11.2.1. <a id='toc11_2_1_'></a>[什么是序列](#toc0_)\n",
    "\n",
    "在深度学习中，**序列**是一段具有连续关系的数据，通常带有时间先后顺序。例如，文本、语音、股票价格、气温、DNA序列等都可以被视为序列数据。为了处理不定长的数据，我们常常使用循环神经网络（RNN）来处理序列信息。总之，序列数据在许多领域中都有广泛的应用，包括自然语言处理、时间序列分析、音频处理和图像处理等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.2. <a id='toc11_2_2_'></a>[语言模型](#toc0_)\n",
    "\n",
    "语言模型 (language model) 是定义在单词序列上的概率模型，可以用来计算一个句子或一段文字的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.3. <a id='toc11_2_3_'></a>[文本预处理](#toc0_)\n",
    "* token：最小单位（字符/单词/词组）\n",
    "* vocab：（token：indice）对照（查询）列表\n",
    "* cropus：token转化为indice后的文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.3.1. <a id='toc11_2_3_1_'></a>[下载《Time machine》并读取数据](#toc0_)\n",
    "首先，我们从H.G.Well的[时光机器](https://www.gutenberg.org/ebooks/35)中加载文本。\n",
    "这是一个相当小的语料库，只有30000多个单词，但足够我们小试牛刀，\n",
    "而现实中的文档集合可能会包含数十亿个单词。\n",
    "下面的函数 (**将数据集读取到由多条文本行组成的列表中**)，其中每条文本行都是一个字符串。\n",
    "为简单起见，我们在这里忽略了标点符号和字母大写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 文本总行数: 3221\n",
      "the time machine by h g wells\n",
      "\n",
      "twinkled and his usually pale face was flushed and animated the\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import re\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#@save\n",
    "# 下载到../data/timemachine.txt\n",
    "d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt', '090b5e7e70c295757f55df93cb0a180b9691891a')\n",
    "\n",
    "def read_time_machine():  #@save\n",
    "    \"\"\"将时间机器数据集加载到文本行的列表中\"\"\"\n",
    "    with open(d2l.download('time_machine'), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
    "\n",
    "lines = read_time_machine()\n",
    "print(f'# 文本总行数: {len(lines)}')\n",
    "print(lines[0])\n",
    "print(lines[1]) # 空的\n",
    "print(lines[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.3.2. <a id='toc11_2_3_2_'></a>[词元化（Token）](#toc0_)\n",
    "* 按照char/word等拆分成列表格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['i']\n",
      "[]\n",
      "[]\n",
      "['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him']\n",
      "['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']\n",
      "['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n"
     ]
    }
   ],
   "source": [
    "# 按照word\n",
    "def tokenize(lines, token='word'):  #@save\n",
    "    \"\"\"将文本行拆分为单词或字符词元\"\"\"\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('错误：未知词元类型：' + token)\n",
    "\n",
    "tokens = tokenize(lines)\n",
    "for i in range(11):\n",
    "    print(tokens[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.3.3. <a id='toc11_2_3_3_'></a>[词表（vocab）](#toc0_)\n",
    "* 构建(token：索引)查询元组\n",
    "* 并将文本的token替换成索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:\t [('<unk>', 0), ('the', 1), ('i', 2), ('and', 3), ('of', 4), ('a', 5), ('to', 6), ('was', 7), ('in', 8), ('that', 9)]\n",
      "文本: ['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
      "索引: [1, 19, 50, 40, 2183, 2184, 400]\n",
      "文本: ['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n",
      "索引: [2186, 3, 25, 1044, 362, 113, 7, 1421, 3, 1045, 1]\n"
     ]
    }
   ],
   "source": [
    "class Vocab:  #@save\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # 按出现频率排序\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # 未知词元的索引为0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "\n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    # 这里的tokens是1D列表或2D列表\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # 将词元列表展平成一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "vocab = Vocab(tokens)\n",
    "print('vocab:\\t', list(vocab.token_to_idx.items())[:10])\n",
    "\n",
    "for i in [0, 10]:\n",
    "    print('文本:', tokens[i])\n",
    "    print('索引:', vocab[tokens[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.3.4. <a id='toc11_2_3_4_'></a>[整合所有功能](#toc0_)\n",
    "* 读取数据\n",
    "* 分割成token\n",
    "* 并构建(token, indice)查询表并替换token成indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170580, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按照char进行词元化 \n",
    "\n",
    "def load_corpus_time_machine(max_tokens=-1):  #@save\n",
    "    \"\"\"返回时光机器数据集的词元索引列表和词表\"\"\"\n",
    "    lines = read_time_machine()\n",
    "    tokens = tokenize(lines, 'char')\n",
    "    vocab = Vocab(tokens)\n",
    "    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n",
    "    # 所以将所有文本行展平到一个列表中\n",
    "    corpus = [vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[:max_tokens]\n",
    "    return corpus, vocab\n",
    "\n",
    "corpus, vocab = load_corpus_time_machine()\n",
    "len(corpus), len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.4. <a id='toc11_2_4_'></a>[语言模型数据集](#toc0_)\n",
    "#### 11.2.4.1. <a id='toc11_2_4_1_'></a>[顺序采样](#toc0_)\n",
    "\n",
    "- 顺序采样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_iter_sequential(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用顺序分区生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始划分序列\n",
    "    offset = random.randint(0, num_steps)\n",
    "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
    "    Xs = torch.tensor(corpus[offset: offset + num_tokens])\n",
    "    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
    "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
    "    num_batches = Xs.shape[1] // num_steps\n",
    "    \n",
    "    for i in range(0, num_steps * num_batches, num_steps):\n",
    "        X = Xs[:, i: i + num_steps]\n",
    "        Y = Ys[:, i: i + num_steps]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):\n",
    "#     print('X: ', X, '\\nY:', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.4.2. <a id='toc11_2_4_2_'></a>[随机采样](#toc0_)\n",
    "\n",
    "- 随机采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seq_data_iter_random(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用随机抽样生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n",
    "    corpus = corpus[random.randint(0, num_steps - 1):]\n",
    "    # 减去1，是因为我们需要考虑标签\n",
    "    num_subseqs = (len(corpus) - 1) // num_steps\n",
    "    # 长度为num_steps的子序列的起始索引\n",
    "    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "    # 在随机抽样的迭代过程中，\n",
    "    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n",
    "    random.shuffle(initial_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        # 返回从pos位置开始的长度为num_steps的序列\n",
    "        return corpus[pos: pos + num_steps]\n",
    "\n",
    "    num_batches = num_subseqs // batch_size\n",
    "    for i in range(0, batch_size * num_batches, batch_size):\n",
    "        # 在这里，initial_indices包含子序列的随机起始索引\n",
    "        initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
    "        X = [data(j) for j in initial_indices_per_batch]\n",
    "        Y = [data(j + 1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(X), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_seq = list(range(35))\n",
    "# for X, Y in seq_data_iter_random(my_seq, batch_size=2, num_steps=5):\n",
    "#     print('X: ', X, '\\nY:', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.4.3. <a id='toc11_2_4_3_'></a>[包装](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataLoader:  #@save\n",
    "    \"\"\"加载序列数据的迭代器\"\"\"\n",
    "    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n",
    "        if use_random_iter:\n",
    "            # self.data_iter_fn = d2l.seq_data_iter_random\n",
    "            self.data_iter_fn = seq_data_iter_random\n",
    "        else:\n",
    "            # self.data_iter_fn = d2l.seq_data_iter_sequential\n",
    "            self.data_iter_fn = seq_data_iter_sequential\n",
    "        # self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)\n",
    "        self.corpus, self.vocab = load_corpus_time_machine(max_tokens)\n",
    "        self.batch_size, self.num_steps = batch_size, num_steps\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_time_machine(\n",
    "        batch_size, num_steps, \n",
    "        use_random_iter=False, \n",
    "        max_tokens=10000\n",
    "    ):\n",
    "    \"\"\"\n",
    "    返回时光机器数据集的迭代器和词表\n",
    "    \"\"\"\n",
    "    data_iter = SeqDataLoader(\n",
    "        batch_size, num_steps, use_random_iter, max_tokens\n",
    "    )\n",
    "    \n",
    "    return data_iter, data_iter.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3. <a id='toc11_3_'></a>[RNN](#toc0_)\n",
    "* 可以处理有顺序的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.1. <a id='toc11_3_1_'></a>[RNN-循环神经网络原理](#toc0_)\n",
    "* 结构：\n",
    "    * 有一层（或多层）隐藏结构；\n",
    "    * 当前隐藏结构由上一侧隐藏结构和当前输入决定\n",
    "    * 依次类推\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/RNN//RNN.jpg\" width = \"500\" height = \"300\" alt=\"图片名称\" align=center />\n",
    "\n",
    "更新隐藏状态：      \n",
    "$\\mathbf{h}_t=\\phi(\\mathbf{W}_{hh}\\mathbf{h}_{t-1}+\\mathbf{W}_{hx}\\mathbf{x}_{t-1}+\\mathbf{b}_h)$  \n",
    "输出：             \n",
    "$\\mathbf{o}_t=\\phi(\\mathbf{W}_\\textit{ho}\\mathbf{h}_t+\\mathbf{b}_o)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1.1. <a id='toc11_3_1_1_'></a>[从头实现网络](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 28]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网络结构\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 初始化模型\n",
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = normal((num_inputs, num_hiddens))\n",
    "    W_hh = normal((num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 附加梯度\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params\n",
    "\n",
    "def init_rnn_state(batch_size, num_hiddens, device):                        # 初始化第一个隐变量的值\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )\n",
    "\n",
    "def rnn(inputs, state, params):\n",
    "    # inputs的形状：(时间步数量，批量大小，词表大小)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    # X的形状：(批量大小，词表大小)\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)         # 隐藏变量\n",
    "        Y = torch.mm(H, W_hq) + b_q                                         # 输出\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H,)\n",
    "\n",
    "class RNNModelScratch: #@save\n",
    "    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, device,\n",
    "                 get_params, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "\n",
    "    def __call__(self, X, state):\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)\n",
    "    \n",
    "# 测试一下\n",
    "X = torch.arange(10).reshape((2, 5))\n",
    "F.one_hot(X.T, 28).shape\n",
    "\n",
    "num_hiddens = 512\n",
    "net = RNNModelScratch(\n",
    "    len(vocab), \n",
    "    num_hiddens, \n",
    "    d2l.try_gpu(), \n",
    "    get_params,\n",
    "    init_rnn_state, \n",
    "    rnn\n",
    ")\n",
    "\n",
    "state = net.begin_state(X.shape[0], d2l.try_gpu())\n",
    "Y, new_state = net(X.to(d2l.try_gpu()), state)\n",
    "Y.shape, len(new_state), new_state[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1.2. <a id='toc11_3_1_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (rnn): RNN(28, 512)\n",
       "  (linear): Linear(in_features=512, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, rnn_layer, vocab_size, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_hiddens = self.rnn.hidden_size\n",
    "        # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1\n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions = 1\n",
    "            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
    "        else:\n",
    "            self.num_directions = 2\n",
    "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        X = F.one_hot(inputs.T.long(), self.vocab_size)\n",
    "        X = X.to(torch.float32)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)\n",
    "        # 它的输出形状是(时间步数*批量大小,词表大小)。\n",
    "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        if not isinstance(self.rnn, nn.LSTM):\n",
    "            # nn.GRU以张量作为隐状态\n",
    "            return  torch.zeros((self.num_directions * self.rnn.num_layers,\n",
    "                                 batch_size, self.num_hiddens),\n",
    "                                device=device)\n",
    "        else:\n",
    "            # nn.LSTM以元组作为隐状态\n",
    "            return (torch.zeros((\n",
    "                self.num_directions * self.rnn.num_layers,\n",
    "                batch_size, self.num_hiddens), device=device),\n",
    "                    torch.zeros((\n",
    "                        self.num_directions * self.rnn.num_layers,\n",
    "                        batch_size, self.num_hiddens), \n",
    "                        device=device))\n",
    "\n",
    "batch_size, num_steps, num_hiddens = 32, 35, 512\n",
    "rnn_layer = nn.RNN(len(vocab), num_hiddens)\n",
    "# 我们(**使用张量来初始化隐状态**)，它的形状是（隐藏层数，批量大小，隐藏单元数）。\n",
    "state = torch.zeros((1, batch_size, num_hiddens))\n",
    "state.shape\n",
    "# [**通过一个隐状态和一个输入，我们就可以用更新后的隐状态计算输出。**]\n",
    "# 需要强调的是，`rnn_layer`的“输出”（`Y`）不涉及输出层的计算：\n",
    "# 它是指每个时间步的隐状态，这些隐状态可以用作后续输出层的输入。\n",
    "X = torch.rand(size=(num_steps, batch_size, len(vocab)))\n",
    "Y, state_new = rnn_layer(X, state)\n",
    "Y.shape, state_new.shape\n",
    "\n",
    "device = d2l.try_gpu()\n",
    "net = RNNModel(rnn_layer, vocab_size=len(vocab))\n",
    "net = net.to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1.3. <a id='toc11_3_1_3_'></a>[训练和预测](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time traveller lcjt cjt c'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测\n",
    "def predict_ch8(prefix, num_preds, net, vocab, device):  #@save\n",
    "    \"\"\"在prefix后面生成新字符\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])\n",
    "\n",
    "# 测试以下\n",
    "predict_ch8('time traveller ', 10, net, vocab, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度剪裁\n",
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "困惑度 1.0, 36068.3 词元/秒 cpu\n",
      "time travelleryou can show black is white by argument said filby\n",
      "travellerywi can anowhs astoun thives sat ancarauina soroun\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"252.646875pt\" height=\"183.35625pt\" viewBox=\"0 0 252.646875 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-06-12T14:07:01.405734</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 252.646875 183.35625 \n",
       "L 252.646875 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 235.903125 145.8 \n",
       "L 235.903125 7.2 \n",
       "L 40.603125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 76.474554 145.8 \n",
       "L 76.474554 7.2 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m9fafbe1039\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9fafbe1039\" x=\"76.474554\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(66.930804 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 116.331696 145.8 \n",
       "L 116.331696 7.2 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9fafbe1039\" x=\"116.331696\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(106.787946 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 156.188839 145.8 \n",
       "L 156.188839 7.2 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9fafbe1039\" x=\"156.188839\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(146.645089 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 196.045982 145.8 \n",
       "L 196.045982 7.2 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9fafbe1039\" x=\"196.045982\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(186.502232 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 235.903125 145.8 \n",
       "L 235.903125 7.2 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9fafbe1039\" x=\"235.903125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 500 -->\n",
       "      <g transform=\"translate(226.359375 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(123.025 174.076563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 40.603125 127.479182 \n",
       "L 235.903125 127.479182 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <defs>\n",
       "       <path id=\"m6c4242c9f0\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6c4242c9f0\" x=\"40.603125\" y=\"127.479182\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(27.240625 131.278401) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 40.603125 102.799364 \n",
       "L 235.903125 102.799364 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6c4242c9f0\" x=\"40.603125\" y=\"102.799364\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(27.240625 106.598583) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 40.603125 78.119546 \n",
       "L 235.903125 78.119546 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6c4242c9f0\" x=\"40.603125\" y=\"78.119546\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(27.240625 81.918765) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 40.603125 53.439729 \n",
       "L 235.903125 53.439729 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6c4242c9f0\" x=\"40.603125\" y=\"53.439729\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(27.240625 57.238947) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 40.603125 28.759911 \n",
       "L 235.903125 28.759911 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6c4242c9f0\" x=\"40.603125\" y=\"28.759911\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(20.878125 32.55913) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- perplexity -->\n",
       "     <g transform=\"translate(14.798437 101.626563) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \n",
       "L 2247 1797 \n",
       "L 3578 0 \n",
       "L 2900 0 \n",
       "L 1881 1375 \n",
       "L 863 0 \n",
       "L 184 0 \n",
       "L 1544 1831 \n",
       "L 300 3500 \n",
       "L 978 3500 \n",
       "L 1906 2253 \n",
       "L 2834 3500 \n",
       "L 3513 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"166.113281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"229.589844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"257.373047\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-78\" x=\"317.146484\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"376.326172\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"404.109375\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"443.318359\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 40.603125 13.5 \n",
       "L 44.588839 38.903188 \n",
       "L 48.574554 50.823382 \n",
       "L 52.560268 55.790138 \n",
       "L 56.545982 57.979064 \n",
       "L 60.531696 57.558539 \n",
       "L 64.517411 65.476167 \n",
       "L 68.503125 68.177691 \n",
       "L 72.488839 77.919137 \n",
       "L 76.474554 92.27673 \n",
       "L 80.460268 104.465713 \n",
       "L 84.445982 115.727056 \n",
       "L 88.431696 122.01171 \n",
       "L 92.417411 127.543307 \n",
       "L 96.403125 130.95291 \n",
       "L 100.388839 133.308078 \n",
       "L 104.374554 134.310327 \n",
       "L 108.360268 134.545716 \n",
       "L 112.345982 135.311029 \n",
       "L 116.331696 136.272286 \n",
       "L 120.317411 136.81972 \n",
       "L 124.303125 136.784054 \n",
       "L 128.288839 136.797256 \n",
       "L 132.274554 138.226705 \n",
       "L 136.260268 138.596783 \n",
       "L 140.245982 138.618342 \n",
       "L 144.231696 139.42294 \n",
       "L 148.217411 139.059762 \n",
       "L 152.203125 138.926626 \n",
       "L 156.188839 139.254369 \n",
       "L 160.174554 138.732718 \n",
       "L 164.160268 139.382934 \n",
       "L 168.145982 139.472775 \n",
       "L 172.131696 139.244456 \n",
       "L 176.117411 139.136444 \n",
       "L 180.103125 137.627235 \n",
       "L 184.088839 137.367193 \n",
       "L 188.074554 137.377273 \n",
       "L 192.060268 137.639637 \n",
       "L 196.045982 138.961781 \n",
       "L 200.031696 139.049954 \n",
       "L 204.017411 138.823063 \n",
       "L 208.003125 139.247419 \n",
       "L 211.988839 139.194583 \n",
       "L 215.974554 139.460182 \n",
       "L 219.960268 139.5 \n",
       "L 223.945982 139.381636 \n",
       "L 227.931696 139.320266 \n",
       "L 231.917411 139.292692 \n",
       "L 235.903125 139.28429 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 40.603125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 235.903125 145.8 \n",
       "L 235.903125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 235.903125 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 40.603125 7.2 \n",
       "L 235.903125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 173.628125 29.878125 \n",
       "L 228.903125 29.878125 \n",
       "Q 230.903125 29.878125 230.903125 27.878125 \n",
       "L 230.903125 14.2 \n",
       "Q 230.903125 12.2 228.903125 12.2 \n",
       "L 173.628125 12.2 \n",
       "Q 171.628125 12.2 171.628125 14.2 \n",
       "L 171.628125 27.878125 \n",
       "Q 171.628125 29.878125 173.628125 29.878125 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_22\">\n",
       "     <path d=\"M 175.628125 20.298438 \n",
       "L 185.628125 20.298438 \n",
       "L 195.628125 20.298438 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- train -->\n",
       "     <g transform=\"translate(203.628125 23.798438) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p7dcae8e3b8\">\n",
       "   <rect x=\"40.603125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练\n",
    "import math \n",
    "\n",
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    \"\"\"训练网络一个迭代周期（定义见第8章）\"\"\"\n",
    "    state, timer = None, d2l.Timer()\n",
    "    metric = d2l.Accumulator(2)  # 训练损失之和,词元数量\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # 在第一次迭代或使用随机抽样时初始化state\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # state对于nn.GRU是个张量\n",
    "                state.detach_()\n",
    "            else:\n",
    "                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            # 因为已经调用了mean函数\n",
    "            updater(batch_size=1)\n",
    "        metric.add(l * y.numel(), y.numel())\n",
    "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()\n",
    "\n",
    "#@save\n",
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n",
    "              use_random_iter=False):\n",
    "    \"\"\"训练模型（定义见第8章）\"\"\"\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',\n",
    "                            legend=['train'], xlim=[10, num_epochs])\n",
    "    # 初始化\n",
    "    if isinstance(net, nn.Module):\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "    else:\n",
    "        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)\n",
    "    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
    "    # 训练和预测\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch_ch8(\n",
    "            net, train_iter, loss, updater, device, use_random_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(predict('time traveller'))\n",
    "            animator.add(epoch + 1, [ppl])\n",
    "    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))\n",
    "\n",
    "# 加载数据\n",
    "batch_size, num_steps = 32, 35\n",
    "# train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)\n",
    "train_iter, vocab = load_data_time_machine(batch_size, num_steps)\n",
    "\n",
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1.4. <a id='toc11_3_1_4_'></a>[深层RNN](#toc0_)\n",
    "* 有多个隐藏层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "rnn_layer = nn.RNN(\n",
    "    input_size=3,            # 输入大小\n",
    "    hidden_size=3,           # 隐藏层大小\n",
    "    bidirectional=False,     # 双向神经网络，默认是单向\n",
    "    num_layers=1             # 深层神经网络，默认是1层\n",
    ")\n",
    "# dir(rnn_layer)      # 查看属性\n",
    "# help(rnn_layer)   # 查看方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1.5. <a id='toc11_3_1_5_'></a>[双向RNN](#toc0_)\n",
    "* 双向（其实就是将输入倒过来再输入）\n",
    "* 不能用双向循环神经网络来预测未来，因为从一开始就透露未来的信息。\n",
    "* 那实际引用场景是什么？\n",
    "    * 翻译\n",
    "    * 文本句子分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "rnn_layer = nn.RNN(\n",
    "    input_size=3,            # 输入大小\n",
    "    hidden_size=3,           # 隐藏层大小\n",
    "    bidirectional=False,     # 双向神经网络，默认是单向\n",
    "    num_layers=1             # 深层神经网络，默认是1层\n",
    ")\n",
    "# dir(rnn_layer)      # 查看属性\n",
    "# help(rnn_layer)   # 查看方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.2. <a id='toc11_3_2_'></a>[GRU](#toc0_)\n",
    "* GRU实际晚于LSTM，但是作用效果相当而更容易理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.2.1. <a id='toc11_3_2_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.2.2. <a id='toc11_3_2_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "gru_layer = nn.GRU(\n",
    "    input_size=3, \n",
    "    hidden_size=3, \n",
    "    num_layers=2, \n",
    "    bidirectional=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.3. <a id='toc11_3_3_'></a>[LSTM](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.3.1. <a id='toc11_3_3_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.3.2. <a id='toc11_3_3_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "lstm_layer = nn.LSTM(\n",
    "    input_size=3, \n",
    "    hidden_size=3, \n",
    "    num_layers=2, \n",
    "    bidirectional=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.4. <a id='toc11_3_4_'></a>[Encoder-Decoder框架](#toc0_)\n",
    "```shell\n",
    "输入-Encoder-中间状态-Decoder-输出\n",
    "                       输入\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.4.1. <a id='toc11_3_4_1_'></a>[Encoder部分](#toc0_)\n",
    "```shell\n",
    "可变长度的输入，固定长度的输出中间状态\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "#@save\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.4.2. <a id='toc11_3_4_2_'></a>[Decoder部分](#toc0_)\n",
    "```shell\n",
    "固定长度中间状态\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.4.3. <a id='toc11_3_4_3_'></a>[Encoder-Decoder（合并编码器和解码器）](#toc0_)\n",
    "```shell\n",
    "Encoder-Decoder\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.5. <a id='toc11_3_5_'></a>[seq2seq (Sequence to sequence learning)](#toc0_)\n",
    "```shell\n",
    "基于RNN的编码器-解码器框架(Encoder-Decoder)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.5.1. <a id='toc11_3_5_1_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4. <a id='toc11_4_'></a>[Attention](#toc0_)\n",
    "\n",
    "- 不是一个新的概念，很早之前就已经出现，只是在Google发表论文Attention is all you need后，越来越知名； \n",
    "- 如果非要找一个依据，从心理学上讲： \n",
    " \n",
    "    - 1. 之前学习的神经网络（CNN、RNN等）都是提取特征->全连接网络，属于“非随意识注意力”-即非主观，如一排黑色水杯中有一个红色的就会很吸引人；  \n",
    "    - 2. Attention提出的是“随意识注意力”即主观的去注意那个物体。\n",
    "\n",
    "Query:主动去查询（注意）  \n",
    "Key:  \n",
    "Value:  \n",
    "\n",
    "<img src=\"./Pytorch_Pictures/Attention//Attention_principle.jpg\" width = \"700\" height = \"300\" alt=\"图片名称\" align=center />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.1. <a id='toc11_4_1_'></a>[非参数注意力汇聚（Attention Pooling）](#toc0_)\n",
    "在以前，统计学家计算机用的不是很溜。用统计模型进行预测，而不是利用计算机的计算资源进行迭代优化逼近真实分布。所得的结果就是只是利用统计模型进行预测的曲线会比较平滑但是准确性不高，可能随着数据量的增高可以提高准确性，但是，现实中能有那么多够用的数据吗？而利用计算迭代优化逼近的方法可以很准确的拟合现有的数据，虽然不是很平滑，优点是数据虽少但可以被充分利用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f(x) = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.2. <a id='toc11_4_2_'></a>[参数注意力汇聚（Attention Pooling）](#toc0_)\n",
    "```shell\n",
    "加入可学习的参数w。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.3. <a id='toc11_4_3_'></a>[注意力分数函数](#toc0_)\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/Attention/Attention_score.jpg\" width = \"500\" height = \"300\" alt=\"图片名称\" align=center />\n",
    "\n",
    "#### 11.4.3.1. <a id='toc11_4_3_1_'></a>[加性注意力](#toc0_)\n",
    "\n",
    "- q和k的长度不一致。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.4.3.2. <a id='toc11_4_3_2_'></a>[缩放点积注意力](#toc0_)\n",
    "\n",
    "- q和k的长度一致。\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/Attention/scale-dot-product.png\" width = \"300\" height = \"300\" alt=\"图片名称\" align=center />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.4. <a id='toc11_4_4_'></a>[自注意力机制](#toc0_)\n",
    "\n",
    "自注意力机制：就是用同一个X分别于Wq、Wk和Wv矩阵相乘得到Q、K和V向量/矩阵。因为用的是同一个X同时作为q、k和v，所以得名为 **自注意力** 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.5. <a id='toc11_4_5_'></a>[多头注意力机制](#toc0_)\n",
    "上述只求一次注意力的过程可以叫做单头注意力。多头注意力就是对同样的Q, K, V求多次注意力，并行计算h个得到h个不同的attention，再把这些不同的h个attention连接起来得到最终的attentions，每一个attention都是一个head（头），总共有h个head（头）。  \n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.6. <a id='toc11_4_6_'></a>[attention-seq2seq](#toc0_)\n",
    "\n",
    "- 加入attention机制的Seq2Seq；\n",
    "\n",
    "- 基于Attention的Seq2Seq。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.7. <a id='toc11_4_7_'></a>[Transformer](#toc0_)\n",
    "```shell\n",
    "完全基于注意力机制的Encoder-Decoder架构。\n",
    "1.多头自注意力机制；\n",
    "2.掩码；\n",
    "3.Encoder-Decoder框架。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.4.7.1. <a id='toc11_4_7_1_'></a>[位置编码](#toc0_)\n",
    "```shell\n",
    "由于Transformer并行运算，没有顺序信息；\n",
    "Google一帮人发明了利用sin和cos函数编码位置信息并添加到输入X中；\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "max_len = 10\n",
    "num_hiddens = 3\n",
    "torch.zeros((1, max_len, num_hiddens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.4.7.2. <a id='toc11_4_7_2_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3112889997.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[55], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class Evoformer(nn.Module):\n",
    "    '''Encoder'''\n",
    "    def __init__(self):\n",
    "        self. \n",
    "\n",
    "    def forward(self, X):\n",
    "        return X \n",
    "    \n",
    "class Structure(nn.Module):\n",
    "    '''Decoder'''\n",
    "    def __init__(self):\n",
    "        self. \n",
    "\n",
    "    def forward(self, X):\n",
    "        return X \n",
    "\n",
    "class AlphaFold2(nn.Module):\n",
    "    '''The network of Encoder-Decoder'''\n",
    "    def __init__(self):\n",
    "        self.evoformer = Evoformer()\n",
    "        self.structure = Structure()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.4.7.3. <a id='toc11_4_7_3_'></a>[基于Attention的Seq2Seq网络](#toc0_)\n",
    "```shell\n",
    "基于Attention的Seq2Seq神经网络框架。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return \n",
    "\n",
    "class MySeq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.8. <a id='toc11_4_8_'></a>[BERT](#toc0_)\n",
    "```shell\n",
    "就是Encoder部分\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.9. <a id='toc11_4_9_'></a>[GPT](#toc0_)\n",
    "```shell\n",
    "就是Transformer的Decoder部分。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. <a id='toc12_'></a>[炼丹心得](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1. <a id='toc12_1_'></a>[关于改变形状](#toc0_)\n",
    "\n",
    "- .reshape((1, 1, 28, 28))\n",
    "\n",
    "- .permute((0, 1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1,28, 28))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.reshape((1, 28, 28, 1)).shape     # 重塑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 1, 1, 28])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.permute((3, 0, 1, 2)).shape       # 迁移"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2. <a id='toc12_2_'></a>[关于调参](#toc0_)\n",
    "1. Pytorch没有变量、常量之分，不需要定义说明什么是变量，全部都是张量；\n",
    "\n",
    "2. 因为变量定义后需要初始化，就相当于常量；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3751])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyLayer(nn.Module):\n",
    "    '''带参数的，自定义层'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(2, requires_grad=True))  # 变量，立即初始化，相当于常量\n",
    "        self.bias = nn.Parameter(torch.zeros(1, requires_grad=True))    # 同上\n",
    "    \n",
    "    def forward(self, X):\n",
    "        y_hat = self.weight.data@X + self.bias.data\n",
    "        # y_hat = torch.matmul(self.weight.data, X) + self.bias.data    # 同上\n",
    "        return F.relu(y_hat)\n",
    "\n",
    "myLayer = MyLayer()\n",
    "X = torch.ones(2)\n",
    "myLayer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([-1.2126,  0.9969])), ('bias', tensor([0.]))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.state_dict() # 访问神经网络参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3. <a id='toc12_3_'></a>[模型选择](#toc0_)\n",
    "```shell\n",
    "模型的复杂度应该合适，不能太大，也不能太小。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4. <a id='toc12_4_'></a>[one-hot](#toc0_)\n",
    "```shell\n",
    "有向量无偏差表示；\n",
    "简单，但可能占空间\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32820/3359500813.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(col_raw == raw) # 只是bool\n",
      "/tmp/ipykernel_32820/3359500813.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  one_hot = torch.tensor(col_raw == raw, dtype=torch.float32) # bool -> torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]]),\n",
       " tensor([[1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "col_raw = raw.reshape(5, 1); col_raw\n",
    "col_raw == raw # （5， 1） 和 （1， 5）先广播后比较\n",
    "torch.tensor(col_raw == raw) # 只是bool\n",
    "one_hot = torch.tensor(col_raw == raw, dtype=torch.float32) # bool -> torch.float32\n",
    "col_raw, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "\n",
    "# help(F.one_hot)\n",
    "F.one_hot(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.5. <a id='toc12_5_'></a>[embedding](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "# 第一种\n",
    "# help(F.embedding)\n",
    "# F.embedding(raw)\n",
    "\n",
    "# 第二种\n",
    "# help(nn.Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.6. <a id='toc12_6_'></a>[BN和LN](#toc0_)\n",
    "Batch norm和Layer norm之间的区别  \n",
    "\n",
    "* BatchNorm：在同一特征（同一列），不同样品之间（不同行）之间做的normalization？ standerlization？\n",
    "\n",
    "* LayerNorm：在同一样品（同一行），不同特征（不同列）之间做的normalization？ standerlization？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "torch.nn.BatchNorm1d()\n",
    "torch.nn.LayerNorm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.7. <a id='toc12_7_'></a>[MLP、FC、FNN、CNN、RNN](#toc0_)\n",
    "Linear()：线性网络，即没有非线性激活函数  \n",
    "MLP()：多层感知机，有非线性激活函数  \n",
    "FNN()：前馈神经网络，同MLP（）  \n",
    "CNN()：卷积神经网络    \n",
    "RNN()：循环神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.8. <a id='toc12_8_'></a>[机器学习](#toc0_)\n",
    "```shell\n",
    "1. 监督学习  \n",
    "    自监督学习  \n",
    "    \n",
    "2. 半监督学习  \n",
    "3. 无监督学习  \n",
    "4. 强化学习  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. <a id='toc13_'></a>[迁移学习-Transfer learning](#toc0_)\n",
    "## 13.1. <a id='toc13_1_'></a>[Fine-tuning](#toc0_)\n",
    "\n",
    "- 在今后的很长时间，深度学习的模型创新上会有很大的难度，基于已有的模型的微调（Fine-tuning）应用于新的可解决的问题是趋势。\n",
    "\n",
    "- Fine-tuning in CV：\n",
    "\n",
    "    - 1.用Pre-trained的参数初始化特征提取器如Encoder的参数，而不是随机初始化；\n",
    "\n",
    "    - 2.用小的lerning-rate和小的epochs；\n",
    "\n",
    "    - 3.固定模型层的（其实就是learning-rate为0）。\n",
    "\n",
    "- 如何找到Pre-trained model？\n",
    "\n",
    "    - TIMM（pytorch）-一个叫Ross的小哥自己维护的；\n",
    "\n",
    "    - HugginFace - 一个早期只是东抄抄西抄抄的公司，逐渐发展为比较好的社区公司。\n",
    "\n",
    "- Fine-tuning in NLP：\n",
    "\n",
    "    - 1.Self-supervised pre-training;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2. <a id='toc13_2_'></a>[torchvision的应用案例](#toc0_)\n",
    "- 参考：https://blog.csdn.net/weixin_42263486/article/details/108302350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Pytorch_datasets/faces/face_landmarks.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m ws \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPytorch_datasets/faces/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 36\u001b[0m face_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mFaceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mface_landmarks.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m sample \u001b[38;5;241m=\u001b[39m face_dataset[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     38\u001b[0m sample_plot(sample\u001b[38;5;241m=\u001b[39msample)\n",
      "Cell \u001b[0;32mIn[110], line 13\u001b[0m, in \u001b[0;36mFaceDataset.__init__\u001b[0;34m(self, extract_path, csv_filename, transform)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv_filename \u001b[38;5;241m=\u001b[39m csv_filename\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mface_landmarks \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Pytorch_datasets/faces/face_landmarks.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset, dataloader\n",
    "import os \n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, extract_path, csv_filename, transform=None):\n",
    "        super(FaceDataset, self).__init__()\n",
    "        self.extract_path = extract_path\n",
    "        self.csv_filename = csv_filename\n",
    "        self.transform = transform\n",
    "        self.face_landmarks = pd.read_csv(os.path.join(extract_path, csv_filename))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.face_landmarks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.face_landmarks.iloc[idx,0]\n",
    "        landmarks = self.face_landmarks.iloc[idx,1:].astype('float32')\n",
    "        point_x = landmarks.to_numpy()[0::2]\n",
    "        point_y = landmarks.to_numpy()[1::2]\n",
    "        image = plt.imread(os.path.join(self.extract_path, image_name))\n",
    "        sample = {'image':image, 'point_x':point_x, 'point_y':point_y}\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "def sample_plot(sample):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(sample['image'], cmap='gray')\n",
    "    plt.scatter(sample['point_x'], sample['point_y'], c='r', s=2)\n",
    "    plt.title('face')\n",
    "\n",
    "ws = 'Pytorch_datasets/faces/'\n",
    "face_dataset = FaceDataset(ws, 'face_landmarks.csv')\n",
    "sample = face_dataset[1]\n",
    "sample_plot(sample=sample)\n",
    "sample_plot(sample=face_dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3. <a id='toc13_3_'></a>[迁移学习案例](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dirname, transform=None):\n",
    "        super(MyDataset, self).__init__() # 要不要都行\n",
    "        self.classes = os.listdir(dirname)\n",
    "        self.images = []\n",
    "        self.transform = transform\n",
    "        for i, classes in enumerate(self.classes):\n",
    "            classes_path = os.path.join(dirname, classes)\n",
    "            for image_name in os.listdir(classes_path):\n",
    "                self.images.append((os.path.join(classes_path, image_name), i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name, classes = self.images[idx]\n",
    "        image = Image.open(image_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, classes\n",
    "    \n",
    "    def get_claesses(self):\n",
    "        return self.classes\n",
    "    \n",
    "# 分布实现训练和预测的transform\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.RandomResizedCrop(224), #随机裁剪一个area然后再resize\n",
    "        transforms.RandomHorizontalFlip(), #随机水平翻转\n",
    "        transforms.Resize(size=(256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.Resize(size=(256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 分别实现loader\n",
    "# ws = 'Pytorch_datasets/hymenoptera_data/'\n",
    "train_dataset = MyDataset('Pytorch_datasets/hymenoptera_data/train/', train_transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "val_dataset = MyDataset('Pytorch_datasets/hymenoptera_data/val/', val_transform)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 选择预训练的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预训练的模型\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0070, -0.0140, -0.0163,  ...,  0.0316,  0.0104,  0.0167],\n",
      "        [-0.0435,  0.0343, -0.0118,  ..., -0.0312, -0.0065,  0.0378]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0042, -0.0128], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 停止权重更新，并将model最后一层替换掉\n",
    "only_train_fc = True\n",
    "if only_train_fc:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(False)\n",
    "fc_in_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(fc_in_features, 2, bias=True)\n",
    "\n",
    "# 查看\n",
    "for i in model.parameters():\n",
    "    if i.requires_grad:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练主体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6548401 0.6635045\n",
      "1 0.4946043 0.76\n",
      "0 0.5137404 0.7222842\n",
      "1 0.46890393 0.7895\n",
      "0.7895\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(lr=0.01, params=model.parameters())\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "model.to(device)\n",
    "opt_step = torch.optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.1)\n",
    "max_acc = 0\n",
    "epoch_acc = []\n",
    "epoch_loss = []\n",
    "for epoch in range(epochs):\n",
    "    for type_id, loader in enumerate([train_loader, val_loader]):\n",
    "        # print('type_id:',type_id)\n",
    "        mean_loss = []\n",
    "        mean_acc = []\n",
    "        for images, labels in loader:\n",
    "            if type_id == 0:\n",
    "                # opt_step.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "            opt.zero_grad()\n",
    "            with torch.set_grad_enabled(type_id==0):\n",
    "                outputs = model(images)\n",
    "                _, pre_labels = torch.max(outputs, 1)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "            if type_id == 0:\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            acc = torch.sum(pre_labels==labels) / torch.tensor(labels.shape[0], dtype=torch.float32)        \n",
    "            mean_loss.append(loss.cpu().detach().numpy())\n",
    "            mean_acc.append(acc.cpu().detach().numpy())\n",
    "        if type_id == 1:\n",
    "            epoch_acc.append(np.mean(mean_acc))\n",
    "            epoch_loss.append(np.mean(mean_loss))\n",
    "            if max_acc < np.mean(mean_acc):\n",
    "                max_acc = np.mean(mean_acc)\n",
    "        print(type_id, np.mean(mean_loss),np.mean(mean_acc))\n",
    "print(max_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. <a id='toc14_'></a>[PyTorch lightning训练框架](#toc0_)\n",
    "- PyTorch lightning官方给的`PyTorch lightning`教程：[https://lightning.ai/docs/pytorch/stable/expertise_levels.html](https://lightning.ai/docs/pytorch/stable/expertise_levels.html)\n",
    "- PyTorch lightning给的`PyTorch`教程：[https://lightning.ai/docs/pytorch/stable/tutorials.html](https://lightning.ai/docs/pytorch/stable/tutorials.html)\n",
    "- PuTorch lightning给的`PyTorch code to PyTorchLightning`：[https://lightning.ai/docs/pytorch/stable/starter/converting.html](https://lightning.ai/docs/pytorch/stable/starter/converting.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Frame](./Pytorch_Pictures/PyTorch_lightning/Frame1.jpg)\n",
    "![Frame2](./Pytorch_Pictures/PyTorch_lightning/Frame2.jpg)\n",
    "![Frame3](./Pytorch_Pictures/PyTorch_lightning/Frame3.jpg)\n",
    "![Frame4](./Pytorch_Pictures/PyTorch_lightning/Frame4.jpg)\n",
    "![Frame5](./Pytorch_Pictures/PyTorch_lightning/Frame5.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch lightning version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "print(f'Pytorch lightning version: {L.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1. <a id='toc14_1_'></a>[Data.py](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 2]),\n",
       " torch.Size([10000, 1]),\n",
       " tensor([ 0.1441, -0.0539]),\n",
       " tensor([3.7984]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 虚拟出一些数据\n",
    "# 仅供参考\n",
    "\n",
    "import torch \n",
    "\n",
    "def syn_datas(\n",
    "    w = torch.tensor([2.0, -3.0]),\n",
    "    b = torch.tensor([3.4]), \n",
    "    nums = 10000):\n",
    "    X = torch.normal(mean=0, std=0.1, size=(nums, w.shape[0]), dtype=torch.float32)\n",
    "    y = X @ w + b\n",
    "    y += torch.normal(mean=0, std=0.1, size=y.shape, dtype=torch.float)\n",
    "    return X, y \n",
    "\n",
    "# 预设参数，注意 形状/维度\n",
    "preset_weight = torch.tensor([2.0, -3.0], dtype=torch.float32).reshape(2, 1)\n",
    "preset_bias = torch.tensor([3.4], dtype=torch.float32)\n",
    "\n",
    "# 虚拟数据\n",
    "features, labels = syn_datas(w=preset_weight, b=preset_bias, nums=10000)\n",
    "\n",
    "# 初步查看\n",
    "features.shape, labels.shape, features[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data \n",
    "\n",
    "datasets = data.TensorDataset(features, labels)\n",
    "\n",
    "train_iter = data.DataLoader(dataset=datasets, shuffle=True, batch_size=128, num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2. <a id='toc14_2_'></a>[Model.py](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用纯PyTorch构建模型的网络结构\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class AlphaFold2(nn.Module):\n",
    "    def __init__(self, in_features=2, out_features=1):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Sequential(nn.Linear(in_features, out_features))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.hidden(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3. <a id='toc14_3_'></a>[ModelWrapper.py](#toc0_)\n",
    "利用PyTorch lightning训练框架进行训练只是方便调用，最后进行模型`魔改`后最好还是用纯PyTorch进行学习。  \n",
    "都是固定框架（API信息如下）\n",
    "- [L.LightningModule API](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#backward)\n",
    "- [Trainer API](https://lightning.ai/docs/pytorch/stable/common/trainer.html)\n",
    "    - Automatically enabling/disabling grads\n",
    "    - Running the training, validation and test dataloaders\n",
    "    - Calling the Callbacks at the appropriate times\n",
    "    - Putting batches and computations on the correct devices\n",
    "    \n",
    "![Trainer_API](./Pytorch_Pictures/PyTorch_lightning/Trainer_API.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# 用PyTorch lightning构建训练步骤\n",
    "\n",
    "from torch import nn \n",
    "from torch import optim\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "class AlphaFold2Wrapper(L.LightningModule):\n",
    "    def __init__(self, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "        ## save hyperparameters\n",
    "        self.save_hyperparameters()                                 # 超参数保存\n",
    "        self.learning_rate = learning_rate                          # 超参数\n",
    "        ## model initiate from model constructed by pure PyTorch\n",
    "        self.demo_model = AlphaFold2(in_features=2, out_features=1)      ## 模型\n",
    "        ## loss_fn\n",
    "        self.loss_fn = torch.nn.MSELoss()                           ## 损失函数\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.demo_model(X)\n",
    "\n",
    "    def configure_optimizers(self):                                 ## 优化函数\n",
    "        opt = optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        return opt\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        '''训练步骤'''\n",
    "        X, y = batch \n",
    "        y_hat = self.forward(X)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)                 # 在进度条上显示出来\n",
    "\n",
    "        self.training_step_outputs.append(loss)                     # 保存结果，以备后续使用 (on_train_epoch_end(self))\n",
    "        return loss\n",
    "    \n",
    "    # def on_train_batch_start(self, batch, batch_idx):\n",
    "    #     '''\n",
    "    #     Called in the training loop before anything happens for that batch.\n",
    "    #     If you return -1 here, you will skip training for the rest of the current epoch.\n",
    "    #     '''\n",
    "    #     pass\n",
    "\n",
    "    # def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "    #     '''\n",
    "    #     Called in the training loop after the batch.\n",
    "    #     Parameters:\n",
    "    #             outputs (Union[Tensor, Mapping[str, Any], None]) – The outputs of training_step(x)\n",
    "    #             batch (Any) – The batched data as it is returned by the training DataLoader.\n",
    "    #             batch_idx (int) – the index of the batch\n",
    "    #     '''\n",
    "    #     pass\n",
    "\n",
    "    # def on_train_epoch_start(self):\n",
    "    #     '''Called in the training loop at the very beginning of the epoch.'''\n",
    "    #     pass\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        '''\n",
    "        Called in the training loop at the very end of the epoch.\n",
    "        To access all batch outputs at the end of the epoch, \n",
    "        you can cache step outputs as an attribute of the LightningModule and access them in this hook:\n",
    "        '''\n",
    "        # do something with all training_step outputs, for example:\n",
    "        epoch_mean = torch.stack(self.training_step_outputs).mean() # 来自于training_step()计算结果\n",
    "        self.log(\"training_epoch_mean\", epoch_mean)\n",
    "        # free up the memory\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        '''验证步骤'''\n",
    "        X, y = batch \n",
    "        y_hat = self.forward(X) \n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    # def on_validation_batch_start(self, batch, batch_idx, dataloader_idx=0):\n",
    "    #     '''Called in the validation loop before anything happens for that batch.'''\n",
    "    #     pass \n",
    "\n",
    "    # def on_validation_batch_end(self, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "    #     '''Called in the validation loop after the batch.\n",
    "    #     Parameters:\n",
    "    #             outputs (Union[Tensor, Mapping[str, Any], None]) – The outputs of validation_step(x)\n",
    "    #             batch (Any) – The batched data as it is returned by the validation DataLoader.\n",
    "    #             batch_idx (int) – the index of the batch\n",
    "    #             dataloader_idx (int) – the index of the dataloader\n",
    "    #     '''\n",
    "    #     pass\n",
    "\n",
    "    # def on_validation_epoch_start(self):\n",
    "    #     '''Called in the validation loop at the very beginning of the epoch.'''\n",
    "    #     pass\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        '''Called in the validation loop at the very end of the epoch.'''\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        '''测试步骤'''\n",
    "        X, y = batch \n",
    "        y_hat = self.forward(X) \n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def prediction_step(self, batch, batch_idx):\n",
    "        '''预测步骤'''\n",
    "        X, y = batch \n",
    "        y_hat = self.forward(X) \n",
    "        self.log('y_hat', y_hat)\n",
    "        return y_hat\n",
    "\n",
    "## 实例化一个对象\n",
    "alphafold2 = AlphaFold2Wrapper(learning_rate=0.01)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",              # cpu, gpu, tpu, auto\n",
    "    devices=1, \n",
    "    # strategy=\"ddp\",\n",
    "    # num_nodes=1,                    # Number of GPU nodes for distributed training.\n",
    "\n",
    "    # precision=\"32-true\",            # There are two different techniques to set the mixed precision. “True” precision and “Mixed” precision.\n",
    "\n",
    "    # callbacks = ,\n",
    "    \n",
    "    # min_epochs=1,\n",
    "    max_epochs=10, \n",
    "    # min_steps=None,                 # Force training for at least this number of global steps. Trainer will train model for at least min_steps or min_epochs (latest).\n",
    "    max_steps=-1,                   # Stop training after this number of global steps. Training will stop if max_steps or max_epochs have reached (earliest).\n",
    "    log_every_n_steps=50,           ## How often to add logging rows (does not write to disk)\n",
    "    check_val_every_n_epoch=1,      # default used by the Trainer\n",
    "\n",
    "    # default_root_dir=os.getcwd(),   # os.getcwd()\n",
    "    # enable_progress_bar=True,       # Whether to enable or disable the progress bar. Defaults to True.\n",
    "    # enable_model_summary=True,      # Whether to enable or disable the model summarization. Defaults to True.\n",
    "\n",
    "    profiler=None,                  # simple, advanced, None: To profile individual steps during training and assist in identifying bottlenecks.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.1. <a id='toc14_3_1_'></a>[Training and vlidation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type       | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | demo_model | AlphaFold2 | 3      | train\n",
      "1 | loss_fn    | MSELoss    | 0      | train\n",
      "--------------------------------------------------\n",
      "3         Trainable params\n",
      "0         Non-trainable params\n",
      "3         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bmp/backup/zhaosy/miniconda3/envs/pytorch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 79/79 [00:01<00:00, 75.30it/s, v_num=0, train_loss=0.217, val_loss=0.133] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 79/79 [00:01<00:00, 74.95it/s, v_num=0, train_loss=0.217, val_loss=0.133]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=alphafold2, \n",
    "    train_dataloaders=train_iter, \n",
    "    val_dataloaders=train_iter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.2. <a id='toc14_3_2_'></a>[Validation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 79/79 [00:00<00:00, 359.93it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val_loss            0.13269878923892975\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.13269878923892975}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model=alphafold2, dataloaders=train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.3. <a id='toc14_3_3_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/bmp/backup/zhaosy/miniconda3/envs/pytorch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 79/79 [00:00<00:00, 404.56it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.13269877433776855\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.13269877433776855}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=alphafold2, dataloaders=train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.4. <a id='toc14_3_4_'></a>[Prediction](#toc0_)\n",
    "\n",
    "![Prediction summary](./Pytorch_Pictures/PyTorch_lightning/Frame4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.3.4.1. <a id='toc14_3_4_1_'></a>[调用PyTorch lightning自身Trainer的predict](#toc0_)\n",
    "调用PyTorch lightning自身Trainer的predict，程序会自动使用：  \n",
    "- model.eval()\n",
    "- with torch.no_grad():\n",
    "- 或 torch.set_grad_enable(True/False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 10000/10000 [00:08<00:00, 1224.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([3.4124]),\n",
       " tensor([3.3868]),\n",
       " tensor([3.3909]),\n",
       " tensor([3.3817]),\n",
       " tensor([3.4208]),\n",
       " tensor([3.3964]),\n",
       " tensor([3.3973]),\n",
       " tensor([3.3862]),\n",
       " tensor([3.3966]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.4066]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.3932]),\n",
       " tensor([3.3774]),\n",
       " tensor([3.3949]),\n",
       " tensor([3.3956]),\n",
       " tensor([3.3845]),\n",
       " tensor([3.3931]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.3898]),\n",
       " tensor([3.4090]),\n",
       " tensor([3.4059]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.3881]),\n",
       " tensor([3.3913]),\n",
       " tensor([3.4166]),\n",
       " tensor([3.3755]),\n",
       " tensor([3.4028]),\n",
       " tensor([3.4021]),\n",
       " tensor([3.4224]),\n",
       " tensor([3.3956]),\n",
       " tensor([3.3914]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.3889]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.4049]),\n",
       " tensor([3.4014]),\n",
       " tensor([3.3925]),\n",
       " tensor([3.3970]),\n",
       " tensor([3.4043]),\n",
       " tensor([3.4050]),\n",
       " tensor([3.4055]),\n",
       " tensor([3.4033]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3934]),\n",
       " tensor([3.4031]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.3942]),\n",
       " tensor([3.3713]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3886]),\n",
       " tensor([3.4044]),\n",
       " tensor([3.3781]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.4258]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3782]),\n",
       " tensor([3.3928]),\n",
       " tensor([3.4193]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.3984]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.4131]),\n",
       " tensor([3.4129]),\n",
       " tensor([3.4034]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.3870]),\n",
       " tensor([3.4152]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.3938]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3921]),\n",
       " tensor([3.3895]),\n",
       " tensor([3.3981]),\n",
       " tensor([3.3871]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.4051]),\n",
       " tensor([3.3864]),\n",
       " tensor([3.4033]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.4010]),\n",
       " tensor([3.3961]),\n",
       " tensor([3.3918]),\n",
       " tensor([3.3886]),\n",
       " tensor([3.4129]),\n",
       " tensor([3.3801]),\n",
       " tensor([3.3956]),\n",
       " tensor([3.3981]),\n",
       " tensor([3.3972]),\n",
       " tensor([3.3699]),\n",
       " tensor([3.3770]),\n",
       " tensor([3.4040]),\n",
       " tensor([3.3986]),\n",
       " tensor([3.3855]),\n",
       " tensor([3.3998]),\n",
       " tensor([3.4040]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.3966]),\n",
       " tensor([3.4106]),\n",
       " tensor([3.4038]),\n",
       " tensor([3.4075]),\n",
       " tensor([3.3972]),\n",
       " tensor([3.3843]),\n",
       " tensor([3.3849]),\n",
       " tensor([3.3885]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.3865]),\n",
       " tensor([3.3973]),\n",
       " tensor([3.3804]),\n",
       " tensor([3.3916]),\n",
       " tensor([3.3607]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.3984]),\n",
       " tensor([3.3910]),\n",
       " tensor([3.4078]),\n",
       " tensor([3.4075]),\n",
       " tensor([3.3888]),\n",
       " tensor([3.3929]),\n",
       " tensor([3.3968]),\n",
       " tensor([3.3875]),\n",
       " tensor([3.3859]),\n",
       " tensor([3.3864]),\n",
       " tensor([3.4090]),\n",
       " tensor([3.3977]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.4120]),\n",
       " tensor([3.4087]),\n",
       " tensor([3.3966]),\n",
       " tensor([3.3961]),\n",
       " tensor([3.3787]),\n",
       " tensor([3.3978]),\n",
       " tensor([3.3952]),\n",
       " tensor([3.3897]),\n",
       " tensor([3.4006]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.4146]),\n",
       " tensor([3.4132]),\n",
       " tensor([3.3967]),\n",
       " tensor([3.3859]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3895]),\n",
       " tensor([3.4091]),\n",
       " tensor([3.3953]),\n",
       " tensor([3.3847]),\n",
       " tensor([3.3809]),\n",
       " tensor([3.4056]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.3968]),\n",
       " tensor([3.3890]),\n",
       " tensor([3.4088]),\n",
       " tensor([3.4081]),\n",
       " tensor([3.4046]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.3803]),\n",
       " tensor([3.3998]),\n",
       " tensor([3.4051]),\n",
       " tensor([3.4086]),\n",
       " tensor([3.3976]),\n",
       " tensor([3.3843]),\n",
       " tensor([3.4084]),\n",
       " tensor([3.3904]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3869]),\n",
       " tensor([3.3834]),\n",
       " tensor([3.4043]),\n",
       " tensor([3.4136]),\n",
       " tensor([3.4164]),\n",
       " tensor([3.3850]),\n",
       " tensor([3.3986]),\n",
       " tensor([3.3877]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.4094]),\n",
       " tensor([3.3838]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.3938]),\n",
       " tensor([3.4015]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3943]),\n",
       " tensor([3.4021]),\n",
       " tensor([3.3885]),\n",
       " tensor([3.3933]),\n",
       " tensor([3.4221]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.3702]),\n",
       " tensor([3.3849]),\n",
       " tensor([3.3721]),\n",
       " tensor([3.4130]),\n",
       " tensor([3.4109]),\n",
       " tensor([3.3931]),\n",
       " tensor([3.4006]),\n",
       " tensor([3.3931]),\n",
       " tensor([3.3830]),\n",
       " tensor([3.4076]),\n",
       " tensor([3.4150]),\n",
       " tensor([3.3928]),\n",
       " tensor([3.3854]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.3804]),\n",
       " tensor([3.3996]),\n",
       " tensor([3.3997]),\n",
       " tensor([3.3945]),\n",
       " tensor([3.3966]),\n",
       " tensor([3.3844]),\n",
       " tensor([3.4151]),\n",
       " tensor([3.3878]),\n",
       " tensor([3.4081]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.3918]),\n",
       " tensor([3.3909]),\n",
       " tensor([3.3790]),\n",
       " tensor([3.3976]),\n",
       " tensor([3.3993]),\n",
       " tensor([3.3754]),\n",
       " tensor([3.3959]),\n",
       " tensor([3.4031]),\n",
       " tensor([3.3949]),\n",
       " tensor([3.3995]),\n",
       " tensor([3.4028]),\n",
       " tensor([3.3978]),\n",
       " tensor([3.3845]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.4012]),\n",
       " tensor([3.4248]),\n",
       " tensor([3.4041]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.3819]),\n",
       " tensor([3.3824]),\n",
       " tensor([3.4074]),\n",
       " tensor([3.4040]),\n",
       " tensor([3.3797]),\n",
       " tensor([3.3876]),\n",
       " tensor([3.3864]),\n",
       " tensor([3.3888]),\n",
       " tensor([3.3748]),\n",
       " tensor([3.3762]),\n",
       " tensor([3.3839]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.4012]),\n",
       " tensor([3.4112]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3846]),\n",
       " tensor([3.3814]),\n",
       " tensor([3.4060]),\n",
       " tensor([3.3960]),\n",
       " tensor([3.3785]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.3812]),\n",
       " tensor([3.4179]),\n",
       " tensor([3.3958]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.3811]),\n",
       " tensor([3.3881]),\n",
       " tensor([3.3697]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.4057]),\n",
       " tensor([3.4168]),\n",
       " tensor([3.4068]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.3939]),\n",
       " tensor([3.3898]),\n",
       " tensor([3.4055]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.3825]),\n",
       " tensor([3.3823]),\n",
       " tensor([3.3900]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.3910]),\n",
       " tensor([3.3669]),\n",
       " tensor([3.4105]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.3930]),\n",
       " tensor([3.3747]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.4129]),\n",
       " tensor([3.3842]),\n",
       " tensor([3.4011]),\n",
       " tensor([3.3984]),\n",
       " tensor([3.3772]),\n",
       " tensor([3.4038]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.3911]),\n",
       " tensor([3.4013]),\n",
       " tensor([3.4021]),\n",
       " tensor([3.3991]),\n",
       " tensor([3.3840]),\n",
       " tensor([3.4171]),\n",
       " tensor([3.4068]),\n",
       " tensor([3.4061]),\n",
       " tensor([3.3943]),\n",
       " tensor([3.4080]),\n",
       " tensor([3.3757]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3848]),\n",
       " tensor([3.3827]),\n",
       " tensor([3.4070]),\n",
       " tensor([3.4035]),\n",
       " tensor([3.3793]),\n",
       " tensor([3.3813]),\n",
       " tensor([3.4006]),\n",
       " tensor([3.3937]),\n",
       " tensor([3.3855]),\n",
       " tensor([3.3849]),\n",
       " tensor([3.3879]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.3842]),\n",
       " tensor([3.4141]),\n",
       " tensor([3.3924]),\n",
       " tensor([3.3830]),\n",
       " tensor([3.4130]),\n",
       " tensor([3.3903]),\n",
       " tensor([3.3871]),\n",
       " tensor([3.4162]),\n",
       " tensor([3.4080]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.4070]),\n",
       " tensor([3.4014]),\n",
       " tensor([3.3858]),\n",
       " tensor([3.3889]),\n",
       " tensor([3.3913]),\n",
       " tensor([3.4134]),\n",
       " tensor([3.3972]),\n",
       " tensor([3.4066]),\n",
       " tensor([3.4012]),\n",
       " tensor([3.3954]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.3966]),\n",
       " tensor([3.3846]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.4278]),\n",
       " tensor([3.4167]),\n",
       " tensor([3.3849]),\n",
       " tensor([3.4030]),\n",
       " tensor([3.3895]),\n",
       " tensor([3.3883]),\n",
       " tensor([3.3797]),\n",
       " tensor([3.3906]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3998]),\n",
       " tensor([3.3837]),\n",
       " tensor([3.3906]),\n",
       " tensor([3.3814]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.3900]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.3977]),\n",
       " tensor([3.3841]),\n",
       " tensor([3.4076]),\n",
       " tensor([3.4021]),\n",
       " tensor([3.3867]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.3875]),\n",
       " tensor([3.3883]),\n",
       " tensor([3.3954]),\n",
       " tensor([3.4117]),\n",
       " tensor([3.3833]),\n",
       " tensor([3.4028]),\n",
       " tensor([3.3847]),\n",
       " tensor([3.3911]),\n",
       " tensor([3.4061]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.4028]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.4019]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.3714]),\n",
       " tensor([3.3898]),\n",
       " tensor([3.4068]),\n",
       " tensor([3.3961]),\n",
       " tensor([3.4316]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.3967]),\n",
       " tensor([3.4210]),\n",
       " tensor([3.4201]),\n",
       " tensor([3.4086]),\n",
       " tensor([3.3852]),\n",
       " tensor([3.3954]),\n",
       " tensor([3.4149]),\n",
       " tensor([3.4019]),\n",
       " tensor([3.4001]),\n",
       " tensor([3.3926]),\n",
       " tensor([3.4000]),\n",
       " tensor([3.4079]),\n",
       " tensor([3.3977]),\n",
       " tensor([3.3997]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.4179]),\n",
       " tensor([3.4061]),\n",
       " tensor([3.3923]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3904]),\n",
       " tensor([3.4022]),\n",
       " tensor([3.3988]),\n",
       " tensor([3.3825]),\n",
       " tensor([3.3840]),\n",
       " tensor([3.4073]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3830]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3870]),\n",
       " tensor([3.4090]),\n",
       " tensor([3.3719]),\n",
       " tensor([3.4009]),\n",
       " tensor([3.3729]),\n",
       " tensor([3.4007]),\n",
       " tensor([3.3830]),\n",
       " tensor([3.4080]),\n",
       " tensor([3.3862]),\n",
       " tensor([3.3794]),\n",
       " tensor([3.3971]),\n",
       " tensor([3.3994]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.3780]),\n",
       " tensor([3.4054]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.3879]),\n",
       " tensor([3.3838]),\n",
       " tensor([3.3832]),\n",
       " tensor([3.4018]),\n",
       " tensor([3.3888]),\n",
       " tensor([3.3988]),\n",
       " tensor([3.3934]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.4056]),\n",
       " tensor([3.3880]),\n",
       " tensor([3.3884]),\n",
       " tensor([3.4088]),\n",
       " tensor([3.3989]),\n",
       " tensor([3.3885]),\n",
       " tensor([3.4058]),\n",
       " tensor([3.4244]),\n",
       " tensor([3.4051]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.3924]),\n",
       " tensor([3.4058]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.4103]),\n",
       " tensor([3.4106]),\n",
       " tensor([3.4228]),\n",
       " tensor([3.4213]),\n",
       " tensor([3.3915]),\n",
       " tensor([3.4078]),\n",
       " tensor([3.3992]),\n",
       " tensor([3.3945]),\n",
       " tensor([3.3877]),\n",
       " tensor([3.3812]),\n",
       " tensor([3.3730]),\n",
       " tensor([3.4031]),\n",
       " tensor([3.3698]),\n",
       " tensor([3.4008]),\n",
       " tensor([3.3902]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.3998]),\n",
       " tensor([3.4109]),\n",
       " tensor([3.4035]),\n",
       " tensor([3.3786]),\n",
       " tensor([3.3959]),\n",
       " tensor([3.3848]),\n",
       " tensor([3.4000]),\n",
       " tensor([3.3748]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.4022]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.3926]),\n",
       " tensor([3.3972]),\n",
       " tensor([3.4044]),\n",
       " tensor([3.4077]),\n",
       " tensor([3.3990]),\n",
       " tensor([3.3943]),\n",
       " tensor([3.3992]),\n",
       " tensor([3.3849]),\n",
       " tensor([3.4102]),\n",
       " tensor([3.3814]),\n",
       " tensor([3.4102]),\n",
       " tensor([3.3866]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.4128]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.4031]),\n",
       " tensor([3.3985]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3875]),\n",
       " tensor([3.4017]),\n",
       " tensor([3.3998]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3932]),\n",
       " tensor([3.3958]),\n",
       " tensor([3.3973]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3947]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.4081]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.4067]),\n",
       " tensor([3.3806]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.4196]),\n",
       " tensor([3.3900]),\n",
       " tensor([3.3872]),\n",
       " tensor([3.3964]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.3981]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.3864]),\n",
       " tensor([3.3797]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.4134]),\n",
       " tensor([3.4020]),\n",
       " tensor([3.3841]),\n",
       " tensor([3.3775]),\n",
       " tensor([3.3854]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3947]),\n",
       " tensor([3.4116]),\n",
       " tensor([3.4051]),\n",
       " tensor([3.3892]),\n",
       " tensor([3.4026]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.4023]),\n",
       " tensor([3.3904]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.4056]),\n",
       " tensor([3.4035]),\n",
       " tensor([3.3766]),\n",
       " tensor([3.3897]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.4063]),\n",
       " tensor([3.3832]),\n",
       " tensor([3.4096]),\n",
       " tensor([3.3850]),\n",
       " tensor([3.4216]),\n",
       " tensor([3.4043]),\n",
       " tensor([3.3882]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.3989]),\n",
       " tensor([3.4090]),\n",
       " tensor([3.3868]),\n",
       " tensor([3.3926]),\n",
       " tensor([3.3796]),\n",
       " tensor([3.3829]),\n",
       " tensor([3.4089]),\n",
       " tensor([3.3850]),\n",
       " tensor([3.3933]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3988]),\n",
       " tensor([3.4028]),\n",
       " tensor([3.3891]),\n",
       " tensor([3.4035]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.3858]),\n",
       " tensor([3.3911]),\n",
       " tensor([3.3868]),\n",
       " tensor([3.3836]),\n",
       " tensor([3.3964]),\n",
       " tensor([3.4149]),\n",
       " tensor([3.3960]),\n",
       " tensor([3.3946]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.3866]),\n",
       " tensor([3.4022]),\n",
       " tensor([3.3883]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.3981]),\n",
       " tensor([3.4169]),\n",
       " tensor([3.3975]),\n",
       " tensor([3.4144]),\n",
       " tensor([3.3744]),\n",
       " tensor([3.4058]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.3881]),\n",
       " tensor([3.3699]),\n",
       " tensor([3.4189]),\n",
       " tensor([3.3954]),\n",
       " tensor([3.3870]),\n",
       " tensor([3.3865]),\n",
       " tensor([3.3838]),\n",
       " tensor([3.3925]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.4019]),\n",
       " tensor([3.4072]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.4002]),\n",
       " tensor([3.3793]),\n",
       " tensor([3.4097]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.3942]),\n",
       " tensor([3.3988]),\n",
       " tensor([3.3954]),\n",
       " tensor([3.3904]),\n",
       " tensor([3.4143]),\n",
       " tensor([3.3803]),\n",
       " tensor([3.4204]),\n",
       " tensor([3.3789]),\n",
       " tensor([3.3836]),\n",
       " tensor([3.4065]),\n",
       " tensor([3.3721]),\n",
       " tensor([3.3925]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.4049]),\n",
       " tensor([3.3764]),\n",
       " tensor([3.3928]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.4004]),\n",
       " tensor([3.3832]),\n",
       " tensor([3.4129]),\n",
       " tensor([3.4088]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3855]),\n",
       " tensor([3.3939]),\n",
       " tensor([3.3819]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.4249]),\n",
       " tensor([3.4143]),\n",
       " tensor([3.4135]),\n",
       " tensor([3.3960]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.3716]),\n",
       " tensor([3.3956]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.3983]),\n",
       " tensor([3.4125]),\n",
       " tensor([3.3915]),\n",
       " tensor([3.4220]),\n",
       " tensor([3.3756]),\n",
       " tensor([3.3922]),\n",
       " tensor([3.3857]),\n",
       " tensor([3.4030]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.3770]),\n",
       " tensor([3.3992]),\n",
       " tensor([3.4071]),\n",
       " tensor([3.4107]),\n",
       " tensor([3.4151]),\n",
       " tensor([3.4113]),\n",
       " tensor([3.4054]),\n",
       " tensor([3.4038]),\n",
       " tensor([3.3863]),\n",
       " tensor([3.4015]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.3857]),\n",
       " tensor([3.3983]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.3808]),\n",
       " tensor([3.4076]),\n",
       " tensor([3.4043]),\n",
       " tensor([3.3870]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3880]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3983]),\n",
       " tensor([3.3919]),\n",
       " tensor([3.4050]),\n",
       " tensor([3.3837]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.3585]),\n",
       " tensor([3.4139]),\n",
       " tensor([3.3854]),\n",
       " tensor([3.4070]),\n",
       " tensor([3.3916]),\n",
       " tensor([3.3823]),\n",
       " tensor([3.3984]),\n",
       " tensor([3.4058]),\n",
       " tensor([3.3818]),\n",
       " tensor([3.4084]),\n",
       " tensor([3.3786]),\n",
       " tensor([3.3798]),\n",
       " tensor([3.3991]),\n",
       " tensor([3.3876]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.4024]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.3973]),\n",
       " tensor([3.3846]),\n",
       " tensor([3.4137]),\n",
       " tensor([3.3864]),\n",
       " tensor([3.3943]),\n",
       " tensor([3.3881]),\n",
       " tensor([3.3978]),\n",
       " tensor([3.4078]),\n",
       " tensor([3.3929]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.3995]),\n",
       " tensor([3.4120]),\n",
       " tensor([3.4318]),\n",
       " tensor([3.3795]),\n",
       " tensor([3.3785]),\n",
       " tensor([3.3924]),\n",
       " tensor([3.3759]),\n",
       " tensor([3.3997]),\n",
       " tensor([3.3840]),\n",
       " tensor([3.4264]),\n",
       " tensor([3.4175]),\n",
       " tensor([3.3834]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.3997]),\n",
       " tensor([3.4206]),\n",
       " tensor([3.3871]),\n",
       " tensor([3.3845]),\n",
       " tensor([3.4004]),\n",
       " tensor([3.3881]),\n",
       " tensor([3.3914]),\n",
       " tensor([3.4153]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.4035]),\n",
       " tensor([3.3940]),\n",
       " tensor([3.3738]),\n",
       " tensor([3.3919]),\n",
       " tensor([3.3889]),\n",
       " tensor([3.3880]),\n",
       " tensor([3.3940]),\n",
       " tensor([3.4042]),\n",
       " tensor([3.4017]),\n",
       " tensor([3.4033]),\n",
       " tensor([3.4213]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.3788]),\n",
       " tensor([3.3851]),\n",
       " tensor([3.3969]),\n",
       " tensor([3.3791]),\n",
       " tensor([3.3855]),\n",
       " tensor([3.3906]),\n",
       " tensor([3.3865]),\n",
       " tensor([3.3909]),\n",
       " tensor([3.3916]),\n",
       " tensor([3.3898]),\n",
       " tensor([3.3884]),\n",
       " tensor([3.3852]),\n",
       " tensor([3.3982]),\n",
       " tensor([3.4141]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.4094]),\n",
       " tensor([3.3684]),\n",
       " tensor([3.4163]),\n",
       " tensor([3.3763]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.3932]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.4012]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.4031]),\n",
       " tensor([3.3958]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3865]),\n",
       " tensor([3.4221]),\n",
       " tensor([3.4161]),\n",
       " tensor([3.3898]),\n",
       " tensor([3.3983]),\n",
       " tensor([3.3923]),\n",
       " tensor([3.4119]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3876]),\n",
       " tensor([3.3926]),\n",
       " tensor([3.3767]),\n",
       " tensor([3.4065]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.4100]),\n",
       " tensor([3.3970]),\n",
       " tensor([3.3796]),\n",
       " tensor([3.4057]),\n",
       " tensor([3.3976]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3911]),\n",
       " tensor([3.3922]),\n",
       " tensor([3.3937]),\n",
       " tensor([3.3938]),\n",
       " tensor([3.3969]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.3967]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.3775]),\n",
       " tensor([3.4075]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3970]),\n",
       " tensor([3.3836]),\n",
       " tensor([3.4081]),\n",
       " tensor([3.3845]),\n",
       " tensor([3.3839]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.3913]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.3920]),\n",
       " tensor([3.3838]),\n",
       " tensor([3.4055]),\n",
       " tensor([3.4126]),\n",
       " tensor([3.4025]),\n",
       " tensor([3.3967]),\n",
       " tensor([3.4007]),\n",
       " tensor([3.3952]),\n",
       " tensor([3.3953]),\n",
       " tensor([3.4139]),\n",
       " tensor([3.4124]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.4197]),\n",
       " tensor([3.3932]),\n",
       " tensor([3.3995]),\n",
       " tensor([3.3759]),\n",
       " tensor([3.3923]),\n",
       " tensor([3.3989]),\n",
       " tensor([3.3915]),\n",
       " tensor([3.3882]),\n",
       " tensor([3.4209]),\n",
       " tensor([3.3956]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.3857]),\n",
       " tensor([3.4188]),\n",
       " tensor([3.3918]),\n",
       " tensor([3.4094]),\n",
       " tensor([3.3897]),\n",
       " tensor([3.3953]),\n",
       " tensor([3.3892]),\n",
       " tensor([3.3970]),\n",
       " tensor([3.3870]),\n",
       " tensor([3.3946]),\n",
       " tensor([3.3978]),\n",
       " tensor([3.3755]),\n",
       " tensor([3.4047]),\n",
       " tensor([3.4014]),\n",
       " tensor([3.4015]),\n",
       " tensor([3.3726]),\n",
       " tensor([3.3975]),\n",
       " tensor([3.4013]),\n",
       " tensor([3.4140]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.3780]),\n",
       " tensor([3.3963]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3960]),\n",
       " tensor([3.3978]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.4156]),\n",
       " tensor([3.4089]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.3753]),\n",
       " tensor([3.3867]),\n",
       " tensor([3.4000]),\n",
       " tensor([3.4068]),\n",
       " tensor([3.4117]),\n",
       " tensor([3.4168]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.4048]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.3758]),\n",
       " tensor([3.4010]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.3967]),\n",
       " tensor([3.4026]),\n",
       " tensor([3.3929]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.3895]),\n",
       " tensor([3.4025]),\n",
       " tensor([3.3774]),\n",
       " tensor([3.3910]),\n",
       " tensor([3.3889]),\n",
       " tensor([3.4063]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.3971]),\n",
       " tensor([3.3923]),\n",
       " tensor([3.4122]),\n",
       " tensor([3.3859]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3989]),\n",
       " tensor([3.3804]),\n",
       " tensor([3.4029]),\n",
       " tensor([3.3983]),\n",
       " tensor([3.3745]),\n",
       " tensor([3.4155]),\n",
       " tensor([3.3889]),\n",
       " tensor([3.3940]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.3784]),\n",
       " tensor([3.4200]),\n",
       " tensor([3.3796]),\n",
       " tensor([3.3854]),\n",
       " tensor([3.3860]),\n",
       " tensor([3.4193]),\n",
       " tensor([3.4039]),\n",
       " tensor([3.4040]),\n",
       " tensor([3.4007]),\n",
       " tensor([3.3829]),\n",
       " tensor([3.3982]),\n",
       " tensor([3.3808]),\n",
       " tensor([3.4081]),\n",
       " tensor([3.3952]),\n",
       " tensor([3.4156]),\n",
       " tensor([3.4112]),\n",
       " tensor([3.4128]),\n",
       " tensor([3.4121]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3943]),\n",
       " tensor([3.3799]),\n",
       " tensor([3.3915]),\n",
       " tensor([3.4176]),\n",
       " tensor([3.3785]),\n",
       " tensor([3.3834]),\n",
       " tensor([3.4043]),\n",
       " tensor([3.3938]),\n",
       " tensor([3.3826]),\n",
       " tensor([3.4024]),\n",
       " tensor([3.3841]),\n",
       " tensor([3.3795]),\n",
       " tensor([3.3810]),\n",
       " tensor([3.3850]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.3959]),\n",
       " tensor([3.3843]),\n",
       " tensor([3.3688]),\n",
       " tensor([3.3970]),\n",
       " tensor([3.4021]),\n",
       " tensor([3.3768]),\n",
       " tensor([3.4121]),\n",
       " tensor([3.3758]),\n",
       " tensor([3.3795]),\n",
       " tensor([3.3867]),\n",
       " tensor([3.3911]),\n",
       " tensor([3.4070]),\n",
       " tensor([3.3904]),\n",
       " tensor([3.4122]),\n",
       " tensor([3.4100]),\n",
       " tensor([3.3890]),\n",
       " tensor([3.4108]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3842]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.4127]),\n",
       " tensor([3.3960]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.4074]),\n",
       " tensor([3.3842]),\n",
       " tensor([3.3875]),\n",
       " tensor([3.3933]),\n",
       " tensor([3.3945]),\n",
       " tensor([3.3959]),\n",
       " tensor([3.3963]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.4010]),\n",
       " tensor([3.3924]),\n",
       " tensor([3.4082]),\n",
       " tensor([3.3833]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.3990]),\n",
       " tensor([3.3942]),\n",
       " tensor([3.3891]),\n",
       " tensor([3.3880]),\n",
       " tensor([3.4155]),\n",
       " tensor([3.3919]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.4238]),\n",
       " tensor([3.3786]),\n",
       " tensor([3.4097]),\n",
       " tensor([3.4214]),\n",
       " tensor([3.3743]),\n",
       " tensor([3.3897]),\n",
       " tensor([3.4080]),\n",
       " tensor([3.4082]),\n",
       " tensor([3.3964]),\n",
       " tensor([3.3845]),\n",
       " tensor([3.4070]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.4056]),\n",
       " tensor([3.3756]),\n",
       " tensor([3.3853]),\n",
       " tensor([3.4129]),\n",
       " tensor([3.4044]),\n",
       " tensor([3.3836]),\n",
       " tensor([3.3902]),\n",
       " tensor([3.3959]),\n",
       " tensor([3.3827]),\n",
       " tensor([3.4051]),\n",
       " tensor([3.3900]),\n",
       " ...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(model=alphafold2, dataloaders=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.3.4.2. <a id='toc14_3_4_2_'></a>[加载权重](#toc0_)\n",
    "需要手动：\n",
    "- model.eval()\n",
    "- with torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4124],\n",
       "        [3.3868],\n",
       "        [3.3909],\n",
       "        ...,\n",
       "        [3.4022],\n",
       "        [3.3898],\n",
       "        [3.3934]], device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_alphafold2 = AlphaFold2Wrapper.load_from_checkpoint('./lightning_logs/version_0/checkpoints/epoch=9-step=790.ckpt')\n",
    "\n",
    "# 进行预测/推理\n",
    "pretrained_alphafold2.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = pretrained_alphafold2(features.to('cuda:0'))\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.3.4.3. <a id='toc14_3_4_3_'></a>[提取权重后加载至纯PyTorch模型](#toc0_)\n",
    "从checkpoint中`提取模型的权重参数`，`修改相关格式`后再加载到纯PyTorch的模型中，就是普通又熟悉的PyTorch的预测方式了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_268120/3329860571.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 9,\n",
       " 'global_step': 790,\n",
       " 'pytorch-lightning_version': '2.4.0',\n",
       " 'state_dict': OrderedDict([('demo_model.hidden.0.weight',\n",
       "               tensor([[ 0.0967, -0.0567]], device='cuda:0')),\n",
       "              ('demo_model.hidden.0.bias',\n",
       "               tensor([3.3954], device='cuda:0'))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 790},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 790,\n",
       "     'completed': 790,\n",
       "     'started': 790,\n",
       "     'processed': 790},\n",
       "    'current': {'ready': 79, 'completed': 79, 'started': 79, 'processed': 79},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 790,\n",
       "       'completed': 790},\n",
       "      'current': {'ready': 79, 'completed': 79}},\n",
       "     'zero_grad': {'total': {'ready': 790, 'completed': 790, 'started': 790},\n",
       "      'current': {'ready': 79, 'completed': 79, 'started': 79}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 79,\n",
       "     'completed': 79,\n",
       "     'started': 79,\n",
       "     'processed': 79},\n",
       "    'current': {'ready': 79, 'completed': 79, 'started': 79, 'processed': 79},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_progress': {'total': {'ready': 10,\n",
       "     'completed': 9,\n",
       "     'started': 10,\n",
       "     'processed': 10},\n",
       "    'current': {'ready': 10, 'completed': 9, 'started': 10, 'processed': 10}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': None,\n",
       "   'best_model_score': None,\n",
       "   'best_model_path': '/bmp/backup/zhaosy/ws/PyTorch_learning/lightning_logs/version_0/checkpoints/epoch=9-step=790.ckpt',\n",
       "   'current_score': None,\n",
       "   'dirpath': '/bmp/backup/zhaosy/ws/PyTorch_learning/lightning_logs/version_0/checkpoints',\n",
       "   'best_k_models': {},\n",
       "   'kth_best_model_path': '',\n",
       "   'kth_value': tensor(inf),\n",
       "   'last_model_path': ''}},\n",
       " 'optimizer_states': [{'state': {},\n",
       "   'param_groups': [{'lr': 0.01,\n",
       "     'momentum': 0,\n",
       "     'dampening': 0,\n",
       "     'weight_decay': 0,\n",
       "     'nesterov': False,\n",
       "     'maximize': False,\n",
       "     'foreach': None,\n",
       "     'differentiable': False,\n",
       "     'fused': None,\n",
       "     'params': [0, 1]}]}],\n",
       " 'lr_schedulers': [],\n",
       " 'hparams_name': 'kwargs',\n",
       " 'hyper_parameters': {'learning_rate': 0.01}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = './lightning_logs/version_0/checkpoints/epoch=9-step=790.ckpt'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "checkpoint  # checkpoint的贮存格式，其中 'state_dict'就是模型权重信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AlphaFold2Wrapper(\n",
       "   (demo_model): AlphaFold2(\n",
       "     (hidden): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "     )\n",
       "   )\n",
       "   (loss_fn): MSELoss()\n",
       " ),\n",
       " OrderedDict([('demo_model.hidden.0.weight',\n",
       "               tensor([[ 0.0967, -0.0567]], device='cuda:0')),\n",
       "              ('demo_model.hidden.0.bias',\n",
       "               tensor([3.3954], device='cuda:0'))]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphafold2, checkpoint['state_dict']    # with AlphaFold2Wrapper, 多了demo_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_model.hidden.0.weight\n",
      "demo_model.hidden.0.bias\n"
     ]
    }
   ],
   "source": [
    "for param in checkpoint['state_dict']:\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `纯PyTorch的state_dict`如下，`如上的checkpoint`中的state_dict`不符合`相应格式，需要进行更改："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AlphaFold2(\n",
       "   (hidden): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "   )\n",
       " ),\n",
       " OrderedDict([('hidden.0.weight', tensor([[-0.5207,  0.0861]])),\n",
       "              ('hidden.0.bias', tensor([0.0467]))]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphafold_with_pure_pytorch = AlphaFold2()\n",
    "alphafold_with_pure_pytorch, alphafold_with_pure_pytorch.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 更改操作如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = checkpoint['state_dict']\n",
    "\n",
    "# 把demo_model.删除即可\n",
    "for key in model_weights:\n",
    "    model_weights[key.replace(\"demo_model.\", \"\")] = model_weights.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('hidden.0.weight',\n",
       "               tensor([[ 0.0967, -0.0567]], device='cuda:0')),\n",
       "              ('hidden.0.bias', tensor([3.3954], device='cuda:0'))]),\n",
       " OrderedDict([('hidden.0.weight',\n",
       "               tensor([[ 0.0967, -0.0567]], device='cuda:0')),\n",
       "              ('hidden.0.bias', tensor([3.3954], device='cuda:0'))]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['state_dict'], model_weights # 都更改了，什么鬼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4124],\n",
       "        [3.3868],\n",
       "        [3.3909],\n",
       "        ...,\n",
       "        [3.4022],\n",
       "        [3.3898],\n",
       "        [3.3934]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重新实例化一个新的对象\n",
    "alphafold_with_pure_pytorch = AlphaFold2()\n",
    "\n",
    "# 加载修改后的权重\n",
    "alphafold_with_pure_pytorch.load_state_dict(model_weights)  # 加载修改后的model_weights\n",
    "\n",
    "# 进行预测/推理\n",
    "alphafold_with_pure_pytorch.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = alphafold_with_pure_pytorch(features)\n",
    "y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
