{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [概述](#toc1_)    \n",
    "- 2. [环境配置](#toc2_)    \n",
    "- 3. [utils](#toc3_)    \n",
    "  - 3.1. [实验可重复性](#toc3_1_)    \n",
    "  - 3.2. [计时器](#toc3_2_)    \n",
    "    - 3.2.1. [cpu计时器](#toc3_2_1_)    \n",
    "    - 3.2.2. [gpu计时器](#toc3_2_2_)    \n",
    "  - 3.3. [numpy和pytorch计算速度比较](#toc3_3_)    \n",
    "- 4. [安装GPU驱动](#toc4_)    \n",
    "  - 4.1. [安装策略](#toc4_1_)    \n",
    "  - 4.2. [首先确认内核版本和发行版本，再确认显卡型号](#toc4_2_)    \n",
    "  - 4.3. [安装驱动-CUDA Driver](#toc4_3_)    \n",
    "    - 4.3.1. [下载CUDA Driver](#toc4_3_1_)    \n",
    "    - 4.3.2. [禁用nouveau](#toc4_3_2_)    \n",
    "    - 4.3.3. [安装CUDA Driver](#toc4_3_3_)    \n",
    "    - 4.3.4. [查看显卡是否安装成功](#toc4_3_4_)    \n",
    "    - 4.3.5. [查看nvcc](#toc4_3_5_)    \n",
    "  - 4.4. [CUDA Toolkit和CuDNN](#toc4_4_)    \n",
    "    - 4.4.1. [下载对应的CUDA Toolkit版本](#toc4_4_1_)    \n",
    "    - 4.4.2. [安装CUDA Toolkit](#toc4_4_2_)    \n",
    "    - 4.4.3. [下载对应的CuDNN](#toc4_4_3_)    \n",
    "    - 4.4.4. [安装CuDNN](#toc4_4_4_)    \n",
    "  - 4.5. [安装对应版本的Pytorch](#toc4_5_)    \n",
    "  - 4.6. [推荐A100](#toc4_6_)    \n",
    "  - 4.7. [GPU测试程序](#toc4_7_)    \n",
    "    - 4.7.1. [测试单机单卡GPU性能](#toc4_7_1_)    \n",
    "    - 4.7.2. [测试单机多卡GPU性能](#toc4_7_2_)    \n",
    "    - 4.7.3. [GPU burn压力测试](#toc4_7_3_)    \n",
    "- 5. [Pytorch模块介绍](#toc5_)    \n",
    "  - 5.1. [导入模块](#toc5_1_)    \n",
    "- 6. [数据封装和加载](#toc6_)    \n",
    "  - 6.1. [torchvison.datasets获得Dataset](#toc6_1_)    \n",
    "  - 6.2. [自定义数据集获得Dataset](#toc6_2_)    \n",
    "    - 6.2.1. [利用TensorDataset()封装成Dataset](#toc6_2_1_)    \n",
    "    - 6.2.2. [重载Dataset类](#toc6_2_2_)    \n",
    "    - 6.2.3. [Pytoch.utils.data.Dataset类分析和总结](#toc6_2_3_)    \n",
    "  - 6.3. [数据加载-DataLoader()](#toc6_3_)    \n",
    "    - 6.3.1. [估计数据加载时间](#toc6_3_1_)    \n",
    "- 7. [张量(Tensors)](#toc7_)    \n",
    "  - 7.1. [Tensors定义](#toc7_1_)    \n",
    "  - 7.2. [Tensors属性](#toc7_2_)    \n",
    "  - 7.3. [Tensors操作](#toc7_3_)    \n",
    "    - 7.3.1. [索引和切片](#toc7_3_1_)    \n",
    "    - 7.3.2. [修改维度](#toc7_3_2_)    \n",
    "      - 7.3.2.1. [reshape函数](#toc7_3_2_1_)    \n",
    "      - 7.3.2.2. [view函数](#toc7_3_2_2_)    \n",
    "      - 7.3.2.3. [transpose函数](#toc7_3_2_3_)    \n",
    "      - 7.3.2.4. [permute函数](#toc7_3_2_4_)    \n",
    "  - 7.4. [线性代数运算](#toc7_4_)    \n",
    "    - 7.4.1. [数值运算](#toc7_4_1_)    \n",
    "    - 7.4.2. [数值运算-乘法](#toc7_4_2_)    \n",
    "      - 7.4.2.1. [哈达玛积](#toc7_4_2_1_)    \n",
    "      - 7.4.2.2. [点积（Dot Product）](#toc7_4_2_2_)    \n",
    "      - 7.4.2.3. [矩阵-向量积](#toc7_4_2_3_)    \n",
    "      - 7.4.2.4. [矩阵-矩阵积](#toc7_4_2_4_)    \n",
    "      - 7.4.2.5. [批量矩阵乘法](#toc7_4_2_5_)    \n",
    "      - 7.4.2.6. [乘总结](#toc7_4_2_6_)    \n",
    "    - 7.4.3. [统计运算](#toc7_4_3_)    \n",
    "  - 7.5. [Pytorch的计算图 和 自动微分 (autograd)](#toc7_5_)    \n",
    "    - 7.5.1. [反向传播 (backward)-批量求梯度，但未进行参数更新](#toc7_5_1_)    \n",
    "    - 7.5.2. [仅计算梯度 (求导计算)](#toc7_5_2_)    \n",
    "  - 7.6. [自动微积-autograd](#toc7_6_)    \n",
    "    - 7.6.1. [自己探索](#toc7_6_1_)    \n",
    "      - 7.6.1.1. [标量-一阶导数（得标量）](#toc7_6_1_1_)    \n",
    "      - 7.6.1.2. [标量/向量-一阶导数（得向量）](#toc7_6_1_2_)    \n",
    "      - 7.6.1.3. [向量/向量-一阶导数（得矩阵）](#toc7_6_1_3_)    \n",
    "      - 7.6.1.4. [求高阶导数](#toc7_6_1_4_)    \n",
    "    - 7.6.2. [一个简单的例子](#toc7_6_2_)    \n",
    "    - 7.6.3. [计算另一个](#toc7_6_3_)    \n",
    "    - 7.6.4. [非标量变量的反向传播](#toc7_6_4_)    \n",
    "    - 7.6.5. [分离计算](#toc7_6_5_)    \n",
    "    - 7.6.6. [Python控制流的梯度计算](#toc7_6_6_)    \n",
    "  - 7.7. [概率论](#toc7_7_)    \n",
    "- 8. [神经网络-训练八股](#toc8_)    \n",
    "  - 8.1. [现线性回归模型于训练过程-从零开始](#toc8_1_)    \n",
    "    - 8.1.1. [虚拟出数据](#toc8_1_1_)    \n",
    "    - 8.1.2. [读取数据](#toc8_1_2_)    \n",
    "    - 8.1.3. [初始化模型参数](#toc8_1_3_)    \n",
    "    - 8.1.4. [定义模型](#toc8_1_4_)    \n",
    "    - 8.1.5. [定义损失函数](#toc8_1_5_)    \n",
    "    - 8.1.6. [定义优化算法](#toc8_1_6_)    \n",
    "    - 8.1.7. [训练](#toc8_1_7_)    \n",
    "  - 8.2. [现线性回归模型于训练过程-简洁实现](#toc8_2_)    \n",
    "    - 8.2.1. [虚拟数据](#toc8_2_1_)    \n",
    "    - 8.2.2. [读取数据](#toc8_2_2_)    \n",
    "    - 8.2.3. [定义模型](#toc8_2_3_)    \n",
    "    - 8.2.4. [初始化模型参数](#toc8_2_4_)    \n",
    "    - 8.2.5. [定义损失函数](#toc8_2_5_)    \n",
    "    - 8.2.6. [定义优化算法](#toc8_2_6_)    \n",
    "    - 8.2.7. [训练](#toc8_2_7_)    \n",
    "    - 8.2.8. [参数保存](#toc8_2_8_)    \n",
    "    - 8.2.9. [重载](#toc8_2_9_)    \n",
    "  - 8.3. [专题-模型定义（计算预测值y_hat）](#toc8_3_)    \n",
    "    - 8.3.1. [块：torch.nn模块](#toc8_3_1_)    \n",
    "    - 8.3.2. [块：自定义](#toc8_3_2_)    \n",
    "      - 8.3.2.1. [自定义块](#toc8_3_2_1_)    \n",
    "      - 8.3.2.2. [顺序块](#toc8_3_2_2_)    \n",
    "      - 8.3.2.3. [效率](#toc8_3_2_3_)    \n",
    "    - 8.3.3. [模型结构/组成](#toc8_3_3_)    \n",
    "      - 8.3.3.1. [.children()](#toc8_3_3_1_)    \n",
    "      - 8.3.3.2. [.named_children()](#toc8_3_3_2_)    \n",
    "      - 8.3.3.3. [.modules()](#toc8_3_3_3_)    \n",
    "      - 8.3.3.4. [.named_modules()](#toc8_3_3_4_)    \n",
    "      - 8.3.3.5. [删除和添加](#toc8_3_3_5_)    \n",
    "      - 8.3.3.6. [替换](#toc8_3_3_6_)    \n",
    "      - 8.3.3.7. [add_module()](#toc8_3_3_7_)    \n",
    "    - 8.3.4. [模型：参数管理](#toc8_3_4_)    \n",
    "      - 8.3.4.1. [参数访问](#toc8_3_4_1_)    \n",
    "        - 8.3.4.1.1. [state_dict](#toc8_3_4_1_1_)    \n",
    "        - 8.3.4.1.2. [parameters](#toc8_3_4_1_2_)    \n",
    "        - 8.3.4.1.3. [named_parameters](#toc8_3_4_1_3_)    \n",
    "      - 8.3.4.2. [参数初始化](#toc8_3_4_2_)    \n",
    "        - 8.3.4.2.1. [内置初始化](#toc8_3_4_2_1_)    \n",
    "        - 8.3.4.2.2. [自定义初始化](#toc8_3_4_2_2_)    \n",
    "        - 8.3.4.2.3. [参数绑定](#toc8_3_4_2_3_)    \n",
    "    - 8.3.5. [层：自定义](#toc8_3_5_)    \n",
    "      - 8.3.5.1. [不带参数的层](#toc8_3_5_1_)    \n",
    "      - 8.3.5.2. [带参数的层](#toc8_3_5_2_)    \n",
    "  - 8.4. [专题-损失函数 (loss_fn)](#toc8_4_)    \n",
    "    - 8.4.1. [均方误差](#toc8_4_1_)    \n",
    "    - 8.4.2. [交叉熵](#toc8_4_2_)    \n",
    "    - 8.4.3. [自定义](#toc8_4_3_)    \n",
    "  - 8.5. [专题-反向传播（求梯度）](#toc8_5_)    \n",
    "  - 8.6. [专题-更新权重（优化算法）](#toc8_6_)    \n",
    "    - 8.6.1. [随机梯度下降（SGD）](#toc8_6_1_)    \n",
    "    - 8.6.2. [adam](#toc8_6_2_)    \n",
    "    - 8.6.3. [RMSprop](#toc8_6_3_)    \n",
    "    - 8.6.4. [学习率调度器](#toc8_6_4_)    \n",
    "      - 8.6.4.1. [StepLR： 按照固定的步长调整学习率](#toc8_6_4_1_)    \n",
    "      - 8.6.4.2. [MultiStepLR： 在指定的里程碑（milestones）上调整学习率](#toc8_6_4_2_)    \n",
    "      - 8.6.4.3. [ExponentialLR： 以指数衰减的方式调整学习率](#toc8_6_4_3_)    \n",
    "      - 8.6.4.4. [CosineAnnealingLR： 余弦退火调整学习率](#toc8_6_4_4_)    \n",
    "      - 8.6.4.5. [ReduceLROnPlateau： 当指标停止改善时，降低学习率](#toc8_6_4_5_)    \n",
    "      - 8.6.4.6. [LambdaLR： 使用自定义的函数来调整学习率](#toc8_6_4_6_)    \n",
    "      - 8.6.4.7. [自定义](#toc8_6_4_7_)    \n",
    "  - 8.7. [专题-训练](#toc8_7_)    \n",
    "    - 8.7.1. [开始训练](#toc8_7_1_)    \n",
    "    - 8.7.2. [自己探索](#toc8_7_2_)    \n",
    "      - 8.7.2.1. [lr的影响](#toc8_7_2_1_)    \n",
    "      - 8.7.2.2. [不同模型的效率](#toc8_7_2_2_)    \n",
    "    - 8.7.3. [K折交叉验证](#toc8_7_3_)    \n",
    "  - 8.8. [可视化训练过程](#toc8_8_)    \n",
    "- 9. [在 GPU 上训练](#toc9_)    \n",
    "  - 9.1. [查看GPU配置](#toc9_1_)    \n",
    "  - 9.2. [单机单卡（GPU）](#toc9_2_)    \n",
    "  - 9.3. [单机多卡（GPU）](#toc9_3_)    \n",
    "    - 9.3.1. [DP](#toc9_3_1_)    \n",
    "    - 9.3.2. [DDP](#toc9_3_2_)    \n",
    "      - 9.3.2.1. [在colab上测试可用](#toc9_3_2_1_)    \n",
    "  - 9.4. [多机多卡（GPU）- 分布式训练](#toc9_4_)    \n",
    "- 10. [模型和参数的保存与加载](#toc10_)    \n",
    "  - 10.1. [加载和保存-张量](#toc10_1_)    \n",
    "  - 10.2. [加载和保存-模型参数](#toc10_2_)    \n",
    "- 11. [神经网络类型](#toc11_)    \n",
    "  - 11.1. [CNN](#toc11_1_)    \n",
    "    - 11.1.1. [概述](#toc11_1_1_)    \n",
    "    - 11.1.2. [简单CNN](#toc11_1_2_)    \n",
    "      - 11.1.2.1. [从头实现](#toc11_1_2_1_)    \n",
    "        - 11.1.2.1.1. [卷积计算过程](#toc11_1_2_1_1_)    \n",
    "        - 11.1.2.1.2. [从头卷积层](#toc11_1_2_1_2_)    \n",
    "      - 11.1.2.2. [简洁实现](#toc11_1_2_2_)    \n",
    "      - 11.1.2.3. [填充和步幅](#toc11_1_2_3_)    \n",
    "      - 11.1.2.4. [多输入和多输出通道](#toc11_1_2_4_)    \n",
    "      - 11.1.2.5. [Pooling (汇聚层)](#toc11_1_2_5_)    \n",
    "        - 11.1.2.5.1. [平均Pooling](#toc11_1_2_5_1_)    \n",
    "        - 11.1.2.5.2. [最大Pooling](#toc11_1_2_5_2_)    \n",
    "    - 11.1.3. [LeNet](#toc11_1_3_)    \n",
    "    - 11.1.4. [AlexNet](#toc11_1_4_)    \n",
    "    - 11.1.5. [VGG](#toc11_1_5_)    \n",
    "    - 11.1.6. [NiN](#toc11_1_6_)    \n",
    "    - 11.1.7. [GoogLeNet](#toc11_1_7_)    \n",
    "    - 11.1.8. [批量规范化](#toc11_1_8_)    \n",
    "    - 11.1.9. [ResNet](#toc11_1_9_)    \n",
    "      - 11.1.9.1. [从头实现](#toc11_1_9_1_)    \n",
    "  - 11.2. [序列数据](#toc11_2_)    \n",
    "    - 11.2.1. [什么是序列](#toc11_2_1_)    \n",
    "    - 11.2.2. [语言模型](#toc11_2_2_)    \n",
    "    - 11.2.3. [文本预处理](#toc11_2_3_)    \n",
    "      - 11.2.3.1. [下载《Time machine》并读取数据](#toc11_2_3_1_)    \n",
    "      - 11.2.3.2. [词元化（Token）](#toc11_2_3_2_)    \n",
    "      - 11.2.3.3. [词表（vocab）](#toc11_2_3_3_)    \n",
    "      - 11.2.3.4. [整合所有功能](#toc11_2_3_4_)    \n",
    "    - 11.2.4. [语言模型数据集](#toc11_2_4_)    \n",
    "      - 11.2.4.1. [顺序采样](#toc11_2_4_1_)    \n",
    "      - 11.2.4.2. [随机采样](#toc11_2_4_2_)    \n",
    "      - 11.2.4.3. [包装](#toc11_2_4_3_)    \n",
    "  - 11.3. [RNN](#toc11_3_)    \n",
    "    - 11.3.1. [RNN-循环神经网络原理](#toc11_3_1_)    \n",
    "      - 11.3.1.1. [从头实现网络](#toc11_3_1_1_)    \n",
    "      - 11.3.1.2. [简洁实现](#toc11_3_1_2_)    \n",
    "      - 11.3.1.3. [训练和预测](#toc11_3_1_3_)    \n",
    "      - 11.3.1.4. [深层RNN](#toc11_3_1_4_)    \n",
    "      - 11.3.1.5. [双向RNN](#toc11_3_1_5_)    \n",
    "    - 11.3.2. [GRU](#toc11_3_2_)    \n",
    "      - 11.3.2.1. [从头实现](#toc11_3_2_1_)    \n",
    "      - 11.3.2.2. [简洁实现](#toc11_3_2_2_)    \n",
    "    - 11.3.3. [LSTM](#toc11_3_3_)    \n",
    "      - 11.3.3.1. [从头实现](#toc11_3_3_1_)    \n",
    "      - 11.3.3.2. [简洁实现](#toc11_3_3_2_)    \n",
    "    - 11.3.4. [Encoder-Decoder框架](#toc11_3_4_)    \n",
    "      - 11.3.4.1. [Encoder部分](#toc11_3_4_1_)    \n",
    "      - 11.3.4.2. [Decoder部分](#toc11_3_4_2_)    \n",
    "      - 11.3.4.3. [Encoder-Decoder（合并编码器和解码器）](#toc11_3_4_3_)    \n",
    "    - 11.3.5. [seq2seq (Sequence to sequence learning)](#toc11_3_5_)    \n",
    "      - 11.3.5.1. [简洁实现](#toc11_3_5_1_)    \n",
    "  - 11.4. [Attention](#toc11_4_)    \n",
    "    - 11.4.1. [非参数注意力汇聚（Attention Pooling）-计算q和k相似度](#toc11_4_1_)    \n",
    "    - 11.4.2. [参数注意力汇聚（Attention Pooling）-计算q和k相似度](#toc11_4_2_)    \n",
    "    - 11.4.3. [注意力分数函数-计算q和k相似度](#toc11_4_3_)    \n",
    "      - 11.4.3.1. [加性注意力](#toc11_4_3_1_)    \n",
    "      - 11.4.3.2. [缩放点积注意力](#toc11_4_3_2_)    \n",
    "    - 11.4.4. [自注意力机制](#toc11_4_4_)    \n",
    "    - 11.4.5. [多头注意力机制](#toc11_4_5_)    \n",
    "    - 11.4.6. [attention-seq2seq](#toc11_4_6_)    \n",
    "  - 11.5. [Transformer](#toc11_5_)    \n",
    "    - 11.5.1. [位置编码](#toc11_5_1_)    \n",
    "    - 11.5.2. [基于位置的前馈网络](#toc11_5_2_)    \n",
    "    - 11.5.3. [残差连接和层规范化](#toc11_5_3_)    \n",
    "    - 11.5.4. [编码器](#toc11_5_4_)    \n",
    "    - 11.5.5. [解码器](#toc11_5_5_)    \n",
    "    - 11.5.6. [基于Attention的Seq2Seq网络](#toc11_5_6_)    \n",
    "    - 11.5.7. [BERT](#toc11_5_7_)    \n",
    "    - 11.5.8. [GPT](#toc11_5_8_)    \n",
    "- 12. [炼丹心得](#toc12_)    \n",
    "  - 12.1. [关于改变形状](#toc12_1_)    \n",
    "  - 12.2. [关于调参](#toc12_2_)    \n",
    "  - 12.3. [模型选择](#toc12_3_)    \n",
    "  - 12.4. [one-hot](#toc12_4_)    \n",
    "  - 12.5. [embedding](#toc12_5_)    \n",
    "  - 12.6. [BN和LN](#toc12_6_)    \n",
    "  - 12.7. [MLP、FC、FNN、CNN、RNN](#toc12_7_)    \n",
    "  - 12.8. [机器学习](#toc12_8_)    \n",
    "- 13. [PyTorch做迁移学习](#toc13_)    \n",
    "  - 13.1. [Fine-tuning](#toc13_1_)    \n",
    "    - 13.1.1. [小的lr](#toc13_1_1_)    \n",
    "    - 13.1.2. [停止计算梯度](#toc13_1_2_)    \n",
    "  - 13.2. [torchvision的应用案例](#toc13_2_)    \n",
    "  - 13.3. [迁移学习案例](#toc13_3_)    \n",
    "- 14. [PyTorch lightning训练框架](#toc14_)    \n",
    "  - 14.1. [训练逻辑](#toc14_1_)    \n",
    "  - 14.2. [Data.py](#toc14_2_)    \n",
    "  - 14.3. [Model.py](#toc14_3_)    \n",
    "  - 14.4. [ModelWrapper.py](#toc14_4_)    \n",
    "    - 14.4.1. [Training and vlidation](#toc14_4_1_)    \n",
    "    - 14.4.2. [Validation](#toc14_4_2_)    \n",
    "    - 14.4.3. [Test](#toc14_4_3_)    \n",
    "    - 14.4.4. [Prediction](#toc14_4_4_)    \n",
    "      - 14.4.4.1. [PyTorch lightning自身Trainer直接predict](#toc14_4_4_1_)    \n",
    "      - 14.4.4.2. [PyTorch lightning加载权重后预测](#toc14_4_4_2_)    \n",
    "      - 14.4.4.3. [提取权重后加载至纯PyTorch模型](#toc14_4_4_3_)    \n",
    "- 15. [L做迁移学习](#toc15_)    \n",
    "  - 15.1. [项目一：](#toc15_1_)    \n",
    "- 16. [Torchvision教程](#toc16_)    \n",
    "  - 16.1. [Models](#toc16_1_)    \n",
    "    - 16.1.1. [可用模型](#toc16_1_1_)    \n",
    "    - 16.1.2. [下载模型和权重](#toc16_1_2_)    \n",
    "    - 16.1.3. [模型加载权重](#toc16_1_3_)    \n",
    "    - 16.1.4. [总结](#toc16_1_4_)    \n",
    "  - 16.2. [Dataset](#toc16_2_)    \n",
    "- 17. [Degub pdb](#toc17_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[概述](#toc0_)\n",
    "写这这个笔记的主要目的是作为学些过程中知识的总结、归纳和反思。作为一个非科班出生的生物人，仅凭着热爱开始了自学深度学习这条路，前路漫漫不敢想，也不曾觉着以后能端这碗饭。只是，羡慕网上像智慧君、李沐这样的人，能够从事如此炫酷的工作，能把自己的热爱开发成一生从事的职业。仔细想想如果自己不做点什么或是不为此努力点什么，就觉得坐立不、安难以入眠。同时深知，这个过程会是无比艰辛，在百无聊赖之际，记录学习的过程或许会是一种苦中作乐的方式。\n",
    "\n",
    "- d2l EN (及时更新): [https://d2l.ai/index.html](https://d2l.ai/index.html)\n",
    "- d2l ZH: [https://zh-v2.d2l.ai/](https://zh-v2.d2l.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id='toc2_'></a>[环境配置](#toc0_)\n",
    "\n",
    "- PyTorch官方教程 [https://pytorch.org/](https://pytorch.org/)\n",
    "\n",
    "- PyTorch lightning官方教程 [https://lightning.ai/docs/pytorch/stable/](https://lightning.ai/docs/pytorch/stable/)\n",
    "\n",
    "- 尽量用conda配置环境，不要conda和pip混搭。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment \n",
    "# and entry the environment\n",
    "conda create -n pytorch -y && conda activate pytorch\n",
    "\n",
    "# Install ipykernel and related packages via conda\n",
    "conda install ipykernel matplotlib pandas seaborn -y\n",
    "\n",
    "# Install PyTorch\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia\n",
    "\n",
    "# Instll PyTorch lightning\n",
    "conda install lightning -c conda-forge -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id='toc3_'></a>[utils](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. <a id='toc3_1_'></a>[实验可重复性](#toc0_)\n",
    "整个代码框架中很多地方使用到随机数的，为了实验的可重复性需要固定随机种子；  \n",
    "另外，有研究表明GPU中的CUDA变成也有很多地方对实验结果的稳定性很重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "\n",
    "# Function for setting the seed\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():  # GPU operation have separate seed\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. <a id='toc3_2_'></a>[计时器](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. <a id='toc3_2_1_'></a>[cpu计时器](#toc0_)\n",
    "\n",
    "* 自定义的一些使用的脚本。\n",
    "```sehll\n",
    "    __init__(self) # 初始化实例时就会执行\n",
    "    __call__(self) # 再次调用时，自动执行\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 0.0302579402923584 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "class cpuTimer():\n",
    "    '''一个计时器'''\n",
    "    def __init__(self):\n",
    "        '''初始化时候自动执行'''\n",
    "        self.start = time.time()\n",
    "\n",
    "    def __call__(self):\n",
    "        '''再次调用该对象时，会自动执行'''\n",
    "        self.stop = time.time()\n",
    "        seconds = self.stop - self.start\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        print('='*20, '\\n', f\"Total：\\n {days} d \\n {hours} h \\n {minutes} m \\n {remaining_seconds} s\")\n",
    "        \n",
    "# Tiemr使用\n",
    "timer_on_cpu = cpuTimer()\n",
    "for i in range(3):\n",
    "    time.sleep(0.01)\n",
    "timer_on_cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. <a id='toc3_2_2_'></a>[gpu计时器](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡ \n",
      "GPU time: 0.00252s\n"
     ]
    }
   ],
   "source": [
    "class gpuTimer():\n",
    "    def __init__(self):\n",
    "        # CUDA is asynchronous, so we need to use different timing functions\n",
    "        self.start = torch.cuda.Event(enable_timing=True)\n",
    "        self.end = torch.cuda.Event(enable_timing=True)\n",
    "        self.start.record()\n",
    "\n",
    "    def __call__(self):\n",
    "        self.end.record()\n",
    "        torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
    "        print(\"⚡\"*20, f\"\\nGPU time: {0.001 * self.start.elapsed_time(self.end):6.5f}s\")  # Milliseconds to seconds\n",
    "\n",
    "# Demo for Timer on GPU devices\n",
    "timer_on_gpu = gpuTimer()\n",
    "a = torch.arange(45).reshape(3, 3, 5)\n",
    "b = torch.arange(45).reshape(3, 5, 3)\n",
    "c = torch.bmm(a, b)\n",
    "timer_on_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. <a id='toc3_3_'></a>[numpy和pytorch计算速度比较](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Datas on cpu with arrary\n",
    "a = np.random.rand(1000, 1000)\n",
    "b = np.random.rand(1000, 1000)\n",
    "\n",
    "# Datas on cpu with tensor\n",
    "at = torch.Tensor(a).to('cpu')\n",
    "bt = torch.Tensor(b).to('cpu')\n",
    "\n",
    "# Datas on gpu with tensor\n",
    "at_gpu = torch.Tensor(a).to('cuda:0')\n",
    "bt_gpu = torch.Tensor(b).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.28 ms ± 12.7 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a + b   # On cpu via numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 μs ± 1.81 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit at + bt # On cpu via PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.00024454399943351745 s\n"
     ]
    }
   ],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "stop = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "at_gpu + bt_gpu\n",
    "stop.record()\n",
    "\n",
    "# Waits for everything to finish running\n",
    "torch.cuda.synchronize()\n",
    "print(f'Time: {0.001 * start.elapsed_time(stop)} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id='toc4_'></a>[安装GPU驱动](#toc0_)\n",
    "\n",
    "- 以CentOS8安装NVIDIA Tesla A100为例，下载CUDA Toolkit和CuDNN，需要注意cudnn的版本必须与cuda的版本相匹配：\n",
    "\n",
    "    - 1.NVIDIA Driver：  \n",
    "    `NVIDIA驱动是NVIDIA显卡的驱动程序，它是CUDA和CuDNN的前提条件。显卡驱动下载地址：https://www.nvidia.com/Download/index.aspx。`\n",
    "\n",
    "    - 2.CUDA Toolkit：  \n",
    "    `CUDA Toolkit是一个开发工具包，其中包含了CUDA编译器、IDE、调试器等工具，以及CUDA程序所需的各种库文件和头文件，每个版本的CUDA Toolkit 都对应一个最低版本的显卡驱动版本（CUDA Driver）。`\n",
    "\n",
    "    - 3.NVCC：  \n",
    "    `其实就是CUDA的编译器,可以从CUDA Toolkit的/bin目录中获取,类似于gcc就是c语言的编译器。`\n",
    "\n",
    "    - 4.CUDA Deep Neural Network (cuDNN)：  \n",
    "    `CuDNN是NVIDIA提供的一个深度神经网络加速库，它包含了一系列高性能的基本函数和算法，用于加速深度学习任务的计算；CuDNN需要与CUDA Toolkit一起使用，以优化深度学习任务。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. <a id='toc4_1_'></a>[安装策略](#toc0_)\n",
    "\n",
    "- 方式一 `全局驱动，各自cuda`：\n",
    "    - `只安装NVIDIA Tesla A100的driver，每个用户自己利用conda安装CUDA Toolkit、cuDNN和对应的Pytorch版本（推荐），但是得注意选择兼容型号。（推荐）`\n",
    "\n",
    "- 方式二 `全局驱动，全局cuda`：\n",
    "    - `安装Driver、CUDA Toolkit (全局安装)`\n",
    "    \n",
    "- 方式三 `docker`：\n",
    "    - `安装Driver、NVIDIA docker (docker虚拟容器)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. <a id='toc4_2_'></a>[首先确认内核版本和发行版本，再确认显卡型号](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看linux内核版本、架构\n",
      "Linux 135.91.205.202.cau.edu.cn 4.18.0-348.7.1.el8_5.x86_64 #1 SMP Wed Dec 22 13:25:12 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\n",
      "发行版本\n",
      "CentOS Linux release 8.1.1911 (Core) \n",
      "显卡型号 （硬件层面）\n",
      "2f:00.0 3D controller: NVIDIA Corporation Device 20b0 (rev a1)\n",
      "86:00.0 3D controller: NVIDIA Corporation Device 20b0 (rev a1)\n",
      "验证系统是否安装gcc编译器\n",
      "gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-4)\n",
      "Copyright (C) 2018 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "echo 查看linux内核版本、架构\n",
    "uname -a\n",
    "# Linux 135.91.205.202.cau.edu.cn 4.18.0-147.el8.x86_64 #1 SMP Wed Dec 4 21:51:45 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\n",
    "# x86_64\n",
    "\n",
    "echo 发行版本\n",
    "cat /etc/redhat-release\n",
    "# CentOS Linux release 8.1.1911 (Core)\n",
    "# CentOS\n",
    "\n",
    "echo 显卡型号 （硬件层面）\n",
    "lspci | grep -i nvidia\n",
    "# 04:00.0 3D controller: NVIDIA Corporation GK208M [GeForce GT 730M] (rev a1)\n",
    "\n",
    "echo 验证系统是否安装gcc编译器\n",
    "gcc --version\n",
    "\n",
    "# sudo yum install kernel-devel-$(uname -r) kernel-headers-$(uname -r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. <a id='toc4_3_'></a>[安装驱动-CUDA Driver](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. <a id='toc4_3_1_'></a>[下载CUDA Driver](#toc0_)\n",
    "\n",
    "![image.png](attachment:image.png) \n",
    "\n",
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 从NVIDIA官网下辖\n",
    "# https://www.nvidia.cn/Download/index.aspx?lang=cn\n",
    "\n",
    "# 2. 通过dnf search nvidia*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. <a id='toc4_3_2_'></a>[禁用nouveau](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 貌似在centos8上默认就禁用了，我没改，直接查看了lsmod | grep nouveau命令，发现没有输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3. <a id='toc4_3_3_'></a>[安装CUDA Driver](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'chmod' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n",
      "'sudo' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "# !chmod a+x *.run\n",
    "# !sudo ./*.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4. <a id='toc4_3_4_'></a>[查看显卡是否安装成功](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug 24 18:54:22 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:2F:00.0 Off |                    0 |\n",
      "| N/A   38C    P0             35W /  400W |   30737MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-40GB          Off |   00000000:86:00.0 Off |                    0 |\n",
      "| N/A   37C    P0             37W /  400W |     425MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   1892460      C   python                                      30728MiB |\n",
      "|    1   N/A  N/A   1892460      C   python                                        416MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.5. <a id='toc4_3_5_'></a>[查看nvcc](#toc0_)\n",
    "```shell\n",
    "nvcc只是CUDA Toolkit中的一个软件。此时，只是安装了驱动程序，没有安装CUDA Toolkit，所以无法查看nvcc。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n",
      "/bin/bash: nvcc: command not found\n"
     ]
    }
   ],
   "source": [
    "!source /bmp/backup/zhaosy/miniconda3/etc/profile.d/conda.sh\n",
    "!conda activate pytorch\n",
    "!nvcc --version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. <a id='toc4_4_'></a>[CUDA Toolkit和CuDNN](#toc0_)\n",
    "```shell\n",
    "不推荐一开始作为root为Linux全局配置CUDA Toolkit，每个用户和软件使用的CUDA Toolkit版本可能不一样。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1. <a id='toc4_4_1_'></a>[下载对应的CUDA Toolkit版本](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc -V # 查看是否安装好CUDA Toolkit\n",
    "\n",
    "wget https://us.download.nvidia.cn/tesla/535.129.03/NVIDIA-Linux-x86_64-535.129.03.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2. <a id='toc4_4_2_'></a>[安装CUDA Toolkit](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# 卸载之前安装的cuda\n",
    "sudo dnf remove nvidia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "chmod +x NVIDIA-Linux-x86_64-535.129.03.run\n",
    "sudo sh NVIDIA-Linux-x86_64-535.129.03.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3. <a id='toc4_4_3_'></a>[下载对应的CuDNN](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://link.zhihu.com/?target=https%3A//developer.nvidia.com/rdp/cudnn-download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4. <a id='toc4_4_4_'></a>[安装CuDNN](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. <a id='toc4_5_'></a>[安装对应版本的Pytorch](#toc0_)\n",
    "```shell\n",
    "在Pytorch的官网进行查询，按照条件检索符合要求的软件版本，最主要的是对应的cuda版本号。\n",
    "```\n",
    "[https://pytorch.org/](https://pytorch.org/)\n",
    "\n",
    "![PyTorch](./Pytorch_Pictures/Install_PyTorch/PyTorch_website.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "# https://pytorch.org/\n",
    "# CUDA 12.1\n",
    "conda create -n pytorch-gpu -y && conda activate pytorch-gpu \n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia # CUDA 12.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6. <a id='toc4_6_'></a>[推荐A100](#toc0_)\n",
    "\n",
    "- 全局A100驱动\n",
    "\n",
    "- conda下cuda toolkit、pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enviroment and actiate environment\n",
    "conda create -n pytorch-gpu && conda activate pytorch-gpu \n",
    "\n",
    "# Install cudatoolkit via conda\n",
    "conda install nvidia/label/cuda-12.6.0::cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7. <a id='toc4_7_'></a>[GPU测试程序](#toc0_)\n",
    "### 4.7.1. <a id='toc4_7_1_'></a>[测试单机单卡GPU性能](#toc0_)\n",
    "```shell\n",
    "net.to('cuda:0')\n",
    "x_gpu = x.to('cuda:0')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Runing on cpu\n",
      "====================================================================================================\n",
      "epoch 1/10: train_loss=1.5761462450027466, train_acc=90.3499984741211, test_acc=90.58000183105469\n",
      "epoch 2/10: train_loss=1.5509774684906006, train_acc=92.18000030517578, test_acc=92.25\n",
      "epoch 3/10: train_loss=1.531611442565918, train_acc=93.84666442871094, test_acc=93.66000366210938\n",
      "epoch 4/10: train_loss=1.5226444005966187, train_acc=94.68167114257812, test_acc=94.41000366210938\n",
      "epoch 5/10: train_loss=1.5157856941223145, train_acc=95.25333404541016, test_acc=94.91000366210938\n",
      "epoch 6/10: train_loss=1.5095164775848389, train_acc=95.75333404541016, test_acc=95.3800048828125\n",
      "epoch 7/10: train_loss=1.5046296119689941, train_acc=96.23666381835938, test_acc=95.6500015258789\n",
      "epoch 8/10: train_loss=1.501118540763855, train_acc=96.57499694824219, test_acc=96.0300064086914\n",
      "epoch 9/10: train_loss=1.4973342418670654, train_acc=96.92333221435547, test_acc=96.4000015258789\n",
      "epoch 10/10: train_loss=1.4947611093521118, train_acc=97.15833282470703, test_acc=96.4800033569336\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 39.68875694274902 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor(), \n",
    "        #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "        #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True\n",
    ")\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 10), nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                         # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)                          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)                # 计算loss\n",
    "            loss.backward()                         # 计算梯度\n",
    "            opt.step()                              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.2. <a id='toc4_7_2_'></a>[测试单机多卡GPU性能](#toc0_)\n",
    "```shell\n",
    "torch.nn.DataParallel()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Runing on cpu\n",
      "====================================================================================================\n",
      "epoch 1/10: train_loss=1.629683494567871, train_acc=84.03166198730469, test_acc=84.69000244140625\n",
      "epoch 2/10: train_loss=1.5497328042984009, train_acc=92.23500061035156, test_acc=92.5199966430664\n",
      "epoch 3/10: train_loss=1.5344191789627075, train_acc=93.5566635131836, test_acc=93.31999969482422\n",
      "epoch 4/10: train_loss=1.523071050643921, train_acc=94.54167175292969, test_acc=94.29000091552734\n",
      "epoch 5/10: train_loss=1.5164700746536255, train_acc=95.11666870117188, test_acc=94.76000213623047\n",
      "epoch 6/10: train_loss=1.5110586881637573, train_acc=95.63500213623047, test_acc=95.20000457763672\n",
      "epoch 7/10: train_loss=1.505732774734497, train_acc=96.13500213623047, test_acc=95.62000274658203\n",
      "epoch 8/10: train_loss=1.5016632080078125, train_acc=96.53666687011719, test_acc=95.84000396728516\n",
      "epoch 9/10: train_loss=1.5003046989440918, train_acc=96.70500183105469, test_acc=95.97000122070312\n",
      "epoch 10/10: train_loss=1.494889736175537, train_acc=97.18833923339844, test_acc=96.36000061035156\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 31.455957412719727 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True\n",
    ")\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 10), nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net = nn.DataParallel(module=net)\n",
    "    net = net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = [ 'cpu' if not torch.cuda.is_available() else ]\n",
    "device = [f'cuda:{i}' for i in range(torch.cuda.device_count())] if torch.cuda.is_available() else ['cpu']\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.3. <a id='toc4_7_3_'></a>[GPU burn压力测试](#toc0_)\n",
    "```shell\n",
    "李沐在装机配置后，进行GPU压力测试所用的程序为GPU_burn（可从github上下载）\n",
    "```\n",
    "\n",
    "- gpu_burn: \n",
    "  - github地址：`git clone https://github.com/wilicc/gpu-burn.git`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# git clone:\n",
    "git clone https://github.com/wilicc/gpu-burn.git\n",
    "\n",
    "cd gpu-burn\n",
    "\n",
    "# make \n",
    "make\n",
    "\n",
    "# 或\n",
    "# make CUDAPATH=~/minicnoda3/pytorch-gpu/\n",
    "\n",
    "# help\n",
    "gpu_burn --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# 2h * 60min * 60s = 7200s with tensor core (avaliable)\n",
    "gpu_burn -tc $(( 3 * 24 * 60 * 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. <a id='toc5_'></a>[Pytorch模块介绍](#toc0_)\n",
    "## 5.1. <a id='toc5_1_'></a>[导入模块](#toc0_)\n",
    "\n",
    "* torchvision\n",
    "  * models\n",
    "  * datasets\n",
    "  * transforms\n",
    "  * utils\n",
    "* torch\n",
    "  * utils\n",
    "    * data            # 数据加载相关\n",
    "      * TensorDataset\n",
    "      * Dataset\n",
    "      * DataLoader\n",
    "  * nn\n",
    "    * functional\n",
    "    * Sequential\n",
    "    * DataParallel\n",
    "    * Linear\n",
    "    * Softmax\n",
    "  * optim\n",
    "    * SGD\n",
    "    * Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version:  2.4.0\n",
      "torchvision version: 0.19.0\n"
     ]
    }
   ],
   "source": [
    "# 现成的数据库\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "\n",
    "import torch\n",
    "\n",
    "# 数据加载\n",
    "import torch.utils.data \n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "# 神经网络结构\n",
    "import torch.nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import torch.nn.DataParallel\n",
    "from torch.nn import DataParallel\n",
    "import torch.distributed as dist\n",
    "\n",
    "# 优化器\n",
    "import torch.optim \n",
    "\n",
    "print('pytorch version: ', torch.__version__)\n",
    "print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. <a id='toc6_'></a>[数据封装和加载](#toc0_)\n",
    "\n",
    "PyTorch为我们提供的`Dataset`和`DataLoader`类分别负责可被Pytorhc使用的数据集的`创建`以及向训练`传递数据`的任务。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. <a id='toc6_1_'></a>[torchvison.datasets获得Dataset](#toc0_)\n",
    "\n",
    "* `tochvision`主要处理图像数据，包含一些常用的数据集、模型、转换函数等。  \n",
    "* torchvision独立于PyTorch，需要专门安装。\n",
    "\n",
    "  * torchvision.`models`: 提供深度学习中各种经典的网络结构、预训练好的模型，如：Alex-Net、VGG、ResNet、Inception等。\n",
    "\n",
    "  * torchvision.`datasets`：提供常用的数据集，设计上继承 torch.utils.data.Dataset，主要包括：MNIST、CIFAR10/100、ImageNet、COCO等。\n",
    "\n",
    "  * torchvision.`transforms`：提供常用的数据预处理操作，主要包括对Tensor及PIL Image对象的操作。\n",
    "  \n",
    "  * torchvision.`utils`：工具类，如保存张量作为图像到磁盘，给一个小批量创建一个图像网格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torchvision.datasets.mnist.FashionMNIST,\n",
       " torchvision.datasets.mnist.FashionMNIST)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "dbs = './Pytorch_datasets/'\n",
    "\n",
    "trans = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),                  # PIL转换为tensor格式\n",
    "        torchvision.transforms.Normalize((0.5,), (1.0,))    # 标准化\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=trans, \n",
    "#   target_transform=False\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=trans, \n",
    "#   target_transform=False\n",
    ")\n",
    "type(train_dataset), type(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./Pytorch_datasets/\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5,), std=(1.0,))\n",
       "            ),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./Pytorch_datasets/\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5,), std=(1.0,))\n",
       "            ))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 封装成torch使用的dataset格式数据\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. <a id='toc6_2_'></a>[自定义数据集获得Dataset](#toc0_)\n",
    "### 6.2.1. <a id='toc6_2_1_'></a>[利用TensorDataset()封装成Dataset](#toc0_)\n",
    "\n",
    "- `TensorDataset`是一个现成的类，用于将数据表示为张量列表。\n",
    "\n",
    "- 如果你只是想创建一个包含输入特征和标签的数据集，可以直接使用 TensorDataset：\n",
    "\n",
    "  - `dataset = torch.utils.data.TensorDataset( input_features, labels )` # 按照下标顺序将input_features和labels值对应起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataset.TensorDataset,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x7f9030b56ab0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# 1. 自建数据集 (Tensor格式的数据)\n",
    "features = torch.tensor([i for i in range(1000)])\n",
    "labels = features * 2                               # labels = torch.mul(features, 2)\n",
    "\n",
    "# 2. 构建dataset数据集\n",
    "datasets = TensorDataset(features, labels) \n",
    "type(datasets), datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features0, labels0 = datasets[0] # 取第一个数据对\n",
    "features0, labels0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.__getitem__(0) # 同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(2))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[1] # 取第二个数据对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(2))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.__getitem__(1) # 同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.__len__()  # 数据对的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataloader.DataLoader,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f9030d214c0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_datasets = datasets\n",
    "\n",
    "# 3. 加载成batch数据\n",
    "data_iter = DataLoader(dataset=datasets, batch_size=256, shuffle=True, num_workers=3)\n",
    "type(data_iter), data_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2. <a id='toc6_2_2_'></a>[重载Dataset类](#toc0_)\n",
    "\n",
    "- `torch.utils.data.Dataset`是一个抽象类，用于定义新类型的自定义数据集。如果你想创建自己的数据集，可以继承这个类并实现以下方法：\n",
    "\n",
    "  - 重载`__init__(self, *args, **kwargs)`: 初始化方法，可以在其中加载你的数据；\n",
    "\n",
    "  - 重载`__len(self)__`: 返回数据集的长度；\n",
    "\n",
    "  - 重载`__getitem__(self, index)`: 根据索引返回数据集中的一个样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.MyData at 0x7f90308f7bc0>,\n",
       " (tensor(0), tensor(0)),\n",
       " (tensor(1), tensor(1)),\n",
       " (tensor(1), tensor(1)),\n",
       " (tensor(2), tensor(2)),\n",
       " (tensor(2), tensor(2)),\n",
       " 15)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1. 重载Dataset类\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, nums:int=15):\n",
    "        self.nums = nums\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nums\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        features = torch.arange(self.nums)\n",
    "        labels = torch.arange(self.nums)\n",
    "        return features[index], labels[index]\n",
    "\n",
    "# 2. 利用重载的Dataset创建数据集\n",
    "datasets = MyData()\n",
    "datasets, datasets[0], datasets[1], datasets.__getitem__(1), datasets[2], datasets.__getitem__(2), datasets.__len__()\n",
    "\n",
    "# 3. 利用DataLoader加载数据\n",
    "# data_iter = DataLoader(dataset=datasets, batch_size=256, shuffle=True, num_workers=3)\n",
    "# data_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3. <a id='toc6_2_3_'></a>[Pytoch.utils.data.Dataset类分析和总结](#toc0_)\n",
    "\n",
    "- 在PyTorch中数据的封装格式为torch.utils.data.Dataset类；\n",
    "\n",
    "- 第一种方式：直接加载`torchvision.datasets`中对应的数据库生成Dataset格式\n",
    "\n",
    "- 第二种方式：自定义\n",
    "  - 利用`Tensordataset(features, labels)`函数将features和labels配对并生成Dataset格式 (推荐，我觉得更加方便)\n",
    "  \n",
    "  - 重载`Dataset`类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. <a id='toc6_3_'></a>[数据加载-DataLoader()](#toc0_)\n",
    "- 1. 先将自制的数据集利用data.TensorDataset生成`dataset`；\n",
    "\n",
    "- 2. 再用data.DataLoader加载到dataset成最终可用的带有batch_size的格式`DataLoader`，方便后续的训练\n",
    "\n",
    "- 3. 先测试以下数据加载的速度，必须比训练计算所耗的时间小，否则将降低训练效率；\n",
    "\n",
    "- 4. 当数据加载时间很长时可以预加载，缩短时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 加载torchvison数据集（格式化好的torch.utils.data.Dataset）\n",
    "train_iter = DataLoader(\n",
    "    dataset = my_datasets, \n",
    "    batch_size = 5, \n",
    "    shuffle = True,                # 打乱顺序\n",
    "    num_workers = 3                # 线程数\n",
    "    drop_last = False,             # 是否删除最后一个不是整数的batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataloader.DataLoader,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f90308f7770>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_iter), train_iter # 直接答应看不到内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机抽取: 1 [tensor([666, 761, 701, 637, 154]), tensor([1332, 1522, 1402, 1274,  308])]\n",
      "随机抽取: 2 [tensor([212,  58, 496, 383, 731]), tensor([ 424,  116,  992,  766, 1462])]\n",
      "随机抽取: 3 [tensor([641, 116, 414, 257, 748]), tensor([1282,  232,  828,  514, 1496])]\n",
      "随机抽取: 4 [tensor([507, 849, 451, 523, 613]), tensor([1014, 1698,  902, 1046, 1226])]\n",
      "随机抽取: 5 [tensor([422, 488, 671, 974, 195]), tensor([ 844,  976, 1342, 1948,  390])]\n",
      "随机抽取: 6 [tensor([258, 848, 583, 454, 328]), tensor([ 516, 1696, 1166,  908,  656])]\n",
      "随机抽取: 7 [tensor([ 73, 920, 288, 245, 486]), tensor([ 146, 1840,  576,  490,  972])]\n",
      "随机抽取: 8 [tensor([792, 152, 462,  71, 190]), tensor([1584,  304,  924,  142,  380])]\n",
      "随机抽取: 9 [tensor([599, 133,  26, 979, 789]), tensor([1198,  266,   52, 1958, 1578])]\n",
      "随机抽取: 10 [tensor([983, 301, 228, 236, 447]), tensor([1966,  602,  456,  472,  894])]\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, batch in enumerate(train_iter): # 小批量的batch_size数据\n",
    "    if batch_idx == 10:\n",
    "        break\n",
    "    print('随机抽取:', batch_idx+1, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1. <a id='toc6_3_1_'></a>[估计数据加载时间](#toc0_)\n",
    "\n",
    "估计加载数据所需时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 0.08644580841064453 s\n"
     ]
    }
   ],
   "source": [
    "# 读完一个epoch的一个batch，耗时\n",
    "timer = cpuTimer()\n",
    "for X, y in train_iter:\n",
    "    break \n",
    "timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 0.2713015079498291 s\n"
     ]
    }
   ],
   "source": [
    "# 读完一个epoch的所有batch，耗时\n",
    "timer = cpuTimer()\n",
    "for X, y in train_iter:\n",
    "    continue \n",
    "timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. <a id='toc7_'></a>[张量(Tensors)](#toc0_)\n",
    "## 7.1. <a id='toc7_1_'></a>[Tensors定义](#toc0_)\n",
    "\n",
    "* Pytorch 的一大作用就是可以代替 Numpy 库，所以首先介绍 Tensors ，也就是张量，它相当于 Numpy 的多维数组(ndarrays)。\n",
    "\n",
    "* 两者的区别就是：\n",
    "    * `数学或物理`概念：张量`Tensors`\n",
    "    \n",
    "    * `编程`概念：数组`Array`\n",
    "    \n",
    "* 总结\n",
    "\n",
    "|函数名称|注释|\n",
    "|:-|:-|\n",
    "|torch.tensor()|tensor|\n",
    "|torch.asarray()||\n",
    "|torch.from_numpy()|numpy2tensor|\n",
    "|torch.empty(size)|垃圾数|\n",
    "|torch.zeros(size)|0|\n",
    "|torch.ones(size)|1|\n",
    "|torch.rand(size)|随机数|\n",
    "|torch.randn(size)|标准正态分布|\n",
    "|torch.normal(mean,std,size)|正态分布|\n",
    "|torch.arange(start,end,step,size)|数组|\n",
    "|.reshape(size)|重塑|\n",
    "|.numpy()|转为numpy的ndarray|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor()\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.asarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asarray()\n",
    "\n",
    "x = torch.asarray([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.from_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]]),\n",
       " tensor([[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy转tensor, from_numpy()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(0, 15).reshape(5, 3)\n",
    "\n",
    "x, torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 2.0114e-25],\n",
       "        [3.0742e-41, 1.3127e-29, 3.0742e-41],\n",
       "        [9.2368e-10, 4.5761e-41, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty()\n",
    "\n",
    "torch.empty((5, 3), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zeros()\n",
    "\n",
    "torch.zeros(5, 3) # 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.ones()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ones()\n",
    "\n",
    "torch.ones((5, 3), dtype=torch.float32) # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.rand()，产生随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8833, 0.0454, 0.5669],\n",
       "        [0.2422, 0.8501, 0.7177],\n",
       "        [0.5687, 0.7171, 0.8636],\n",
       "        [0.3550, 0.5657, 0.5965],\n",
       "        [0.4050, 0.6776, 0.9841]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rand()\n",
    "\n",
    "torch.rand((5, 3), dtype=torch.float32) # 随机数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.randn()，标准正态分布随机数，产生正态分布随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7855, -0.0245, -0.9618, -1.4634, -0.2726],\n",
       "        [ 1.1404, -0.9721,  0.4194,  0.1732, -1.2649],\n",
       "        [ 0.0139,  1.0817, -2.1748,  0.5782, -1.0274]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randn()\n",
    "\n",
    "torch.randn((3, 5), dtype=torch.float32) # 标准正态分布随机数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.normal()，正态分布随机数，产生mean和std的size个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4510,  0.2798, -0.8032, -0.5851,  0.7675],\n",
       "        [ 2.0413,  1.1163, -0.1891,  0.9543,  0.6753],\n",
       "        [ 1.4002,  0.8864,  0.6356, -1.2399,  1.1891]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=0, std=1, size=(3, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arange()\n",
    "\n",
    "torch.arange(3) # 0, 1, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape()\n",
    "\n",
    "torch.arange(start=0, end=15, step=1).reshape(5, 3) # reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .numpy()，将tensor转化为numpy的ndarray格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14]]),\n",
       " array([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]], dtype=int64))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor转化为numpy\n",
    "\n",
    "x = torch.arange(start=0, end=15, step=1).reshape(5, 3)\n",
    "x, x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. <a id='toc7_2_'></a>[Tensors属性](#toc0_)\n",
    "\n",
    "|函数名称|注释|\n",
    "|:-|:-|\n",
    "|x.size()||\n",
    "|x.shape()||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0123, -1.3446,  0.6211, -0.9366, -0.1685],\n",
       "        [-0.1473,  0.0577, -0.5306, -1.7354, -0.6717],\n",
       "        [-2.4554, -0.3991, -0.5653, -0.6845,  0.2150]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.normal(mean=0, std=1, size=(3, 5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size() # shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. <a id='toc7_3_'></a>[Tensors操作](#toc0_)\n",
    "### 7.3.1. <a id='toc7_3_1_'></a>[索引和切片](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(15).reshape(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # 1行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1] # 2行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  3,  6,  9, 12])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0] # 1列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  4,  7, 10, 13])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1] # 2列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2. <a id='toc7_3_2_'></a>[修改维度](#toc0_)\n",
    "\n",
    "* 形状/维度：其实整个张量运算就是线性代数中的矩阵运算，所以最重要是明白`矩阵运算前后`的`形状/维度`。  \n",
    "\n",
    "* 高阶张量由若干低阶张量构成，如\n",
    "    * 结构为 (n, c, h, w)的 4 阶张量由 n 个结构为 (c, h, w) 的 3 阶张量构成，\n",
    "    * 结构为 (c, h, w)的 3 阶张量由 c 个结构为 (h, w) 的 2 阶张量构成，\n",
    "    * 结构为 (h, w)的 2 阶张量又由 h 个长度为 w 的 1 阶张量构成，h 为行数，w 为列数。\n",
    "\n",
    "* 修改形状/维度：reshape和view都是用来重塑tensor的shape的。view只适合对满足连续性条件（contiguous）的tensor进行操作，而reshape同时还可以对不满足连续性条件的tensor进行操作，具有更好的鲁棒性。view能干的reshape都能干，如果view不能干就可以用reshape来处理。\n",
    "\n",
    "- 维度`重组`：\n",
    "\n",
    "    - `.reshape()`\n",
    "\n",
    "    - `.view()`\n",
    "\n",
    "- 维度重排或转换或`挪动`：\n",
    "\n",
    "    - `permute()`\n",
    "\n",
    "    - `transpose()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.1. <a id='toc7_3_2_1_'></a>[reshape函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       " torch.Size([15]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(15)\n",
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14]]),\n",
       " torch.Size([3, 5]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape\n",
    "\n",
    "X.reshape(3, 5), X.reshape(3, 5).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.2. <a id='toc7_3_2_2_'></a>[view函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14]]),\n",
       " torch.Size([3, 5]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view\n",
    "\n",
    "X.view(3, 5), X.view(3, 5).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.3. <a id='toc7_3_2_3_'></a>[transpose函数](#toc0_)\n",
    "\n",
    "`transpose()`函数一次进行两个维度的交换，参数是 0, 1, 2, 3, … ，随着待转换张量的阶数上升参数越来越多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14]]),\n",
       " tensor([[ 0,  5, 10],\n",
       "         [ 1,  6, 11],\n",
       "         [ 2,  7, 12],\n",
       "         [ 3,  8, 13],\n",
       "         [ 4,  9, 14]]),\n",
       " tensor([[ 0,  5, 10],\n",
       "         [ 1,  6, 11],\n",
       "         [ 2,  7, 12],\n",
       "         [ 3,  8, 13],\n",
       "         [ 4,  9, 14]]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 阶张量，结构为 (h, w)，\n",
    "# 对应 transpose() 函数中的参数是 (0, 1) 两个索引，\n",
    "# 进行 transpose(0, 1) 操作就是在交换 h, w 两个维度，\n",
    "# 得到的结果与常见的矩阵转置相同。\n",
    "X = torch.arange(15).reshape(3, 5)\n",
    "X, X.transpose(0, 1), X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.4. <a id='toc7_3_2_4_'></a>[permute函数](#toc0_)\n",
    "\n",
    "`permute()`函数一次可以进行多个维度的交换或者可以成为维度重新排列，参数是 0, 1, 2, 3, … ，随着待转换张量的阶数上升参数越来越多，本质上可以理解为多个 transpose() 操作的叠加，因此理解 permute() 函数的关键在于理解 transpose() 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14]]),\n",
       " tensor([[ 0,  5, 10],\n",
       "         [ 1,  6, 11],\n",
       "         [ 2,  7, 12],\n",
       "         [ 3,  8, 13],\n",
       "         [ 4,  9, 14]]),\n",
       " tensor([[ 0,  5, 10],\n",
       "         [ 1,  6, 11],\n",
       "         [ 2,  7, 12],\n",
       "         [ 3,  8, 13],\n",
       "         [ 4,  9, 14]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(15).reshape(3, 5)\n",
    "X, X.permute(1, 0), X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. <a id='toc7_4_'></a>[线性代数运算](#toc0_)\n",
    "PyTorch的运算很大一块是`线性代数运算-矩阵运算`，所以需要搞清楚每一步计算前后矩阵的`形状/维度`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1. <a id='toc7_4_1_'></a>[数值运算](#toc0_)\n",
    "\n",
    "- 自动做广播：\n",
    "    - x, y的size维度对应的维度数值必须为`无 (不是0)`或`1`，才能被广播。\n",
    "\n",
    "|操作|函数|\n",
    "|:-|:-|\n",
    "|+|torch.add(X, Y)|\n",
    "|-|torch.sub(X, Y)|\n",
    "|*|torch.mul(X, Y|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.],\n",
       "         [ 9., 10., 11.],\n",
       "         [12., 13., 14.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5, 3, dtype=torch.float32)\n",
    "y = torch.arange(0, 15, 1, dtype=torch.float32).reshape(5, 3)\n",
    "z = torch.arange(0, 15, 1, dtype=torch.float32).reshape(3, 5)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [10., 11., 12.],\n",
       "         [13., 14., 15.]]),\n",
       " tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [10., 11., 12.],\n",
       "         [13., 14., 15.]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y, torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2, 1, 1, 9, 9]),\n",
       " torch.Size([10, 1, 9, 9, 1, 1]),\n",
       " torch.Size([10, 2, 9, 9, 9, 9]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自动做广播 (很重要)\n",
    "# 两个tensor的维度数完全相同，但对应为维度数值不同时：\n",
    "# x或y中的一个必须是1，才能被自动做广播。\n",
    "x = torch.randn(size=(10, 2, 1, 1, 9, 9))   # 被自动广播成 (10, 2, 9, 9, 9, 9)\n",
    "y = torch.randn(size=(10, 1, 9, 9, 1, 1))   # 被自动广播成 (10, 2, 9, 9, 9, 9)\n",
    "x.size(), y.size(), (x+y).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2, 1, 1, 9, 9]),\n",
       " torch.Size([9, 1, 1]),\n",
       " torch.Size([10, 2, 1, 9, 9, 9]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自动做广播 (很重要)\n",
    "# 两个tensor的维度数不同，且对应为维度数值不同时：\n",
    "# x或y中的一个必须是1，才能被自动做广播，且\n",
    "# 短的维度会被自动广播成长的一样。\n",
    "x = torch.randn(size=(10, 2, 1, 1, 9, 9))   # 被自动广播成 (10, 2, 1, 9, 9, 9)\n",
    "y = torch.randn(size=(9, 1, 1))             # 被自动广播成 (10, 2, 1, 9, 9, 9)\n",
    "x.size(), y.size(), (x+y).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.,   0.,  -1.],\n",
       "         [ -2.,  -3.,  -4.],\n",
       "         [ -5.,  -6.,  -7.],\n",
       "         [ -8.,  -9., -10.],\n",
       "         [-11., -12., -13.]]),\n",
       " tensor([[  1.,   0.,  -1.],\n",
       "         [ -2.,  -3.,  -4.],\n",
       "         [ -5.,  -6.,  -7.],\n",
       "         [ -8.,  -9., -10.],\n",
       "         [-11., -12., -13.]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - y, torch.sub(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * 3 # 数乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(x, 3) # 同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x, z) # 矩阵相乘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2. <a id='toc7_4_2_'></a>[数值运算-乘法](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4.2.1. <a id='toc7_4_2_1_'></a>[哈达玛积](#toc0_)\n",
    "* 按照`元素`进行乘法\n",
    "* 乘前形状必须相同，乘后不改变形状\n",
    "* x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[ 0,  1,  4],\n",
       "         [ 9, 16, 25]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.arange(6).reshape(2, 3)\n",
    "x, x * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4.2.2. <a id='toc7_4_2_2_'></a>[点积（Dot Product）](#toc0_)\n",
    "* 按照元素进行乘法后相加\n",
    "* 乘前形状一样，乘后`标量`\n",
    "* `torch.dot(x, x)` # dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor([0, 1, 4]), tensor(5))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(3)\n",
    "x, x * x, torch.dot(x, x) # 打印， 哈德玛积， 点积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4.2.3. <a id='toc7_4_2_3_'></a>[矩阵-向量积](#toc0_)\n",
    "* 矩阵乘法的特殊\n",
    "* 乘后`向量`\n",
    "* `torch.mv(A, x)` # matrix-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([4]), torch.Size([3]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "x = torch.ones(4, dtype=torch.float32)\n",
    "A.shape, x.shape, torch.mv(A, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]),)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * x).shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4.2.4. <a id='toc7_4_2_4_'></a>[矩阵-矩阵积](#toc0_)\n",
    "* 乘后**矩阵**\n",
    "* `torch.matmul(X, Y)`  # 矩阵乘法，`支持广播`\n",
    "* `X @ Y`               # 同上\n",
    "* `torch.mm(X, Y)`      # 矩阵乘法，`不支持广播`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]),\n",
       " torch.Size([5, 3]),\n",
       " torch.Size([3, 3]),\n",
       " torch.Size([3, 3]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(15).reshape(3, 5)\n",
    "Y = torch.arange(15).reshape(5, 3)\n",
    "X.shape, Y.shape, (X @ Y).shape, torch.mm(X, Y).shape, torch.matmul(X, Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4.2.5. <a id='toc7_4_2_5_'></a>[批量矩阵乘法](#toc0_)\n",
    "\n",
    "* A: (b x n x m) \n",
    "* B: (b x m x p)\n",
    "* `torch.bmm(A, B)`   # b x n x p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3, 5]), torch.Size([3, 5, 3]), torch.Size([3, 3, 3]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(45).reshape(3, 3, 5)\n",
    "Y = torch.arange(45).reshape(3, 5, 3)\n",
    "X.shape, Y.shape, torch.bmm(X, Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4.2.6. <a id='toc7_4_2_6_'></a>[乘总结](#toc0_)\n",
    "\n",
    "参考PyTorch lightning 总结：[https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/01-introduction-to-pytorch.html](https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/01-introduction-to-pytorch.html)\n",
    "\n",
    "|乘法|函数|\n",
    "|:-|:-|\n",
    "|哈德玛积|A * B|\n",
    "|点积|dot(A, B)|\n",
    "|矩阵-向量|mv(A, x)|\n",
    "|矩阵-矩阵|matmul(A, B) 或  A @ B，同时mm(A, B)不支持广播|\n",
    "|批量矩阵乘法|`bmm(A, B)`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3. <a id='toc7_4_3_'></a>[统计运算](#toc0_)\n",
    "\n",
    "|操作|注释|\n",
    "|:-|:-|\n",
    "|torch.mean()|取平均|\n",
    "|torch.median()||\n",
    "|torch.mode()||\n",
    "|torch.min()||\n",
    "|torch.max()||\n",
    "|torch.std()||\n",
    "|torch.var()||\n",
    "|torch.squar()||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(15, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.), tensor(7.))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x), x.mean() # 平均数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.), tensor(7.))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.median(x), x.median() # 中位数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x), x.min()   # 最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14.), tensor(14.))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), x.max()   # 最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.mode(\n",
       " values=tensor(0.),\n",
       " indices=tensor(0)),\n",
       " torch.return_types.mode(\n",
       " values=tensor(0.),\n",
       " indices=tensor(0)))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mode(x), x.mode() # 众数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.4721), tensor(4.4721))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(x), x.std()   # 标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(20.), tensor(20.))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.var(x), x.var()   # 方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. <a id='toc7_5_'></a>[Pytorch的计算图 和 自动微分 (autograd)](#toc0_)\n",
    "\n",
    "- PyTorch是动态图，即计算图的搭建和运算是同时的，随时可以输出结果；而TensorFlow是静态图。\n",
    "\n",
    "- 在pytorch的计算图里只有两种元素：`数据（tensor）`和 `运算（operation）`\n",
    "\n",
    "  - 运算包括了：加减乘除、开方、幂指对、三角函数等可求导运算\n",
    "\n",
    "  - 数据可分为：`叶子节点（leaf node`）和`非叶子节点`；\n",
    "    - 叶子节点：\n",
    "    - 非叶子节点：\n",
    "    - 叶子节点是用户创建的节点，不依赖其它节点；它们表现出来的区别在于`用y.backward()进行反向传播`结束之后，`非叶子节点的梯度会被释放掉`，只保留叶子节点的梯度，这样就节省了内存。如果想要保留非叶子节点的梯度，可以使用`retain_grad()`方法。\n",
    "\n",
    "- torch.tensor节点 具有如下属性：\n",
    "  - 查看 是否可以求导 `requires_grad`\n",
    "  - 查看 运算名称 `grad_fn`\n",
    "  - 查看 是否为叶子节点 `is_leaf`\n",
    "  - 查看 导数值 `grad`\n",
    "\n",
    "- 针对requires_grad属性，自己定义的叶子节点默认为False，而非叶子节点默认为True，神经网络中的权重默认为True。判断哪些节点是True/False的一个原则就是从你需要求导的叶子节点到loss节点之间是一条可求导的通路。\n",
    "\n",
    "---\n",
    "\n",
    "- PyTorch提供两种求梯度的方法：`backward()` 和 `torch.autograd.grad()` ，他们的区别在于前者是给叶子节点填充.grad字段，而后者是直接返回梯度给你，我会在后面举例说明。还需要知道y.backward()其实等同于`torch.autograd.backward(y)`。\n",
    "\n",
    "\n",
    "![PyTorch的计算图](./Pytorch_Pictures/PyTorch_graphacial_demo/graph.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.1. <a id='toc7_5_1_'></a>[反向传播 (backward)-批量求梯度，但未进行参数更新](#toc0_)\n",
    "\n",
    "计算`所有节点 (Tensor)` 的梯度并存储在节点的`grad属性中`，但未进行节点参数更新 (是优化函数干的事)。\n",
    "\n",
    "- `y.backward()` 或 `torch.autograd.backward(y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]], requires_grad=True),\n",
       " tensor([[ 1.1690,  1.1080, -1.3046, -0.0044, -1.4428],\n",
       "         [ 0.9029, -1.0754,  0.1783, -0.5008, -0.0571],\n",
       "         [ 1.5950, -0.4997, -0.5458,  0.8798, -0.9804]], requires_grad=True),\n",
       " tensor(15.6153, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.ones(size=(3, 5), dtype=torch.float32, requires_grad=True)       # 自定义需要存储梯度\n",
    "x2 = torch.randn(size=(3, 5), dtype=torch.float32, requires_grad=True)      # 默认是不存储梯度\n",
    "\n",
    "y = torch.add(x1**2, x2**3).sum()   # 应变量必须是标量\n",
    "\n",
    "x1, x2, y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 查看is_leaf属性\n",
    "x1.is_leaf, x2.is_leaf, y.is_leaf   \n",
    "# x1, x2是叶子节点，y不是叶子节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 查看requires_grad属性\n",
    "x1.requires_grad, x2.requires_grad, y.requires_grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, <SumBackward0 at 0x7fce06bff0d0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 查看grad_fn属性\n",
    "x1.grad_fn, x2.grad_fn, y.grad_fn   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32820/1085795512.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538439675/work/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  x1.grad, x2.grad, y.grad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 查看grad属性\n",
    "x1.grad, x2.grad, y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()\n",
    "# torch.autograd.backward(y)  # 同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32820/1085795512.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538439675/work/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  x1.grad, x2.grad, y.grad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]]),\n",
       " tensor([[4.0998e+00, 3.6832e+00, 5.1059e+00, 5.9216e-05, 6.2451e+00],\n",
       "         [2.4456e+00, 3.4693e+00, 9.5398e-02, 7.5255e-01, 9.7835e-03],\n",
       "         [7.6321e+00, 7.4899e-01, 8.9373e-01, 2.3219e+00, 2.8837e+00]]),\n",
       " None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 查看grad属性\n",
    "x1.grad, x2.grad, y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.2. <a id='toc7_5_2_'></a>[仅计算梯度 (求导计算)](#toc0_)\n",
    "\n",
    "和backward不同，torch.autograd.grad只是计算`应变量 (output)` 对`自变量 (input)`的`导数 (梯度)`；`应变量必须是标量`。\n",
    "\n",
    "- `torch.autograd.grad(output=y, input=x, retain_grad=False/True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.]],\n",
       " \n",
       "         [[3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.]],\n",
       " \n",
       "         [[3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3., 3.]]]),)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(size=(3, 3, 5), dtype=torch.float32, requires_grad=True) # 必须是float类型\n",
    "y = (x**3).sum()\n",
    "torch.autograd.grad(outputs=y, inputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6. <a id='toc7_6_'></a>[自动微积-autograd](#toc0_)\n",
    "```shell\n",
    "深度学习框架可以自动计算导数：\n",
    "```\n",
    "|操作|函数|\n",
    "|:-|:-|\n",
    "|1. 我们首先将梯度附加到想要对其计算偏导数的变量上，|x.requires_grad_(True)|\n",
    "|2. 然后记录目标值的计算，|y = x * x (grad_fn)|\n",
    "|3. 执行它的反向传播函数(求梯度)，|y.backward()|\n",
    "|4. 并访得到的梯度。|x.grad|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1. <a id='toc7_6_1_'></a>[自己探索](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6.1.1. <a id='toc7_6_1_1_'></a>[标量-一阶导数（得标量）](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2., requires_grad=True), tensor(4., grad_fn=<PowBackward0>))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2.0, dtype=torch.float32, requires_grad=True)  # 标量\n",
    "y = x**2                                                        # 标量\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为None\n",
    "x.grad, x.grad == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y对x进行求导\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为2 * 2 = 4\n",
    "x.grad                                                          # 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 2*x # y关于x的一阶导函数就是2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造新的关于x的函数：z = x**3\n",
    "z = x**2\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为：\n",
    "x.grad.zero_()\n",
    "x.grad # 应该为0才对，需要手动清零# x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z关于x求导\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为：\n",
    "x.grad # 应该为4，但是残留的4 + 本次的4 = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6.1.2. <a id='toc7_6_1_2_'></a>[标量/向量-一阶导数（得向量）](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0, dtype=torch.float32, requires_grad=True)  # 向量\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14., grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.dot(x, x)                                              # 标量\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad                                                          # 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 2*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6.1.3. <a id='toc7_6_1_3_'></a>[向量/向量-一阶导数（得矩阵）](#toc0_)\n",
    "\n",
    "- pytorch只能对标量/标量，标量/向量求导，`即x可以为标量也可以为向量，但是y必须为标量`\n",
    "\n",
    "- `只需要先将y转变为标量，对分别求导没影响的就是求和`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.arange(4, dtype=torch.float32, requires_grad=True)    # 向量\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = i ** 2                                                      # 向量\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h.backward()      # 报错\n",
    "h.sum().backward()  # 正常\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6.1.4. <a id='toc7_6_1_4_'></a>[求高阶导数](#toc0_)\n",
    "\n",
    "- 利用`torch.autograd.grad(outputs=y, inputs=x, create_grad=True)`\n",
    "\n",
    "- 保留计算图 (链表指针), `create_grad=True `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(12., grad_fn=<MulBackward0>),)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2, dtype=torch.float32, requires_grad=True)\n",
    "y = x**3\n",
    "grad1 = torch.autograd.grad(outputs=y, inputs=x, create_graph=True) # create_graph=True, 必须保留计算图才能进行后续的高阶导数计算\n",
    "grad1 # 3 * x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(12., grad_fn=<MulBackward0>),)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad2 = torch.autograd.grad(outputs=grad1, inputs=x, create_graph=True)\n",
    "grad2 # 6 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.),)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad3 = torch.autograd.grad(outputs=grad2, inputs=x)\n",
    "grad3 # 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2. <a id='toc7_6_2_'></a>[一个简单的例子](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在我们计算关于的梯度之前，需要一个地方来存储梯度。\n",
    "x.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)\n",
    "x.grad                  # 默认值是None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在计算。\n",
    "y = 2 * torch.dot(x, x)\n",
    "y                       # x是一个长度为4的向量，计算x和x的点积，得到了我们赋值给y的标量输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 接下来，通过调用反向传播函数来自动计算y关于x每个分量的梯度，并打印这些梯度。\n",
    "y.backward()            # [4x, 4x, 4x, 4x] 导函数\n",
    "x.grad                  # [4*0, 4*1, 4*2, 4*3] 导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x         # [4x, 4x, 4x, 4x] 导函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.3. <a id='toc7_6_3_'></a>[计算另一个](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值\n",
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor(6., grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.4. <a id='toc7_6_4_'></a>[非标量变量的反向传播](#toc0_)\n",
    "\n",
    "- 当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵。 \n",
    "\n",
    "- 对于高阶和高维的y和x，求导的结果可以是一个高阶张量。\n",
    "\n",
    "- 然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括深度学习中）， 但当调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的**偏导数之和**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n",
    "# 本例只想求偏导数的和，所以传递一个1的梯度是合适的\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "# 等价于y.backward(torch.ones(len(x)))\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x * x \n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0.]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad, x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([0., 2., 4., 6.]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum().backward(), x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.5. <a id='toc7_6_5_'></a>[分离计算](#toc0_)\n",
    "\n",
    "- 有时，我们希望将某些计算移动到记录的计算图之外。 例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。 想象一下，我们想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数， 并且只考虑到x在y被计算后发挥的作用。\n",
    "\n",
    "- 这里可以分离y来返回一个新变量u，该变量与y具有相同的值， 但丢弃计算图中如何计算y的任何信息。 换句话说，梯度不会向后流经u到x。 因此，下面的反向传播函数计算z=u*x关于x的偏导数，同时将u作为常数处理， 而不是z=x*x*x关于x的偏导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x\n",
    "u = y.detach()\n",
    "z = u * x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由于记录了y的计算结果，我们可以随后在y上调用反向传播， 得到y=x*x关于的x的导数，即2*x。\n",
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.6. <a id='toc7_6_6_'></a>[Python控制流的梯度计算](#toc0_)\n",
    "\n",
    "- 使用自动微分的一个好处是： 即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度。 在下面的代码中，while循环的迭代次数和if语句的结果都取决于输入a的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让我们计算梯度。\n",
    "a = torch.randn(size=(), requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们现在可以分析上面定义的f函数。 请注意，它在其输入a中是分段线性的。 换言之，对于任何a，存在某个常量标量k，使得f(a)=k*a，其中k的值取决于输入a，因此可以用d/a验证梯度是否正确。\n",
    "a.grad == d / a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7. <a id='toc7_7_'></a>[概率论](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 正太函数分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7607, -0.3525, -0.6538,  0.3404, -1.0323, -0.4394,  0.0676,  0.7667,\n",
      "         1.7211, -0.0475, -1.1181,  0.7353, -1.7605,  1.4901, -0.9803,  0.8902,\n",
      "        -0.0931, -1.7484,  2.3997,  0.6524,  0.6782, -1.1440, -1.3923,  0.1212,\n",
      "        -1.0076, -1.7668, -1.4322, -0.6901,  0.2830,  0.5470,  1.4634,  0.6256,\n",
      "         1.2161, -1.3545, -1.2281, -0.6693,  0.2557,  0.2750, -0.1981,  0.4620,\n",
      "         0.5137, -0.3635,  0.7580,  0.6187, -2.0609, -1.9659, -0.0752,  0.7554,\n",
      "        -0.6792, -1.2573, -0.1298, -0.4564,  0.3095,  1.2856, -0.7012,  0.5607,\n",
      "        -1.0115,  1.1368,  1.0839,  1.5874, -1.1725,  0.8335, -1.8986,  1.1627,\n",
      "         1.5963, -1.7788,  1.4887,  2.6236,  0.0521, -0.5584, -1.2956, -1.0912,\n",
      "         1.0101,  0.6228,  0.3619,  1.4112,  0.1833,  0.4523, -0.5056,  0.2020,\n",
      "         1.4686,  1.8315, -0.8283,  0.6796, -0.1077,  0.0794, -0.2321,  1.2689,\n",
      "        -0.5188,  0.6315,  1.2953, -0.0427,  0.0622, -0.6244, -0.6351, -1.3894,\n",
      "         0.1629, -0.7895, -0.0437,  1.6747])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f350d9c5df0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cpu'\n",
    "data = torch.normal(mean=0, std=1, size=(100,), dtype=torch.float32, device=device)\n",
    "print(data)\n",
    "plt.figure()\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. <a id='toc8_'></a>[神经网络-训练八股](#toc0_)\n",
    "\n",
    "|步骤|计算|操作|\n",
    "|:-|:-|:-|\n",
    "|1|定义网络模型|->计算出`y_hat`|\n",
    "|2|选择损失函数|->计算`loss值`、求梯度|\n",
    "|3|选择优化器|->`更新`网络权重参数|\n",
    "|4|训练|->实施1、2、3|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. <a id='toc8_1_'></a>[现线性回归模型于训练过程-从零开始](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1. <a id='toc8_1_1_'></a>[虚拟出数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([1.6710, 0.3170])\n",
      "label: tensor([6.4774])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import random\n",
    "\n",
    "def synthetic_data(w, b, num_examples):  \n",
    "    \"\"\"生成y=Xw+b+噪声\"\"\"\n",
    "    X = torch.normal(mean=0, std=1, size=(num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(mean=0, std=0.01, size=y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "\n",
    "print('features:', features[0])\n",
    "print('label:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"231.442187pt\" height=\"169.678125pt\" viewBox=\"0 0 231.442187 169.678125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-05-18T15:08:53.316260</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 169.678125 \n",
       "L 231.442187 169.678125 \n",
       "L 231.442187 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "L 28.942188 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"m18bb6ce550\" d=\"M 0 0.5 \n",
       "C 0.132602 0.5 0.25979 0.447317 0.353553 0.353553 \n",
       "C 0.447317 0.25979 0.5 0.132602 0.5 0 \n",
       "C 0.5 -0.132602 0.447317 -0.25979 0.353553 -0.353553 \n",
       "C 0.25979 -0.447317 0.132602 -0.5 0 -0.5 \n",
       "C -0.132602 -0.5 -0.25979 -0.447317 -0.353553 -0.353553 \n",
       "C -0.447317 -0.25979 -0.5 -0.132602 -0.5 0 \n",
       "C -0.5 0.132602 -0.447317 0.25979 -0.353553 0.353553 \n",
       "C -0.25979 0.447317 -0.132602 0.5 0 0.5 \n",
       "z\n",
       "\" style=\"stroke: #1f77b4\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p149bb96678)\">\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.095479\" y=\"47.161377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.851713\" y=\"83.62544\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.208597\" y=\"87.238868\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"87.729918\" y=\"40.397538\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.573273\" y=\"74.594754\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.717888\" y=\"60.945456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.324851\" y=\"78.7769\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.745046\" y=\"79.445989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.425785\" y=\"38.908429\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.929806\" y=\"116.402206\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.433764\" y=\"88.486938\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.993977\" y=\"81.085971\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.88151\" y=\"87.997522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.448528\" y=\"88.393808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.731191\" y=\"76.554431\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.365738\" y=\"73.519191\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.023584\" y=\"74.321666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.343054\" y=\"93.603985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.480389\" y=\"88.551763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"82.783874\" y=\"35.366294\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.40635\" y=\"58.043827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.163633\" y=\"103.28369\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.402431\" y=\"57.861658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.67707\" y=\"81.847122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.810681\" y=\"77.415171\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.459828\" y=\"90.031881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"74.291277\" y=\"35.628451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.353451\" y=\"92.726373\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.567219\" y=\"65.921645\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.252503\" y=\"67.827082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.357592\" y=\"73.868138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.556005\" y=\"81.497491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.588391\" y=\"57.255578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.873451\" y=\"56.665809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.53247\" y=\"72.549742\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.363962\" y=\"85.38564\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.858176\" y=\"58.074153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.627228\" y=\"51.205587\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.274568\" y=\"46.708364\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.191399\" y=\"111.673949\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.057851\" y=\"75.989104\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.467418\" y=\"67.739194\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.631192\" y=\"59.798297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.163912\" y=\"74.989388\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.397586\" y=\"59.375105\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.25971\" y=\"59.267597\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.847122\" y=\"93.854999\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.1543\" y=\"71.690158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.433433\" y=\"87.617628\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.147698\" y=\"63.623364\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.640488\" y=\"73.829216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.738102\" y=\"89.36582\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.302647\" y=\"94.878713\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.085924\" y=\"98.631002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.452017\" y=\"69.606532\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.770517\" y=\"77.322051\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.949251\" y=\"72.458828\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"75.617311\" y=\"44.551745\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.242985\" y=\"71.231531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.456331\" y=\"87.507944\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.942623\" y=\"89.154946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"172.84967\" y=\"115.023299\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.293778\" y=\"57.941606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.996861\" y=\"64.990028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.079155\" y=\"124.951583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.600268\" y=\"47.266292\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.097375\" y=\"82.798065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"171.793196\" y=\"84.905216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.647189\" y=\"63.342156\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.612985\" y=\"71.311502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.608414\" y=\"71.440978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.656532\" y=\"109.509315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.409678\" y=\"76.930463\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.748237\" y=\"81.979596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.86734\" y=\"45.388764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.971797\" y=\"96.679841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.111144\" y=\"39.170635\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"172.522205\" y=\"104.843924\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"215.364915\" y=\"136.669454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.039242\" y=\"64.485384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.026192\" y=\"92.242205\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"87.829908\" y=\"58.495525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.715044\" y=\"43.485036\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.536737\" y=\"66.785002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.411851\" y=\"75.943248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.084039\" y=\"105.039855\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.865947\" y=\"90.586554\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.345475\" y=\"70.239975\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.715025\" y=\"86.234712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.761775\" y=\"72.272405\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"90.937862\" y=\"42.120415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"108.620502\" y=\"52.733002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.71258\" y=\"91.534395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.038561\" y=\"78.277075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.303632\" y=\"80.007046\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.680851\" y=\"123.495815\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.102381\" y=\"87.647679\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.983381\" y=\"68.147087\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.287017\" y=\"77.973753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.728341\" y=\"102.953634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.255003\" y=\"48.117778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.176357\" y=\"79.685957\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.072006\" y=\"105.065753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.081318\" y=\"94.163776\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.789688\" y=\"39.249632\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.093641\" y=\"94.996263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"179.020821\" y=\"110.657126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.413335\" y=\"56.029453\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.839972\" y=\"95.454916\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.064537\" y=\"95.256836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.861671\" y=\"79.859375\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.424467\" y=\"86.897922\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.523298\" y=\"94.19315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"174.220273\" y=\"100.574648\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.411392\" y=\"95.633883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"99.245321\" y=\"77.128793\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.974341\" y=\"42.823713\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.346943\" y=\"71.69238\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.730968\" y=\"43.229075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.599003\" y=\"84.788153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.921167\" y=\"72.66032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"87.318025\" y=\"58.450722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"194.960884\" y=\"131.832798\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.851446\" y=\"54.265354\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.738185\" y=\"79.788226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.232769\" y=\"39.581108\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.609002\" y=\"74.271061\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.604959\" y=\"96.641912\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.290707\" y=\"95.322537\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"86.920401\" y=\"37.140992\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.569027\" y=\"88.381482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.631163\" y=\"82.87251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.473124\" y=\"114.644034\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.089957\" y=\"81.887664\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"171.2269\" y=\"110.831563\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.389193\" y=\"79.688158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.145673\" y=\"72.500684\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.439791\" y=\"64.647256\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.448923\" y=\"83.772278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.538471\" y=\"126.892836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.310948\" y=\"52.077508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.07802\" y=\"71.031701\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.269235\" y=\"77.309642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.764291\" y=\"95.714536\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.771941\" y=\"78.662995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"88.05873\" y=\"52.853989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.825865\" y=\"85.024525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.04984\" y=\"65.790707\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.985694\" y=\"73.972357\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.372596\" y=\"73.366803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"179.97065\" y=\"103.786181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.344855\" y=\"70.019699\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"93.447802\" y=\"46.796222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.990588\" y=\"71.131398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.143886\" y=\"67.727624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.66859\" y=\"87.823199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.899883\" y=\"74.458643\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.576442\" y=\"119.338468\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.434056\" y=\"65.114343\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.373461\" y=\"90.545777\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"74.95746\" y=\"32.072086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.379211\" y=\"89.646188\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"179.659058\" y=\"131.976622\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.916788\" y=\"37.519916\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.311539\" y=\"68.471924\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.407896\" y=\"58.213502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.98083\" y=\"67.209455\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.578836\" y=\"83.648026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.530611\" y=\"81.247013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.676106\" y=\"78.386436\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"188.590076\" y=\"110.099002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.701229\" y=\"79.870857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.85927\" y=\"86.82456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.10514\" y=\"55.800128\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.751938\" y=\"95.543365\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.73323\" y=\"80.716385\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"97.229499\" y=\"49.869361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.169676\" y=\"78.313592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"181.657673\" y=\"108.965791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.523107\" y=\"89.407648\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.105095\" y=\"102.732158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"168.184204\" y=\"130.289923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.883837\" y=\"77.297087\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.828564\" y=\"77.985982\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.511402\" y=\"86.539024\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.205736\" y=\"88.497173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.420465\" y=\"82.445164\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.183605\" y=\"100.566278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.508009\" y=\"78.2606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.071365\" y=\"104.95213\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.33869\" y=\"90.006435\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.497756\" y=\"66.676858\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.538572\" y=\"44.376892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.319541\" y=\"50.800963\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.013391\" y=\"73.130755\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.436765\" y=\"90.054365\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.851902\" y=\"88.832337\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.298429\" y=\"109.265351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.81924\" y=\"105.520126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"99.125532\" y=\"45.042519\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.520817\" y=\"71.352702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.616857\" y=\"87.712444\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.361615\" y=\"93.431903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.955365\" y=\"115.084394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.302701\" y=\"65.664837\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.00782\" y=\"41.543072\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.22642\" y=\"65.483171\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.02213\" y=\"73.541159\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.117686\" y=\"107.280884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.369294\" y=\"81.808232\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.787771\" y=\"92.773059\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.140729\" y=\"110.615348\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.002826\" y=\"87.620506\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.425689\" y=\"95.841866\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.446106\" y=\"67.122825\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.509686\" y=\"77.513579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.088532\" y=\"65.123268\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"172.731574\" y=\"108.43805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.832592\" y=\"59.570065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.975699\" y=\"71.318317\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.907336\" y=\"103.523987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"92.159527\" y=\"43.963427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.55038\" y=\"71.800816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"86.639005\" y=\"50.486663\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.806314\" y=\"80.491925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.015768\" y=\"101.020893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.847569\" y=\"103.960201\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.777105\" y=\"64.961187\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"178.333764\" y=\"108.101154\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.172839\" y=\"71.272436\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"86.066135\" y=\"54.533553\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.714613\" y=\"77.715356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.050538\" y=\"85.805685\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.294464\" y=\"84.457284\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.123238\" y=\"110.462091\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.150669\" y=\"40.894705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.184716\" y=\"69.718393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.640153\" y=\"99.022385\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"103.863809\" y=\"47.724193\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.626844\" y=\"94.62609\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.241278\" y=\"69.007238\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"178.5462\" y=\"115.545579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.599468\" y=\"50.701739\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.598236\" y=\"93.231596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.028281\" y=\"48.494835\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.972378\" y=\"60.52896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"175.093025\" y=\"115.579612\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.674163\" y=\"57.422106\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"81.816997\" y=\"48.033332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.268201\" y=\"92.460497\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.982868\" y=\"94.537197\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"166.366972\" y=\"105.885217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.981166\" y=\"89.998881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.909952\" y=\"57.369795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.800072\" y=\"109.391435\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.3025\" y=\"68.146646\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.112621\" y=\"77.863288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.019004\" y=\"82.309716\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.437598\" y=\"64.998791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.85551\" y=\"62.189196\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.337286\" y=\"90.072432\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.260642\" y=\"75.777629\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.736644\" y=\"88.600963\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.817745\" y=\"62.371521\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.558975\" y=\"81.635209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.054067\" y=\"54.280767\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.664876\" y=\"73.743823\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.419599\" y=\"70.005569\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.615409\" y=\"67.434763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.973077\" y=\"76.827061\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.851912\" y=\"83.246127\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.465775\" y=\"62.814925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.69414\" y=\"82.432944\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.5567\" y=\"66.571063\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.865298\" y=\"61.460029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.895165\" y=\"84.160395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.69307\" y=\"68.818434\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.775156\" y=\"52.552853\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.131616\" y=\"95.612473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.314575\" y=\"60.307027\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.398024\" y=\"65.64585\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.260952\" y=\"90.950681\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.303587\" y=\"67.75297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.26854\" y=\"53.050234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"184.810641\" y=\"106.433803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.187906\" y=\"49.907413\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.298809\" y=\"81.185502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.691714\" y=\"64.86224\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.551724\" y=\"63.739985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"190.442405\" y=\"101.59375\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"168.636939\" y=\"110.318736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"189.434988\" y=\"122.525807\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"83.010608\" y=\"38.326326\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.135154\" y=\"91.321178\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.262778\" y=\"77.393835\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.275451\" y=\"49.56985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.832572\" y=\"85.533263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.746231\" y=\"72.671207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.820777\" y=\"99.386596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.683545\" y=\"67.775845\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.196624\" y=\"74.056585\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.203098\" y=\"75.661508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.907138\" y=\"61.146314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.719176\" y=\"105.44496\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"90.349765\" y=\"37.429393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.196461\" y=\"78.800497\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.30426\" y=\"76.243697\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.995264\" y=\"65.434945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.206289\" y=\"95.744662\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.555366\" y=\"60.535636\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.926729\" y=\"87.970989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.454368\" y=\"86.192893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.242903\" y=\"57.788411\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.740043\" y=\"75.358756\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.248791\" y=\"35.551553\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.69951\" y=\"78.30334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.329754\" y=\"64.711556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.247098\" y=\"101.88973\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.406229\" y=\"97.819789\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.031335\" y=\"88.734081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.843379\" y=\"45.330227\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.434758\" y=\"44.209348\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.13027\" y=\"76.632356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.58724\" y=\"108.769978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.484005\" y=\"100.102314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.946035\" y=\"88.620482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.437023\" y=\"96.788656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.015895\" y=\"60.901465\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.169374\" y=\"93.607883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.803278\" y=\"74.933473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.571926\" y=\"82.22746\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.47718\" y=\"95.62631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.262069\" y=\"60.61157\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.718515\" y=\"81.496522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"92.181732\" y=\"41.516842\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.331169\" y=\"88.36295\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.890814\" y=\"70.030588\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.969004\" y=\"78.772412\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.483839\" y=\"69.940603\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.305641\" y=\"72.17007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.064401\" y=\"108.453568\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.168083\" y=\"66.977319\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"186.070028\" y=\"121.685772\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.440592\" y=\"96.364357\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.615906\" y=\"83.36262\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.334251\" y=\"77.685671\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.832708\" y=\"77.021255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.584402\" y=\"81.933449\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.030805\" y=\"56.89179\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"169.2568\" y=\"109.930138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"81.284677\" y=\"46.477058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.833589\" y=\"107.725896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.628025\" y=\"95.836344\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.51822\" y=\"25.80849\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.05078\" y=\"83.93642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.24022\" y=\"41.798879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"176.812922\" y=\"100.699816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"206.112711\" y=\"132.059178\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.459017\" y=\"61.119264\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"166.340598\" y=\"102.003628\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.568646\" y=\"90.938355\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"178.466042\" y=\"135.076353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.576191\" y=\"89.697253\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.493513\" y=\"84.102082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.957632\" y=\"70.643879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.199816\" y=\"77.271077\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"175.249178\" y=\"118.26173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.033036\" y=\"100.42625\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.798255\" y=\"85.449113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.32953\" y=\"91.51232\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.504324\" y=\"98.445219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.286187\" y=\"69.827219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.735623\" y=\"96.551888\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.230718\" y=\"69.991721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.659505\" y=\"77.144345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.011388\" y=\"53.943991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"97.674035\" y=\"42.491325\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.566322\" y=\"71.860096\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.753018\" y=\"71.452624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.905282\" y=\"87.64505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.361549\" y=\"59.370096\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.572454\" y=\"71.761607\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"97.975877\" y=\"59.617879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.789529\" y=\"76.742222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.474806\" y=\"104.341687\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.264875\" y=\"68.026442\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.512114\" y=\"87.193492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.937993\" y=\"69.71948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"108.383548\" y=\"45.774082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.136088\" y=\"64.811021\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.571522\" y=\"54.048753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.810063\" y=\"47.273691\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.294015\" y=\"79.306596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.120782\" y=\"90.852565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.06859\" y=\"66.468719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.146701\" y=\"63.262394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.221559\" y=\"65.665216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.708983\" y=\"89.563288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.273493\" y=\"66.439287\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.837173\" y=\"83.170556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.803884\" y=\"65.386806\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.632525\" y=\"94.60237\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.695338\" y=\"77.253336\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.70951\" y=\"40.351655\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.687648\" y=\"79.915883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"88.793452\" y=\"52.793148\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.863376\" y=\"74.635042\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.501331\" y=\"91.09296\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.99569\" y=\"73.305529\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.416351\" y=\"88.123721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.367629\" y=\"93.357726\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.029471\" y=\"96.797956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.194088\" y=\"101.376634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.180676\" y=\"59.779791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.57167\" y=\"83.17462\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.986711\" y=\"58.26251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.046832\" y=\"93.280006\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.214217\" y=\"89.448882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.969972\" y=\"92.86561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.20047\" y=\"76.563584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.767122\" y=\"73.075454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.681444\" y=\"59.21978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.292355\" y=\"66.063946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.960186\" y=\"93.067459\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.53253\" y=\"74.32969\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"177.84401\" y=\"120.319759\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.647964\" y=\"89.083226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"75.729887\" y=\"21.716144\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.927387\" y=\"67.650078\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.175365\" y=\"65.223208\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.556223\" y=\"97.346334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.029483\" y=\"110.278113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"92.402947\" y=\"55.04702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"88.987071\" y=\"36.320377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.230393\" y=\"66.727421\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.536374\" y=\"54.699249\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.740495\" y=\"68.524397\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"68.20164\" y=\"18.152251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.864201\" y=\"96.415787\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"103.393444\" y=\"53.098791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.272119\" y=\"55.945706\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.119748\" y=\"67.417656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.167812\" y=\"50.437323\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.387767\" y=\"53.971836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.477571\" y=\"60.758656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.02508\" y=\"108.205526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.285307\" y=\"67.258656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.331823\" y=\"82.418834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.486232\" y=\"77.876968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.91161\" y=\"82.143424\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.717006\" y=\"57.152768\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.891315\" y=\"94.68598\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.848712\" y=\"112.619282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.33896\" y=\"84.338058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"169.909578\" y=\"105.269701\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.05359\" y=\"90.123526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.726965\" y=\"103.768415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.333197\" y=\"90.380013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.915242\" y=\"55.457805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.672469\" y=\"80.84138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.840902\" y=\"70.947599\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.958121\" y=\"23.162991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.110344\" y=\"77.873558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.218008\" y=\"105.443857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.779349\" y=\"91.711486\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.503636\" y=\"44.255994\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.471323\" y=\"95.849579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.37937\" y=\"83.283928\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.675286\" y=\"47.93496\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"76.540277\" y=\"41.384245\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.953678\" y=\"78.467352\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"99.887518\" y=\"50.069211\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.066197\" y=\"94.835505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.852849\" y=\"108.472892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.112367\" y=\"104.72846\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.869502\" y=\"106.281367\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.342459\" y=\"51.793366\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.511957\" y=\"70.717656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.192634\" y=\"98.065695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.357245\" y=\"93.409271\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.565301\" y=\"91.783085\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.027944\" y=\"60.077816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.546238\" y=\"51.08775\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.902369\" y=\"70.340151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.13645\" y=\"64.663011\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.119843\" y=\"55.93901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.90781\" y=\"54.780247\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.844246\" y=\"88.241005\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.684121\" y=\"81.15877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.593471\" y=\"81.571363\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.760849\" y=\"62.661631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.407119\" y=\"69.693332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.228326\" y=\"74.384589\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.196136\" y=\"98.598832\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"97.523503\" y=\"66.33793\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"206.761358\" y=\"125.79795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.095197\" y=\"98.4751\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.539013\" y=\"64.56139\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.164185\" y=\"81.606658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.702628\" y=\"98.219326\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.258917\" y=\"94.831201\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.037722\" y=\"104.699339\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.170226\" y=\"89.41371\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.059483\" y=\"72.784708\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.702482\" y=\"87.411776\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"88.989185\" y=\"52.687565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"87.075942\" y=\"50.725829\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.970726\" y=\"65.130989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.883673\" y=\"63.986565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.96272\" y=\"80.834248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.150811\" y=\"81.052541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.807994\" y=\"68.298331\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.10131\" y=\"63.476082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.210835\" y=\"84.375522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.352392\" y=\"73.802402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.34687\" y=\"91.968214\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"103.696498\" y=\"35.232469\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.963518\" y=\"78.597462\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.385956\" y=\"70.788778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.184783\" y=\"59.685314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.853204\" y=\"90.993283\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.690509\" y=\"129.760231\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.434951\" y=\"95.79107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.306675\" y=\"49.856484\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.074512\" y=\"86.650945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.928025\" y=\"84.532026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.962191\" y=\"63.882353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.203076\" y=\"56.071804\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.794781\" y=\"91.749217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.275888\" y=\"88.082351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.2505\" y=\"105.130473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.045802\" y=\"51.890282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.08613\" y=\"58.570508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.192583\" y=\"59.913878\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.382741\" y=\"77.805222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.026704\" y=\"88.190008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.660371\" y=\"52.29818\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.102869\" y=\"74.407627\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.28041\" y=\"86.544145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.533615\" y=\"97.2812\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.039942\" y=\"47.401588\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.798571\" y=\"72.467508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.605425\" y=\"117.705185\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.117282\" y=\"77.578839\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.863978\" y=\"68.35539\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.916677\" y=\"67.610349\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"70.69861\" y=\"29.829656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.49309\" y=\"101.365519\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.800132\" y=\"65.258895\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.875062\" y=\"77.986457\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"37.81946\" y=\"22.041043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.9688\" y=\"82.919953\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"184.717724\" y=\"139.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.23157\" y=\"93.679042\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"177.22424\" y=\"110.310029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.395139\" y=\"96.225358\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.573684\" y=\"51.327124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.758672\" y=\"58.736199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.570633\" y=\"66.047748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.098949\" y=\"80.562145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"180.18112\" y=\"122.612181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.484323\" y=\"72.588527\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.19446\" y=\"68.419977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.194549\" y=\"69.203448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.39048\" y=\"99.604671\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.836511\" y=\"95.278895\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"168.276288\" y=\"116.960095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.729036\" y=\"62.502891\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.406236\" y=\"75.34703\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.079402\" y=\"65.876611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.053701\" y=\"59.436446\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.071025\" y=\"94.729298\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.838797\" y=\"65.936659\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.557707\" y=\"66.413173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.492099\" y=\"71.617763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.297919\" y=\"65.554642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.249566\" y=\"50.537598\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.751482\" y=\"60.66267\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.829179\" y=\"85.850677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.804102\" y=\"69.59409\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.009757\" y=\"33.39075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.889071\" y=\"84.740389\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"92.930904\" y=\"56.896367\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.109569\" y=\"80.144903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.085701\" y=\"78.820328\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.607475\" y=\"90.114192\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.197228\" y=\"90.689906\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.888189\" y=\"86.676935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.803833\" y=\"100.273606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.385509\" y=\"71.28935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"168.428015\" y=\"93.395327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.227251\" y=\"75.908799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"83.610668\" y=\"47.334452\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"77.11768\" y=\"42.681032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.21452\" y=\"68.254932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"194.397655\" y=\"121.483361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.216604\" y=\"92.04012\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.076437\" y=\"84.291729\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.395224\" y=\"80.507211\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"189.387072\" y=\"111.456825\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.094041\" y=\"70.558834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.844024\" y=\"99.113743\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.045958\" y=\"79.203896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.793533\" y=\"43.082933\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.747365\" y=\"49.999154\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.860075\" y=\"80.905868\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.956165\" y=\"53.759361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"106.715826\" y=\"57.926678\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"86.062914\" y=\"30.864672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.261816\" y=\"84.073393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.33017\" y=\"85.092948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.086697\" y=\"59.609608\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.664584\" y=\"85.599525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.832551\" y=\"37.233837\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.292719\" y=\"57.501901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"197.885911\" y=\"136.476002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.417242\" y=\"93.124352\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.590631\" y=\"79.8113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.826924\" y=\"62.819942\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.21641\" y=\"81.136541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.116507\" y=\"106.779282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.198812\" y=\"73.861437\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"166.610014\" y=\"107.285008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.8329\" y=\"86.318162\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"85.447827\" y=\"41.339427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.662964\" y=\"98.494541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.15241\" y=\"55.854203\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.675945\" y=\"74.743863\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.303793\" y=\"96.890186\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.650283\" y=\"68.410737\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.823973\" y=\"86.884353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.11893\" y=\"48.318827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.12326\" y=\"82.182124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"86.71922\" y=\"43.483263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.301609\" y=\"72.569612\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.466356\" y=\"72.806161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.890497\" y=\"47.114905\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"69.84394\" y=\"49.194621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.667698\" y=\"66.412408\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.492479\" y=\"105.564466\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.887408\" y=\"100.306264\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.067891\" y=\"106.950633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.148809\" y=\"64.954008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.429482\" y=\"90.1105\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.664646\" y=\"86.995488\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.867215\" y=\"62.85089\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.549793\" y=\"93.940841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.053745\" y=\"79.150901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.650576\" y=\"68.84641\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.230696\" y=\"101.662611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.701619\" y=\"49.77235\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.691186\" y=\"69.579363\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"169.18138\" y=\"111.892028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.551708\" y=\"60.302929\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.733292\" y=\"103.65314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"58.010948\" y=\"15.765491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.198177\" y=\"94.586921\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.120971\" y=\"54.787315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.041368\" y=\"83.67882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.275511\" y=\"68.62897\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.086569\" y=\"82.079448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.750245\" y=\"67.164617\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.120777\" y=\"97.354337\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.347228\" y=\"90.121634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.348334\" y=\"79.292481\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.444262\" y=\"61.17923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.839766\" y=\"64.295246\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.445458\" y=\"116.605219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.649238\" y=\"82.715272\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.715663\" y=\"92.86394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.159696\" y=\"70.888666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"65.476058\" y=\"13.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.099375\" y=\"69.149559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.263962\" y=\"42.032186\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.166695\" y=\"57.837107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.732869\" y=\"75.377153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"169.679882\" y=\"131.895592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.939425\" y=\"59.141719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.714627\" y=\"111.353278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.763694\" y=\"96.236795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.906559\" y=\"64.276207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.604701\" y=\"60.290799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.973405\" y=\"106.724808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.629961\" y=\"85.050771\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.981322\" y=\"107.254549\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"180.513474\" y=\"111.184544\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.836516\" y=\"95.462359\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.914484\" y=\"67.259161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.479348\" y=\"70.232714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"96.272523\" y=\"49.957704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.135323\" y=\"66.102736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.628174\" y=\"83.945404\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.519095\" y=\"77.177288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.061573\" y=\"76.923153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.333124\" y=\"90.314048\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.929194\" y=\"62.515236\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.347144\" y=\"59.281458\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.947892\" y=\"101.318345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.997123\" y=\"64.226513\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.902053\" y=\"102.041242\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.913735\" y=\"77.644053\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.177522\" y=\"91.387142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.664466\" y=\"27.810463\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.855771\" y=\"81.917821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.229796\" y=\"89.348764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"79.634661\" y=\"35.092983\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.891549\" y=\"65.048166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"93.968327\" y=\"43.871166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.907416\" y=\"75.364399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.486247\" y=\"76.088841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.810386\" y=\"72.693093\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.978057\" y=\"83.175531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.110827\" y=\"79.505546\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.016312\" y=\"100.975342\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.702803\" y=\"124.807206\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.412038\" y=\"90.983812\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.235486\" y=\"83.077619\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.534762\" y=\"83.761282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.610104\" y=\"87.596558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.090768\" y=\"84.604151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"187.20176\" y=\"116.228875\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.439972\" y=\"77.64884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.274607\" y=\"113.955505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.646856\" y=\"68.287306\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.591017\" y=\"71.528892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.994477\" y=\"74.031821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.041914\" y=\"98.097999\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"103.900527\" y=\"48.35415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.638862\" y=\"86.280172\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.804202\" y=\"67.597294\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.845581\" y=\"77.180758\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.671126\" y=\"64.412474\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"174.310451\" y=\"112.626968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.847771\" y=\"95.91145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.881409\" y=\"79.49606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.306849\" y=\"84.052712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.250617\" y=\"83.414741\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.994616\" y=\"75.428867\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.067052\" y=\"78.310834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.191582\" y=\"70.326748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.147501\" y=\"73.301386\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.13053\" y=\"71.147066\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"167.426643\" y=\"99.081935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.168215\" y=\"78.237334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.189183\" y=\"89.874683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.419576\" y=\"74.284852\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.419249\" y=\"72.372303\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.053958\" y=\"75.555399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.359279\" y=\"121.223819\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.815822\" y=\"80.050575\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.911547\" y=\"78.240407\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.923255\" y=\"75.147613\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.133718\" y=\"102.542952\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.329025\" y=\"87.033987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"93.422504\" y=\"45.301327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.517571\" y=\"91.822422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.024305\" y=\"76.642438\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.614931\" y=\"77.949601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"64.970981\" y=\"30.519615\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.081606\" y=\"73.579209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.838706\" y=\"82.110649\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.292935\" y=\"79.188468\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.982502\" y=\"104.574014\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.096378\" y=\"61.68454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.129246\" y=\"62.090174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.758126\" y=\"64.382054\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.906803\" y=\"114.576675\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.911888\" y=\"93.266282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.247932\" y=\"45.160321\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.519383\" y=\"104.21218\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.846885\" y=\"71.754109\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.148961\" y=\"68.087322\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.615576\" y=\"81.411749\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"90.316396\" y=\"50.130527\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"95.132399\" y=\"50.705691\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.188074\" y=\"63.967413\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.547703\" y=\"57.232677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.194564\" y=\"84.365181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.661788\" y=\"77.832046\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.034306\" y=\"113.094996\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.93483\" y=\"91.140991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.505665\" y=\"105.741195\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"105.334975\" y=\"68.392803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.794785\" y=\"75.12353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.469321\" y=\"90.649089\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.66032\" y=\"104.070657\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.906548\" y=\"63.468873\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.338784\" y=\"82.86794\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.549296\" y=\"85.608542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.546588\" y=\"97.206753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.718311\" y=\"68.260558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.147706\" y=\"56.226981\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"97.842273\" y=\"60.232185\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.668063\" y=\"51.873542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"84.617334\" y=\"18.103516\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.451103\" y=\"93.246023\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.265351\" y=\"73.027207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.902407\" y=\"43.075637\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.954757\" y=\"67.577574\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.89097\" y=\"79.029583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"187.621362\" y=\"119.915368\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.612109\" y=\"83.74487\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.686826\" y=\"76.370095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.799684\" y=\"92.48442\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.290279\" y=\"49.338792\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.838858\" y=\"100.184448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.269882\" y=\"97.096052\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.038635\" y=\"67.031251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.041575\" y=\"87.363325\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"84.014338\" y=\"21.562226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.515553\" y=\"69.816669\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.565861\" y=\"78.500167\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.95154\" y=\"89.430395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"145.14065\" y=\"91.456843\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"103.202022\" y=\"56.366234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.22455\" y=\"64.606874\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"131.958635\" y=\"78.651995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.252548\" y=\"72.41565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.756206\" y=\"107.662652\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.515326\" y=\"99.172621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"162.706676\" y=\"96.370217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.105019\" y=\"79.02333\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.779544\" y=\"89.016402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.200818\" y=\"104.754022\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.632423\" y=\"96.801986\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"172.282279\" y=\"111.927308\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.18855\" y=\"82.793202\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.458103\" y=\"41.859056\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.123526\" y=\"93.851658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.584503\" y=\"60.980031\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.909372\" y=\"74.145029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.550977\" y=\"94.163492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.472081\" y=\"68.159095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.929361\" y=\"102.06078\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.826549\" y=\"57.863059\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.134436\" y=\"85.641259\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.168939\" y=\"94.75956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"169.293359\" y=\"112.293427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"144.506265\" y=\"90.257794\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"99.356788\" y=\"65.223327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.398334\" y=\"83.79076\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.570078\" y=\"75.850764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.328916\" y=\"55.738297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.610495\" y=\"72.706857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"115.378193\" y=\"78.429072\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.583122\" y=\"73.384083\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.425629\" y=\"88.150926\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.353432\" y=\"84.380879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.209797\" y=\"89.189101\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.685341\" y=\"62.18428\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.618398\" y=\"71.018209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.333136\" y=\"70.038488\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.322245\" y=\"72.531255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.823646\" y=\"74.393081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"98.608225\" y=\"53.162821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"202.783655\" y=\"121.830153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.99309\" y=\"80.320939\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"104.391942\" y=\"64.345249\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.876304\" y=\"80.548704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.58977\" y=\"63.643561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.906441\" y=\"81.658512\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.266019\" y=\"101.152384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.281286\" y=\"66.060699\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.366461\" y=\"92.592949\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.516261\" y=\"67.56122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.92194\" y=\"90.036556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.144481\" y=\"57.539528\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.135178\" y=\"79.329016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.908034\" y=\"78.861112\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"137.491266\" y=\"83.921422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"113.807697\" y=\"75.450786\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.051651\" y=\"66.182709\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"166.019487\" y=\"98.983666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.111516\" y=\"65.131705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.162638\" y=\"69.319809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.660903\" y=\"78.456473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"91.734064\" y=\"51.867579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"109.351045\" y=\"82.685242\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.6349\" y=\"73.055611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.068739\" y=\"84.355827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.63787\" y=\"87.599534\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.409568\" y=\"93.319693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.704529\" y=\"67.56309\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"101.300494\" y=\"63.42464\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"120.499743\" y=\"48.451007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.69255\" y=\"55.90116\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.128581\" y=\"62.556877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.883643\" y=\"67.885119\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.241836\" y=\"77.585043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.797919\" y=\"87.156956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.0616\" y=\"58.183763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.015626\" y=\"82.54097\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.302346\" y=\"63.575948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.302998\" y=\"76.863967\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"155.911611\" y=\"99.133675\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.123813\" y=\"66.921095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.865968\" y=\"52.645248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.78829\" y=\"79.424332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"110.709863\" y=\"63.33256\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.644056\" y=\"39.476263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"124.256625\" y=\"86.515271\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.738507\" y=\"99.654722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.612702\" y=\"91.443661\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.821672\" y=\"93.766817\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"119.388459\" y=\"72.543665\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.919281\" y=\"96.980838\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.278235\" y=\"93.142453\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"179.94484\" y=\"130.32799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"89.820298\" y=\"37.928601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.650908\" y=\"62.978298\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.414425\" y=\"73.937807\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.594095\" y=\"88.439678\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"170.995955\" y=\"109.732608\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.47018\" y=\"97.713903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"91.416199\" y=\"51.397677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.637216\" y=\"69.78173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"135.319177\" y=\"71.655387\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.374822\" y=\"74.834836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.427259\" y=\"52.43887\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.449895\" y=\"78.713174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.719218\" y=\"70.531854\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"108.072781\" y=\"61.076881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.88235\" y=\"74.547729\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"88.217137\" y=\"52.674687\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.762105\" y=\"59.810942\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"117.558407\" y=\"61.533266\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"165.053974\" y=\"105.538605\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"134.286644\" y=\"83.827882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.266477\" y=\"73.022932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.574237\" y=\"72.99407\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"102.381512\" y=\"64.55689\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.693437\" y=\"83.376626\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"154.460302\" y=\"91.934398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.00611\" y=\"85.236683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.702211\" y=\"80.325857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"94.346003\" y=\"53.38592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"125.269631\" y=\"86.51086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.152682\" y=\"68.541043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.952226\" y=\"100.24009\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"171.111968\" y=\"118.103977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.53369\" y=\"90.561111\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.717881\" y=\"69.697515\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.815171\" y=\"62.456778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.308034\" y=\"94.957518\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"157.427407\" y=\"92.102869\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"116.582537\" y=\"66.853116\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.54365\" y=\"90.435422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"123.207181\" y=\"71.333254\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"151.161298\" y=\"103.614709\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"158.907013\" y=\"98.96007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.818717\" y=\"81.294635\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"141.449835\" y=\"81.23083\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.090995\" y=\"102.947303\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"150.379022\" y=\"79.235428\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.079829\" y=\"82.178295\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.273181\" y=\"91.059508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.334522\" y=\"86.045153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"100.770433\" y=\"65.405451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"108.552052\" y=\"69.00258\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.765937\" y=\"82.574475\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"161.607644\" y=\"115.920234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.087753\" y=\"89.551559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.319823\" y=\"77.133567\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"132.731657\" y=\"68.029976\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.131994\" y=\"84.591819\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"160.73471\" y=\"95.674044\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"128.18093\" y=\"83.951852\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"118.339812\" y=\"48.107719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"126.868383\" y=\"91.144692\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"111.915862\" y=\"77.966158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"159.038497\" y=\"101.867718\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"121.953976\" y=\"69.104578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"147.381854\" y=\"95.437832\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"163.145448\" y=\"91.398395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"140.161531\" y=\"82.985289\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.390359\" y=\"113.470475\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"139.705958\" y=\"87.582783\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"122.643029\" y=\"80.594545\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.61515\" y=\"75.882131\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"129.371491\" y=\"83.48542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"136.091775\" y=\"75.831255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"164.084409\" y=\"84.442152\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"107.313126\" y=\"66.885205\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"138.356645\" y=\"87.367559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"112.569709\" y=\"75.389946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"99.88968\" y=\"62.102534\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"130.395297\" y=\"89.780347\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.960033\" y=\"73.903159\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"156.651549\" y=\"115.759169\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"149.600207\" y=\"99.445677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"173.972016\" y=\"100.660773\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"146.195861\" y=\"95.951702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"143.305644\" y=\"91.992748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"142.934713\" y=\"93.511792\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"148.517035\" y=\"93.644631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"114.15317\" y=\"39.124589\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"152.259368\" y=\"89.347345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"127.762384\" y=\"69.862951\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"153.40995\" y=\"101.115803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m18bb6ce550\" x=\"133.643811\" y=\"68.037402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m2cbfe66e94\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2cbfe66e94\" x=\"37.108605\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −4 -->\n",
       "      <g transform=\"translate(29.737511 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2cbfe66e94\" x=\"84.839648\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- −2 -->\n",
       "      <g transform=\"translate(77.468554 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2cbfe66e94\" x=\"132.57069\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(129.38944 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2cbfe66e94\" x=\"180.301733\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(177.120483 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <defs>\n",
       "       <path id=\"m67ee9f9fc6\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m67ee9f9fc6\" x=\"28.942188\" y=\"125.71812\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- −5 -->\n",
       "      <g transform=\"translate(7.2 129.517339) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m67ee9f9fc6\" x=\"28.942188\" y=\"99.751174\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(15.579688 103.550393) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m67ee9f9fc6\" x=\"28.942188\" y=\"73.784228\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(15.579688 77.583446) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m67ee9f9fc6\" x=\"28.942188\" y=\"47.817281\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(9.217188 51.6165) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m67ee9f9fc6\" x=\"28.942188\" y=\"21.850335\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(9.217188 25.649554) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 28.942188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 224.242188 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 28.942188 7.2 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p149bb96678\">\n",
       "   <rect x=\"28.942188\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘图，查看分布\n",
    "d2l.set_figsize()\n",
    "d2l.plt.scatter(features[:, (1)].detach().numpy(), \n",
    "                labels.detach().numpy(), 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"231.442187pt\" height=\"169.678125pt\" viewBox=\"0 0 231.442187 169.678125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-05-18T15:08:56.251352</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 169.678125 \n",
       "L 231.442187 169.678125 \n",
       "L 231.442187 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "L 28.942188 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"m823589f946\" d=\"M 0 0.5 \n",
       "C 0.132602 0.5 0.25979 0.447317 0.353553 0.353553 \n",
       "C 0.447317 0.25979 0.5 0.132602 0.5 0 \n",
       "C 0.5 -0.132602 0.447317 -0.25979 0.353553 -0.353553 \n",
       "C 0.25979 -0.447317 0.132602 -0.5 0 -0.5 \n",
       "C -0.132602 -0.5 -0.25979 -0.447317 -0.353553 -0.353553 \n",
       "C -0.447317 -0.25979 -0.5 -0.132602 -0.5 0 \n",
       "C -0.5 0.132602 -0.447317 0.25979 -0.353553 0.353553 \n",
       "C -0.25979 0.447317 -0.132602 0.5 0 0.5 \n",
       "z\n",
       "\" style=\"stroke: #1f77b4\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p4610e2cf3f)\">\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.049598\" y=\"47.161377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.963107\" y=\"83.62544\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.927232\" y=\"87.238868\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.499187\" y=\"40.397538\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.738829\" y=\"74.594754\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"168.177498\" y=\"60.945456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.120588\" y=\"78.7769\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.100157\" y=\"79.445989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"167.203315\" y=\"38.908429\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"66.24924\" y=\"116.402206\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"96.90644\" y=\"88.486938\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.287288\" y=\"81.085971\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.367315\" y=\"87.997522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.325299\" y=\"88.393808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.647682\" y=\"76.554431\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.127695\" y=\"73.519191\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"174.422087\" y=\"74.321666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.875464\" y=\"93.603985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.86115\" y=\"88.551763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.341229\" y=\"35.366294\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.2019\" y=\"58.043827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.565749\" y=\"103.28369\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.72149\" y=\"57.861658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"73.517474\" y=\"81.847122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.731428\" y=\"77.415171\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.879391\" y=\"90.031881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.688161\" y=\"35.628451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.386178\" y=\"92.726373\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.192063\" y=\"65.921645\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.646121\" y=\"67.827082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.295666\" y=\"73.868138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.981588\" y=\"81.497491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.834866\" y=\"57.255578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.896673\" y=\"56.665809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.227189\" y=\"72.549742\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.329422\" y=\"85.38564\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.058958\" y=\"58.074153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"178.342288\" y=\"51.205587\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.373088\" y=\"46.708364\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"77.803974\" y=\"111.673949\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.240795\" y=\"75.989104\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.312012\" y=\"67.739194\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.926694\" y=\"59.798297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.913672\" y=\"74.989388\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.635024\" y=\"59.375105\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.512233\" y=\"59.267597\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.543894\" y=\"93.854999\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.832725\" y=\"71.690158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.390046\" y=\"87.617628\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.727296\" y=\"63.623364\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.260721\" y=\"73.829216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.220665\" y=\"89.36582\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.38085\" y=\"94.878713\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.725452\" y=\"98.631002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.94471\" y=\"69.606532\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"73.676253\" y=\"77.322051\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.217505\" y=\"72.458828\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.958828\" y=\"44.551745\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.123908\" y=\"71.231531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.629155\" y=\"87.507944\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.86245\" y=\"89.154946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.219201\" y=\"115.023299\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"189.643748\" y=\"57.941606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.691932\" y=\"64.990028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"79.878438\" y=\"124.951583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.820831\" y=\"47.266292\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.795653\" y=\"82.798065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"185.46487\" y=\"84.905216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.289184\" y=\"63.342156\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.790243\" y=\"71.311502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.555683\" y=\"71.440978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"96.680579\" y=\"109.509315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.142542\" y=\"76.930463\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.204389\" y=\"81.979596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.270455\" y=\"45.388764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"37.81946\" y=\"96.679841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"187.724045\" y=\"39.170635\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.818021\" y=\"104.843924\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.548633\" y=\"136.669454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.098167\" y=\"64.485384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"69.900495\" y=\"92.242205\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.078741\" y=\"58.495525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.047477\" y=\"43.485036\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.94966\" y=\"66.785002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"170.966781\" y=\"75.943248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.77618\" y=\"105.039855\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.366653\" y=\"90.586554\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.319769\" y=\"70.239975\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.740655\" y=\"86.234712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.564353\" y=\"72.272405\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.289525\" y=\"42.120415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.977459\" y=\"52.733002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.326608\" y=\"91.534395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.793803\" y=\"78.277075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.637716\" y=\"80.007046\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"72.535262\" y=\"123.495815\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.666409\" y=\"87.647679\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.243464\" y=\"68.147087\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"79.233118\" y=\"77.973753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.615171\" y=\"102.953634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.83466\" y=\"48.117778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.245982\" y=\"79.685957\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"85.339264\" y=\"105.065753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.043811\" y=\"94.163776\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.807544\" y=\"39.249632\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.697482\" y=\"94.996263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.091272\" y=\"110.657126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.549356\" y=\"56.029453\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"86.928383\" y=\"95.454916\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.897108\" y=\"95.256836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.102496\" y=\"79.859375\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"51.276685\" y=\"86.897922\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.651787\" y=\"94.19315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.784394\" y=\"100.574648\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.524805\" y=\"95.633883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"61.405454\" y=\"77.128793\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"165.479099\" y=\"42.823713\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.107527\" y=\"71.69238\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"174.024353\" y=\"43.229075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.383267\" y=\"84.788153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.958005\" y=\"72.66032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.9598\" y=\"58.450722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.732142\" y=\"131.832798\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"204.588149\" y=\"54.265354\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.193145\" y=\"79.788226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.838601\" y=\"39.581108\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.481894\" y=\"74.271061\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.181891\" y=\"96.641912\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.217305\" y=\"95.322537\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.981023\" y=\"37.140992\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.457846\" y=\"88.381482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.444136\" y=\"82.87251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.320171\" y=\"114.644034\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.182927\" y=\"81.887664\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.052671\" y=\"110.831563\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.614091\" y=\"79.688158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.600058\" y=\"72.500684\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.438867\" y=\"64.647256\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.804829\" y=\"83.772278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"63.421576\" y=\"126.892836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.066561\" y=\"52.077508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.440322\" y=\"71.031701\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.984559\" y=\"77.309642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.146232\" y=\"95.714536\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.036364\" y=\"78.662995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.580275\" y=\"52.853989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.086729\" y=\"85.024525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.583032\" y=\"65.790707\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.297572\" y=\"73.972357\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"161.872947\" y=\"73.366803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.728672\" y=\"103.786181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.589504\" y=\"70.019699\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.80647\" y=\"46.796222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.874851\" y=\"71.131398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"170.34891\" y=\"67.727624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.207703\" y=\"87.823199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.000766\" y=\"74.458643\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"60.052055\" y=\"119.338468\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.077031\" y=\"65.114343\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.30747\" y=\"90.545777\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.660782\" y=\"32.072086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.63782\" y=\"89.646188\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"74.008351\" y=\"131.976622\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.802539\" y=\"37.519916\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.031993\" y=\"68.471924\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"160.842431\" y=\"58.213502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.530854\" y=\"67.209455\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.319874\" y=\"83.648026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.749716\" y=\"81.247013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.943817\" y=\"78.386436\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.952825\" y=\"110.099002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.80105\" y=\"79.870857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.17755\" y=\"86.82456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.775787\" y=\"55.800128\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.787785\" y=\"95.543365\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.680858\" y=\"80.716385\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.31618\" y=\"49.869361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"83.986793\" y=\"78.313592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.027008\" y=\"108.965791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.632561\" y=\"89.407648\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"86.120077\" y=\"102.732158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"55.340667\" y=\"130.289923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.168331\" y=\"77.297087\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.052556\" y=\"77.985982\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.276859\" y=\"86.539024\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.447145\" y=\"88.497173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.160475\" y=\"82.445164\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"77.770008\" y=\"100.566278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.059892\" y=\"78.2606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.837459\" y=\"104.95213\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.805963\" y=\"90.006435\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.199906\" y=\"66.676858\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.479051\" y=\"44.376892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.643194\" y=\"50.800963\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.651571\" y=\"73.130755\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.739921\" y=\"90.054365\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.782681\" y=\"88.832337\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.722082\" y=\"109.265351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.765036\" y=\"105.520126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.92917\" y=\"45.042519\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.462902\" y=\"71.352702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.305053\" y=\"87.712444\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.404515\" y=\"93.431903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"84.110943\" y=\"115.084394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.583832\" y=\"65.664837\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.929312\" y=\"41.543072\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.699533\" y=\"65.483171\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.61974\" y=\"73.541159\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"79.611058\" y=\"107.280884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.971819\" y=\"81.808232\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"86.09323\" y=\"92.773059\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"80.631611\" y=\"110.615348\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.394381\" y=\"87.620506\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.171816\" y=\"95.841866\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.954207\" y=\"67.122825\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.024508\" y=\"77.513579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"163.642053\" y=\"65.123268\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.571848\" y=\"108.43805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"187.924902\" y=\"59.570065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.405573\" y=\"71.318317\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.291421\" y=\"103.523987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.894751\" y=\"43.963427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.396273\" y=\"71.800816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.090681\" y=\"50.486663\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.573461\" y=\"80.491925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"72.203491\" y=\"101.020893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.981394\" y=\"103.960201\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.084978\" y=\"64.961187\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.747365\" y=\"108.101154\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.659146\" y=\"71.272436\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.896406\" y=\"54.533553\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.622954\" y=\"77.715356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.506828\" y=\"85.805685\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.689788\" y=\"84.457284\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.744492\" y=\"110.462091\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.914233\" y=\"40.894705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.029819\" y=\"69.718393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.924367\" y=\"99.022385\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.206793\" y=\"47.724193\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.371572\" y=\"94.62609\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.283811\" y=\"69.007238\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.098857\" y=\"115.545579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"187.707201\" y=\"50.701739\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.111841\" y=\"93.231596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.278095\" y=\"48.494835\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.721283\" y=\"60.52896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.206497\" y=\"115.579612\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.264923\" y=\"57.422106\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.301552\" y=\"48.033332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.042311\" y=\"92.460497\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"81.554385\" y=\"94.537197\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.620078\" y=\"105.885217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.920391\" y=\"89.998881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.870621\" y=\"57.369795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.159061\" y=\"109.391435\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.698184\" y=\"68.146646\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.944293\" y=\"77.863288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.880527\" y=\"82.309716\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.515502\" y=\"64.998791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.94588\" y=\"62.189196\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"82.297836\" y=\"90.072432\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.01675\" y=\"75.777629\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.402728\" y=\"88.600963\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.38606\" y=\"62.371521\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.955738\" y=\"81.635209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.671034\" y=\"54.280767\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.351852\" y=\"73.743823\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.858871\" y=\"70.005569\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.11235\" y=\"67.434763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.694098\" y=\"76.827061\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.895866\" y=\"83.246127\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.46799\" y=\"62.814925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.1394\" y=\"82.432944\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.65086\" y=\"66.571063\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.977175\" y=\"61.460029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.67534\" y=\"84.160395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.576162\" y=\"68.818434\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"178.764923\" y=\"52.552853\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.268663\" y=\"95.612473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.919849\" y=\"60.307027\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.769421\" y=\"65.64585\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.102148\" y=\"90.950681\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.715173\" y=\"67.75297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.335523\" y=\"53.050234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.15796\" y=\"106.433803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.824974\" y=\"49.907413\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.53108\" y=\"81.185502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.397239\" y=\"64.86224\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.153422\" y=\"63.739985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"177.608589\" y=\"101.59375\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.390429\" y=\"110.318736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.027687\" y=\"122.525807\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.667361\" y=\"38.326326\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.64613\" y=\"91.321178\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"96.587818\" y=\"77.393835\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.031757\" y=\"49.56985\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.687921\" y=\"85.533263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.260207\" y=\"72.671207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"92.050953\" y=\"99.386596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.476967\" y=\"67.775845\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.306363\" y=\"74.056585\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"92.989877\" y=\"75.661508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"163.810489\" y=\"61.146314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.631908\" y=\"105.44496\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.028653\" y=\"37.429393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.080218\" y=\"78.800497\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.75805\" y=\"76.243697\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.333868\" y=\"65.434945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.884273\" y=\"95.744662\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.75585\" y=\"60.535636\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.694347\" y=\"87.970989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.355425\" y=\"86.192893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.322212\" y=\"57.788411\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"169.078373\" y=\"75.358756\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"203.677167\" y=\"35.551553\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.900537\" y=\"78.30334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.003074\" y=\"64.711556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.375884\" y=\"101.88973\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.776485\" y=\"97.819789\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.548848\" y=\"88.734081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"174.623095\" y=\"45.330227\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"166.504097\" y=\"44.209348\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.490532\" y=\"76.632356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"42.223604\" y=\"108.769978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"79.483809\" y=\"100.102314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.557705\" y=\"88.620482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.493029\" y=\"96.788656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.602751\" y=\"60.901465\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.314864\" y=\"93.607883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.405215\" y=\"74.933473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.2544\" y=\"82.22746\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.82136\" y=\"95.62631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.820357\" y=\"60.61157\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.426303\" y=\"81.496522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.750114\" y=\"41.516842\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.995442\" y=\"88.36295\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.801026\" y=\"70.030588\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.461677\" y=\"78.772412\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.195137\" y=\"69.940603\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.935805\" y=\"72.17007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"76.383706\" y=\"108.453568\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.861479\" y=\"66.977319\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.519279\" y=\"121.685772\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.620947\" y=\"96.364357\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.402655\" y=\"83.36262\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.037137\" y=\"77.685671\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.506589\" y=\"77.021255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"177.185268\" y=\"81.933449\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.590134\" y=\"56.89179\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.6819\" y=\"109.930138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.241482\" y=\"46.477058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.572872\" y=\"107.725896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.637728\" y=\"95.836344\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"212.651217\" y=\"25.80849\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.587829\" y=\"83.93642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"180.754959\" y=\"41.798879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.633346\" y=\"100.699816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.661397\" y=\"132.059178\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.076599\" y=\"61.119264\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.355169\" y=\"102.003628\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.63579\" y=\"90.938355\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"62.976754\" y=\"135.076353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.202629\" y=\"89.697253\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.238987\" y=\"84.102082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"168.109165\" y=\"70.643879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.793745\" y=\"77.271077\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.972281\" y=\"118.26173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.883808\" y=\"100.42625\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.039785\" y=\"85.449113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.66428\" y=\"91.51232\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.241492\" y=\"98.445219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.03768\" y=\"69.827219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"75.822165\" y=\"96.551888\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.904047\" y=\"69.991721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.273474\" y=\"77.144345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.75058\" y=\"53.943991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.731207\" y=\"42.491325\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.123343\" y=\"71.860096\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.473095\" y=\"71.452624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"76.20589\" y=\"87.64505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.625086\" y=\"59.370096\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.623662\" y=\"71.761607\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.872865\" y=\"59.617879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.328513\" y=\"76.742222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.067496\" y=\"104.341687\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.101\" y=\"68.026442\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"84.540093\" y=\"87.193492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.715822\" y=\"69.71948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.45679\" y=\"45.774082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.390465\" y=\"64.811021\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.321209\" y=\"54.048753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.308722\" y=\"47.273691\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.437076\" y=\"79.306596\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.410571\" y=\"90.852565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.786144\" y=\"66.468719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.533711\" y=\"63.262394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.389089\" y=\"65.665216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.792984\" y=\"89.563288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.134847\" y=\"66.439287\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.283384\" y=\"83.170556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.321473\" y=\"65.386806\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.674786\" y=\"94.60237\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.015272\" y=\"77.253336\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.597825\" y=\"40.351655\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.524061\" y=\"79.915883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.986621\" y=\"52.793148\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.451529\" y=\"74.635042\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.319855\" y=\"91.09296\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.287857\" y=\"73.305529\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"81.69111\" y=\"88.123721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.736298\" y=\"93.357726\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.638866\" y=\"96.797956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"63.749778\" y=\"101.376634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.916784\" y=\"59.779791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.478063\" y=\"83.17462\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.579643\" y=\"58.26251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.260889\" y=\"93.280006\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.856746\" y=\"89.448882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.132326\" y=\"92.86561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.64914\" y=\"76.563584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"78.98032\" y=\"73.075454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.448037\" y=\"59.21978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.196027\" y=\"66.063946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.623498\" y=\"93.067459\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"167.48427\" y=\"74.32969\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.613633\" y=\"120.319759\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.849133\" y=\"89.083226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.136872\" y=\"21.716144\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.194044\" y=\"67.650078\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.50902\" y=\"65.223208\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.345405\" y=\"97.346334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.290961\" y=\"110.278113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.149373\" y=\"55.04702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.172144\" y=\"36.320377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.482255\" y=\"66.727421\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.525141\" y=\"54.699249\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.40025\" y=\"68.524397\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.578988\" y=\"18.152251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.351455\" y=\"96.415787\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.619062\" y=\"53.098791\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.703068\" y=\"55.945706\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.422522\" y=\"67.417656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"179.246541\" y=\"50.437323\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.299476\" y=\"53.971836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.247584\" y=\"60.758656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.829639\" y=\"108.205526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.127188\" y=\"67.258656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.219419\" y=\"82.418834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.733263\" y=\"77.876968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.098952\" y=\"82.143424\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.306709\" y=\"57.152768\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.29035\" y=\"94.68598\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"56.441672\" y=\"112.619282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.18383\" y=\"84.338058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.610361\" y=\"105.269701\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.990516\" y=\"90.123526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.297022\" y=\"103.768415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.657461\" y=\"90.380013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.048586\" y=\"55.457805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.176953\" y=\"80.84138\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"161.15855\" y=\"70.947599\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"188.818438\" y=\"23.162991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.81954\" y=\"77.873558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"52.788866\" y=\"105.443857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.073555\" y=\"91.711486\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.648184\" y=\"44.255994\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.24535\" y=\"95.849579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.719859\" y=\"83.283928\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.82831\" y=\"47.93496\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.600949\" y=\"41.384245\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"170.925208\" y=\"78.467352\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.491491\" y=\"50.069211\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.285578\" y=\"94.835505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.612509\" y=\"108.472892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.57265\" y=\"104.72846\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.8394\" y=\"106.281367\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.025283\" y=\"51.793366\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.112622\" y=\"70.717656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"90.392245\" y=\"98.065695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.588362\" y=\"93.409271\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.28\" y=\"91.783085\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.005108\" y=\"60.077816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.487075\" y=\"51.08775\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.931134\" y=\"70.340151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.782326\" y=\"64.663011\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.487126\" y=\"55.93901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.874491\" y=\"54.780247\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.387538\" y=\"88.241005\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.230036\" y=\"81.15877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.805315\" y=\"81.571363\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"175.518051\" y=\"62.661631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.912117\" y=\"69.693332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.50853\" y=\"74.384589\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.022979\" y=\"98.598832\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.308852\" y=\"66.33793\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.66247\" y=\"125.79795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.230846\" y=\"98.4751\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.927235\" y=\"64.56139\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.136891\" y=\"81.606658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.011061\" y=\"98.219326\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.433355\" y=\"94.831201\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"90.01999\" y=\"104.699339\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.124803\" y=\"89.41371\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.731162\" y=\"72.784708\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.449115\" y=\"87.411776\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.901989\" y=\"52.687565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.230845\" y=\"50.725829\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.264013\" y=\"65.130989\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"174.363999\" y=\"63.986565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.755118\" y=\"80.834248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.336992\" y=\"81.052541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.442112\" y=\"68.298331\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.985402\" y=\"63.476082\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.662602\" y=\"84.375522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.727325\" y=\"73.802402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"91.581023\" y=\"91.968214\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"183.538607\" y=\"35.232469\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.842907\" y=\"78.597462\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.752634\" y=\"70.788778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.254133\" y=\"59.685314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.991266\" y=\"90.993283\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"51.962785\" y=\"129.760231\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.49515\" y=\"95.79107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.077792\" y=\"49.856484\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.310112\" y=\"86.650945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.556629\" y=\"84.532026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.689037\" y=\"63.882353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.347151\" y=\"56.071804\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.809807\" y=\"91.749217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.976101\" y=\"88.082351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.36503\" y=\"105.130473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"175.369996\" y=\"51.890282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.0653\" y=\"58.570508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.694646\" y=\"59.913878\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.833458\" y=\"77.805222\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.038152\" y=\"88.190008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.299748\" y=\"52.29818\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.303556\" y=\"74.407627\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.91774\" y=\"86.544145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"83.32546\" y=\"97.2812\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"209.389793\" y=\"47.401588\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"181.015184\" y=\"72.467508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"72.360497\" y=\"117.705185\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.733952\" y=\"77.578839\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.36438\" y=\"68.35539\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.414222\" y=\"67.610349\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.119107\" y=\"29.829656\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"80.299656\" y=\"101.365519\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.623621\" y=\"65.258895\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.323999\" y=\"77.986457\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.074237\" y=\"22.041043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"161.23561\" y=\"82.919953\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"63.623552\" y=\"139.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.357694\" y=\"93.679042\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.611059\" y=\"110.310029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.936631\" y=\"96.225358\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.522297\" y=\"51.327124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.057859\" y=\"58.736199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.800353\" y=\"66.047748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.564327\" y=\"80.562145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.434737\" y=\"122.612181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.082975\" y=\"72.588527\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.615517\" y=\"68.419977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.593645\" y=\"69.203448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.359412\" y=\"99.604671\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.507215\" y=\"95.278895\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"91.779967\" y=\"116.960095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.826354\" y=\"62.502891\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.243687\" y=\"75.34703\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.302767\" y=\"65.876611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"175.021664\" y=\"59.436446\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.267938\" y=\"94.729298\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"171.014277\" y=\"65.936659\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.896302\" y=\"66.413173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.794339\" y=\"71.617763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.880567\" y=\"65.554642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"169.210858\" y=\"50.537598\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.656678\" y=\"60.66267\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.911634\" y=\"85.850677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.673002\" y=\"69.59409\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"189.161769\" y=\"33.39075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.753796\" y=\"84.740389\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.063714\" y=\"56.896367\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.889163\" y=\"80.144903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.337622\" y=\"78.820328\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.048405\" y=\"90.114192\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.60175\" y=\"90.689906\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.546441\" y=\"86.676935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.150959\" y=\"100.273606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.452988\" y=\"71.28935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.797849\" y=\"93.395327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.605712\" y=\"75.908799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.511792\" y=\"47.334452\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.202954\" y=\"42.681032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.34902\" y=\"68.254932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.52931\" y=\"121.483361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.118569\" y=\"92.04012\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.717182\" y=\"84.291729\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.564481\" y=\"80.507211\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.997267\" y=\"111.456825\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.925205\" y=\"70.558834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.319636\" y=\"99.113743\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.278791\" y=\"79.203896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"178.434161\" y=\"43.082933\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"167.558883\" y=\"49.999154\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.350653\" y=\"80.905868\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.014254\" y=\"53.759361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.995502\" y=\"57.926678\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"160.34066\" y=\"30.864672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.452077\" y=\"84.073393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.964594\" y=\"85.092948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.420073\" y=\"59.609608\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.2422\" y=\"85.599525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.279531\" y=\"37.233837\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.299046\" y=\"57.501901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.090431\" y=\"136.476002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.285742\" y=\"93.124352\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.883758\" y=\"79.8113\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.341734\" y=\"62.819942\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.614272\" y=\"81.136541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.947694\" y=\"106.779282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.874459\" y=\"73.861437\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.434917\" y=\"107.285008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.587661\" y=\"86.318162\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.568218\" y=\"41.339427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.334003\" y=\"98.494541\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.792341\" y=\"55.854203\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.765284\" y=\"74.743863\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"65.950443\" y=\"96.890186\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.953128\" y=\"68.410737\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.076785\" y=\"86.884353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"165.077753\" y=\"48.318827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.557638\" y=\"82.182124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.465336\" y=\"43.483263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.999096\" y=\"72.569612\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"175.658194\" y=\"72.806161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.614113\" y=\"47.114905\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"78.097028\" y=\"49.194621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.168313\" y=\"66.412408\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.900855\" y=\"105.564466\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.904687\" y=\"100.306264\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"90.283924\" y=\"106.950633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.055145\" y=\"64.954008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.513609\" y=\"90.1105\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.437905\" y=\"86.995488\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.146056\" y=\"62.85089\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.417844\" y=\"93.940841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"161.497704\" y=\"79.150901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.479509\" y=\"68.84641\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.86093\" y=\"101.662611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.037075\" y=\"49.77235\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.592107\" y=\"69.579363\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.298391\" y=\"111.892028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.540151\" y=\"60.302929\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.701447\" y=\"103.65314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.675451\" y=\"15.765491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.119625\" y=\"94.586921\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.41555\" y=\"54.787315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.166349\" y=\"83.67882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.124819\" y=\"68.62897\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.697529\" y=\"82.079448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.465559\" y=\"67.164617\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.395364\" y=\"97.354337\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.4787\" y=\"90.121634\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.71934\" y=\"79.292481\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.647301\" y=\"61.17923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.39114\" y=\"64.295246\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"68.965886\" y=\"116.605219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.765768\" y=\"82.715272\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.540192\" y=\"92.86394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"83.89068\" y=\"70.888666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"165.89304\" y=\"13.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"176.577749\" y=\"69.149559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"172.099286\" y=\"42.032186\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"171.240875\" y=\"57.837107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.595161\" y=\"75.377153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"54.132348\" y=\"131.895592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.467119\" y=\"59.141719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.744611\" y=\"111.353278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.646477\" y=\"96.236795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.454028\" y=\"64.276207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.72858\" y=\"60.290799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"86.81705\" y=\"106.724808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.66873\" y=\"85.050771\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.426944\" y=\"107.254549\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.781012\" y=\"111.184544\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.073136\" y=\"95.462359\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"175.5756\" y=\"67.259161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.399948\" y=\"70.232714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.661228\" y=\"49.957704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.02515\" y=\"66.102736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.587138\" y=\"83.945404\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.828517\" y=\"77.177288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.246521\" y=\"76.923153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"85.757621\" y=\"90.314048\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.148795\" y=\"62.515236\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.402578\" y=\"59.281458\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"71.00132\" y=\"101.318345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"163.57908\" y=\"64.226513\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"73.297553\" y=\"102.041242\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"149.14116\" y=\"77.644053\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.532508\" y=\"91.387142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"215.364915\" y=\"27.810463\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.557131\" y=\"81.917821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.399975\" y=\"89.348764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.696899\" y=\"35.092983\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.216523\" y=\"65.048166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.750923\" y=\"43.871166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.567312\" y=\"75.364399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.841989\" y=\"76.088841\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"174.497954\" y=\"72.693093\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"82.079833\" y=\"83.175531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.359196\" y=\"79.505546\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"86.410509\" y=\"100.975342\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"81.404638\" y=\"124.807206\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.355983\" y=\"90.983812\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.025712\" y=\"83.077619\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.753408\" y=\"83.761282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.473648\" y=\"87.596558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"76.848333\" y=\"84.604151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.54825\" y=\"116.228875\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"72.241611\" y=\"77.64884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.800053\" y=\"113.955505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.94458\" y=\"68.287306\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"151.352201\" y=\"71.528892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.151741\" y=\"74.031821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.390124\" y=\"98.097999\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.295013\" y=\"48.35415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.282461\" y=\"86.280172\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.137694\" y=\"67.597294\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.418614\" y=\"77.180758\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"180.585042\" y=\"64.412474\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.505276\" y=\"112.626968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.83676\" y=\"95.91145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"81.953483\" y=\"79.49606\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.450492\" y=\"84.052712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.20357\" y=\"83.414741\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.473731\" y=\"75.428867\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.974924\" y=\"78.310834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.555073\" y=\"70.326748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"155.47176\" y=\"73.301386\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.135547\" y=\"71.147066\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.265214\" y=\"99.081935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.139364\" y=\"78.237334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.121391\" y=\"89.874683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.026376\" y=\"74.284852\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.496048\" y=\"72.372303\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.263738\" y=\"75.555399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"66.330597\" y=\"121.223819\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.496239\" y=\"80.050575\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"163.746725\" y=\"78.240407\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.019036\" y=\"75.147613\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.167031\" y=\"102.542952\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.733378\" y=\"87.033987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.758837\" y=\"45.301327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"110.225777\" y=\"91.822422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.013595\" y=\"76.642438\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.577436\" y=\"77.949601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.717064\" y=\"30.519615\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.419942\" y=\"73.579209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.874708\" y=\"82.110649\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.592761\" y=\"79.188468\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"70.614825\" y=\"104.574014\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.928618\" y=\"61.68454\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"173.787735\" y=\"62.090174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.897787\" y=\"64.382054\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.262547\" y=\"114.576675\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.003667\" y=\"93.266282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.857955\" y=\"45.160321\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.470098\" y=\"104.21218\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.86453\" y=\"71.754109\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.791658\" y=\"68.087322\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.37824\" y=\"81.411749\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.522723\" y=\"50.130527\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.619915\" y=\"50.705691\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"164.740067\" y=\"63.967413\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.503223\" y=\"57.232677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.90262\" y=\"84.365181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.082842\" y=\"77.832046\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"73.714402\" y=\"113.094996\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.922321\" y=\"91.140991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.429953\" y=\"105.741195\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"97.251272\" y=\"68.392803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.652541\" y=\"75.12353\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.281016\" y=\"90.649089\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.225874\" y=\"104.070657\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.851862\" y=\"63.468873\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.874801\" y=\"82.86794\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.361829\" y=\"85.608542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"133.679553\" y=\"97.206753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.433652\" y=\"68.260558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.707459\" y=\"56.226981\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.466984\" y=\"60.232185\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"162.211002\" y=\"51.873542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"191.749207\" y=\"18.103516\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.151989\" y=\"93.246023\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.586849\" y=\"73.027207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.664094\" y=\"43.075637\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"92.632218\" y=\"67.577574\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.688456\" y=\"79.029583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.443717\" y=\"119.915368\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.064883\" y=\"83.74487\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"166.324197\" y=\"76.370095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.687512\" y=\"92.48442\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"184.488892\" y=\"49.338792\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"74.158453\" y=\"100.184448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.142167\" y=\"97.096052\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.452225\" y=\"67.031251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.464654\" y=\"87.363325\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"180.956995\" y=\"21.562226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"169.849401\" y=\"69.816669\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.234793\" y=\"78.500167\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.43934\" y=\"89.430395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.511813\" y=\"91.456843\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.525078\" y=\"56.366234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.370516\" y=\"64.606874\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.840956\" y=\"78.651995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.986175\" y=\"72.41565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"67.812426\" y=\"107.662652\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.24277\" y=\"99.172621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.122348\" y=\"96.370217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.984574\" y=\"79.02333\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"78.10275\" y=\"89.016402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.469622\" y=\"104.754022\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.055326\" y=\"96.801986\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.311371\" y=\"111.927308\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.977943\" y=\"82.793202\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"181.183955\" y=\"41.859056\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.899333\" y=\"93.851658\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.641859\" y=\"60.980031\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.884806\" y=\"74.145029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"82.031302\" y=\"94.163492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.943946\" y=\"68.159095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.227504\" y=\"102.06078\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.542706\" y=\"57.863059\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.00117\" y=\"85.641259\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.462926\" y=\"94.75956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.415666\" y=\"112.293427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.501266\" y=\"90.257794\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.875095\" y=\"65.223327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.522966\" y=\"83.79076\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.38404\" y=\"75.850764\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"191.302369\" y=\"55.738297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.952036\" y=\"72.706857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"90.052766\" y=\"78.429072\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"142.100739\" y=\"73.384083\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.68414\" y=\"88.150926\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"83.949254\" y=\"84.380879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"126.488359\" y=\"89.189101\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.403712\" y=\"62.18428\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"88.634546\" y=\"71.018209\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.618662\" y=\"70.038488\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.950225\" y=\"72.531255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"117.796374\" y=\"74.393081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"124.97434\" y=\"53.162821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"147.619682\" y=\"121.830153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.26606\" y=\"80.320939\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.049219\" y=\"64.345249\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"107.42358\" y=\"80.548704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.697011\" y=\"63.643561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.620693\" y=\"81.658512\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.167502\" y=\"101.152384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"153.36571\" y=\"66.060699\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.537929\" y=\"92.592949\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.695567\" y=\"67.56122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.542432\" y=\"90.036556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"168.065405\" y=\"57.539528\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.202409\" y=\"79.329016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.17291\" y=\"78.861112\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.472423\" y=\"83.921422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.067353\" y=\"75.450786\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"158.600733\" y=\"66.182709\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"135.687881\" y=\"98.983666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.388839\" y=\"65.131705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.364471\" y=\"69.319809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"144.523987\" y=\"78.456473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.684456\" y=\"51.867579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"66.500922\" y=\"82.685242\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.931686\" y=\"73.055611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.580351\" y=\"84.355827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.128055\" y=\"87.599534\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"130.042181\" y=\"93.319693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.098316\" y=\"67.56309\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"102.452956\" y=\"63.42464\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"181.400577\" y=\"48.451007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.510389\" y=\"55.90116\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.469543\" y=\"62.556877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"141.694968\" y=\"67.885119\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"106.093586\" y=\"77.585043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"85.199189\" y=\"87.156956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.044037\" y=\"58.183763\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.598942\" y=\"82.54097\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.157904\" y=\"63.575948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.28948\" y=\"76.863967\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.132618\" y=\"99.133675\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.697074\" y=\"66.921095\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"182.751259\" y=\"52.645248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"136.206545\" y=\"79.424332\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.563205\" y=\"63.33256\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"143.903969\" y=\"39.476263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"85.87899\" y=\"86.515271\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.267502\" y=\"99.654722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.307719\" y=\"91.443661\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.555387\" y=\"93.766817\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.017868\" y=\"72.543665\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.969671\" y=\"96.980838\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"118.293017\" y=\"93.142453\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"78.994584\" y=\"130.32799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.427291\" y=\"37.928601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"166.354605\" y=\"62.978298\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.483096\" y=\"73.937807\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.54527\" y=\"88.439678\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.541587\" y=\"109.732608\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.425463\" y=\"97.713903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.188517\" y=\"51.397677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.721828\" y=\"69.78173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.177918\" y=\"71.655387\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"129.965602\" y=\"74.834836\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"188.57917\" y=\"52.43887\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.583692\" y=\"78.713174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.018702\" y=\"70.531854\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"122.213885\" y=\"61.076881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.605197\" y=\"74.547729\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.640975\" y=\"52.674687\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"139.011495\" y=\"59.810942\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"140.194426\" y=\"61.533266\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"116.221769\" y=\"105.538605\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"113.302124\" y=\"83.827882\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.453243\" y=\"73.022932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.00141\" y=\"72.99407\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.698996\" y=\"64.55689\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.138168\" y=\"83.376626\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.811148\" y=\"91.934398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"120.818379\" y=\"85.236683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"111.508163\" y=\"80.325857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.762443\" y=\"53.38592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"87.850859\" y=\"86.51086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"132.383111\" y=\"68.541043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"68.207159\" y=\"100.24009\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"94.417239\" y=\"118.103977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"99.672379\" y=\"90.561111\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"156.416054\" y=\"69.697515\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"148.346262\" y=\"62.456778\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"131.383049\" y=\"94.957518\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.253293\" y=\"92.102869\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"123.880967\" y=\"66.853116\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"84.0285\" y=\"90.435422\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"125.009441\" y=\"71.333254\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.573869\" y=\"103.614709\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"121.573603\" y=\"98.96007\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"145.108641\" y=\"81.294635\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.700306\" y=\"81.23083\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"85.120846\" y=\"102.947303\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"157.863831\" y=\"79.235428\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"91.39912\" y=\"82.178295\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.719783\" y=\"91.059508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"119.136266\" y=\"86.045153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"95.852558\" y=\"65.405451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.931748\" y=\"69.00258\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"171.923474\" y=\"82.574475\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"81.203872\" y=\"115.920234\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.399908\" y=\"89.551559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.549853\" y=\"77.133567\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"152.650045\" y=\"68.029976\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.900625\" y=\"84.591819\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.236454\" y=\"95.674044\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"100.441901\" y=\"83.951852\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"178.453651\" y=\"48.107719\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"78.528815\" y=\"91.144692\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"84.272931\" y=\"77.966158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.235085\" y=\"101.867718\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"128.639236\" y=\"69.104578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"108.173343\" y=\"95.437832\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"150.640558\" y=\"91.398395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"127.366991\" y=\"82.985289\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"93.357063\" y=\"113.470475\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"114.19085\" y=\"87.582783\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"98.92588\" y=\"80.594545\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"163.507434\" y=\"75.882131\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.130443\" y=\"83.48542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"138.525102\" y=\"75.831255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"171.416936\" y=\"84.442152\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"105.333151\" y=\"66.885205\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"112.185721\" y=\"87.367559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"92.657561\" y=\"75.389946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"103.15855\" y=\"62.102534\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"89.341837\" y=\"89.780347\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"159.317039\" y=\"73.903159\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"71.70301\" y=\"115.759169\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"101.533778\" y=\"99.445677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"146.90197\" y=\"100.660773\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.346168\" y=\"95.951702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"109.431077\" y=\"91.992748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.271051\" y=\"93.511792\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"115.176293\" y=\"93.644631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"193.891924\" y=\"39.124589\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"134.574687\" y=\"89.347345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"137.69041\" y=\"69.862951\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"104.956908\" y=\"101.115803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#m823589f946\" x=\"154.691024\" y=\"68.037402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m6ff9f381ac\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6ff9f381ac\" x=\"69.573382\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −2 -->\n",
       "      <g transform=\"translate(62.202288 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6ff9f381ac\" x=\"125.776441\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(122.595191 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6ff9f381ac\" x=\"181.979501\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(178.798251 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <defs>\n",
       "       <path id=\"m28622f4ef6\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m28622f4ef6\" x=\"28.942188\" y=\"125.71812\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- −5 -->\n",
       "      <g transform=\"translate(7.2 129.517339) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m28622f4ef6\" x=\"28.942188\" y=\"99.751174\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(15.579688 103.550393) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m28622f4ef6\" x=\"28.942188\" y=\"73.784228\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(15.579688 77.583446) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m28622f4ef6\" x=\"28.942188\" y=\"47.817281\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(9.217188 51.6165) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m28622f4ef6\" x=\"28.942188\" y=\"21.850335\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(9.217188 25.649554) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 28.942188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 224.242188 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 28.942188 7.2 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p4610e2cf3f\">\n",
       "   <rect x=\"28.942188\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘图，查看分布\n",
    "d2l.set_figsize()\n",
    "d2l.plt.scatter(features[:, (0)].detach().numpy(), \n",
    "                labels.detach().numpy(), 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2. <a id='toc8_1_2_'></a>[读取数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7269, -0.1631],\n",
      "        [ 2.0933, -0.5410],\n",
      "        [ 0.7562, -0.6686],\n",
      "        [-0.4302,  0.3302],\n",
      "        [-0.1591,  1.4465],\n",
      "        [ 0.7235, -0.8781],\n",
      "        [ 0.0123,  0.3597],\n",
      "        [ 1.0409, -2.0936],\n",
      "        [ 0.6744, -0.2588],\n",
      "        [-0.2561, -0.4138]]) \n",
      " tensor([[ 6.2141],\n",
      "        [10.2228],\n",
      "        [ 7.9691],\n",
      "        [ 2.2033],\n",
      "        [-1.0338],\n",
      "        [ 8.6305],\n",
      "        [ 2.9873],\n",
      "        [13.3875],\n",
      "        [ 6.4233],\n",
      "        [ 5.0989]])\n"
     ]
    }
   ],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # 这些样本是随机读取的，没有特定的顺序\n",
    "    random.shuffle(indices)                                 # 把原来的indices顺序给打乱了\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "batch_size = 10\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.3. <a id='toc8_1_3_'></a>[初始化模型参数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.normal(mean=0, std=0.01, size=(2,1), requires_grad=True)\n",
    "b = torch.zeros(size=(1,), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.4. <a id='toc8_1_4_'></a>[定义模型](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b): \n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return torch.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.5. <a id='toc8_1_5_'></a>[定义损失函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):  \n",
    "    \"\"\"均方损失\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.6. <a id='toc8_1_6_'></a>[定义优化算法](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):  \n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.7. <a id='toc8_1_7_'></a>[训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000051\n",
      "epoch 2, loss 0.000056\n",
      "epoch 3, loss 0.000051\n",
      "epoch 4, loss 0.000050\n",
      "epoch 5, loss 0.000048\n",
      "epoch 6, loss 0.000052\n",
      "epoch 7, loss 0.000052\n",
      "epoch 8, loss 0.000049\n",
      "epoch 9, loss 0.000049\n",
      "epoch 10, loss 0.000049\n",
      "w的估计误差: tensor([-0.0010,  0.0004], grad_fn=<SubBackward0>)\n",
      "b的估计误差: tensor([-0.0013], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "num_epochs = 10\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y)  # X和y的小批量损失\n",
    "        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n",
    "        # 并以此计算关于[w,b]的梯度\n",
    "        l.sum().backward()\n",
    "        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n",
    "\n",
    "print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')\n",
    "print(f'b的估计误差: {true_b - b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. <a id='toc8_2_'></a>[现线性回归模型于训练过程-简洁实现](#toc0_)\n",
    "### 8.2.1. <a id='toc8_2_1_'></a>[虚拟数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2. <a id='toc8_2_2_'></a>[读取数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3. <a id='toc8_2_3_'></a>[定义模型](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn是神经网络的缩写\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.4. <a id='toc8_2_4_'></a>[初始化模型参数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.5. <a id='toc8_2_5_'></a>[定义损失函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.6. <a id='toc8_2_6_'></a>[定义优化算法](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "trainer = optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.7. <a id='toc8_2_7_'></a>[训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000298\n",
      "epoch 2, loss 0.000098\n",
      "epoch 3, loss 0.000099\n",
      "epoch 4, loss 0.000098\n",
      "epoch 5, loss 0.000100\n",
      "epoch 6, loss 0.000099\n",
      "epoch 7, loss 0.000099\n",
      "epoch 8, loss 0.000099\n",
      "epoch 9, loss 0.000100\n",
      "epoch 10, loss 0.000098\n",
      "w的估计误差： tensor([-0.0003,  0.0004])\n",
      "b的估计误差： tensor([-0.0004])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        y_hat = net(X)                  # 1. 计算y_hat\n",
    "        loss = loss_fn(y_hat ,y)        # 2. 计算loss值\n",
    "        trainer.zero_grad()\n",
    "        loss.backward()                 # 2. 求梯度           \n",
    "        trainer.step()                  # 3. 更新网络权重参数\n",
    "    train_loss = loss_fn(net(features), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {train_loss:f}')\n",
    "\n",
    "w = net[0].weight.data\n",
    "print('w的估计误差：', true_w - w.reshape(true_w.shape))\n",
    "b = net[0].bias.data\n",
    "print('b的估计误差：', true_b - b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.8. <a id='toc8_2_8_'></a>[参数保存](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"epoch\": num_epochs, \n",
    "        'mode_state_dict': net.state_dict(), \n",
    "        'opt_state_dict': trainer.state_dict(), \n",
    "        'loss': 'loss'\n",
    "    }, \n",
    "    'Pytorch_params/line_params.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.9. <a id='toc8_2_9_'></a>[重载](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0603])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32820/1977999358.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  check_point = torch.load('./Pytorch_params/line_params.pt')\n"
     ]
    }
   ],
   "source": [
    "check_point = torch.load('./Pytorch_params/line_params.pt')\n",
    "\n",
    "new_net = net = nn.Sequential(nn.Linear(2, 1))\n",
    "new_net.load_state_dict(check_point['mode_state_dict'])\n",
    "\n",
    "new_opt = optim.SGD(new_net.parameters(), lr=0.03)\n",
    "new_opt.load_state_dict(check_point['opt_state_dict'])\n",
    "\n",
    "# Stop BN、Dropout ...\n",
    "new_net.eval()\n",
    "\n",
    "# 停止计算梯度，节省运算和内存\n",
    "with torch.no_grad():\n",
    "    pre = new_net(torch.Tensor([3.0, 2.1]))\n",
    "    print(pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. <a id='toc8_3_'></a>[专题-模型定义（计算预测值y_hat）](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1. <a id='toc8_3_1_'></a>[块：torch.nn模块](#toc0_)\n",
    "```shell\n",
    "1. 简单、快速，但不够灵活\n",
    "```\n",
    "```shell\n",
    "优点：\n",
    "    一般，pytorch的nn.Sequentail类就比较方便的快速构建神经网络的框架；\n",
    "    同时，nn也包含了很多完整的神经网络如：CNN、RNN等；\n",
    "缺点：\n",
    "    高度封装，需要复杂的自定义神经网络时就不适用了。\n",
    "```\n",
    "\n",
    "1. nn.`Sequential`(module1, module2, module3, ...)\n",
    "    1. .append()\n",
    "    2. .extend()\n",
    "    3. .insert()\n",
    "    4. .pop()\n",
    "    5. add_module()\n",
    "\n",
    "2. nn.`ModuleList`([module1, module2, modeul3, ...])\n",
    "    1. .append()    # 追加\n",
    "    2. .extend()    # 拼接两个ModuleList\n",
    "    3. .insert()    # 指定位置插入\n",
    "    4. .add_module()\n",
    "\n",
    "3. nn.`ModuleDict`({'m1': module1, 'm2': module2, 'm3': module3, ...})\n",
    "    1. clear()  # 清空ModuleDict\n",
    "    2. items()  # 返回可迭代key: value\n",
    "    3. keys()   # 返回keys\n",
    "    4. values() # 返回values\n",
    "    5. pop()    # 返回一对key: value，并从字典中删除\n",
    "    6. add_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(nn.ModuleDict), help(nn.ModuleList), help(nn.Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=786, out_features=256, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (6): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(786, 256), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(256, 256), \n",
    "    nn.Tanh(),\n",
    "    nn.Linear(256, 10), \n",
    "    nn.Softmax()\n",
    ")\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-2): 3 x Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=786, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (6): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = nn.ModuleList([net, net, net])\n",
    "net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (m1): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=786, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (6): Softmax(dim=None)\n",
       "  )\n",
       "  (m2): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=786, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (6): Softmax(dim=None)\n",
       "  )\n",
       "  (m3): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=786, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (6): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = nn.ModuleDict(\n",
    "    {\n",
    "        'm1': net,\n",
    "        'm2': net, \n",
    "        'm3': net\n",
    "    }\n",
    ")\n",
    "net2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2. <a id='toc8_3_2_'></a>[块：自定义](#toc0_)\n",
    "```shell\n",
    "2. 灵活，但麻烦\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2.1. <a id='toc8_3_2_1_'></a>[自定义块](#toc0_)\n",
    "\n",
    "* 从编程的角度看：块就是Class\n",
    "\n",
    "* `nn.Module`会自动调用`forward()`方法，我们也可以重写该方法，从而实现更加灵活的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''定义每个块或层'''\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''正向传播'''\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2.2. <a id='toc8_3_2_2_'></a>[顺序块](#toc0_)\n",
    "```\n",
    "Sequential就是顺序块，这里我们自己从头实现一边Sequential这个方法\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Sequential()\n",
    "\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "\n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2.3. <a id='toc8_3_2_3_'></a>[效率](#toc0_)\n",
    "```shell\n",
    "1. 一个块可以由许多层组成；一个块可以由许多块组成。\n",
    "2. 块可以包含代码。\n",
    "3. 块负责大量的内部处理，包括参数初始化和反向传播。\n",
    "4. 层和块的顺序连接由Sequential块处理。\n",
    "```\n",
    "```shell\n",
    "读者可能会开始担心操作效率的问题。 毕竟，我们在一个高性能的深度学习库中进行了大量的字典查找、 代码执行和许多其他的Python代码。 Python的问题全局解释器锁 是众所周知的。 在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.3. <a id='toc8_3_3_'></a>[模型结构/组成](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 3)\n",
    "        self.block = nn.Sequential(nn.Linear(3, 128))\n",
    "        self.decode = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        y = self.linear(X)\n",
    "        y = self.bloack(y)\n",
    "        y = self.decode(y)\n",
    "        return y\n",
    "\n",
    "# Init the Net()\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.3.1. <a id='toc8_3_3_1_'></a>[.children()](#toc0_)\n",
    "列出`第一级别`的module权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=2, out_features=3, bias=True),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=3, out_features=128, bias=True)\n",
       " ),\n",
       " Linear(in_features=128, out_features=2, bias=True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net\n",
    "list(net.children())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.3.2. <a id='toc8_3_3_2_'></a>[.named_children()](#toc0_)\n",
    "列出`第一级别`的module权重名称和权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear \t Linear(in_features=2, out_features=3, bias=True)\n",
      "block \t Sequential(\n",
      "  (0): Linear(in_features=3, out_features=128, bias=True)\n",
      ")\n",
      "decode \t Linear(in_features=128, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, children in net.named_children():\n",
    "    print(name, '\\t', children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.3.3. <a id='toc8_3_3_3_'></a>[.modules()](#toc0_)\n",
    "依次列出`所有`的module权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (linear): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (block): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
      "  )\n",
      "  (decode): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "==========\n",
      "Linear(in_features=2, out_features=3, bias=True)\n",
      "==========\n",
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=128, bias=True)\n",
      ")\n",
      "==========\n",
      "Linear(in_features=3, out_features=128, bias=True)\n",
      "==========\n",
      "Linear(in_features=128, out_features=2, bias=True)\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "for module in net.modules():\n",
    "    print( module)\n",
    "    print('='*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.3.4. <a id='toc8_3_3_4_'></a>[.named_modules()](#toc0_)\n",
    "依次列出`所有`的module权重名和权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>> Net(\n",
      "  (linear): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (block): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
      "  )\n",
      "  (decode): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "==========\n",
      "linear >>> Linear(in_features=2, out_features=3, bias=True)\n",
      "==========\n",
      "block >>> Sequential(\n",
      "  (0): Linear(in_features=3, out_features=128, bias=True)\n",
      ")\n",
      "==========\n",
      "block.0 >>> Linear(in_features=3, out_features=128, bias=True)\n",
      "==========\n",
      "decode >>> Linear(in_features=128, out_features=2, bias=True)\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "for name, module in net.named_modules():\n",
    "    print(name, '>>>', module)\n",
    "    print('='*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.3.5. <a id='toc8_3_3_5_'></a>[删除和添加](#toc0_)\n",
    "先利用 net`.children()`迭代话模型第一层级，再`列表化 (list())` 并进行`索引提取`，最终实现删除或添加的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Linear(in_features=2, out_features=3, bias=True)\n",
       "   (1): Sequential(\n",
       "     (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "   )\n",
       "   (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "   (3): Linear(in_features=256, out_features=2, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 3)\n",
    "        self.block = nn.Sequential(nn.Linear(3, 128))\n",
    "        self.decode = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        y = self.linear(X)\n",
    "        y = self.bloack(y)\n",
    "        y = self.decode(y)\n",
    "        return y\n",
    "\n",
    "class NetDel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.net = Net()                                              ## 会报错\n",
    "        self.netdel_list = list(Net().children())[0:-1]                 # 删除最后一个结构\n",
    "        self.netdel_list += [nn.Linear(128, 256), nn.Linear(256, 2)]    # 添加两个新的结构\n",
    "        self.netdel = nn.Sequential(*self.netdel_list)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.netdel(X)\n",
    "\n",
    "netdel = NetDel()\n",
    "# netdel\n",
    "list(netdel.children())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.3.6. <a id='toc8_3_3_6_'></a>[替换](#toc0_)\n",
    "直接访`问模型的具体层级`，`替换`即可。\n",
    "\n",
    "* 当通过 `Sequential类` 定义模型时，我们可以通过 `索引 (下标)` 来访问模型的任意层；\n",
    "\n",
    "* `自定义的重载nn.Module` 的layer1、layer2等等，需要net`.`layer1或net`.`layer2方式进行调用；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetMod(\n",
       "  (model): Net(\n",
       "    (linear): Linear(in_features=2, out_features=3, bias=True)\n",
       "    (block): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "    )\n",
       "    (decode): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 3)\n",
    "        self.block = nn.Sequential(nn.Linear(3, 128))\n",
    "        self.decode = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        y = self.linear(X)\n",
    "        y = self.bloack(y)\n",
    "        y = self.decode(y)\n",
    "        return y\n",
    "\n",
    "class NetMod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Net()\n",
    "        in_features = self.model.decode.in_features\n",
    "        self.model.decode = nn.Linear(in_features=in_features, out_features=10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "netmod = NetMod()\n",
    "netmod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.3.7. <a id='toc8_3_3_7_'></a>[add_module()](#toc0_)\n",
    "`add_module()` 方法用于将子模块添加到当前模块中，并为其指定一个名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear): Linear(in_features=2, out_features=3, bias=True)\n",
       "  (block): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "  )\n",
       "  (decode): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (add_demo): Linear(in_features=2, out_features=256, bias=True)\n",
       "  (final_demo): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 3)\n",
    "        self.block = nn.Sequential(nn.Linear(3, 128))\n",
    "        self.decode = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        y = self.linear(X)\n",
    "        y = self.bloack(y)\n",
    "        y = self.decode(y)\n",
    "        return y\n",
    "\n",
    "net = Net()\n",
    "net.add_module(name='add_demo', module=nn.Linear(2, 256))\n",
    "net.add_module(name='final_demo', module=nn.Sequential(nn.Linear(256, 128), nn.Linear(128, 2)))\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.4. <a id='toc8_3_4_'></a>[模型：参数管理](#toc0_)\n",
    "\n",
    "* 其实可以将`nn.Sequential`视为Python的`list数据结构`，`按顺序`储存神经网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0865],\n",
       "        [-0.0746]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 8), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.4.1. <a id='toc8_3_4_1_'></a>[参数访问](#toc0_)\n",
    "\n",
    "* 我们从已有模型中访问参数；\n",
    "\n",
    "* 当通过 `Sequential类` 定义模型时，我们可以通过 `索引 (下标)` 来访问模型的任意层；\n",
    "\n",
    "* `自定义的重载nn.Module` 的layer1、layer2等等，需要net`.`layer1或net`.`layer2方式进行调用；\n",
    "\n",
    "* 这就像模型是一个列表一样，每层的参数都在其属性中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.3.4.1.1. <a id='toc8_3_4_1_1_'></a>[state_dict](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net # nn.Sequential类，可以直接用下标进行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=4, out_features=8, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=8, out_features=1, bias=True))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0], net[1], net[2] # nn.Sequential类，可以直接用下标进行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],\n",
       "                      [-0.1280, -0.2531, -0.0131, -0.2696],\n",
       "                      [ 0.0538,  0.1759, -0.1103, -0.3805],\n",
       "                      [-0.2477, -0.0914,  0.1431,  0.2419],\n",
       "                      [ 0.1345, -0.0516, -0.0536, -0.4364],\n",
       "                      [ 0.1144, -0.3585, -0.2615,  0.1957],\n",
       "                      [ 0.2924,  0.0015,  0.4087,  0.3759],\n",
       "                      [ 0.4440, -0.2937, -0.0911, -0.4929]])),\n",
       "             ('bias',\n",
       "              tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880]))])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],\n",
       "        [-0.1280, -0.2531, -0.0131, -0.2696],\n",
       "        [ 0.0538,  0.1759, -0.1103, -0.3805],\n",
       "        [-0.2477, -0.0914,  0.1431,  0.2419],\n",
       "        [ 0.1345, -0.0516, -0.0536, -0.4364],\n",
       "        [ 0.1144, -0.3585, -0.2615,  0.1957],\n",
       "        [ 0.2924,  0.0015,  0.4087,  0.3759],\n",
       "        [ 0.4440, -0.2937, -0.0911, -0.4929]], requires_grad=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],\n",
       "        [-0.1280, -0.2531, -0.0131, -0.2696],\n",
       "        [ 0.0538,  0.1759, -0.1103, -0.3805],\n",
       "        [-0.2477, -0.0914,  0.1431,  0.2419],\n",
       "        [ 0.1345, -0.0516, -0.0536, -0.4364],\n",
       "        [ 0.1144, -0.3585, -0.2615,  0.1957],\n",
       "        [ 0.2924,  0.0015,  0.4087,  0.3759],\n",
       "        [ 0.4440, -0.2937, -0.0911, -0.4929]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data # 访问目标参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].bias.data # 访问目标参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],\n",
       "                      [-0.1280, -0.2531, -0.0131, -0.2696],\n",
       "                      [ 0.0538,  0.1759, -0.1103, -0.3805],\n",
       "                      [-0.2477, -0.0914,  0.1431,  0.2419],\n",
       "                      [ 0.1345, -0.0516, -0.0536, -0.4364],\n",
       "                      [ 0.1144, -0.3585, -0.2615,  0.1957],\n",
       "                      [ 0.2924,  0.0015,  0.4087,  0.3759],\n",
       "                      [ 0.4440, -0.2937, -0.0911, -0.4929]])),\n",
       "             ('0.bias',\n",
       "              tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880])),\n",
       "             ('2.weight',\n",
       "              tensor([[-0.0894, -0.1603, -0.1185,  0.0858, -0.0592, -0.1632,  0.1876, -0.0784]])),\n",
       "             ('2.bias', tensor([-0.1285]))])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以直接输出神经网络的所有层参数信息，net[1]是relu激活函数，没有参数，所以就显示无\n",
    "# 后续，torch.save(net.state_dict(), 'Pytorch_datasets/net_params)\n",
    "net.state_dict() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.3.4.1.2. <a id='toc8_3_4_1_2_'></a>[parameters](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<generator object Module.parameters at 0x7f0dc565da80>,\n",
       " <bound method Module.parameters of Sequential(\n",
       "   (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
       " )>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters(), net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],\n",
      "        [-0.1280, -0.2531, -0.0131, -0.2696],\n",
      "        [ 0.0538,  0.1759, -0.1103, -0.3805],\n",
      "        [-0.2477, -0.0914,  0.1431,  0.2419],\n",
      "        [ 0.1345, -0.0516, -0.0536, -0.4364],\n",
      "        [ 0.1144, -0.3585, -0.2615,  0.1957],\n",
      "        [ 0.2924,  0.0015,  0.4087,  0.3759],\n",
      "        [ 0.4440, -0.2937, -0.0911, -0.4929]], requires_grad=True)\n",
      "True\n",
      "None\n",
      "True\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880],\n",
      "       requires_grad=True)\n",
      "True\n",
      "None\n",
      "True\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([[-0.0894, -0.1603, -0.1185,  0.0858, -0.0592, -0.1632,  0.1876, -0.0784]],\n",
      "       requires_grad=True)\n",
      "True\n",
      "None\n",
      "True\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.1285], requires_grad=True)\n",
      "True\n",
      "None\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(type(param))\n",
    "    print(param)\n",
    "    print(param.requires_grad)\n",
    "    print(param.grad)\n",
    "    print(param.is_leaf)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],\n",
      "        [-0.1280, -0.2531, -0.0131, -0.2696],\n",
      "        [ 0.0538,  0.1759, -0.1103, -0.3805],\n",
      "        [-0.2477, -0.0914,  0.1431,  0.2419],\n",
      "        [ 0.1345, -0.0516, -0.0536, -0.4364],\n",
      "        [ 0.1144, -0.3585, -0.2615,  0.1957],\n",
      "        [ 0.2924,  0.0015,  0.4087,  0.3759],\n",
      "        [ 0.4440, -0.2937, -0.0911, -0.4929]], requires_grad=True)\n",
      "True\n",
      "None\n",
      "True\n",
      "Parameter containing:\n",
      "tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880],\n",
      "       requires_grad=True)\n",
      "True\n",
      "None\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param  in net[0].parameters():\n",
    "    print(param)\n",
    "    print(param.requires_grad)\n",
    "    print(param.grad)\n",
    "    print(param.is_leaf)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.3.4.1.3. <a id='toc8_3_4_1_3_'></a>[named_parameters](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight \t Parameter containing:\n",
      "tensor([[ 0.4129, -0.2663,  0.0648, -0.3372],\n",
      "        [-0.1280, -0.2531, -0.0131, -0.2696],\n",
      "        [ 0.0538,  0.1759, -0.1103, -0.3805],\n",
      "        [-0.2477, -0.0914,  0.1431,  0.2419],\n",
      "        [ 0.1345, -0.0516, -0.0536, -0.4364],\n",
      "        [ 0.1144, -0.3585, -0.2615,  0.1957],\n",
      "        [ 0.2924,  0.0015,  0.4087,  0.3759],\n",
      "        [ 0.4440, -0.2937, -0.0911, -0.4929]], requires_grad=True)\n",
      "0.bias \t Parameter containing:\n",
      "tensor([-0.4462,  0.1640,  0.4165, -0.2921, -0.0450, -0.2606, -0.1634,  0.2880],\n",
      "       requires_grad=True)\n",
      "2.weight \t Parameter containing:\n",
      "tensor([[-0.0894, -0.1603, -0.1185,  0.0858, -0.0592, -0.1632,  0.1876, -0.0784]],\n",
      "       requires_grad=True)\n",
      "2.bias \t Parameter containing:\n",
      "tensor([-0.1285], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# list(net.named_parameters())\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, '\\t', param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.4.2. <a id='toc8_3_4_2_'></a>[参数初始化](#toc0_)\n",
    "\n",
    "* 初始化，主要是为了不要再一开始训练就炸掉了，其实不用太迷信了。\n",
    "\n",
    "* 默认情况下，PyTorch会根据一个范围均匀地初始化权重和偏置矩阵， 这个范围是根据输入和输出维度计算出的。 \n",
    "\n",
    "* PyTorch的nn.init模块提供了多种预置初始化方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.3.4.2.1. <a id='toc8_3_4_2_1_'></a>[内置初始化](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = net[0]\n",
    "nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.3.4.2.2. <a id='toc8_3_4_2_2_'></a>[自定义初始化](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.3.4.2.3. <a id='toc8_3_4_2_3_'></a>[参数绑定](#toc0_)\n",
    "```\n",
    "有时我们希望在多个层间共享参数： 我们可以定义一个稠密层，然后使用它的参数来设置另一个层的参数。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# 我们需要给共享层一个名称，以便可以引用它的参数\n",
    "shared = nn.Linear(8, 8)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 8), \n",
    "    nn.ReLU(),\n",
    "    shared, \n",
    "    nn.ReLU(),\n",
    "    shared, \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "net(X)\n",
    "\n",
    "# 检查参数是否相同\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "\n",
    "net[2].weight.data[0, 0] = 100\n",
    "\n",
    "# 确保它们实际上是同一个对象，而不只是有相同的值\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.5. <a id='toc8_3_5_'></a>[层：自定义](#toc0_)\n",
    "```shell\n",
    "深度学习成功背后的一个因素是神经网络的灵活性： \n",
    "我们可以用创造性的方式组合不同的层，从而设计出适用于各种任务的架构。 \n",
    "例如，研究人员发明了专门用于处理图像、文本、序列数据和执行动态规划的层。 \n",
    "有时我们会遇到或要自己发明一个现在在深度学习框架中还不存在的层。 \n",
    "在这些情况下，必须构建自定义层。本节将展示如何构建自定义层。\n",
    "```\n",
    "```shell\n",
    "块和层其实并无本质的区别，因为都是torch.nn.Module的子类\n",
    "\n",
    "e.g. \n",
    "    全连接层（FC）\n",
    "    池化层（Pooling）\n",
    "    BN层\n",
    "    Dropout层\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.5.1. <a id='toc8_3_5_1_'></a>[不带参数的层](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  0.,  1.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()\n",
    "    \n",
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-9.3132e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在，我们可以将层作为组件合并到更复杂的模型中。\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(8, 128), \n",
    "    CenteredLayer()\n",
    ")\n",
    "\n",
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.5.2. <a id='toc8_3_5_2_'></a>[带参数的层](#toc0_)\n",
    "\n",
    "用到`nn.Parameter()`可以将参数加入神经网络中，便于自动管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000],\n",
       "        [0.1466, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units)) \n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)\n",
    "    \n",
    "linear = MyLinear(5, 3)\n",
    "# linear.weight\n",
    "\n",
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们还可以使用自定义层构建模型，就像使用内置的全连接层一样使用自定义层。\n",
    "net = nn.Sequential(\n",
    "    MyLinear(64, 8), \n",
    "    MyLinear(8, 1)\n",
    ")\n",
    "\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4. <a id='toc8_4_'></a>[专题-损失函数 (loss_fn)](#toc0_)\n",
    "- 损失函数的输入是 (output, target) ，即网络输出和真实标签对的数据，然后返回一个数值表示网络输出和真实标签的差距。\n",
    "\n",
    "  1. 均方误差\n",
    "\n",
    "  2. 交叉熵\n",
    "  \n",
    "  3. 自定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.1. <a id='toc8_4_1_'></a>[均方误差](#toc0_)\n",
    "回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.2. <a id='toc8_4_2_'></a>[交叉熵](#toc0_)\n",
    "分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.3. <a id='toc8_4_3_'></a>[自定义](#toc0_)\n",
    "自己定义赏罚分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y, y_hat):\n",
    "    '''例如真实值于预测值之差'''\n",
    "    error_values = y - y_hat\n",
    "    return error_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5. <a id='toc8_5_'></a>[专题-反向传播（求梯度）](#toc0_)\n",
    "```\n",
    "求梯度（求偏导数）\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 见autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6. <a id='toc8_6_'></a>[专题-更新权重（优化算法）](#toc0_)\n",
    "- 优化算法，在深度学习中是非常重要的一环。在对损失函数进行优化的时候，比较关注损失函数的凹凸性的问题。  \n",
    "- 可惜的是，在现有损失函数中，只有线性函数网络结构和softmax结构是凸函数，其它例如MLP、CNN、RNN、注意力等都是非凸函数。  \n",
    "- 并且，在优化过程中通常只是得到了局部最小值，而不是全局最小值；\n",
    "- 小批量随机梯度下降算法是最常用的优化算法；\n",
    "- 冲量对梯度做平滑；\n",
    "- Adam对梯度做平滑，且对梯度各纬度值重新做调整。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 原函数图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Function')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADtCAYAAACms3k/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgEklEQVR4nO3deXxU5b3H8c/MhEwSkkwgKyEhCRA2AyRhj6BQbBStSq2tC1JxaasNqFBtC74EwVtTsVe5rcC9VgVcUFywKGolliVg2HcIIBBIAkkgYZnJvsyc+8ckkRASsszMmZP83q/X+SPDzDk/wnx5zjnPeZ5HpyiKghBCFXq1CxCiM5MACqEiCaAQKpIACqEiCaAQKpIACqEiCaAQKpIACqEiCaAQKpIAurnly5ej0+muuT377LOq1bVy5UoWLVp0zT/T6XS8+OKLLq1HqzzULkC0zLJlyxgwYECD18LDw1Wqxh7AQ4cO8cwzzzT6s61btxIREeH6ojRIAqgRcXFxDB8+XO0yWmT06NFql6AZcgqqcU2d7kVHRzNt2rT6n+tOZTds2MCTTz5JUFAQgYGB3HPPPeTl5TX6/MqVKxkzZgy+vr74+voSHx/P22+/DcD48eP56quvyM7ObnBK3FxNhw4d4u6776Zbt254eXkRHx/PihUrGrxn48aN6HQ6PvzwQ55//nnCw8Px9/fnlltu4dixY23/JbkxCaBGWK1WampqGmxt8fjjj9OlSxdWrlzJwoUL2bhxIw899FCD98ydO5cpU6YQHh7O8uXL+fzzz3n44YfJzs4GYMmSJdx4442EhYWxdevW+q0px44dIykpicOHD/P3v/+d1atXM2jQIKZNm8bChQsbvX/OnDlkZ2fz1ltv8eabb3L8+HHuvPNOrFZrm/7Obk0Rbm3ZsmUKcM2turpaAZR58+Y1+lxUVJTy8MMPN9rP73//+wbvW7hwoQIo+fn5iqIoSlZWlmIwGJQpU6Y0W9cdd9yhREVFXfPPrq7p/vvvV4xGo5KTk9PgfZMmTVJ8fHyUy5cvK4qiKBs2bFAA5fbbb2/wvo8//lgBlK1btzZbkxZJC6gR7777Ljt37myweXi0/hL+rrvuavDzkCFDAOpbt7S0NKxWKykpKe0vutb69euZOHEikZGRDV6fNm0aZWVljVrP69XYkchNGI0YOHCgQ27CBAYGNvjZaDQCUF5eDkBhYSGAQ+9iXrhwgR49ejR6ve4u7oULF1pVY0ciLaDGGY1GKisrG71+9Ze6pYKDgwE4c+ZMu+q6UmBgIPn5+Y1er7v5ExQU5LBjaY0EUOOio6M5cOBAg9fWr19PSUlJm/aXnJyMwWBg6dKlzb7PaDS2uEWaOHEi69evb3S39d1338XHx6dTd1vIKajGTZ06lRdeeIG5c+dy8803k5mZyRtvvIHJZGrT/qKjo5kzZw4vvfQS5eXlPPDAA5hMJjIzMykqKmL+/PkADB48mNWrV7N06VKGDRuGXq9v8hR53rx5rF27lgkTJjB37ly6d+/OBx98wFdffcXChQvbXGtHIAHUuOeeew6LxcLy5cv529/+xsiRI/n444+5++6727zPBQsWEBsbyz/+8Q+mTJmCh4cHsbGxPPXUU/Xvefrppzl8+DBz5szBbDajKApKE/N79e/fn4yMDObMmUNKSgrl5eUMHDiQZcuWNeir7Ix0SlO/NSGE08k1oBAqkgAKoSIJoBAqkgAKoSIJoBAqkgAKoaJO1Q9os9nIy8vDz8+vwfg1IRxNURSKi4sJDw9Hr2+6netUAczLy2v0RL4QzpSbm9vsg+2dKoB+fn6A/Zfi7++vcjWiI7NYLERGRtZ/55qimQCmpqayevVqjh49ire3N0lJSbzyyiv079+/xfuoO+309/eXAAqXuN6ljmZuwmzatImUlBS2bdtGWloaNTU1JCcnU1paqnZpQrSZZp8FLSwsJCQkhE2bNnHTTTe16DMWiwWTyYTZbJYWUDhVS79rmmkBr2Y2mwHo3r17k++prKzEYrE02IRwBEVRWLzhBOctFe3ajyYDqCgKs2bNYuzYscTFxTX5vtTUVEwmU/0md0CFo6zckcOr3x7jrje+p7yq7bO1aTKA06dP58CBA3z44YfNvm/27NmYzeb6LTc310UVio4sq7CEBV9mAvDY2Bi8PQ1t3pdm7oLWmTFjBl988QXp6enXnTjIaDTWT+gjhKO8tDaTyhob42KDeGxsTLv2pZkAKorCjBkz+Pzzz9m4cSMxMe37iwvRFtuzLrDhWCEeeh3z77oBvb59T1RpJoApKSmsXLmSNWvW4OfnR0FBAQAmkwlvb2+VqxOdxf+lZwHwqxGR9A72bff+NHMNuHTpUsxmM+PHj6dHjx7126pVq9QuTXQSxwqKWX/0PDod/HZcb4fsUzMtoEa7K0UHsuz7UwBMigsjOqirQ/apmRZQCDWVVdXw5X77vKYPj4l22H4lgEK0wDcHCyitshIV6MPImKYf/mgtCaAQLfDpbvtU/fcmRjh0LKkEUIjrKDBXsDXLvtbGzxN7OnTfEkAhrmNdpr3LK7FXABHdfBy6bwmgENfx70P2AN4WF+bwfUsAhWjGxdIqtp+6CMBtNzRe47C9JIBCNOO7I+ew2hQG9fCnV6BjTz9BAihEszYds68YfMugUKfsXwIoRBNqrDa2nCgC4OZ+wU45hgRQiCbsP2PGXF6NybsLQyOcs4ioBFCIJqT/YD/9HNs3CA+Dc6IiARSiCZtqA+is00+QAApxTZdKqzhw5jIAN0kAhXCtjJMXsCnQP9SPMJOX044jARTiGrbVPvs5pk+gU48jARTiGrafsgdwdG8JoBAudaGkkh/OlQA4dOzftUgAhbjKjtpnP/uH+tG9q6dTjyUBFOIqddd/o3o7t/UDCaAQjdSNfnD29R9IAIVo4FJpFUcLigHnX/+BBFCIBnZlXwKgT3BXgnydv6yBBFCIK+zJsQdwWFQ3lxxPAijEFfbUtoCJvSSAQrhUjdXGgTP2hV8TpQUUwrWOFhRTXm3Fz8uDvg5YeKUlJIBC1Kq7/ouPDGj3smMtJQEUoparr/9AAihEvT05lwHXXf+BBFAIAIpKKsm5WAbYT0FdRQIoBD+efsaG+GLy7uKy40oAheCK008XXv+BBFAI4Mc7oIlRAS49rgRQdHrVVlv9BEzSAjYjPT2dO++8k/DwcHQ6Hf/617/ULkl0AMfPlVBRbcPP6EEfF3XA19FUAEtLSxk6dChvvPGG2qWIDuTg2csAxPU0uawDvo6HS4/WTpMmTWLSpElO2Xe11YaHXufQ5YeFNtQ9/znESdPPN0dTLWBrVVZWYrFYGmzXYi6v5qG3trNk40kXVyjcwcGz9gAOlgA6VmpqKiaTqX6LjIy85vv+c+Qc209d5NVvj/HJrlwXVynUVFlj5Ui+/T/moREBLj9+hw7g7NmzMZvN9Vtu7rXDdU9iBL+7uTcAf159sH5WLNHx/VBQQrVVIcCnCxHdvF1+/A4dQKPRiL+/f4OtKX+6dQB3Dg3HalN45qO9mMuqXVipUMv+2u6HwT1Nqlz/d+gAtoZeryP1nsFEB/qQZ65g3heH1C5JuMBBFW/AgMYCWFJSwr59+9i3bx8Ap06dYt++feTk5Dhk/75GDxbdn4BOB//al0fGySKH7Fe4rwN1N2B6BqhyfE0FcNeuXSQkJJCQkADArFmzSEhIYO7cuQ47RnxkAA+NigJg7prDVNXYHLZv4V4qqq38cM4+BaG0gC0wfvx4FEVptC1fvtyhx3k2uT9Bvp6cOF/C8oxTDt23cB+Z+RasNoUgX096OHEJsuZoKoCuYvLpwh9vGwDA4g0nsVTIDZmO6MfrvwDVHsCQADbhF4kRxIb4Yi6v5p/pWWqXI5yg7gmYwT3VOf0ECWCTDHodf0juD8DbW05RVFKpckXC0epGQKh1/QcSwGbdekMoQyNMlFVZeVNawQ6ltLKGE4X2NQClBXRTOp2Op2+JBeCDbdnSOd+BHM6zoCgQ5u9FiL86N2BAAnhdE/qHMCDMj9IqKyu2nla7HOEgdaefajyAfSUJ4HXodDqeHN8HgGXfn6KsqkblioQj1I2AGKLi6SdIAFvkjsE96NXdh0tl1azaKaMlOoL6LggXTkF4LRLAFvAw6OtHS7y1+RQ1Vnk6RsssFdVkFZUC6t6AAQlgi/0iMYLuXT05e7mctMxzapcj2uFQbesX0c2b7l09Va1FAthCXl0MTBnVC4B3vpfH07Ss7gFsNfv/6kgAW+Gh0VF0MejYefpS/V00oT0Hz6g7AuJKEsBWCPX34mdDwgFY9v1pdYsRbXagdhY0aQE16JEbowFYeyCP85YKdYsRrXaptIrci+WAfRpCtUkAW2lIRADDo7pRbVV4f1u22uWIVqrr/4sJ6urSRVia0uoATps2jfT0dGfUohmPjo0B4P3tOVRUW1WuRrRG/RSEbtD6QRsCWFxcTHJyMrGxsbz88sucPXvWGXW5teRBofQM8OZiaRVf7MtTuxzRCvtzLwMaDuBnn33G2bNnmT59Op988gnR0dFMmjSJTz/9lOrqzvGwsodBz8NJ9mkr3vn+FIqiqFyRaKmDbtQFAW28BgwMDOTpp59m79697Nixg759+zJ16lTCw8OZOXMmx48fd3Sdbue+4b3w8TRwtKCYjJMX1C5HtMD54gryzRXodO5xAwbaeRMmPz+fdevWsW7dOgwGA7fffjuHDx9m0KBBvP76646q0S2ZfLpw77AIAN7ZIh3zWlDX/9c32JeuRvdYFqXVAayuruazzz7jZz/7GVFRUXzyySfMnDmT/Px8VqxYwbp163jvvfdYsGCBM+p1K4/caL8Z85+j58mqHdwp3Nf+M+qtAdGUVv830KNHD2w2Gw888AA7duwgPj6+0XtuvfVWAgICHFCee4sJ6srEASH85+h5lmecZsHdcWqXJJpxsPbpJTXWgGhKq1vA119/nby8PBYvXnzN8AF069aNU6c6x2nZY7VdEp/sOiMj5t2Yoig/TsLkRi1gqwM4depUvLzUG8Lvbsb0CWRAmB/l1VY+2umYGbqF4+WZK7hQWoWHXsegHk2vEeJq8iRMO+l0uvqO+RUZp2WsoJs6UNv/1y/UD68uBnWLuYIE0AHuGhpOYFdP8swV/PtwgdrliGuoG4I0NNJ9Tj9BAugQXl0MTBlt75h/W7ok3FL9JExuMATpShJAB3lodC88DXr25lxmd/YltcsRV7jyBoy7PAFTRwLoICF+XkxOsI8VXLLhhMrViCtlXyijuKIGTw89/cP81C6nAQmgAz1xcx/0OnvH/OE8s9rliFp1q+AO6uFPF4N7feXd43mcDqJ3sC93DAnny/15LNlwksVTEtUuqYHj54r596EC9uZe5kJJJTqdjuhAH8bFBpN8Qyh+XuqPj3MGtVfBbY4E0MFSJvThy/15fH0onxPnS+gb4qt2SRw4c5nUr4+yNavxQ+P7ci/zr315+H/pQcqEvjw6NsbtWon2OnDFMmTuRgLoYAPC/PnpoFDSMs/xxvrjLLo/QbVaSitr+K+vMvlwh30yYYNex4T+wYztG0Rkdx+qrTYy8yysPZBPVlEpqd8c5dvDBSyekkgPk7dqdTuS1aZwKE9awE7l6YmxpGWeY83+PH5zU29uCHf9P/yRfAspK/eQVWifgPaehJ48e2t/wgMaBuu2uB48fUs/PttzhpfWZrIn5zI/X5zBB78ZRZ9g9Vvv9jpZWEJZlRUfT4Nb/n061rmGm4jraeLOoeEoCvz1m6MuP37GiSLuXZpBVmEpYf5efPTb0bx2X3yj8NUx6HX8angkX80YR2yILwWWCu5/cxs5F8pcXLnj1Z1+xoWbMOjVWQW3ORJAJ3kuuT9dDDo2Hy9iy/Eilx133eECpi3fSWmVlaQ+gXz99DhG9w5s0Wd7Bfrw0W9HMyDMj8LiSh5ZvgNzubYfMN+Xa++TdcfTT9BgAJcsWUJMTAxeXl4MGzaMzZs3q13SNfUK9GHKKPvTManfHMFqc/60FZ/vPcOTH+yhqsbGrTeEsuyREa2eej3Q18iKR0fSw+TFycJS/vDxPk1PubEn+zIAiVHd1C2kCZoK4KpVq3jmmWd4/vnn2bt3L+PGjWPSpEnk5LjnKIQZP+mLn9GDw3kWp09huCLjNDNX7cdqU/hFYgSLH0zE6NG2h45D/b3456+H42nQ892R83yw3T1/v9dTVlXD0QILAAm9AtQtpgmaCuBrr73GY489xuOPP87AgQNZtGgRkZGRLF269Jrvr6ysxGKxNNhcKdDXyB9vs68z/+q3xygwO34iX0VR+Md/jjPvi8MATEuK5tV7h+DRzq6EuJ6m+tr/66tMTpwvbnetrnbgjBmbAj1MXm57V1czAayqqmL37t0kJyc3eD05OZmMjIxrfiY1NRWTyVS/RUZGuqLUBh4cFUV8ZAAllTW8sOaQQ0/nFEXh5a+P8N9pPwD2u6/z7hyE3kE3Gx69MYaxfYOoqLYxZ7Vja3eFPTn26z93bf1AQwEsKirCarUSGhra4PXQ0FAKCq49BGj27NmYzeb6LTfX9YtrGvQ6Xv75YDz0OtIyz/G+g07nrDaFP392kH9uto++mPuzQcz8aT90Osfd6dPrdbxy7xC8uxjYcfoin+/V1hywe3MuA5AQ6Z7Xf6ChANa5+gumKEqTXzqj0Yi/v3+DTQ2Dwv35020DAHhpbWa7nxOtqLby5Pu7WbUrF70OXr13SP2gYEfrGeDNjIl9AXj56yOauSuqKEp9ABOjAlStpTmaCWBQUBAGg6FRa3f+/PlGraI7enxcDBMHhFBVY+O37+5u88Iul8uqeOit7azLPIenh54lUxL55XDnnlo/PrY3vYO7UlRSxWKNjPQ4c6mcopJKuhh0qjwI0VKaCaCnpyfDhg0jLS2twetpaWkkJSWpVFXL6XQ6/vbLoUQH+nD2cjkPL9vJxdKqVu0jM8/C5MXfsyv7Ev5eHrz/2Chui+vhpIp/5Omh54U7BgGwPOM0+eZypx+zvequ/waFm9xqCoqraSaAALNmzeKtt97inXfe4ciRI8ycOZOcnByeeOIJtUtrkW5dPXn30VEE+Ro5km/h3qUZnK5dq7w5NpvCe1tP8/Ml33P6Qhk9A7z59MkkRsZ0d0HVduP7BzMyujtVNTYWpbn/zOc/Xv8FqFrH9WgqgPfddx+LFi1iwYIFxMfHk56eztdff01UVJTapbVY3dMmPQO8ySoq5fa/b+bdraepqmk8mZOiKGzLusA9SzN4Yc1hKmts3NwvmLUzxtIv1LUDS3U6HX+aZL+O/WR3LifOu/dExHtrJ2Fy5zugADpFa/eW28FisWAymTCbzardkKlTYK7gqY/2suPURQDC/L24ZVAI/UP90Ot1ZF8oY8PR8xyv/aL7Gj34Q3I/Hh4T7bBuhrZ4fMUuvjtyjnsSe/Lar+JVq6M5FdVWBr/4LdVWhc1/nEBkdx+X19DS75qMhlBJmMmLj34zmve3Z7N4wwkKLBW8v61xF4XRQ8+9wyJ4amIsof7qz8f61MS+fHfkHGv25fHMxH70CnT9l/t6Dp01U21VCPI1EtHNPTvg60gAVaTX6/j1mGjuGxFJ+g9FZJwsIv9yBTU2Gz1M3gyP7sb4fiGYfNxnpPqQiABu6hdM+g+F/G/6SV7++WC1S2pk52n7DZhhUQEO7Rd1BgmgGzB6GPjpoFB+Osj9u1MApk/oS/oPhXy66wxP/SSWMJP6LfOVtp+yj/wfFdOyUSBq0tRNGOEeRsZ0Z2RMd6qsNt5Mz1K7nAasNoVdtS2gK+8St5UEULRJygT70zGrduZgqXCfp2OO5FsoqazBz8uDgW60BkRTJICiTW6KDaJfqC+lVVZW7XD9M7ZN2V57V3lEdHe3HAF/NQmgaBOdTle/NNtyN1qUZkft9Z8WTj9BAija4e74ngR29eTs5XK3WJRGUZT6flUJoOjwvLoYeKh2UZq3Nqu/KM3x8yVcKqvGu4uBODd+APtKEkDRLg+NjsLToGdfrvqL0tRd/yVGBeDpoY2vtjaqFG4r2M9YvyjN21vU7ZLYVjvz98ho9+//qyMBFO322NjeAPz7UAFnLqkzl6jNppBxwj794419JYCiE+kf5sfYvkHYFPvsbGo4nGfhUlk1vkYPhrr5EKQrSQCFQzw6NhqAj3bmUlJZ4/Ljpx8vBGBMn0BNLS6jnUqFWxvfL4TeQV0prqjhs91nXH78utnHx8UGufzY7SEBFA6h1+t45MZoAJZ9fwqbC2YCr1NWVcOubPsd0LF9JYCik7onMQJ/Lw9OXyhj/dHzLjvu9lMXqbYq9AzwJiaoq8uO6wgSQOEwXY0ePDCyFwDvfO+6jvlNx+zXf+Nig9x+/N/VJIDCoX6dFI1BryPj5AWO5Dt/KQBFUUjLPAfATwaEOP14jiYBFA7VM8Cb2+LCAHhni/NbwaMFxZy9XI7RQ8+42GCnH8/RJIDC4R690T5KYs2+PIpKKp16rLrWb1xsEN6e7jv/Z1MkgMLhhkV1Iz4ygCqrjQ+uMdGUI9UFUCvTeVxNAiicom6tive2ZVNZY3XKMfLN5Rw8a0ang58MkAAKUW9SXBhh/l4UlVTy5f58pxyjrvVL7NWNYD+jU47hbBJA4RRdDHp+nWQfK/j2llNOWVvwi315gD3sWiUBFE7z4MheeHcxcCTfQnrto2KOknuxjF3Zl9Dp4K6h4Q7dtytJAIXTBPh48uAoe8f8/3z3g0NbwS/221u/pD6BhLjBjOFtJQEUTvW7m3rj6aFnT85lMk5ecMg+FUWpX6337qE9HbJPtUgAhVOF+HvxYO3jaf/zH8csa7bz9CVOnC/Bx9PAbYO1e/0HEkDhAr+7uTeeBj07Tl1kqwNawQ+2ZwNwd3w4/l7us25GW0gAhdP1MHlz3wj7Mtp//eZIu4YqXSip5JuD9ikQHxypnXUhmyIBFC7x1MRYunoa2H/GzJcH8tq8nxUZp6my2hgaYWJwhDamHmyOBFC4RLCfkd/XrifxyjdHqahu/dMxxRXVLK+dc+aJm/s4sjzVSACFyzw2NoZwkxd55gr+sb71N2Te3ZqNpaKGPsFdufUGbd98qSMBFC7j1cXA3DtvAOD/NmVxOM/c4s+eL65g6caTgH1lJjWX6XYkzQTwL3/5C0lJSfj4+BAQEKB2OaKNbosL4/bBYdTYFGat2k9ZVctmUHvlm2OUVNYwNMLE5Hht9/1dSTMBrKqq4pe//CVPPvmk2qWIdpp/VxzBfkaOnSvm+c8PXfcJmfVHz/HZHvtMay/edUOHaf1AQwGcP38+M2fOZPBg91uTXLROsJ+RNx5IwKDX8fnes/z1m6NNhjCrsIQ/fLwfgGlJ0ST06ubKUp1OMwFsi8rKSiwWS4NNuIdRvQNZcHft9WB6Fi+sOdRo3OCRfAtT3trOpbJqhkSY+POkAWqU6lQeahfgTKmpqcyfP1/tMkQTpoyKoqrGxvwvM3l/Ww7pPxRx34hIepi82JNziVU7c6m2KvQO7so700bg1UV7U05cj6ot4IsvvohOp2t227VrV5v3P3v2bMxmc/2Wm+s+SykLu0dujOHth4cT4mck52IZr357jFkf7+f9bTlUWxV+MiCE1U8mEeSrzQG316NqCzh9+nTuv//+Zt8THR3d5v0bjUaMxo75D9eRTBwYyoZnA/l871kyThZxuayaXt19uHNoOEl9AjU312drqBrAoKAggoK0NZW4cI6uRg8eGh1Vv+JuZ6GZa8CcnBwuXrxITk4OVquVffv2AdC3b198fX3VLU6INtJMAOfOncuKFSvqf05ISABgw4YNjB8/XqWqhGgfneKM2XLclMViwWQyYTab8ff3V7sc0YG19LvWofsBhXB3mjkFdYS6xl465IWz1X3HrneC2akCWFxcDEBkZKTKlYjOori4GJOp6YHDneoa0GazkZeXh5+fX4fqW7JYLERGRpKbmyvXti7U3O9dURSKi4sJDw9Hr2/6Sq9TtYB6vZ6IiAi1y3Aaf39/CaAKmvq9N9fy1ZGbMEKoSAIohIokgB2A0Whk3rx58tyrizni996pbsII4W6kBRRCRRJAIVQkARRCRRJAIVQkAdS4JUuWEBMTg5eXF8OGDWPz5s1ql9ThpaamMmLECPz8/AgJCWHy5MkcO3asTfuSAGrYqlWreOaZZ3j++efZu3cv48aNY9KkSeTk5KhdWoe2adMmUlJS2LZtG2lpadTU1JCcnExpaWmr9yXdEBo2atQoEhMTWbp0af1rAwcOZPLkyaSmpqpYWedSWFhISEgImzZt4qabbmrVZ6UF1Kiqqip2795NcnJyg9eTk5PJyMhQqarOyWy2r3HRvXv3Vn9WAqhRRUVFWK1WQkNDG7weGhpKQUGBSlV1PoqiMGvWLMaOHUtcXFyrP9+pRkN0RFcPq1IUpUMNtXJ306dP58CBA2zZsqVNn5cAalRQUBAGg6FRa3f+/PlGraJwjhkzZvDFF1+Qnp7e5mFucgqqUZ6engwbNoy0tLQGr6elpZGUlKRSVZ2DoihMnz6d1atXs379emJiYtq8L2kBNWzWrFlMnTqV4cOHM2bMGN58801ycnJ44okn1C6tQ0tJSWHlypWsWbMGPz+/+rMQk8mEt7d363amCE1bvHixEhUVpXh6eiqJiYnKpk2b1C6pwwOuuS1btqzV+5J+QCFUJNeAQqhIAiiEiiSAQqhIAiiEiiSAQqhIAiiEiiSAQqhIAiiEiiSAQqhIAiiEiiSAQqhIAiiuqbCwkLCwMF5++eX617Zv346npyfr1q1TsbKORR7GFk36+uuvmTx5MhkZGQwYMICEhATuuOMOFi1apHZpHYYEUDQrJSWF7777jhEjRrB//3527tyJl5eX2mV1GBJA0azy8nLi4uLIzc1l165dDBkyRO2SOhS5BhTNysrKIi8vD5vNRnZ2ttrldDjSAoomVVVVMXLkSOLj4xkwYACvvfYaBw8elEmfHEgCKJr03HPP8emnn7J//358fX2ZMGECfn5+rF27Vu3SOgw5BRXXtHHjRhYtWsR7772Hv78/er2e9957jy1btjSYCl+0j7SAQqhIWkAhVCQBFEJFEkAhVCQBFEJFEkAhVCQBFEJFEkAhVCQBFEJFEkAhVCQBFEJFEkAhVPT/i8MqxLAkcsAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "x = torch.arange(-1, 2, 0.01, dtype=torch.float32, requires_grad=True)\n",
    "y = x * torch.cos(torch.pi * x)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.plot(x.detach().cpu().numpy(), y.detach().cpu().numpy())\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 导函数图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'grad')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def y(x):\n",
    "    y_hat = x * torch.cos(torch.pi * x)\n",
    "    x_grad = torch.autograd.grad(outputs=y_hat, inputs=x)\n",
    "    return x_grad[0].detach().cpu().numpy()\n",
    "\n",
    "x_grads = [y(i) for i in x]\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.plot(x.detach().cpu().numpy(), x_grads)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y`')\n",
    "plt.title('grad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc46c4198e0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return x * torch.cos(torch.pi * x)\n",
    "\n",
    "def gd(x, y=f, eta=0.01, iter:int=5):\n",
    "    x_list = [x]    # 先存第一个数\n",
    "    i = 1\n",
    "    for _ in range(iter):\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32, requires_grad=True)\n",
    "        x_grad = torch.autograd.grad(outputs= f(x_tensor), inputs=x_tensor)\n",
    "        x -= (eta * x_grad[0].item())\n",
    "        x_list.append(x)\n",
    "        i += 1\n",
    "    return x_list\n",
    "\n",
    "# 从x开始，迭代iter次\n",
    "def demo(x, y, eta, iter, c):\n",
    "    xx = gd(x=x, y=f, eta=eta, iter=iter )\n",
    "    yy = f(torch.tensor(xx))\n",
    "    return xx, yy.detach().cpu().numpy(), c\n",
    "\n",
    "x = torch.arange(-1, 2, 0.01, dtype=torch.float32, requires_grad=True)\n",
    "y = f(x)\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.plot(x.detach().cpu().numpy(), y.detach().cpu().numpy())\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Function')\n",
    "\n",
    "x, y, c = demo(x=2, y=f, eta=0.01, iter=15, c='red')    # lr很小就接近收敛\n",
    "plt.scatter(x=x, y=y, c=c)\n",
    "plt.plot(x, y, c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc46c2c5580>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.arange(-1, 2, 0.01, dtype=torch.float32, requires_grad=True)\n",
    "y = f(x)\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.plot(x.detach().cpu().numpy(), y.detach().cpu().numpy())\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Function')\n",
    "\n",
    "x, y, c = demo(x=2, y=f, eta=0.1, iter=30, c='blue')    # lr很大就很快收敛\n",
    "plt.scatter(x=x, y=y, c=c)\n",
    "plt.plot(x, y, c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc46c30f380>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.arange(-1, 2, 0.01, dtype=torch.float32, requires_grad=True)\n",
    "y = f(x)\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.plot(x.detach().cpu().numpy(), y.detach().cpu().numpy())\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Function')\n",
    "\n",
    "x, y, c = demo(x=0, y=f, eta=0.1, iter=30, c='blue')    # 陷入0左侧附近的局部最小值点\n",
    "plt.scatter(x=x, y=y, c=c)\n",
    "plt.plot(x, y, c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc46c37d5b0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.arange(-1, 2, 0.01, dtype=torch.float32, requires_grad=True)\n",
    "y = f(x)\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.plot(x.detach().cpu().numpy(), y.detach().cpu().numpy())\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Function')\n",
    "\n",
    "x, y, c = demo(x=0, y=f, eta=0.5, iter=5, c='blue')   # lr太大就乱跳\n",
    "plt.scatter(x=x, y=y, c=c)\n",
    "plt.plot(x, y, c=c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.1. <a id='toc8_6_1_'></a>[随机梯度下降（SGD）](#toc0_)\n",
    "- 随机梯度下降法，利用单个样本进行估算所有样本的梯度，然后进行后续的优化。这是计算效率很低的方式，所有改成小批量的随机梯度下降，可以提高计算效率。  \n",
    "- `小批量随机梯度下降法`是最常用的优化算法；\n",
    "- batch_size是所有样本，就是`梯度下降`。\n",
    "- `动量 (momentum)` 可以起到缓冲的作用，使得优化方向不会不停跳动，而是考虑之前几步的方向，具体考虑前多少步依赖于值的大小，一般取值为：0.5, 0.90, 0.99 等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0.99\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.SGD(\n",
    "    params=net.parameters(), \n",
    "    lr=0.01, \n",
    "    momentum=0.99, \n",
    "    # weight_decay=\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.2. <a id='toc8_6_2_'></a>[adam](#toc0_)\n",
    "- Adam其实就是非常平滑的SGD，只是其对lr不敏感；  \n",
    "- Adam未必比SGD效果更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.Adam(\n",
    "    params=net.parameters(), \n",
    "    lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.3. <a id='toc8_6_3_'></a>[RMSprop](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSprop (\n",
       "Parameter Group 0\n",
       "    alpha: 0.99\n",
       "    centered: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.RMSprop(\n",
    "    params=net.parameters(), \n",
    "    lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.4. <a id='toc8_6_4_'></a>[学习率调度器](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.6.4.1. <a id='toc8_6_4_1_'></a>[StepLR： 按照固定的步长调整学习率](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train(...)\n",
    "    validate(...)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.6.4.2. <a id='toc8_6_4_2_'></a>[MultiStepLR： 在指定的里程碑（milestones）上调整学习率](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 80], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.6.4.3. <a id='toc8_6_4_3_'></a>[ExponentialLR： 以指数衰减的方式调整学习率](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.6.4.4. <a id='toc8_6_4_4_'></a>[CosineAnnealingLR： 余弦退火调整学习率](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.6.4.5. <a id='toc8_6_4_5_'></a>[ReduceLROnPlateau： 当指标停止改善时，降低学习率](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train(...)\n",
    "    val_loss = validate(...)\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.6.4.6. <a id='toc8_6_4_6_'></a>[LambdaLR： 使用自定义的函数来调整学习率](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "lambda1 = lambda epoch: 0.65 ** epoch\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.6.4.7. <a id='toc8_6_4_7_'></a>[自定义](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# torch.optim.lr_scheduler._LRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class _LRScheduler in module torch.optim.lr_scheduler:\n",
      "\n",
      "class _LRScheduler(LRScheduler)\n",
      " |  _LRScheduler(optimizer: torch.optim.optimizer.Optimizer, last_epoch=-1, verbose='deprecated')\n",
      " |\n",
      " |  # Including _LRScheduler for backwards compatibility\n",
      " |  # Subclass instead of assign because we want __name__ of _LRScheduler to be _LRScheduler (assigning would make it LRScheduler).\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      _LRScheduler\n",
      " |      LRScheduler\n",
      " |      builtins.object\n",
      " |\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LRScheduler:\n",
      " |\n",
      " |  __init__(self, optimizer: torch.optim.optimizer.Optimizer, last_epoch=-1, verbose='deprecated')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  get_last_lr(self) -> List[float]\n",
      " |      Return last computed learning rate by current scheduler.\n",
      " |\n",
      " |  get_lr(self) -> List[float]\n",
      " |\n",
      " |  load_state_dict(self, state_dict: Dict[str, Any])\n",
      " |      Loads the schedulers state.\n",
      " |\n",
      " |      Args:\n",
      " |          state_dict (dict): scheduler state. Should be an object returned\n",
      " |              from a call to :meth:`state_dict`.\n",
      " |\n",
      " |  print_lr(self, is_verbose: bool, group: Dict[str, Any], lr: float, epoch: Optional[int] = None)\n",
      " |      Display the current learning rate.\n",
      " |\n",
      " |      .. deprecated:: 2.4\n",
      " |          ``print_lr()`` is deprecated. Please use ``get_last_lr()`` to access the\n",
      " |          learning rate.\n",
      " |\n",
      " |  state_dict(self)\n",
      " |      Returns the state of the scheduler as a :class:`dict`.\n",
      " |\n",
      " |      It contains an entry for every variable in self.__dict__ which\n",
      " |      is not the optimizer.\n",
      " |\n",
      " |  step(self, epoch: Optional[int] = None)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from LRScheduler:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.optim.lr_scheduler._LRScheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7. <a id='toc8_7_'></a>[专题-训练](#toc0_)\n",
    "\n",
    "![Train step via pure PyTorch](./Pytorch_Pictures/PyTorch_graphacial_demo/Train_step_via_pure_PyTorch.jpg)\n",
    "\n",
    "```shell\n",
    "训练的模板代码\n",
    "```\n",
    "```sehll\n",
    "net.train():\n",
    "    启用 Batch Normalization 和 Dropout。\n",
    "    如果模型中有BN层(Batch Normalization）和Dropout，需要在训练时添加model.train()\n",
    "    model.train()作用： \n",
    "                        对BN层，保证BN层能够用到每一批数据的均值和方差，并进行计算更新；\n",
    "                        对于Dropout，model.train()是随机取一部分网络连接来训练更新参数。\n",
    "\n",
    "net.eval()\n",
    "    不启用 Batch Normalization 和 Dropout。\n",
    "    如果模型中有BN层(Batch Normalization）和Dropout，在测试时添加model.eval()。\n",
    "    model.eval()是保证BN层直接利用之前训练阶段得到的均值和方差，即测试过程中要保证BN层的均值和方差不变；\n",
    "                        对于Dropout，model.eval()是利用到了所有网络连接，即不进行随机舍弃神经元。\n",
    "                        \n",
    "with torch.no_grad():\n",
    "    pass\n",
    "\n",
    "    无论是train() 还是eval() 模式，各层的gradient计算和存储都在进行且完全一致，在forward的时候会保存中间结果和创建计算图以为后续的\n",
    "    反向传播做准备。而with torch.no_grad()则主要是用于停止autograd模块的工作，在内存中不储存的forward计算结果和不构建计算图，以起到加速和节省显存的作用。它的作用是将该with语句包裹起来的部分停止梯度的更新，从而节省了GPU算力和显存，但是并不会影响dropout和BN层的行为。\n",
    "    若想节约算力，可在test阶段带上torch.no_grad()，示例代码：\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 3659860.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Pytorch_datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 119645.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Pytorch_datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 912416.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Pytorch_datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./Pytorch_datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 17224709.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Pytorch_datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./Pytorch_datasets/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 数据准备\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "# import torch.nn.functional as F \n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 256), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10), \n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.network(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程封装\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "import IPython.display as display\n",
    "import os\n",
    "\n",
    "def train_steps(\n",
    "        epochs, \n",
    "        train_dataset, \n",
    "        train_iter, \n",
    "        test_dataset, \n",
    "        net, \n",
    "        loss_fn, \n",
    "        opt, \n",
    "        device, \n",
    "        train_figure = False, \n",
    "        resume = False, \n",
    "        PATH = 'Pytorch_params/weights'\n",
    "    ):\n",
    "    '''\n",
    "    参数记录:\n",
    "            epochs = epochs                         # epoch\n",
    "            train_dataset = train_dataset           # 全部train数据集\n",
    "            train_iter = train_iter                 # batch之后的train数据集\n",
    "            test_dataset = test_dataset             # 全部test数据集\n",
    "            net = net                               # 网络模型\n",
    "            loss_fn = loss_fn                       # 损失函数\n",
    "            opt = opt                               # 优化器\n",
    "            device = device                         # device GPU/CPU\n",
    "            train_figure = False                    # 可视化训练过程\n",
    "            resume = False                          # 断点续训\n",
    "    '''\n",
    "    # 拷贝数据和模型到device上\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    ## 数据\n",
    "    train_all_data_gpu = train_dataset.data.to(device)                                      # .to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)                                # .to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)                                        # .to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)                                  # .to(device)\n",
    "    ## 模型\n",
    "    net.to(device)                                                                          # .to(device)\n",
    "\n",
    "    def dl_plot(epochs:int, epoch_list:list, train_loss_list:list, train_acc_list:list, test_acc_list:list):\n",
    "        '''绘图'''\n",
    "        plt.rcParams['font.sans-serif']=['Times new roman', 'Arial', 'KaiTi']\n",
    "        plt.style.context(['ggplot', 'seaborn'])\n",
    "        \n",
    "        plt.close()\n",
    "        fig = plt.figure(figsize=(3.0, 3.0))\n",
    "\n",
    "        # for y, label in zip([train_loss_list, train_acc_list, test_acc_list], ['train_loss', 'train_acc', 'test_acc']):\n",
    "        for y, label in zip([train_acc_list, test_acc_list], ['train_acc', 'test_acc']):\n",
    "            plt.plot(epoch_list, y, label=label)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.xlim((1, epochs))\n",
    "        plt.ylabel('Values')\n",
    "        plt.ylim((0, 1))\n",
    "        plt.yticks(torch.arange(0, 1, 0.05).numpy())\n",
    "        # plt.tight_layout()\n",
    "\n",
    "        display.display(fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    epoch_list = []\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "    best_test_acc = 0\n",
    "\n",
    "    # 断点续训\n",
    "    start_epoch = 0\n",
    "    if resume:\n",
    "        if os.path.isfile(PATH+'/last.pt'):\n",
    "            check_point = torch.load(PATH+'/last.pt')\n",
    "            start_epoch = check_point['epoch']\n",
    "            net.load_state_dict(check_point['model_state_dict'])\n",
    "            opt.load_state_dict(check_point['opt_state_dict'])\n",
    "        else:\n",
    "            print(f'没有训练记录。')\n",
    "        \n",
    "    print('start_epoch: ', start_epoch)\n",
    "    for epoch in range(start_epoch, epochs, 1):\n",
    "        net.train()                             # 训练模式\n",
    "        epoch_list.append(epoch+1)\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   ## 复制到device（GPU/CPU）上                    # .to(device)\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            y_hat = net(X)                      # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)            # 计算loss\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            loss.backward()                     # 计算梯度\n",
    "            opt.step()                          # 更新网络参数\n",
    "\n",
    "        net.eval()                              # 切换至评估模式\n",
    "                                                # 模型默认是net.train()\n",
    "                                                # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                                                # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad():                   # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            train_loss_list.append(train_loss.item())\n",
    "            # print(train_loss)\n",
    "\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) \n",
    "            train_acc_list.append(train_acc.item())\n",
    "            # print(train_acc)\n",
    "\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp))\n",
    "            test_acc_list.append(test_acc.item())\n",
    "            # print(test_acc)\n",
    "\n",
    "            if train_figure:\n",
    "                if epoch % 1 == 0:\n",
    "                    dl_plot(epochs, epoch_list, train_loss_list, train_acc_list, test_acc_list)\n",
    "            else:\n",
    "                print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "        # 保存权重参数：last.pt和best.pt\n",
    "        torch.save({'epoch':epoch, 'model_state_dict':net.state_dict(), 'opt_state_dict':opt.state_dict(), 'loss':test_acc}, PATH+'/last.pt') \n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            torch.save({'epoch':epoch, 'model_state_dict':net.state_dict(), 'opt_state_dict':opt.state_dict(), 'loss':test_acc}, PATH+'/best.pt') \n",
    "\n",
    "    stop = time.time()\n",
    "    print('='*100)\n",
    "    print(f\"耗时： {stop - start} seconds.\")\n",
    "    return (train_loss, train_acc, test_acc)\n",
    "    # return (epoch_list, train_loss_list, train_acc_list, test_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程封装\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "import IPython.display as display\n",
    "import os\n",
    "\n",
    "def training_step(\n",
    "        epochs, \n",
    "        train_dataset, \n",
    "        train_iter, \n",
    "        test_dataset, \n",
    "        net, \n",
    "        loss_fn, \n",
    "        opt, \n",
    "        device, \n",
    "        train_figure = False, \n",
    "        resume = False, \n",
    "        PATH = 'Pytorch_params/weights'):\n",
    "    '''\n",
    "    训练过程\n",
    "    params:\n",
    "            epochs = epochs                         # epoch\n",
    "            train_dataset = train_dataset           # 全部train数据集\n",
    "            train_iter = train_iter                 # batch之后的train数据集\n",
    "            test_dataset = test_dataset             # 全部test数据集\n",
    "            net = net                               # 网络模型\n",
    "            loss_fn = loss_fn                       # 损失函数\n",
    "            opt = opt                               # 优化器\n",
    "            device = device                         # device GPU/CPU\n",
    "            train_figure = False                    # 可视化训练过程\n",
    "            resume = False                          # 断点续训\n",
    "    return:\n",
    "            tra_loss, val_loss, val_acc, test_loss, test_acc\n",
    "    '''\n",
    "    # 拷贝数据和模型到device上\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    ## 数据\n",
    "    train_all_data_gpu = train_dataset.data.to(device)                                      # .to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)                                # .to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)                                        # .to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)                                  # .to(device)\n",
    "    ## 模型\n",
    "    net.to(device)                                                                          # .to(device)\n",
    "\n",
    "    def dl_plot(epochs:int, epoch_list:list, train_loss_list:list, train_acc_list:list, test_acc_list:list):\n",
    "        '''绘图'''\n",
    "        plt.rcParams['font.sans-serif']=['Times new roman', 'Arial', 'KaiTi']\n",
    "        plt.style.context(['ggplot', 'seaborn'])\n",
    "        \n",
    "        plt.close()\n",
    "        fig = plt.figure(figsize=(3.0, 3.0))\n",
    "\n",
    "        # for y, label in zip([train_loss_list, train_acc_list, test_acc_list], ['train_loss', 'train_acc', 'test_acc']):\n",
    "        for y, label in zip([train_acc_list, test_acc_list], ['train_acc', 'test_acc']):\n",
    "            plt.plot(epoch_list, y, label=label)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.xlim((1, epochs))\n",
    "        plt.ylabel('Values')\n",
    "        plt.ylim((0, 1))\n",
    "        plt.yticks(torch.arange(0, 1, 0.05).numpy())\n",
    "        # plt.tight_layout()\n",
    "\n",
    "        display.display(fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    epoch_list = []\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "    best_test_acc = 0\n",
    "\n",
    "    # 断点续训\n",
    "    start_epoch = 0\n",
    "    if resume:\n",
    "        if os.path.isfile(PATH+'/last.pt'):\n",
    "            check_point = torch.load(PATH+'/last.pt')\n",
    "            start_epoch = check_point['epoch']\n",
    "            net.load_state_dict(check_point['model_state_dict'])\n",
    "            opt.load_state_dict(check_point['opt_state_dict'])\n",
    "        else:\n",
    "            print(f'没有训练记录。')\n",
    "        \n",
    "    print('start_epoch: ', start_epoch)\n",
    "    for epoch in range(start_epoch, epochs, 1):\n",
    "        net.train()                             # 训练模式\n",
    "        epoch_list.append(epoch+1)\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   ## 复制到device（GPU/CPU）上                    # .to(device)\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            y_hat = net(X)                      # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)            # 计算loss\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            loss.backward()                     # 计算梯度\n",
    "            opt.step()                          # 更新网络参数\n",
    "\n",
    "        net.eval()                              # 切换至评估模式\n",
    "                                                # 模型默认是net.train()\n",
    "                                                # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                                                # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad():                   # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            train_loss_list.append(train_loss.item())\n",
    "            # print(train_loss)\n",
    "\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) \n",
    "            train_acc_list.append(train_acc.item())\n",
    "            # print(train_acc)\n",
    "\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp))\n",
    "            test_acc_list.append(test_acc.item())\n",
    "            # print(test_acc)\n",
    "\n",
    "            if train_figure:\n",
    "                if epoch % 1 == 0:\n",
    "                    dl_plot(epochs, epoch_list, train_loss_list, train_acc_list, test_acc_list)\n",
    "            else:\n",
    "                print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "        # 保存权重参数：last.pt和best.pt\n",
    "        torch.save({'epoch':epoch, 'model_state_dict':net.state_dict(), 'opt_state_dict':opt.state_dict(), 'loss':test_acc}, PATH+'/last.pt') \n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            torch.save({'epoch':epoch, 'model_state_dict':net.state_dict(), 'opt_state_dict':opt.state_dict(), 'loss':test_acc}, PATH+'/best.pt') \n",
    "\n",
    "    stop = time.time()\n",
    "    print('='*100)\n",
    "    print(f\"耗时： {stop - start} seconds.\")\n",
    "    return (train_loss, train_acc, test_acc)\n",
    "    # return (epoch_list, train_loss_list, train_acc_list, test_acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.1. <a id='toc8_7_1_'></a>[开始训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 59.95664095878601 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.7594, device='cuda:0'),\n",
       " tensor(0.7902, device='cuda:0'),\n",
       " tensor(0.8000, device='cuda:0'))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Times new roman, Arial, KaiTi\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 开始训练\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.01)\n",
    "\n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device, \n",
    "    train_figure=True, \n",
    "    resume = False, \n",
    "    PATH = './Pytorch_params/weights'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32820/198423743.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best = torch.load('./Pytorch_params/weights/best.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9,\n",
       " tensor(0.8000, device='cuda:0'),\n",
       " OrderedDict([('network.1.weight',\n",
       "               tensor([[-0.0241, -0.0069,  0.0088,  ..., -0.0267, -0.0129, -0.0065],\n",
       "                       [ 0.0302, -0.0323,  0.0237,  ..., -0.0168,  0.0240,  0.0341],\n",
       "                       [-0.0151,  0.0176, -0.0027,  ...,  0.0083, -0.0131,  0.0065],\n",
       "                       ...,\n",
       "                       [ 0.0030,  0.0136, -0.0048,  ..., -0.0145, -0.0219, -0.0337],\n",
       "                       [-0.0136, -0.0261,  0.0065,  ..., -0.0004,  0.0057,  0.0013],\n",
       "                       [-0.0356, -0.0046, -0.0026,  ..., -0.0298,  0.0247,  0.0137]],\n",
       "                      device='cuda:0')),\n",
       "              ('network.1.bias',\n",
       "               tensor([ 3.9702e-02,  3.4285e-02,  4.3656e-02, -7.5687e-04,  4.5628e-02,\n",
       "                       -1.5764e-03,  9.1527e-03,  1.2884e-02,  5.1464e-02,  1.3203e-02,\n",
       "                        3.2777e-02,  2.3281e-02, -7.0645e-07, -2.0750e-02,  1.0967e-02,\n",
       "                        1.6538e-02, -3.8702e-02,  1.7775e-02,  4.1511e-02,  1.2678e-02,\n",
       "                        2.1664e-02, -2.0623e-02,  3.2701e-02,  2.3492e-02,  4.9457e-03,\n",
       "                        3.9780e-02, -1.1985e-02,  4.2158e-02,  5.6506e-02,  2.7593e-02,\n",
       "                        9.5884e-03,  2.4593e-02,  5.3445e-03,  1.0407e-02, -2.9220e-02,\n",
       "                       -7.0291e-03,  1.5674e-02, -1.9235e-02,  2.1151e-02,  2.2816e-02,\n",
       "                        7.4965e-03,  5.0568e-02, -8.6301e-03, -1.1696e-02,  1.7590e-02,\n",
       "                        5.1232e-02, -1.1965e-02,  3.1024e-02,  3.3625e-02,  1.2786e-02,\n",
       "                        2.7856e-02,  2.0230e-02,  1.9761e-02,  4.9548e-02,  4.0749e-02,\n",
       "                        1.2994e-02,  5.2624e-02,  2.0533e-02,  2.9313e-02,  6.8340e-03,\n",
       "                       -2.8082e-02,  1.5062e-02, -3.0884e-02, -2.3156e-02, -2.2881e-03,\n",
       "                        2.6252e-03, -3.0055e-02, -1.5311e-02,  3.1937e-02,  3.6528e-02,\n",
       "                        3.3189e-02, -1.0149e-02,  2.0503e-02, -1.4367e-02,  4.2755e-02,\n",
       "                       -1.9800e-02, -1.1765e-02,  3.1096e-02,  2.9567e-02, -2.6079e-02,\n",
       "                        2.4057e-02,  2.8671e-02,  6.5098e-03,  1.6217e-02,  1.6545e-02,\n",
       "                        1.9598e-02,  3.9184e-02, -1.1046e-02,  6.2070e-03,  3.1246e-02,\n",
       "                        9.4902e-03,  3.0827e-02, -1.2420e-02, -1.8113e-02, -7.5191e-03,\n",
       "                       -2.3051e-02,  1.2938e-02, -1.2393e-02, -2.3524e-02, -9.9774e-03,\n",
       "                        8.9223e-03,  3.3172e-02,  3.3347e-02,  1.9719e-02, -5.4457e-03,\n",
       "                        1.0521e-02, -2.5926e-03,  3.6220e-03, -8.9649e-03,  3.5096e-03,\n",
       "                        3.9662e-02,  8.8037e-03,  2.5711e-02, -6.7204e-03, -8.7729e-03,\n",
       "                        1.3268e-02,  2.2215e-02, -7.2406e-03,  1.6775e-03, -1.3178e-02,\n",
       "                        2.2741e-02, -1.6813e-02,  6.5540e-03,  4.7898e-02,  1.7329e-02,\n",
       "                       -1.8237e-02,  2.3492e-02, -2.1715e-02,  3.1797e-02, -2.3865e-03,\n",
       "                        1.9146e-03,  2.0191e-02,  2.1575e-02, -5.3633e-03,  1.5864e-02,\n",
       "                        4.8251e-02, -1.8978e-03, -2.8512e-03,  3.3479e-02,  3.3359e-02,\n",
       "                       -2.1005e-02,  1.0200e-04, -2.5433e-02, -8.3805e-03,  5.2502e-02,\n",
       "                       -2.7321e-02,  6.5998e-02,  8.3883e-03,  2.5566e-02,  8.6262e-03,\n",
       "                       -2.2832e-02,  4.9074e-02, -2.7729e-02, -6.6179e-03,  3.1971e-02,\n",
       "                        4.1276e-02, -2.6954e-02, -9.3661e-03, -6.8694e-03,  1.2666e-02,\n",
       "                       -1.8432e-02, -3.2942e-02,  3.6010e-02,  1.3340e-02,  1.3230e-02,\n",
       "                        1.2177e-03, -4.0268e-03,  2.4358e-02, -1.4252e-02,  1.7725e-02,\n",
       "                        1.4390e-02,  4.5555e-02,  4.3820e-03, -9.9201e-03,  2.5283e-03,\n",
       "                       -1.3692e-02, -3.6250e-02,  2.1885e-03,  3.5891e-02,  2.4769e-02,\n",
       "                        9.7989e-03,  4.4549e-02,  1.1250e-02,  2.9513e-04, -8.4876e-03,\n",
       "                       -1.0764e-02, -5.3896e-03,  3.9276e-02,  3.1027e-02,  1.1406e-02,\n",
       "                        3.0260e-02,  1.2267e-02,  4.6958e-03,  3.7215e-02,  3.9977e-02,\n",
       "                        3.3820e-02, -1.0931e-02,  1.0565e-02,  1.1181e-02, -1.3401e-02,\n",
       "                        3.6825e-02,  4.5035e-02, -2.7077e-02, -2.0625e-02, -1.2974e-02,\n",
       "                       -2.3754e-02,  3.1041e-02,  4.6583e-02,  5.2671e-02, -1.2074e-02,\n",
       "                       -1.2163e-02, -2.2311e-02, -1.4121e-02, -2.3022e-02,  1.5178e-02,\n",
       "                        2.2413e-02,  2.1362e-02, -1.1371e-02, -2.4531e-02,  3.2458e-02,\n",
       "                        2.1671e-02,  3.3461e-02,  6.0620e-03,  2.3813e-02,  4.7138e-02,\n",
       "                       -3.1214e-02, -2.6454e-03, -2.5188e-02,  3.4154e-02,  2.0549e-02,\n",
       "                       -9.4273e-03,  2.9883e-02, -8.0837e-03,  4.4898e-02,  5.3602e-03,\n",
       "                       -2.3646e-02,  2.8702e-02,  2.7271e-02,  5.5416e-02, -2.3502e-02,\n",
       "                        1.4266e-02, -4.1066e-02,  3.4123e-02,  2.6651e-02,  3.1687e-02,\n",
       "                        2.6590e-02, -3.7192e-03,  2.8239e-02,  5.7477e-03, -2.0121e-02,\n",
       "                        5.4461e-03,  3.0526e-02, -9.5012e-03,  2.7479e-02, -2.8464e-02,\n",
       "                        4.6071e-02], device='cuda:0')),\n",
       "              ('network.3.weight',\n",
       "               tensor([[-0.0505, -0.1163, -0.0902,  ..., -0.0762,  0.0453,  0.0470],\n",
       "                       [ 0.0724,  0.1765,  0.0936,  ..., -0.0425,  0.0104, -0.0149],\n",
       "                       [-0.0884, -0.0270,  0.0364,  ..., -0.0410, -0.0254, -0.0206],\n",
       "                       ...,\n",
       "                       [-0.0540,  0.0514, -0.1432,  ..., -0.1346, -0.0148,  0.1571],\n",
       "                       [ 0.0946,  0.0494,  0.0184,  ...,  0.0630,  0.0512, -0.0797],\n",
       "                       [ 0.0776,  0.0689, -0.0066,  ..., -0.0522,  0.0436, -0.0084]],\n",
       "                      device='cuda:0')),\n",
       "              ('network.3.bias',\n",
       "               tensor([-0.0526,  0.1243, -0.0987,  0.0301,  0.0522, -0.0409,  0.0423,  0.0652,\n",
       "                       -0.1231,  0.0462], device='cuda:0'))]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = torch.load('./Pytorch_params/weights/best.pt')\n",
    "best['epoch'], best['loss'], best['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 70.18707489967346 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.7867), tensor(0.7317), tensor(0.7402))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 再试一次，会不会造成net的parameter的累加，结果表明不会\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()   \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.01)  \n",
    "    \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device, \n",
    "            train_figure=True, \n",
    "            resume = False\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.2. <a id='toc8_7_2_'></a>[自己探索](#toc0_)\n",
    "#### 8.7.2.1. <a id='toc8_7_2_1_'></a>[lr的影响](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 69.80070853233337 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.4991), tensor(0.9673), tensor(0.9614))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()      \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device, \n",
    "    train_figure=True\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.7.2.2. <a id='toc8_7_2_2_'></a>[不同模型的效率](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 87.9712917804718 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.4962), tensor(0.9704), tensor(0.9643))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"335.982812pt\" height=\"265.325625pt\" viewBox=\"0 0 335.982812 265.325625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-04-25T11:13:04.145402</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 265.325625 \n",
       "L 335.982812 265.325625 \n",
       "L 335.982812 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "L 44.782812 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 44.782812 228.96 \n",
       "L 44.782812 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m92953bacde\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"44.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(42.282812 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-31\" d=\"M 750 3822 \n",
       "L 1781 4325 \n",
       "L 1884 4325 \n",
       "L 1884 747 \n",
       "Q 1884 391 1914 303 \n",
       "Q 1944 216 2037 169 \n",
       "Q 2131 122 2419 116 \n",
       "L 2419 0 \n",
       "L 825 0 \n",
       "L 825 116 \n",
       "Q 1125 122 1212 167 \n",
       "Q 1300 213 1334 289 \n",
       "Q 1369 366 1369 747 \n",
       "L 1369 3034 \n",
       "Q 1369 3497 1338 3628 \n",
       "Q 1316 3728 1258 3775 \n",
       "Q 1200 3822 1119 3822 \n",
       "Q 1003 3822 797 3725 \n",
       "L 750 3822 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 75.782813 228.96 \n",
       "L 75.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"75.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(73.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-32\" d=\"M 2934 816 \n",
       "L 2638 0 \n",
       "L 138 0 \n",
       "L 138 116 \n",
       "Q 1241 1122 1691 1759 \n",
       "Q 2141 2397 2141 2925 \n",
       "Q 2141 3328 1894 3587 \n",
       "Q 1647 3847 1303 3847 \n",
       "Q 991 3847 742 3664 \n",
       "Q 494 3481 375 3128 \n",
       "L 259 3128 \n",
       "Q 338 3706 661 4015 \n",
       "Q 984 4325 1469 4325 \n",
       "Q 1984 4325 2329 3994 \n",
       "Q 2675 3663 2675 3213 \n",
       "Q 2675 2891 2525 2569 \n",
       "Q 2294 2063 1775 1497 \n",
       "Q 997 647 803 472 \n",
       "L 1909 472 \n",
       "Q 2247 472 2383 497 \n",
       "Q 2519 522 2628 598 \n",
       "Q 2738 675 2819 816 \n",
       "L 2934 816 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 106.782813 228.96 \n",
       "L 106.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"106.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 3 -->\n",
       "      <g transform=\"translate(104.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-33\" d=\"M 325 3431 \n",
       "Q 506 3859 782 4092 \n",
       "Q 1059 4325 1472 4325 \n",
       "Q 1981 4325 2253 3994 \n",
       "Q 2459 3747 2459 3466 \n",
       "Q 2459 3003 1878 2509 \n",
       "Q 2269 2356 2469 2072 \n",
       "Q 2669 1788 2669 1403 \n",
       "Q 2669 853 2319 450 \n",
       "Q 1863 -75 997 -75 \n",
       "Q 569 -75 414 31 \n",
       "Q 259 138 259 259 \n",
       "Q 259 350 332 419 \n",
       "Q 406 488 509 488 \n",
       "Q 588 488 669 463 \n",
       "Q 722 447 909 348 \n",
       "Q 1097 250 1169 231 \n",
       "Q 1284 197 1416 197 \n",
       "Q 1734 197 1970 444 \n",
       "Q 2206 691 2206 1028 \n",
       "Q 2206 1275 2097 1509 \n",
       "Q 2016 1684 1919 1775 \n",
       "Q 1784 1900 1550 2001 \n",
       "Q 1316 2103 1072 2103 \n",
       "L 972 2103 \n",
       "L 972 2197 \n",
       "Q 1219 2228 1467 2375 \n",
       "Q 1716 2522 1828 2728 \n",
       "Q 1941 2934 1941 3181 \n",
       "Q 1941 3503 1739 3701 \n",
       "Q 1538 3900 1238 3900 \n",
       "Q 753 3900 428 3381 \n",
       "L 325 3431 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 137.782813 228.96 \n",
       "L 137.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"137.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(135.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-34\" d=\"M 2978 1563 \n",
       "L 2978 1119 \n",
       "L 2409 1119 \n",
       "L 2409 0 \n",
       "L 1894 0 \n",
       "L 1894 1119 \n",
       "L 100 1119 \n",
       "L 100 1519 \n",
       "L 2066 4325 \n",
       "L 2409 4325 \n",
       "L 2409 1563 \n",
       "L 2978 1563 \n",
       "z\n",
       "M 1894 1563 \n",
       "L 1894 3666 \n",
       "L 406 1563 \n",
       "L 1894 1563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 168.782813 228.96 \n",
       "L 168.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"168.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(166.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-35\" d=\"M 2778 4238 \n",
       "L 2534 3706 \n",
       "L 1259 3706 \n",
       "L 981 3138 \n",
       "Q 1809 3016 2294 2522 \n",
       "Q 2709 2097 2709 1522 \n",
       "Q 2709 1188 2573 903 \n",
       "Q 2438 619 2231 419 \n",
       "Q 2025 219 1772 97 \n",
       "Q 1413 -75 1034 -75 \n",
       "Q 653 -75 479 54 \n",
       "Q 306 184 306 341 \n",
       "Q 306 428 378 495 \n",
       "Q 450 563 559 563 \n",
       "Q 641 563 702 538 \n",
       "Q 763 513 909 409 \n",
       "Q 1144 247 1384 247 \n",
       "Q 1750 247 2026 523 \n",
       "Q 2303 800 2303 1197 \n",
       "Q 2303 1581 2056 1914 \n",
       "Q 1809 2247 1375 2428 \n",
       "Q 1034 2569 447 2591 \n",
       "L 1259 4238 \n",
       "L 2778 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 199.782813 228.96 \n",
       "L 199.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"199.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(197.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-36\" d=\"M 2869 4325 \n",
       "L 2869 4209 \n",
       "Q 2456 4169 2195 4045 \n",
       "Q 1934 3922 1679 3669 \n",
       "Q 1425 3416 1258 3105 \n",
       "Q 1091 2794 978 2366 \n",
       "Q 1428 2675 1881 2675 \n",
       "Q 2316 2675 2634 2325 \n",
       "Q 2953 1975 2953 1425 \n",
       "Q 2953 894 2631 456 \n",
       "Q 2244 -75 1606 -75 \n",
       "Q 1172 -75 869 213 \n",
       "Q 275 772 275 1663 \n",
       "Q 275 2231 503 2743 \n",
       "Q 731 3256 1154 3653 \n",
       "Q 1578 4050 1965 4187 \n",
       "Q 2353 4325 2688 4325 \n",
       "L 2869 4325 \n",
       "z\n",
       "M 925 2138 \n",
       "Q 869 1716 869 1456 \n",
       "Q 869 1156 980 804 \n",
       "Q 1091 453 1309 247 \n",
       "Q 1469 100 1697 100 \n",
       "Q 1969 100 2183 356 \n",
       "Q 2397 613 2397 1088 \n",
       "Q 2397 1622 2184 2012 \n",
       "Q 1972 2403 1581 2403 \n",
       "Q 1463 2403 1327 2353 \n",
       "Q 1191 2303 925 2138 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 230.782813 228.96 \n",
       "L 230.782813 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"230.782813\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 7 -->\n",
       "      <g transform=\"translate(228.282813 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-37\" d=\"M 644 4238 \n",
       "L 2916 4238 \n",
       "L 2916 4119 \n",
       "L 1503 -88 \n",
       "L 1153 -88 \n",
       "L 2419 3728 \n",
       "L 1253 3728 \n",
       "Q 900 3728 750 3644 \n",
       "Q 488 3500 328 3200 \n",
       "L 238 3234 \n",
       "L 644 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-37\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 261.782812 228.96 \n",
       "L 261.782812 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"261.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(259.282812 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-38\" d=\"M 1228 2134 \n",
       "Q 725 2547 579 2797 \n",
       "Q 434 3047 434 3316 \n",
       "Q 434 3728 753 4026 \n",
       "Q 1072 4325 1600 4325 \n",
       "Q 2113 4325 2425 4047 \n",
       "Q 2738 3769 2738 3413 \n",
       "Q 2738 3175 2569 2928 \n",
       "Q 2400 2681 1866 2347 \n",
       "Q 2416 1922 2594 1678 \n",
       "Q 2831 1359 2831 1006 \n",
       "Q 2831 559 2490 242 \n",
       "Q 2150 -75 1597 -75 \n",
       "Q 994 -75 656 303 \n",
       "Q 388 606 388 966 \n",
       "Q 388 1247 577 1523 \n",
       "Q 766 1800 1228 2134 \n",
       "z\n",
       "M 1719 2469 \n",
       "Q 2094 2806 2194 3001 \n",
       "Q 2294 3197 2294 3444 \n",
       "Q 2294 3772 2109 3958 \n",
       "Q 1925 4144 1606 4144 \n",
       "Q 1288 4144 1088 3959 \n",
       "Q 888 3775 888 3528 \n",
       "Q 888 3366 970 3203 \n",
       "Q 1053 3041 1206 2894 \n",
       "L 1719 2469 \n",
       "z\n",
       "M 1375 2016 \n",
       "Q 1116 1797 991 1539 \n",
       "Q 866 1281 866 981 \n",
       "Q 866 578 1086 336 \n",
       "Q 1306 94 1647 94 \n",
       "Q 1984 94 2187 284 \n",
       "Q 2391 475 2391 747 \n",
       "Q 2391 972 2272 1150 \n",
       "Q 2050 1481 1375 2016 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 292.782812 228.96 \n",
       "L 292.782812 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"292.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 9 -->\n",
       "      <g transform=\"translate(290.282812 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-39\" d=\"M 338 -88 \n",
       "L 338 28 \n",
       "Q 744 34 1094 217 \n",
       "Q 1444 400 1770 856 \n",
       "Q 2097 1313 2225 1859 \n",
       "Q 1734 1544 1338 1544 \n",
       "Q 891 1544 572 1889 \n",
       "Q 253 2234 253 2806 \n",
       "Q 253 3363 572 3797 \n",
       "Q 956 4325 1575 4325 \n",
       "Q 2097 4325 2469 3894 \n",
       "Q 2925 3359 2925 2575 \n",
       "Q 2925 1869 2578 1258 \n",
       "Q 2231 647 1613 244 \n",
       "Q 1109 -88 516 -88 \n",
       "L 338 -88 \n",
       "z\n",
       "M 2275 2091 \n",
       "Q 2331 2497 2331 2741 \n",
       "Q 2331 3044 2228 3395 \n",
       "Q 2125 3747 1936 3934 \n",
       "Q 1747 4122 1506 4122 \n",
       "Q 1228 4122 1018 3872 \n",
       "Q 809 3622 809 3128 \n",
       "Q 809 2469 1088 2097 \n",
       "Q 1291 1828 1588 1828 \n",
       "Q 1731 1828 1928 1897 \n",
       "Q 2125 1966 2275 2091 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-39\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m92953bacde\" x=\"323.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(318.782812 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-30\" d=\"M 231 2094 \n",
       "Q 231 2819 450 3342 \n",
       "Q 669 3866 1031 4122 \n",
       "Q 1313 4325 1613 4325 \n",
       "Q 2100 4325 2488 3828 \n",
       "Q 2972 3213 2972 2159 \n",
       "Q 2972 1422 2759 906 \n",
       "Q 2547 391 2217 158 \n",
       "Q 1888 -75 1581 -75 \n",
       "Q 975 -75 572 641 \n",
       "Q 231 1244 231 2094 \n",
       "z\n",
       "M 844 2016 \n",
       "Q 844 1141 1059 588 \n",
       "Q 1238 122 1591 122 \n",
       "Q 1759 122 1940 273 \n",
       "Q 2122 425 2216 781 \n",
       "Q 2359 1319 2359 2297 \n",
       "Q 2359 3022 2209 3506 \n",
       "Q 2097 3866 1919 4016 \n",
       "Q 1791 4119 1609 4119 \n",
       "Q 1397 4119 1231 3928 \n",
       "Q 1006 3669 925 3112 \n",
       "Q 844 2556 844 2016 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_11\">\n",
       "     <!-- Epoch -->\n",
       "     <g transform=\"translate(171.509375 255.986562) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-45\" d=\"M 1338 4006 \n",
       "L 1338 2331 \n",
       "L 2269 2331 \n",
       "Q 2631 2331 2753 2441 \n",
       "Q 2916 2584 2934 2947 \n",
       "L 3050 2947 \n",
       "L 3050 1472 \n",
       "L 2934 1472 \n",
       "Q 2891 1781 2847 1869 \n",
       "Q 2791 1978 2662 2040 \n",
       "Q 2534 2103 2269 2103 \n",
       "L 1338 2103 \n",
       "L 1338 706 \n",
       "Q 1338 425 1363 364 \n",
       "Q 1388 303 1450 267 \n",
       "Q 1513 231 1688 231 \n",
       "L 2406 231 \n",
       "Q 2766 231 2928 281 \n",
       "Q 3091 331 3241 478 \n",
       "Q 3434 672 3638 1063 \n",
       "L 3763 1063 \n",
       "L 3397 0 \n",
       "L 131 0 \n",
       "L 131 116 \n",
       "L 281 116 \n",
       "Q 431 116 566 188 \n",
       "Q 666 238 702 338 \n",
       "Q 738 438 738 747 \n",
       "L 738 3500 \n",
       "Q 738 3903 656 3997 \n",
       "Q 544 4122 281 4122 \n",
       "L 131 4122 \n",
       "L 131 4238 \n",
       "L 3397 4238 \n",
       "L 3444 3309 \n",
       "L 3322 3309 \n",
       "Q 3256 3644 3176 3769 \n",
       "Q 3097 3894 2941 3959 \n",
       "Q 2816 4006 2500 4006 \n",
       "L 1338 4006 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-70\" d=\"M -6 2578 \n",
       "L 875 2934 \n",
       "L 994 2934 \n",
       "L 994 2266 \n",
       "Q 1216 2644 1439 2795 \n",
       "Q 1663 2947 1909 2947 \n",
       "Q 2341 2947 2628 2609 \n",
       "Q 2981 2197 2981 1534 \n",
       "Q 2981 794 2556 309 \n",
       "Q 2206 -88 1675 -88 \n",
       "Q 1444 -88 1275 -22 \n",
       "Q 1150 25 994 166 \n",
       "L 994 -706 \n",
       "Q 994 -1000 1030 -1079 \n",
       "Q 1066 -1159 1155 -1206 \n",
       "Q 1244 -1253 1478 -1253 \n",
       "L 1478 -1369 \n",
       "L -22 -1369 \n",
       "L -22 -1253 \n",
       "L 56 -1253 \n",
       "Q 228 -1256 350 -1188 \n",
       "Q 409 -1153 442 -1076 \n",
       "Q 475 -1000 475 -688 \n",
       "L 475 2019 \n",
       "Q 475 2297 450 2372 \n",
       "Q 425 2447 370 2484 \n",
       "Q 316 2522 222 2522 \n",
       "Q 147 2522 31 2478 \n",
       "L -6 2578 \n",
       "z\n",
       "M 994 2081 \n",
       "L 994 1013 \n",
       "Q 994 666 1022 556 \n",
       "Q 1066 375 1236 237 \n",
       "Q 1406 100 1666 100 \n",
       "Q 1978 100 2172 344 \n",
       "Q 2425 663 2425 1241 \n",
       "Q 2425 1897 2138 2250 \n",
       "Q 1938 2494 1663 2494 \n",
       "Q 1513 2494 1366 2419 \n",
       "Q 1253 2363 994 2081 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6f\" d=\"M 1600 2947 \n",
       "Q 2250 2947 2644 2453 \n",
       "Q 2978 2031 2978 1484 \n",
       "Q 2978 1100 2793 706 \n",
       "Q 2609 313 2286 112 \n",
       "Q 1963 -88 1566 -88 \n",
       "Q 919 -88 538 428 \n",
       "Q 216 863 216 1403 \n",
       "Q 216 1797 411 2186 \n",
       "Q 606 2575 925 2761 \n",
       "Q 1244 2947 1600 2947 \n",
       "z\n",
       "M 1503 2744 \n",
       "Q 1338 2744 1170 2645 \n",
       "Q 1003 2547 900 2300 \n",
       "Q 797 2053 797 1666 \n",
       "Q 797 1041 1045 587 \n",
       "Q 1294 134 1700 134 \n",
       "Q 2003 134 2200 384 \n",
       "Q 2397 634 2397 1244 \n",
       "Q 2397 2006 2069 2444 \n",
       "Q 1847 2744 1503 2744 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-63\" d=\"M 2631 1088 \n",
       "Q 2516 522 2178 217 \n",
       "Q 1841 -88 1431 -88 \n",
       "Q 944 -88 581 321 \n",
       "Q 219 731 219 1428 \n",
       "Q 219 2103 620 2525 \n",
       "Q 1022 2947 1584 2947 \n",
       "Q 2006 2947 2278 2723 \n",
       "Q 2550 2500 2550 2259 \n",
       "Q 2550 2141 2473 2067 \n",
       "Q 2397 1994 2259 1994 \n",
       "Q 2075 1994 1981 2113 \n",
       "Q 1928 2178 1911 2362 \n",
       "Q 1894 2547 1784 2644 \n",
       "Q 1675 2738 1481 2738 \n",
       "Q 1169 2738 978 2506 \n",
       "Q 725 2200 725 1697 \n",
       "Q 725 1184 976 792 \n",
       "Q 1228 400 1656 400 \n",
       "Q 1963 400 2206 609 \n",
       "Q 2378 753 2541 1131 \n",
       "L 2631 1088 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-68\" d=\"M 1041 4444 \n",
       "L 1041 2350 \n",
       "Q 1388 2731 1591 2839 \n",
       "Q 1794 2947 1997 2947 \n",
       "Q 2241 2947 2416 2812 \n",
       "Q 2591 2678 2675 2391 \n",
       "Q 2734 2191 2734 1659 \n",
       "L 2734 647 \n",
       "Q 2734 375 2778 275 \n",
       "Q 2809 200 2884 156 \n",
       "Q 2959 113 3159 113 \n",
       "L 3159 0 \n",
       "L 1753 0 \n",
       "L 1753 113 \n",
       "L 1819 113 \n",
       "Q 2019 113 2097 173 \n",
       "Q 2175 234 2206 353 \n",
       "Q 2216 403 2216 647 \n",
       "L 2216 1659 \n",
       "Q 2216 2128 2167 2275 \n",
       "Q 2119 2422 2012 2495 \n",
       "Q 1906 2569 1756 2569 \n",
       "Q 1603 2569 1437 2487 \n",
       "Q 1272 2406 1041 2159 \n",
       "L 1041 647 \n",
       "Q 1041 353 1073 281 \n",
       "Q 1106 209 1195 161 \n",
       "Q 1284 113 1503 113 \n",
       "L 1503 0 \n",
       "L 84 0 \n",
       "L 84 113 \n",
       "Q 275 113 384 172 \n",
       "Q 447 203 484 290 \n",
       "Q 522 378 522 647 \n",
       "L 522 3238 \n",
       "Q 522 3728 498 3840 \n",
       "Q 475 3953 426 3993 \n",
       "Q 378 4034 297 4034 \n",
       "Q 231 4034 84 3984 \n",
       "L 41 4094 \n",
       "L 897 4444 \n",
       "L 1041 4444 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-45\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-70\" x=\"61.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6f\" x=\"111.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"161.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-68\" x=\"205.46875\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <defs>\n",
       "       <path id=\"m2ec95d50d3\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.00 -->\n",
       "      <g transform=\"translate(20.282812 232.431875) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-2e\" d=\"M 800 606 \n",
       "Q 947 606 1047 504 \n",
       "Q 1147 403 1147 259 \n",
       "Q 1147 116 1045 14 \n",
       "Q 944 -88 800 -88 \n",
       "Q 656 -88 554 14 \n",
       "Q 453 116 453 259 \n",
       "Q 453 406 554 506 \n",
       "Q 656 606 800 606 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 44.782812 217.872 \n",
       "L 323.782812 217.872 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"217.872\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.05 -->\n",
       "      <g transform=\"translate(20.282812 221.343875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path d=\"M 44.782812 206.784 \n",
       "L 323.782812 206.784 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_26\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"206.784\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.282812 210.255875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path d=\"M 44.782812 195.695999 \n",
       "L 323.782812 195.695999 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_28\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"195.695999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.282812 199.167874) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <path d=\"M 44.782812 184.607999 \n",
       "L 323.782812 184.607999 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_30\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"184.607999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 0.20 -->\n",
       "      <g transform=\"translate(20.282812 188.079874) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_31\">\n",
       "      <path d=\"M 44.782812 173.52 \n",
       "L 323.782812 173.52 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_32\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"173.52\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 0.25 -->\n",
       "      <g transform=\"translate(20.282812 176.991875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_33\">\n",
       "      <path d=\"M 44.782812 162.431997 \n",
       "L 323.782812 162.431997 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_34\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"162.431997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- 0.30 -->\n",
       "      <g transform=\"translate(20.282812 165.903872) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_35\">\n",
       "      <path d=\"M 44.782812 151.344001 \n",
       "L 323.782812 151.344001 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_36\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"151.344001\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 0.35 -->\n",
       "      <g transform=\"translate(20.282812 154.815876) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_37\">\n",
       "      <path d=\"M 44.782812 140.255999 \n",
       "L 323.782812 140.255999 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_38\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"140.255999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_20\">\n",
       "      <!-- 0.40 -->\n",
       "      <g transform=\"translate(20.282812 143.727874) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-34\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_39\">\n",
       "      <path d=\"M 44.782812 129.167996 \n",
       "L 323.782812 129.167996 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_40\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"129.167996\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_21\">\n",
       "      <!-- 0.45 -->\n",
       "      <g transform=\"translate(20.282812 132.639871) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-34\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_11\">\n",
       "     <g id=\"line2d_41\">\n",
       "      <path d=\"M 44.782812 118.08 \n",
       "L 323.782812 118.08 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_42\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"118.08\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_22\">\n",
       "      <!-- 0.50 -->\n",
       "      <g transform=\"translate(20.282812 121.551875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_12\">\n",
       "     <g id=\"line2d_43\">\n",
       "      <path d=\"M 44.782812 106.991997 \n",
       "L 323.782812 106.991997 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_44\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"106.991997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_23\">\n",
       "      <!-- 0.55 -->\n",
       "      <g transform=\"translate(20.282812 110.463872) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_13\">\n",
       "     <g id=\"line2d_45\">\n",
       "      <path d=\"M 44.782812 95.903995 \n",
       "L 323.782812 95.903995 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_46\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"95.903995\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_24\">\n",
       "      <!-- 0.60 -->\n",
       "      <g transform=\"translate(20.282812 99.37587) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-36\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_14\">\n",
       "     <g id=\"line2d_47\">\n",
       "      <path d=\"M 44.782812 84.816005 \n",
       "L 323.782812 84.816005 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_48\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"84.816005\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_25\">\n",
       "      <!-- 0.65 -->\n",
       "      <g transform=\"translate(20.282812 88.28788) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-36\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_15\">\n",
       "     <g id=\"line2d_49\">\n",
       "      <path d=\"M 44.782812 73.728003 \n",
       "L 323.782812 73.728003 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_50\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"73.728003\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_26\">\n",
       "      <!-- 0.70 -->\n",
       "      <g transform=\"translate(20.282812 77.199878) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-37\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_16\">\n",
       "     <g id=\"line2d_51\">\n",
       "      <path d=\"M 44.782812 62.64 \n",
       "L 323.782812 62.64 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_52\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"62.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_27\">\n",
       "      <!-- 0.75 -->\n",
       "      <g transform=\"translate(20.282812 66.111875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-37\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_17\">\n",
       "     <g id=\"line2d_53\">\n",
       "      <path d=\"M 44.782812 51.551997 \n",
       "L 323.782812 51.551997 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_54\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"51.551997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_28\">\n",
       "      <!-- 0.80 -->\n",
       "      <g transform=\"translate(20.282812 55.023872) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-38\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_18\">\n",
       "     <g id=\"line2d_55\">\n",
       "      <path d=\"M 44.782812 40.463995 \n",
       "L 323.782812 40.463995 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_56\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"40.463995\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_29\">\n",
       "      <!-- 0.85 -->\n",
       "      <g transform=\"translate(20.282812 43.93587) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-38\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_19\">\n",
       "     <g id=\"line2d_57\">\n",
       "      <path d=\"M 44.782812 29.376005 \n",
       "L 323.782812 29.376005 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_58\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"29.376005\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_30\">\n",
       "      <!-- 0.90 -->\n",
       "      <g transform=\"translate(20.282812 32.84788) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-39\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_20\">\n",
       "     <g id=\"line2d_59\">\n",
       "      <path d=\"M 44.782812 18.288003 \n",
       "L 323.782812 18.288003 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_60\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ec95d50d3\" x=\"44.782812\" y=\"18.288003\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_31\">\n",
       "      <!-- 0.95 -->\n",
       "      <g transform=\"translate(20.282812 21.759878) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-39\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_32\">\n",
       "     <!-- Values -->\n",
       "     <g transform=\"translate(14.14375 131.408906) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-56\" d=\"M 4544 4238 \n",
       "L 4544 4122 \n",
       "Q 4319 4081 4203 3978 \n",
       "Q 4038 3825 3909 3509 \n",
       "L 2431 -97 \n",
       "L 2316 -97 \n",
       "L 728 3556 \n",
       "Q 606 3838 556 3900 \n",
       "Q 478 3997 364 4051 \n",
       "Q 250 4106 56 4122 \n",
       "L 56 4238 \n",
       "L 1788 4238 \n",
       "L 1788 4122 \n",
       "Q 1494 4094 1406 4022 \n",
       "Q 1319 3950 1319 3838 \n",
       "Q 1319 3681 1463 3350 \n",
       "L 2541 866 \n",
       "L 3541 3319 \n",
       "Q 3688 3681 3688 3822 \n",
       "Q 3688 3913 3597 3995 \n",
       "Q 3506 4078 3291 4113 \n",
       "Q 3275 4116 3238 4122 \n",
       "L 3238 4238 \n",
       "L 4544 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-61\" d=\"M 1822 413 \n",
       "Q 1381 72 1269 19 \n",
       "Q 1100 -59 909 -59 \n",
       "Q 613 -59 420 144 \n",
       "Q 228 347 228 678 \n",
       "Q 228 888 322 1041 \n",
       "Q 450 1253 767 1440 \n",
       "Q 1084 1628 1822 1897 \n",
       "L 1822 2009 \n",
       "Q 1822 2438 1686 2597 \n",
       "Q 1550 2756 1291 2756 \n",
       "Q 1094 2756 978 2650 \n",
       "Q 859 2544 859 2406 \n",
       "L 866 2225 \n",
       "Q 866 2081 792 2003 \n",
       "Q 719 1925 600 1925 \n",
       "Q 484 1925 411 2006 \n",
       "Q 338 2088 338 2228 \n",
       "Q 338 2497 613 2722 \n",
       "Q 888 2947 1384 2947 \n",
       "Q 1766 2947 2009 2819 \n",
       "Q 2194 2722 2281 2516 \n",
       "Q 2338 2381 2338 1966 \n",
       "L 2338 994 \n",
       "Q 2338 584 2353 492 \n",
       "Q 2369 400 2405 369 \n",
       "Q 2441 338 2488 338 \n",
       "Q 2538 338 2575 359 \n",
       "Q 2641 400 2828 588 \n",
       "L 2828 413 \n",
       "Q 2478 -56 2159 -56 \n",
       "Q 2006 -56 1915 50 \n",
       "Q 1825 156 1822 413 \n",
       "z\n",
       "M 1822 616 \n",
       "L 1822 1706 \n",
       "Q 1350 1519 1213 1441 \n",
       "Q 966 1303 859 1153 \n",
       "Q 753 1003 753 825 \n",
       "Q 753 600 887 451 \n",
       "Q 1022 303 1197 303 \n",
       "Q 1434 303 1822 616 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6c\" d=\"M 1184 4444 \n",
       "L 1184 647 \n",
       "Q 1184 378 1223 290 \n",
       "Q 1263 203 1344 158 \n",
       "Q 1425 113 1647 113 \n",
       "L 1647 0 \n",
       "L 244 0 \n",
       "L 244 113 \n",
       "Q 441 113 512 153 \n",
       "Q 584 194 625 287 \n",
       "Q 666 381 666 647 \n",
       "L 666 3247 \n",
       "Q 666 3731 644 3842 \n",
       "Q 622 3953 573 3993 \n",
       "Q 525 4034 450 4034 \n",
       "Q 369 4034 244 3984 \n",
       "L 191 4094 \n",
       "L 1044 4444 \n",
       "L 1184 4444 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-75\" d=\"M 2709 2863 \n",
       "L 2709 1128 \n",
       "Q 2709 631 2732 520 \n",
       "Q 2756 409 2807 365 \n",
       "Q 2859 322 2928 322 \n",
       "Q 3025 322 3147 375 \n",
       "L 3191 266 \n",
       "L 2334 -88 \n",
       "L 2194 -88 \n",
       "L 2194 519 \n",
       "Q 1825 119 1631 15 \n",
       "Q 1438 -88 1222 -88 \n",
       "Q 981 -88 804 51 \n",
       "Q 628 191 559 409 \n",
       "Q 491 628 491 1028 \n",
       "L 491 2306 \n",
       "Q 491 2509 447 2587 \n",
       "Q 403 2666 317 2708 \n",
       "Q 231 2750 6 2747 \n",
       "L 6 2863 \n",
       "L 1009 2863 \n",
       "L 1009 947 \n",
       "Q 1009 547 1148 422 \n",
       "Q 1288 297 1484 297 \n",
       "Q 1619 297 1789 381 \n",
       "Q 1959 466 2194 703 \n",
       "L 2194 2325 \n",
       "Q 2194 2569 2105 2655 \n",
       "Q 2016 2741 1734 2747 \n",
       "L 1734 2863 \n",
       "L 2709 2863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-65\" d=\"M 681 1784 \n",
       "Q 678 1147 991 784 \n",
       "Q 1303 422 1725 422 \n",
       "Q 2006 422 2214 576 \n",
       "Q 2422 731 2563 1106 \n",
       "L 2659 1044 \n",
       "Q 2594 616 2278 264 \n",
       "Q 1963 -88 1488 -88 \n",
       "Q 972 -88 605 314 \n",
       "Q 238 716 238 1394 \n",
       "Q 238 2128 614 2539 \n",
       "Q 991 2950 1559 2950 \n",
       "Q 2041 2950 2350 2633 \n",
       "Q 2659 2316 2659 1784 \n",
       "L 681 1784 \n",
       "z\n",
       "M 681 1966 \n",
       "L 2006 1966 \n",
       "Q 1991 2241 1941 2353 \n",
       "Q 1863 2528 1708 2628 \n",
       "Q 1553 2728 1384 2728 \n",
       "Q 1125 2728 920 2526 \n",
       "Q 716 2325 681 1966 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-73\" d=\"M 2050 2947 \n",
       "L 2050 1972 \n",
       "L 1947 1972 \n",
       "Q 1828 2431 1642 2597 \n",
       "Q 1456 2763 1169 2763 \n",
       "Q 950 2763 815 2647 \n",
       "Q 681 2531 681 2391 \n",
       "Q 681 2216 781 2091 \n",
       "Q 878 1963 1175 1819 \n",
       "L 1631 1597 \n",
       "Q 2266 1288 2266 781 \n",
       "Q 2266 391 1970 151 \n",
       "Q 1675 -88 1309 -88 \n",
       "Q 1047 -88 709 6 \n",
       "Q 606 38 541 38 \n",
       "Q 469 38 428 -44 \n",
       "L 325 -44 \n",
       "L 325 978 \n",
       "L 428 978 \n",
       "Q 516 541 762 319 \n",
       "Q 1009 97 1316 97 \n",
       "Q 1531 97 1667 223 \n",
       "Q 1803 350 1803 528 \n",
       "Q 1803 744 1651 891 \n",
       "Q 1500 1038 1047 1263 \n",
       "Q 594 1488 453 1669 \n",
       "Q 313 1847 313 2119 \n",
       "Q 313 2472 555 2709 \n",
       "Q 797 2947 1181 2947 \n",
       "Q 1350 2947 1591 2875 \n",
       "Q 1750 2828 1803 2828 \n",
       "Q 1853 2828 1881 2850 \n",
       "Q 1909 2872 1947 2947 \n",
       "L 2050 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-56\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"61.091797\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6c\" x=\"105.476562\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-75\" x=\"133.259766\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-65\" x=\"183.259766\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-73\" x=\"227.644531\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_61\">\n",
       "    <path d=\"M 44.782812 41.894346 \n",
       "L 75.782813 24.622945 \n",
       "L 106.782813 21.26698 \n",
       "L 137.782813 20.35407 \n",
       "L 168.782813 18.262122 \n",
       "L 199.782813 17.020271 \n",
       "L 230.782813 15.996477 \n",
       "L 261.782812 14.891379 \n",
       "L 292.782812 14.248274 \n",
       "L 323.782812 13.753012 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_62\">\n",
       "    <path d=\"M 44.782812 40.707932 \n",
       "L 75.782813 24.031588 \n",
       "L 106.782813 21.614399 \n",
       "L 137.782813 21.126526 \n",
       "L 168.782813 18.975454 \n",
       "L 199.782813 18.177117 \n",
       "L 230.782813 17.134844 \n",
       "L 261.782812 16.136931 \n",
       "L 292.782812 15.693403 \n",
       "L 323.782812 15.116837 \n",
       "\" clip-path=\"url(#p21d23a3a71)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 44.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 44.782812 7.2 \n",
       "L 323.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 51.782812 223.96 \n",
       "L 120.425 223.96 \n",
       "Q 122.425 223.96 122.425 221.96 \n",
       "L 122.425 194.644375 \n",
       "Q 122.425 192.644375 120.425 192.644375 \n",
       "L 51.782812 192.644375 \n",
       "Q 49.782812 192.644375 49.782812 194.644375 \n",
       "L 49.782812 221.96 \n",
       "Q 49.782812 223.96 51.782812 223.96 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_63\">\n",
       "     <path d=\"M 53.782812 200.144375 \n",
       "L 63.782812 200.144375 \n",
       "L 73.782813 200.144375 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_33\">\n",
       "     <!-- train_acc -->\n",
       "     <g transform=\"translate(81.782813 203.644375) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-74\" d=\"M 1031 3803 \n",
       "L 1031 2863 \n",
       "L 1700 2863 \n",
       "L 1700 2644 \n",
       "L 1031 2644 \n",
       "L 1031 788 \n",
       "Q 1031 509 1111 412 \n",
       "Q 1191 316 1316 316 \n",
       "Q 1419 316 1516 380 \n",
       "Q 1613 444 1666 569 \n",
       "L 1788 569 \n",
       "Q 1678 263 1478 108 \n",
       "Q 1278 -47 1066 -47 \n",
       "Q 922 -47 784 33 \n",
       "Q 647 113 581 261 \n",
       "Q 516 409 516 719 \n",
       "L 516 2644 \n",
       "L 63 2644 \n",
       "L 63 2747 \n",
       "Q 234 2816 414 2980 \n",
       "Q 594 3144 734 3369 \n",
       "Q 806 3488 934 3803 \n",
       "L 1031 3803 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-72\" d=\"M 1038 2947 \n",
       "L 1038 2303 \n",
       "Q 1397 2947 1775 2947 \n",
       "Q 1947 2947 2059 2842 \n",
       "Q 2172 2738 2172 2600 \n",
       "Q 2172 2478 2090 2393 \n",
       "Q 2009 2309 1897 2309 \n",
       "Q 1788 2309 1652 2417 \n",
       "Q 1516 2525 1450 2525 \n",
       "Q 1394 2525 1328 2463 \n",
       "Q 1188 2334 1038 2041 \n",
       "L 1038 669 \n",
       "Q 1038 431 1097 309 \n",
       "Q 1138 225 1241 169 \n",
       "Q 1344 113 1538 113 \n",
       "L 1538 0 \n",
       "L 72 0 \n",
       "L 72 113 \n",
       "Q 291 113 397 181 \n",
       "Q 475 231 506 341 \n",
       "Q 522 394 522 644 \n",
       "L 522 1753 \n",
       "Q 522 2253 501 2348 \n",
       "Q 481 2444 426 2487 \n",
       "Q 372 2531 291 2531 \n",
       "Q 194 2531 72 2484 \n",
       "L 41 2597 \n",
       "L 906 2947 \n",
       "L 1038 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-69\" d=\"M 928 4444 \n",
       "Q 1059 4444 1151 4351 \n",
       "Q 1244 4259 1244 4128 \n",
       "Q 1244 3997 1151 3903 \n",
       "Q 1059 3809 928 3809 \n",
       "Q 797 3809 703 3903 \n",
       "Q 609 3997 609 4128 \n",
       "Q 609 4259 701 4351 \n",
       "Q 794 4444 928 4444 \n",
       "z\n",
       "M 1188 2947 \n",
       "L 1188 647 \n",
       "Q 1188 378 1227 289 \n",
       "Q 1266 200 1342 156 \n",
       "Q 1419 113 1622 113 \n",
       "L 1622 0 \n",
       "L 231 0 \n",
       "L 231 113 \n",
       "Q 441 113 512 153 \n",
       "Q 584 194 626 287 \n",
       "Q 669 381 669 647 \n",
       "L 669 1750 \n",
       "Q 669 2216 641 2353 \n",
       "Q 619 2453 572 2492 \n",
       "Q 525 2531 444 2531 \n",
       "Q 356 2531 231 2484 \n",
       "L 188 2597 \n",
       "L 1050 2947 \n",
       "L 1188 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6e\" d=\"M 1034 2341 \n",
       "Q 1538 2947 1994 2947 \n",
       "Q 2228 2947 2397 2830 \n",
       "Q 2566 2713 2666 2444 \n",
       "Q 2734 2256 2734 1869 \n",
       "L 2734 647 \n",
       "Q 2734 375 2778 278 \n",
       "Q 2813 200 2889 156 \n",
       "Q 2966 113 3172 113 \n",
       "L 3172 0 \n",
       "L 1756 0 \n",
       "L 1756 113 \n",
       "L 1816 113 \n",
       "Q 2016 113 2095 173 \n",
       "Q 2175 234 2206 353 \n",
       "Q 2219 400 2219 647 \n",
       "L 2219 1819 \n",
       "Q 2219 2209 2117 2386 \n",
       "Q 2016 2563 1775 2563 \n",
       "Q 1403 2563 1034 2156 \n",
       "L 1034 647 \n",
       "Q 1034 356 1069 288 \n",
       "Q 1113 197 1189 155 \n",
       "Q 1266 113 1500 113 \n",
       "L 1500 0 \n",
       "L 84 0 \n",
       "L 84 113 \n",
       "L 147 113 \n",
       "Q 366 113 442 223 \n",
       "Q 519 334 519 647 \n",
       "L 519 1709 \n",
       "Q 519 2225 495 2337 \n",
       "Q 472 2450 423 2490 \n",
       "Q 375 2531 294 2531 \n",
       "Q 206 2531 84 2484 \n",
       "L 38 2597 \n",
       "L 900 2947 \n",
       "L 1034 2947 \n",
       "L 1034 2341 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-5f\" d=\"M 3256 -1381 \n",
       "L -53 -1381 \n",
       "L -53 -1119 \n",
       "L 3256 -1119 \n",
       "L 3256 -1381 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-72\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"61.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-69\" x=\"105.46875\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6e\" x=\"133.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-5f\" x=\"183.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"233.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"277.636719\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"322.021484\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_64\">\n",
       "     <path d=\"M 53.782812 214.302187 \n",
       "L 63.782812 214.302187 \n",
       "L 73.782813 214.302187 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_34\">\n",
       "     <!-- test_acc -->\n",
       "     <g transform=\"translate(81.782813 217.802187) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-65\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-73\" x=\"72.167969\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\" x=\"111.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-5f\" x=\"138.867188\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"188.867188\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"233.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"277.636719\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p21d23a3a71\">\n",
       "   <rect x=\"44.782812\" y=\"7.2\" width=\"279\" height=\"221.76\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_acc一直在92%左右，如何才能提高？\n",
    "# 使用CNN会好一点吗？\n",
    "# 我们来试一试：\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 10), nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net1()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device, \n",
    "    train_figure=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 210.56247329711914 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.4977), tensor(0.9650), tensor(0.9571))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"335.982812pt\" height=\"265.325625pt\" viewBox=\"0 0 335.982812 265.325625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-04-25T11:16:47.537576</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 265.325625 \n",
       "L 335.982812 265.325625 \n",
       "L 335.982812 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "L 44.782812 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 83.265571 228.96 \n",
       "L 83.265571 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"mc04ace902a\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"83.265571\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(80.765571 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-35\" d=\"M 2778 4238 \n",
       "L 2534 3706 \n",
       "L 1259 3706 \n",
       "L 981 3138 \n",
       "Q 1809 3016 2294 2522 \n",
       "Q 2709 2097 2709 1522 \n",
       "Q 2709 1188 2573 903 \n",
       "Q 2438 619 2231 419 \n",
       "Q 2025 219 1772 97 \n",
       "Q 1413 -75 1034 -75 \n",
       "Q 653 -75 479 54 \n",
       "Q 306 184 306 341 \n",
       "Q 306 428 378 495 \n",
       "Q 450 563 559 563 \n",
       "Q 641 563 702 538 \n",
       "Q 763 513 909 409 \n",
       "Q 1144 247 1384 247 \n",
       "Q 1750 247 2026 523 \n",
       "Q 2303 800 2303 1197 \n",
       "Q 2303 1581 2056 1914 \n",
       "Q 1809 2247 1375 2428 \n",
       "Q 1034 2569 447 2591 \n",
       "L 1259 4238 \n",
       "L 2778 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 131.369019 228.96 \n",
       "L 131.369019 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"131.369019\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(126.369019 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-31\" d=\"M 750 3822 \n",
       "L 1781 4325 \n",
       "L 1884 4325 \n",
       "L 1884 747 \n",
       "Q 1884 391 1914 303 \n",
       "Q 1944 216 2037 169 \n",
       "Q 2131 122 2419 116 \n",
       "L 2419 0 \n",
       "L 825 0 \n",
       "L 825 116 \n",
       "Q 1125 122 1212 167 \n",
       "Q 1300 213 1334 289 \n",
       "Q 1369 366 1369 747 \n",
       "L 1369 3034 \n",
       "Q 1369 3497 1338 3628 \n",
       "Q 1316 3728 1258 3775 \n",
       "Q 1200 3822 1119 3822 \n",
       "Q 1003 3822 797 3725 \n",
       "L 750 3822 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"TimesNewRomanPSMT-30\" d=\"M 231 2094 \n",
       "Q 231 2819 450 3342 \n",
       "Q 669 3866 1031 4122 \n",
       "Q 1313 4325 1613 4325 \n",
       "Q 2100 4325 2488 3828 \n",
       "Q 2972 3213 2972 2159 \n",
       "Q 2972 1422 2759 906 \n",
       "Q 2547 391 2217 158 \n",
       "Q 1888 -75 1581 -75 \n",
       "Q 975 -75 572 641 \n",
       "Q 231 1244 231 2094 \n",
       "z\n",
       "M 844 2016 \n",
       "Q 844 1141 1059 588 \n",
       "Q 1238 122 1591 122 \n",
       "Q 1759 122 1940 273 \n",
       "Q 2122 425 2216 781 \n",
       "Q 2359 1319 2359 2297 \n",
       "Q 2359 3022 2209 3506 \n",
       "Q 2097 3866 1919 4016 \n",
       "Q 1791 4119 1609 4119 \n",
       "Q 1397 4119 1231 3928 \n",
       "Q 1006 3669 925 3112 \n",
       "Q 844 2556 844 2016 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 179.472468 228.96 \n",
       "L 179.472468 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"179.472468\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(174.472468 242.90375) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 227.575916 228.96 \n",
       "L 227.575916 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"227.575916\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(222.575916 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-32\" d=\"M 2934 816 \n",
       "L 2638 0 \n",
       "L 138 0 \n",
       "L 138 116 \n",
       "Q 1241 1122 1691 1759 \n",
       "Q 2141 2397 2141 2925 \n",
       "Q 2141 3328 1894 3587 \n",
       "Q 1647 3847 1303 3847 \n",
       "Q 991 3847 742 3664 \n",
       "Q 494 3481 375 3128 \n",
       "L 259 3128 \n",
       "Q 338 3706 661 4015 \n",
       "Q 984 4325 1469 4325 \n",
       "Q 1984 4325 2329 3994 \n",
       "Q 2675 3663 2675 3213 \n",
       "Q 2675 2891 2525 2569 \n",
       "Q 2294 2063 1775 1497 \n",
       "Q 997 647 803 472 \n",
       "L 1909 472 \n",
       "Q 2247 472 2383 497 \n",
       "Q 2519 522 2628 598 \n",
       "Q 2738 675 2819 816 \n",
       "L 2934 816 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 275.679364 228.96 \n",
       "L 275.679364 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"275.679364\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(270.679364 242.90375) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc04ace902a\" x=\"323.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 30 -->\n",
       "      <g transform=\"translate(318.782812 242.90375) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-33\" d=\"M 325 3431 \n",
       "Q 506 3859 782 4092 \n",
       "Q 1059 4325 1472 4325 \n",
       "Q 1981 4325 2253 3994 \n",
       "Q 2459 3747 2459 3466 \n",
       "Q 2459 3003 1878 2509 \n",
       "Q 2269 2356 2469 2072 \n",
       "Q 2669 1788 2669 1403 \n",
       "Q 2669 853 2319 450 \n",
       "Q 1863 -75 997 -75 \n",
       "Q 569 -75 414 31 \n",
       "Q 259 138 259 259 \n",
       "Q 259 350 332 419 \n",
       "Q 406 488 509 488 \n",
       "Q 588 488 669 463 \n",
       "Q 722 447 909 348 \n",
       "Q 1097 250 1169 231 \n",
       "Q 1284 197 1416 197 \n",
       "Q 1734 197 1970 444 \n",
       "Q 2206 691 2206 1028 \n",
       "Q 2206 1275 2097 1509 \n",
       "Q 2016 1684 1919 1775 \n",
       "Q 1784 1900 1550 2001 \n",
       "Q 1316 2103 1072 2103 \n",
       "L 972 2103 \n",
       "L 972 2197 \n",
       "Q 1219 2228 1467 2375 \n",
       "Q 1716 2522 1828 2728 \n",
       "Q 1941 2934 1941 3181 \n",
       "Q 1941 3503 1739 3701 \n",
       "Q 1538 3900 1238 3900 \n",
       "Q 753 3900 428 3381 \n",
       "L 325 3431 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Epoch -->\n",
       "     <g transform=\"translate(171.509375 255.986562) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-45\" d=\"M 1338 4006 \n",
       "L 1338 2331 \n",
       "L 2269 2331 \n",
       "Q 2631 2331 2753 2441 \n",
       "Q 2916 2584 2934 2947 \n",
       "L 3050 2947 \n",
       "L 3050 1472 \n",
       "L 2934 1472 \n",
       "Q 2891 1781 2847 1869 \n",
       "Q 2791 1978 2662 2040 \n",
       "Q 2534 2103 2269 2103 \n",
       "L 1338 2103 \n",
       "L 1338 706 \n",
       "Q 1338 425 1363 364 \n",
       "Q 1388 303 1450 267 \n",
       "Q 1513 231 1688 231 \n",
       "L 2406 231 \n",
       "Q 2766 231 2928 281 \n",
       "Q 3091 331 3241 478 \n",
       "Q 3434 672 3638 1063 \n",
       "L 3763 1063 \n",
       "L 3397 0 \n",
       "L 131 0 \n",
       "L 131 116 \n",
       "L 281 116 \n",
       "Q 431 116 566 188 \n",
       "Q 666 238 702 338 \n",
       "Q 738 438 738 747 \n",
       "L 738 3500 \n",
       "Q 738 3903 656 3997 \n",
       "Q 544 4122 281 4122 \n",
       "L 131 4122 \n",
       "L 131 4238 \n",
       "L 3397 4238 \n",
       "L 3444 3309 \n",
       "L 3322 3309 \n",
       "Q 3256 3644 3176 3769 \n",
       "Q 3097 3894 2941 3959 \n",
       "Q 2816 4006 2500 4006 \n",
       "L 1338 4006 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-70\" d=\"M -6 2578 \n",
       "L 875 2934 \n",
       "L 994 2934 \n",
       "L 994 2266 \n",
       "Q 1216 2644 1439 2795 \n",
       "Q 1663 2947 1909 2947 \n",
       "Q 2341 2947 2628 2609 \n",
       "Q 2981 2197 2981 1534 \n",
       "Q 2981 794 2556 309 \n",
       "Q 2206 -88 1675 -88 \n",
       "Q 1444 -88 1275 -22 \n",
       "Q 1150 25 994 166 \n",
       "L 994 -706 \n",
       "Q 994 -1000 1030 -1079 \n",
       "Q 1066 -1159 1155 -1206 \n",
       "Q 1244 -1253 1478 -1253 \n",
       "L 1478 -1369 \n",
       "L -22 -1369 \n",
       "L -22 -1253 \n",
       "L 56 -1253 \n",
       "Q 228 -1256 350 -1188 \n",
       "Q 409 -1153 442 -1076 \n",
       "Q 475 -1000 475 -688 \n",
       "L 475 2019 \n",
       "Q 475 2297 450 2372 \n",
       "Q 425 2447 370 2484 \n",
       "Q 316 2522 222 2522 \n",
       "Q 147 2522 31 2478 \n",
       "L -6 2578 \n",
       "z\n",
       "M 994 2081 \n",
       "L 994 1013 \n",
       "Q 994 666 1022 556 \n",
       "Q 1066 375 1236 237 \n",
       "Q 1406 100 1666 100 \n",
       "Q 1978 100 2172 344 \n",
       "Q 2425 663 2425 1241 \n",
       "Q 2425 1897 2138 2250 \n",
       "Q 1938 2494 1663 2494 \n",
       "Q 1513 2494 1366 2419 \n",
       "Q 1253 2363 994 2081 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6f\" d=\"M 1600 2947 \n",
       "Q 2250 2947 2644 2453 \n",
       "Q 2978 2031 2978 1484 \n",
       "Q 2978 1100 2793 706 \n",
       "Q 2609 313 2286 112 \n",
       "Q 1963 -88 1566 -88 \n",
       "Q 919 -88 538 428 \n",
       "Q 216 863 216 1403 \n",
       "Q 216 1797 411 2186 \n",
       "Q 606 2575 925 2761 \n",
       "Q 1244 2947 1600 2947 \n",
       "z\n",
       "M 1503 2744 \n",
       "Q 1338 2744 1170 2645 \n",
       "Q 1003 2547 900 2300 \n",
       "Q 797 2053 797 1666 \n",
       "Q 797 1041 1045 587 \n",
       "Q 1294 134 1700 134 \n",
       "Q 2003 134 2200 384 \n",
       "Q 2397 634 2397 1244 \n",
       "Q 2397 2006 2069 2444 \n",
       "Q 1847 2744 1503 2744 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-63\" d=\"M 2631 1088 \n",
       "Q 2516 522 2178 217 \n",
       "Q 1841 -88 1431 -88 \n",
       "Q 944 -88 581 321 \n",
       "Q 219 731 219 1428 \n",
       "Q 219 2103 620 2525 \n",
       "Q 1022 2947 1584 2947 \n",
       "Q 2006 2947 2278 2723 \n",
       "Q 2550 2500 2550 2259 \n",
       "Q 2550 2141 2473 2067 \n",
       "Q 2397 1994 2259 1994 \n",
       "Q 2075 1994 1981 2113 \n",
       "Q 1928 2178 1911 2362 \n",
       "Q 1894 2547 1784 2644 \n",
       "Q 1675 2738 1481 2738 \n",
       "Q 1169 2738 978 2506 \n",
       "Q 725 2200 725 1697 \n",
       "Q 725 1184 976 792 \n",
       "Q 1228 400 1656 400 \n",
       "Q 1963 400 2206 609 \n",
       "Q 2378 753 2541 1131 \n",
       "L 2631 1088 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-68\" d=\"M 1041 4444 \n",
       "L 1041 2350 \n",
       "Q 1388 2731 1591 2839 \n",
       "Q 1794 2947 1997 2947 \n",
       "Q 2241 2947 2416 2812 \n",
       "Q 2591 2678 2675 2391 \n",
       "Q 2734 2191 2734 1659 \n",
       "L 2734 647 \n",
       "Q 2734 375 2778 275 \n",
       "Q 2809 200 2884 156 \n",
       "Q 2959 113 3159 113 \n",
       "L 3159 0 \n",
       "L 1753 0 \n",
       "L 1753 113 \n",
       "L 1819 113 \n",
       "Q 2019 113 2097 173 \n",
       "Q 2175 234 2206 353 \n",
       "Q 2216 403 2216 647 \n",
       "L 2216 1659 \n",
       "Q 2216 2128 2167 2275 \n",
       "Q 2119 2422 2012 2495 \n",
       "Q 1906 2569 1756 2569 \n",
       "Q 1603 2569 1437 2487 \n",
       "Q 1272 2406 1041 2159 \n",
       "L 1041 647 \n",
       "Q 1041 353 1073 281 \n",
       "Q 1106 209 1195 161 \n",
       "Q 1284 113 1503 113 \n",
       "L 1503 0 \n",
       "L 84 0 \n",
       "L 84 113 \n",
       "Q 275 113 384 172 \n",
       "Q 447 203 484 290 \n",
       "Q 522 378 522 647 \n",
       "L 522 3238 \n",
       "Q 522 3728 498 3840 \n",
       "Q 475 3953 426 3993 \n",
       "Q 378 4034 297 4034 \n",
       "Q 231 4034 84 3984 \n",
       "L 41 4094 \n",
       "L 897 4444 \n",
       "L 1041 4444 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-45\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-70\" x=\"61.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6f\" x=\"111.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"161.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-68\" x=\"205.46875\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <defs>\n",
       "       <path id=\"mcd123fd2b1\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.00 -->\n",
       "      <g transform=\"translate(20.282812 232.431875) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-2e\" d=\"M 800 606 \n",
       "Q 947 606 1047 504 \n",
       "Q 1147 403 1147 259 \n",
       "Q 1147 116 1045 14 \n",
       "Q 944 -88 800 -88 \n",
       "Q 656 -88 554 14 \n",
       "Q 453 116 453 259 \n",
       "Q 453 406 554 506 \n",
       "Q 656 606 800 606 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 44.782812 217.872 \n",
       "L 323.782812 217.872 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"217.872\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.05 -->\n",
       "      <g transform=\"translate(20.282812 221.343875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 44.782812 206.784 \n",
       "L 323.782812 206.784 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"206.784\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.282812 210.255875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 44.782812 195.695999 \n",
       "L 323.782812 195.695999 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"195.695999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.282812 199.167874) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-31\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 44.782812 184.607999 \n",
       "L 323.782812 184.607999 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"184.607999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.20 -->\n",
       "      <g transform=\"translate(20.282812 188.079874) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 44.782812 173.52 \n",
       "L 323.782812 173.52 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"173.52\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.25 -->\n",
       "      <g transform=\"translate(20.282812 176.991875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-32\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path d=\"M 44.782812 162.431997 \n",
       "L 323.782812 162.431997 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_26\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"162.431997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.30 -->\n",
       "      <g transform=\"translate(20.282812 165.903872) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path d=\"M 44.782812 151.344001 \n",
       "L 323.782812 151.344001 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_28\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"151.344001\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.35 -->\n",
       "      <g transform=\"translate(20.282812 154.815876) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-33\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <path d=\"M 44.782812 140.255999 \n",
       "L 323.782812 140.255999 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_30\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"140.255999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 0.40 -->\n",
       "      <g transform=\"translate(20.282812 143.727874) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-34\" d=\"M 2978 1563 \n",
       "L 2978 1119 \n",
       "L 2409 1119 \n",
       "L 2409 0 \n",
       "L 1894 0 \n",
       "L 1894 1119 \n",
       "L 100 1119 \n",
       "L 100 1519 \n",
       "L 2066 4325 \n",
       "L 2409 4325 \n",
       "L 2409 1563 \n",
       "L 2978 1563 \n",
       "z\n",
       "M 1894 1563 \n",
       "L 1894 3666 \n",
       "L 406 1563 \n",
       "L 1894 1563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-34\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_31\">\n",
       "      <path d=\"M 44.782812 129.167996 \n",
       "L 323.782812 129.167996 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_32\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"129.167996\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 0.45 -->\n",
       "      <g transform=\"translate(20.282812 132.639871) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-34\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_11\">\n",
       "     <g id=\"line2d_33\">\n",
       "      <path d=\"M 44.782812 118.08 \n",
       "L 323.782812 118.08 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_34\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"118.08\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- 0.50 -->\n",
       "      <g transform=\"translate(20.282812 121.551875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_12\">\n",
       "     <g id=\"line2d_35\">\n",
       "      <path d=\"M 44.782812 106.991997 \n",
       "L 323.782812 106.991997 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_36\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"106.991997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 0.55 -->\n",
       "      <g transform=\"translate(20.282812 110.463872) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_13\">\n",
       "     <g id=\"line2d_37\">\n",
       "      <path d=\"M 44.782812 95.903995 \n",
       "L 323.782812 95.903995 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_38\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"95.903995\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_20\">\n",
       "      <!-- 0.60 -->\n",
       "      <g transform=\"translate(20.282812 99.37587) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-36\" d=\"M 2869 4325 \n",
       "L 2869 4209 \n",
       "Q 2456 4169 2195 4045 \n",
       "Q 1934 3922 1679 3669 \n",
       "Q 1425 3416 1258 3105 \n",
       "Q 1091 2794 978 2366 \n",
       "Q 1428 2675 1881 2675 \n",
       "Q 2316 2675 2634 2325 \n",
       "Q 2953 1975 2953 1425 \n",
       "Q 2953 894 2631 456 \n",
       "Q 2244 -75 1606 -75 \n",
       "Q 1172 -75 869 213 \n",
       "Q 275 772 275 1663 \n",
       "Q 275 2231 503 2743 \n",
       "Q 731 3256 1154 3653 \n",
       "Q 1578 4050 1965 4187 \n",
       "Q 2353 4325 2688 4325 \n",
       "L 2869 4325 \n",
       "z\n",
       "M 925 2138 \n",
       "Q 869 1716 869 1456 \n",
       "Q 869 1156 980 804 \n",
       "Q 1091 453 1309 247 \n",
       "Q 1469 100 1697 100 \n",
       "Q 1969 100 2183 356 \n",
       "Q 2397 613 2397 1088 \n",
       "Q 2397 1622 2184 2012 \n",
       "Q 1972 2403 1581 2403 \n",
       "Q 1463 2403 1327 2353 \n",
       "Q 1191 2303 925 2138 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-36\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_14\">\n",
       "     <g id=\"line2d_39\">\n",
       "      <path d=\"M 44.782812 84.816005 \n",
       "L 323.782812 84.816005 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_40\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"84.816005\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_21\">\n",
       "      <!-- 0.65 -->\n",
       "      <g transform=\"translate(20.282812 88.28788) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-36\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_15\">\n",
       "     <g id=\"line2d_41\">\n",
       "      <path d=\"M 44.782812 73.728003 \n",
       "L 323.782812 73.728003 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_42\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"73.728003\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_22\">\n",
       "      <!-- 0.70 -->\n",
       "      <g transform=\"translate(20.282812 77.199878) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-37\" d=\"M 644 4238 \n",
       "L 2916 4238 \n",
       "L 2916 4119 \n",
       "L 1503 -88 \n",
       "L 1153 -88 \n",
       "L 2419 3728 \n",
       "L 1253 3728 \n",
       "Q 900 3728 750 3644 \n",
       "Q 488 3500 328 3200 \n",
       "L 238 3234 \n",
       "L 644 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-37\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_16\">\n",
       "     <g id=\"line2d_43\">\n",
       "      <path d=\"M 44.782812 62.64 \n",
       "L 323.782812 62.64 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_44\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"62.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_23\">\n",
       "      <!-- 0.75 -->\n",
       "      <g transform=\"translate(20.282812 66.111875) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-37\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_17\">\n",
       "     <g id=\"line2d_45\">\n",
       "      <path d=\"M 44.782812 51.551997 \n",
       "L 323.782812 51.551997 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_46\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"51.551997\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_24\">\n",
       "      <!-- 0.80 -->\n",
       "      <g transform=\"translate(20.282812 55.023872) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-38\" d=\"M 1228 2134 \n",
       "Q 725 2547 579 2797 \n",
       "Q 434 3047 434 3316 \n",
       "Q 434 3728 753 4026 \n",
       "Q 1072 4325 1600 4325 \n",
       "Q 2113 4325 2425 4047 \n",
       "Q 2738 3769 2738 3413 \n",
       "Q 2738 3175 2569 2928 \n",
       "Q 2400 2681 1866 2347 \n",
       "Q 2416 1922 2594 1678 \n",
       "Q 2831 1359 2831 1006 \n",
       "Q 2831 559 2490 242 \n",
       "Q 2150 -75 1597 -75 \n",
       "Q 994 -75 656 303 \n",
       "Q 388 606 388 966 \n",
       "Q 388 1247 577 1523 \n",
       "Q 766 1800 1228 2134 \n",
       "z\n",
       "M 1719 2469 \n",
       "Q 2094 2806 2194 3001 \n",
       "Q 2294 3197 2294 3444 \n",
       "Q 2294 3772 2109 3958 \n",
       "Q 1925 4144 1606 4144 \n",
       "Q 1288 4144 1088 3959 \n",
       "Q 888 3775 888 3528 \n",
       "Q 888 3366 970 3203 \n",
       "Q 1053 3041 1206 2894 \n",
       "L 1719 2469 \n",
       "z\n",
       "M 1375 2016 \n",
       "Q 1116 1797 991 1539 \n",
       "Q 866 1281 866 981 \n",
       "Q 866 578 1086 336 \n",
       "Q 1306 94 1647 94 \n",
       "Q 1984 94 2187 284 \n",
       "Q 2391 475 2391 747 \n",
       "Q 2391 972 2272 1150 \n",
       "Q 2050 1481 1375 2016 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-38\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_18\">\n",
       "     <g id=\"line2d_47\">\n",
       "      <path d=\"M 44.782812 40.463995 \n",
       "L 323.782812 40.463995 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_48\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"40.463995\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_25\">\n",
       "      <!-- 0.85 -->\n",
       "      <g transform=\"translate(20.282812 43.93587) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-38\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_19\">\n",
       "     <g id=\"line2d_49\">\n",
       "      <path d=\"M 44.782812 29.376005 \n",
       "L 323.782812 29.376005 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_50\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"29.376005\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_26\">\n",
       "      <!-- 0.90 -->\n",
       "      <g transform=\"translate(20.282812 32.84788) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"TimesNewRomanPSMT-39\" d=\"M 338 -88 \n",
       "L 338 28 \n",
       "Q 744 34 1094 217 \n",
       "Q 1444 400 1770 856 \n",
       "Q 2097 1313 2225 1859 \n",
       "Q 1734 1544 1338 1544 \n",
       "Q 891 1544 572 1889 \n",
       "Q 253 2234 253 2806 \n",
       "Q 253 3363 572 3797 \n",
       "Q 956 4325 1575 4325 \n",
       "Q 2097 4325 2469 3894 \n",
       "Q 2925 3359 2925 2575 \n",
       "Q 2925 1869 2578 1258 \n",
       "Q 2231 647 1613 244 \n",
       "Q 1109 -88 516 -88 \n",
       "L 338 -88 \n",
       "z\n",
       "M 2275 2091 \n",
       "Q 2331 2497 2331 2741 \n",
       "Q 2331 3044 2228 3395 \n",
       "Q 2125 3747 1936 3934 \n",
       "Q 1747 4122 1506 4122 \n",
       "Q 1228 4122 1018 3872 \n",
       "Q 809 3622 809 3128 \n",
       "Q 809 2469 1088 2097 \n",
       "Q 1291 1828 1588 1828 \n",
       "Q 1731 1828 1928 1897 \n",
       "Q 2125 1966 2275 2091 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-39\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_20\">\n",
       "     <g id=\"line2d_51\">\n",
       "      <path d=\"M 44.782812 18.288003 \n",
       "L 323.782812 18.288003 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_52\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcd123fd2b1\" x=\"44.782812\" y=\"18.288003\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_27\">\n",
       "      <!-- 0.95 -->\n",
       "      <g transform=\"translate(20.282812 21.759878) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-30\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-39\" x=\"75\"/>\n",
       "       <use xlink:href=\"#TimesNewRomanPSMT-35\" x=\"125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_28\">\n",
       "     <!-- Values -->\n",
       "     <g transform=\"translate(14.14375 131.408906) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-56\" d=\"M 4544 4238 \n",
       "L 4544 4122 \n",
       "Q 4319 4081 4203 3978 \n",
       "Q 4038 3825 3909 3509 \n",
       "L 2431 -97 \n",
       "L 2316 -97 \n",
       "L 728 3556 \n",
       "Q 606 3838 556 3900 \n",
       "Q 478 3997 364 4051 \n",
       "Q 250 4106 56 4122 \n",
       "L 56 4238 \n",
       "L 1788 4238 \n",
       "L 1788 4122 \n",
       "Q 1494 4094 1406 4022 \n",
       "Q 1319 3950 1319 3838 \n",
       "Q 1319 3681 1463 3350 \n",
       "L 2541 866 \n",
       "L 3541 3319 \n",
       "Q 3688 3681 3688 3822 \n",
       "Q 3688 3913 3597 3995 \n",
       "Q 3506 4078 3291 4113 \n",
       "Q 3275 4116 3238 4122 \n",
       "L 3238 4238 \n",
       "L 4544 4238 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-61\" d=\"M 1822 413 \n",
       "Q 1381 72 1269 19 \n",
       "Q 1100 -59 909 -59 \n",
       "Q 613 -59 420 144 \n",
       "Q 228 347 228 678 \n",
       "Q 228 888 322 1041 \n",
       "Q 450 1253 767 1440 \n",
       "Q 1084 1628 1822 1897 \n",
       "L 1822 2009 \n",
       "Q 1822 2438 1686 2597 \n",
       "Q 1550 2756 1291 2756 \n",
       "Q 1094 2756 978 2650 \n",
       "Q 859 2544 859 2406 \n",
       "L 866 2225 \n",
       "Q 866 2081 792 2003 \n",
       "Q 719 1925 600 1925 \n",
       "Q 484 1925 411 2006 \n",
       "Q 338 2088 338 2228 \n",
       "Q 338 2497 613 2722 \n",
       "Q 888 2947 1384 2947 \n",
       "Q 1766 2947 2009 2819 \n",
       "Q 2194 2722 2281 2516 \n",
       "Q 2338 2381 2338 1966 \n",
       "L 2338 994 \n",
       "Q 2338 584 2353 492 \n",
       "Q 2369 400 2405 369 \n",
       "Q 2441 338 2488 338 \n",
       "Q 2538 338 2575 359 \n",
       "Q 2641 400 2828 588 \n",
       "L 2828 413 \n",
       "Q 2478 -56 2159 -56 \n",
       "Q 2006 -56 1915 50 \n",
       "Q 1825 156 1822 413 \n",
       "z\n",
       "M 1822 616 \n",
       "L 1822 1706 \n",
       "Q 1350 1519 1213 1441 \n",
       "Q 966 1303 859 1153 \n",
       "Q 753 1003 753 825 \n",
       "Q 753 600 887 451 \n",
       "Q 1022 303 1197 303 \n",
       "Q 1434 303 1822 616 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6c\" d=\"M 1184 4444 \n",
       "L 1184 647 \n",
       "Q 1184 378 1223 290 \n",
       "Q 1263 203 1344 158 \n",
       "Q 1425 113 1647 113 \n",
       "L 1647 0 \n",
       "L 244 0 \n",
       "L 244 113 \n",
       "Q 441 113 512 153 \n",
       "Q 584 194 625 287 \n",
       "Q 666 381 666 647 \n",
       "L 666 3247 \n",
       "Q 666 3731 644 3842 \n",
       "Q 622 3953 573 3993 \n",
       "Q 525 4034 450 4034 \n",
       "Q 369 4034 244 3984 \n",
       "L 191 4094 \n",
       "L 1044 4444 \n",
       "L 1184 4444 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-75\" d=\"M 2709 2863 \n",
       "L 2709 1128 \n",
       "Q 2709 631 2732 520 \n",
       "Q 2756 409 2807 365 \n",
       "Q 2859 322 2928 322 \n",
       "Q 3025 322 3147 375 \n",
       "L 3191 266 \n",
       "L 2334 -88 \n",
       "L 2194 -88 \n",
       "L 2194 519 \n",
       "Q 1825 119 1631 15 \n",
       "Q 1438 -88 1222 -88 \n",
       "Q 981 -88 804 51 \n",
       "Q 628 191 559 409 \n",
       "Q 491 628 491 1028 \n",
       "L 491 2306 \n",
       "Q 491 2509 447 2587 \n",
       "Q 403 2666 317 2708 \n",
       "Q 231 2750 6 2747 \n",
       "L 6 2863 \n",
       "L 1009 2863 \n",
       "L 1009 947 \n",
       "Q 1009 547 1148 422 \n",
       "Q 1288 297 1484 297 \n",
       "Q 1619 297 1789 381 \n",
       "Q 1959 466 2194 703 \n",
       "L 2194 2325 \n",
       "Q 2194 2569 2105 2655 \n",
       "Q 2016 2741 1734 2747 \n",
       "L 1734 2863 \n",
       "L 2709 2863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-65\" d=\"M 681 1784 \n",
       "Q 678 1147 991 784 \n",
       "Q 1303 422 1725 422 \n",
       "Q 2006 422 2214 576 \n",
       "Q 2422 731 2563 1106 \n",
       "L 2659 1044 \n",
       "Q 2594 616 2278 264 \n",
       "Q 1963 -88 1488 -88 \n",
       "Q 972 -88 605 314 \n",
       "Q 238 716 238 1394 \n",
       "Q 238 2128 614 2539 \n",
       "Q 991 2950 1559 2950 \n",
       "Q 2041 2950 2350 2633 \n",
       "Q 2659 2316 2659 1784 \n",
       "L 681 1784 \n",
       "z\n",
       "M 681 1966 \n",
       "L 2006 1966 \n",
       "Q 1991 2241 1941 2353 \n",
       "Q 1863 2528 1708 2628 \n",
       "Q 1553 2728 1384 2728 \n",
       "Q 1125 2728 920 2526 \n",
       "Q 716 2325 681 1966 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-73\" d=\"M 2050 2947 \n",
       "L 2050 1972 \n",
       "L 1947 1972 \n",
       "Q 1828 2431 1642 2597 \n",
       "Q 1456 2763 1169 2763 \n",
       "Q 950 2763 815 2647 \n",
       "Q 681 2531 681 2391 \n",
       "Q 681 2216 781 2091 \n",
       "Q 878 1963 1175 1819 \n",
       "L 1631 1597 \n",
       "Q 2266 1288 2266 781 \n",
       "Q 2266 391 1970 151 \n",
       "Q 1675 -88 1309 -88 \n",
       "Q 1047 -88 709 6 \n",
       "Q 606 38 541 38 \n",
       "Q 469 38 428 -44 \n",
       "L 325 -44 \n",
       "L 325 978 \n",
       "L 428 978 \n",
       "Q 516 541 762 319 \n",
       "Q 1009 97 1316 97 \n",
       "Q 1531 97 1667 223 \n",
       "Q 1803 350 1803 528 \n",
       "Q 1803 744 1651 891 \n",
       "Q 1500 1038 1047 1263 \n",
       "Q 594 1488 453 1669 \n",
       "Q 313 1847 313 2119 \n",
       "Q 313 2472 555 2709 \n",
       "Q 797 2947 1181 2947 \n",
       "Q 1350 2947 1591 2875 \n",
       "Q 1750 2828 1803 2828 \n",
       "Q 1853 2828 1881 2850 \n",
       "Q 1909 2872 1947 2947 \n",
       "L 2050 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-56\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"61.091797\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6c\" x=\"105.476562\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-75\" x=\"133.259766\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-65\" x=\"183.259766\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-73\" x=\"227.644531\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_53\">\n",
       "    <path d=\"M 44.782812 27.317327 \n",
       "L 54.403502 23.913314 \n",
       "L 64.024192 23.163025 \n",
       "L 73.644881 21.640267 \n",
       "L 83.265571 20.716268 \n",
       "L 92.886261 20.383626 \n",
       "L 102.50695 19.07895 \n",
       "L 112.12764 18.720427 \n",
       "L 121.74833 18.398875 \n",
       "L 131.369019 17.707722 \n",
       "L 140.989709 18.288003 \n",
       "L 150.610399 17.219862 \n",
       "L 160.231088 16.84286 \n",
       "L 169.851778 16.813292 \n",
       "L 179.472468 16.550876 \n",
       "L 189.093157 16.354987 \n",
       "L 198.713847 16.84286 \n",
       "L 208.334537 16.32173 \n",
       "L 217.955226 16.107362 \n",
       "L 227.575916 16.151708 \n",
       "L 237.196606 15.778421 \n",
       "L 246.817295 16.007567 \n",
       "L 256.437985 15.815378 \n",
       "L 266.058675 15.545574 \n",
       "L 275.679364 15.353372 \n",
       "L 285.300054 15.368163 \n",
       "L 294.920744 15.04661 \n",
       "L 304.541433 15.334893 \n",
       "L 314.162123 15.212931 \n",
       "L 323.782812 14.965294 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_54\">\n",
       "    <path d=\"M 44.782812 27.114048 \n",
       "L 54.403502 23.499355 \n",
       "L 64.024192 23.299778 \n",
       "L 73.644881 21.547874 \n",
       "L 83.265571 20.727358 \n",
       "L 92.886261 21.281757 \n",
       "L 102.50695 19.951201 \n",
       "L 112.12764 19.662918 \n",
       "L 121.74833 19.24157 \n",
       "L 131.369019 18.642811 \n",
       "L 140.989709 19.552033 \n",
       "L 150.610399 18.376708 \n",
       "L 160.231088 18.044066 \n",
       "L 169.851778 18.376708 \n",
       "L 179.472468 18.110592 \n",
       "L 189.093157 17.511846 \n",
       "L 198.713847 17.999706 \n",
       "L 208.334537 17.866655 \n",
       "L 217.955226 17.711423 \n",
       "L 227.575916 17.866655 \n",
       "L 237.196606 17.090498 \n",
       "L 246.817295 17.711423 \n",
       "L 256.437985 17.777949 \n",
       "L 266.058675 17.445307 \n",
       "L 275.679364 16.735676 \n",
       "L 285.300054 17.334435 \n",
       "L 294.920744 16.447393 \n",
       "L 304.541433 16.868741 \n",
       "L 314.162123 17.068319 \n",
       "L 323.782812 16.71351 \n",
       "\" clip-path=\"url(#pef7e57143d)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 44.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 323.782812 228.96 \n",
       "L 323.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 44.782812 228.96 \n",
       "L 323.782812 228.96 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 44.782812 7.2 \n",
       "L 323.782812 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 51.782812 223.96 \n",
       "L 120.425 223.96 \n",
       "Q 122.425 223.96 122.425 221.96 \n",
       "L 122.425 194.644375 \n",
       "Q 122.425 192.644375 120.425 192.644375 \n",
       "L 51.782812 192.644375 \n",
       "Q 49.782812 192.644375 49.782812 194.644375 \n",
       "L 49.782812 221.96 \n",
       "Q 49.782812 223.96 51.782812 223.96 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_55\">\n",
       "     <path d=\"M 53.782812 200.144375 \n",
       "L 63.782812 200.144375 \n",
       "L 73.782813 200.144375 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_29\">\n",
       "     <!-- train_acc -->\n",
       "     <g transform=\"translate(81.782813 203.644375) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"TimesNewRomanPSMT-74\" d=\"M 1031 3803 \n",
       "L 1031 2863 \n",
       "L 1700 2863 \n",
       "L 1700 2644 \n",
       "L 1031 2644 \n",
       "L 1031 788 \n",
       "Q 1031 509 1111 412 \n",
       "Q 1191 316 1316 316 \n",
       "Q 1419 316 1516 380 \n",
       "Q 1613 444 1666 569 \n",
       "L 1788 569 \n",
       "Q 1678 263 1478 108 \n",
       "Q 1278 -47 1066 -47 \n",
       "Q 922 -47 784 33 \n",
       "Q 647 113 581 261 \n",
       "Q 516 409 516 719 \n",
       "L 516 2644 \n",
       "L 63 2644 \n",
       "L 63 2747 \n",
       "Q 234 2816 414 2980 \n",
       "Q 594 3144 734 3369 \n",
       "Q 806 3488 934 3803 \n",
       "L 1031 3803 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-72\" d=\"M 1038 2947 \n",
       "L 1038 2303 \n",
       "Q 1397 2947 1775 2947 \n",
       "Q 1947 2947 2059 2842 \n",
       "Q 2172 2738 2172 2600 \n",
       "Q 2172 2478 2090 2393 \n",
       "Q 2009 2309 1897 2309 \n",
       "Q 1788 2309 1652 2417 \n",
       "Q 1516 2525 1450 2525 \n",
       "Q 1394 2525 1328 2463 \n",
       "Q 1188 2334 1038 2041 \n",
       "L 1038 669 \n",
       "Q 1038 431 1097 309 \n",
       "Q 1138 225 1241 169 \n",
       "Q 1344 113 1538 113 \n",
       "L 1538 0 \n",
       "L 72 0 \n",
       "L 72 113 \n",
       "Q 291 113 397 181 \n",
       "Q 475 231 506 341 \n",
       "Q 522 394 522 644 \n",
       "L 522 1753 \n",
       "Q 522 2253 501 2348 \n",
       "Q 481 2444 426 2487 \n",
       "Q 372 2531 291 2531 \n",
       "Q 194 2531 72 2484 \n",
       "L 41 2597 \n",
       "L 906 2947 \n",
       "L 1038 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-69\" d=\"M 928 4444 \n",
       "Q 1059 4444 1151 4351 \n",
       "Q 1244 4259 1244 4128 \n",
       "Q 1244 3997 1151 3903 \n",
       "Q 1059 3809 928 3809 \n",
       "Q 797 3809 703 3903 \n",
       "Q 609 3997 609 4128 \n",
       "Q 609 4259 701 4351 \n",
       "Q 794 4444 928 4444 \n",
       "z\n",
       "M 1188 2947 \n",
       "L 1188 647 \n",
       "Q 1188 378 1227 289 \n",
       "Q 1266 200 1342 156 \n",
       "Q 1419 113 1622 113 \n",
       "L 1622 0 \n",
       "L 231 0 \n",
       "L 231 113 \n",
       "Q 441 113 512 153 \n",
       "Q 584 194 626 287 \n",
       "Q 669 381 669 647 \n",
       "L 669 1750 \n",
       "Q 669 2216 641 2353 \n",
       "Q 619 2453 572 2492 \n",
       "Q 525 2531 444 2531 \n",
       "Q 356 2531 231 2484 \n",
       "L 188 2597 \n",
       "L 1050 2947 \n",
       "L 1188 2947 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-6e\" d=\"M 1034 2341 \n",
       "Q 1538 2947 1994 2947 \n",
       "Q 2228 2947 2397 2830 \n",
       "Q 2566 2713 2666 2444 \n",
       "Q 2734 2256 2734 1869 \n",
       "L 2734 647 \n",
       "Q 2734 375 2778 278 \n",
       "Q 2813 200 2889 156 \n",
       "Q 2966 113 3172 113 \n",
       "L 3172 0 \n",
       "L 1756 0 \n",
       "L 1756 113 \n",
       "L 1816 113 \n",
       "Q 2016 113 2095 173 \n",
       "Q 2175 234 2206 353 \n",
       "Q 2219 400 2219 647 \n",
       "L 2219 1819 \n",
       "Q 2219 2209 2117 2386 \n",
       "Q 2016 2563 1775 2563 \n",
       "Q 1403 2563 1034 2156 \n",
       "L 1034 647 \n",
       "Q 1034 356 1069 288 \n",
       "Q 1113 197 1189 155 \n",
       "Q 1266 113 1500 113 \n",
       "L 1500 0 \n",
       "L 84 0 \n",
       "L 84 113 \n",
       "L 147 113 \n",
       "Q 366 113 442 223 \n",
       "Q 519 334 519 647 \n",
       "L 519 1709 \n",
       "Q 519 2225 495 2337 \n",
       "Q 472 2450 423 2490 \n",
       "Q 375 2531 294 2531 \n",
       "Q 206 2531 84 2484 \n",
       "L 38 2597 \n",
       "L 900 2947 \n",
       "L 1034 2947 \n",
       "L 1034 2341 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"TimesNewRomanPSMT-5f\" d=\"M 3256 -1381 \n",
       "L -53 -1381 \n",
       "L -53 -1119 \n",
       "L 3256 -1119 \n",
       "L 3256 -1381 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-72\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"61.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-69\" x=\"105.46875\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-6e\" x=\"133.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-5f\" x=\"183.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"233.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"277.636719\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"322.021484\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_56\">\n",
       "     <path d=\"M 53.782812 214.302187 \n",
       "L 63.782812 214.302187 \n",
       "L 73.782813 214.302187 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_30\">\n",
       "     <!-- test_acc -->\n",
       "     <g transform=\"translate(81.782813 217.802187) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-65\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-73\" x=\"72.167969\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-74\" x=\"111.083984\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-5f\" x=\"138.867188\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-61\" x=\"188.867188\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"233.251953\"/>\n",
       "      <use xlink:href=\"#TimesNewRomanPSMT-63\" x=\"277.636719\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pef7e57143d\">\n",
       "   <rect x=\"44.782812\" y=\"7.2\" width=\"279\" height=\"221.76\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 开始训练\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.network = nn.Sequential(nn.Flatten(),\n",
    "        #                              nn.Linear(28*28, 2**5), nn.ReLU(),\n",
    "        #                              nn.Linear(2**5, 10), nn.Softmax())\n",
    "        self.num_hidden = 2**5\n",
    "        self.layer1 = nn.Flatten()\n",
    "        self.layer2 = nn.Linear(28*28, self.num_hidden)\n",
    "        self.layer3 = nn.Linear(self.num_hidden, self.num_hidden)\n",
    "        self.ac = nn.ReLU()\n",
    "        # self.ac = nn.Tanh()\n",
    "        self.dp = nn.Dropout()\n",
    "        self.bn = nn.BatchNorm1d(self.num_hidden)\n",
    "        self.layer4 = nn.Linear(self.num_hidden, 10)\n",
    "        self.layer5 = nn.Softmax()\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        y = self.layer1(X)\n",
    "        y = self.layer2(y)\n",
    "        \n",
    "        for i in range(2):\n",
    "            y = y + self.dp(self.ac(self.bn(self.layer3(y))))\n",
    "                   \n",
    "        y = self.layer4(y)\n",
    "        y = self.layer5(y)\n",
    "        return y\n",
    "\n",
    "net = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)\n",
    "\n",
    "train_steps(\n",
    "    epochs=30, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device, \n",
    "    train_figure=True\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.3. <a id='toc8_7_3_'></a>[K折交叉验证](#toc0_)\n",
    "- 简述：把数据分成K份，分别只取1份做Test_data，（K-1）做Train_data，做K次，计算Test_acc的平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1 # k必须大于1\n",
    "    fold_size = X.shape[0] // k # 窗口大小：X一维数据长度除以k向下取整数\n",
    "    print('fold_size: ', fold_size)\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size) # 切片范围 (窗口大小)\n",
    "        print(idx)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat([X_train, X_part], 0)\n",
    "            y_train = torch.cat([y_train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14]]),\n",
       " tensor([[  0,  -1,  -2],\n",
       "         [ -3,  -4,  -5],\n",
       "         [ -6,  -7,  -8],\n",
       "         [ -9, -10, -11],\n",
       "         [-12, -13, -14]]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(15).reshape(5, 3)\n",
    "y = torch.negative(torch.arange(15).reshape(5, 3))\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_size:  2\n",
      "slice(0, 2, None)\n",
      "slice(2, 4, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[ 0, -1, -2],\n",
       "         [-3, -4, -5]]),\n",
       " tensor([[ 6,  7,  8],\n",
       "         [ 9, 10, 11]]),\n",
       " tensor([[ -6,  -7,  -8],\n",
       "         [ -9, -10, -11]]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_k_fold_data(2, 1, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8. <a id='toc8_8_'></a>[可视化训练过程](#toc0_)\n",
    "* 清理上一次\n",
    "    * figure plt.clf() # 只是清理figure内容\n",
    "    * figure `plt.colse()` # 关闭（释放）figure\n",
    "    * axes plt.cla() # 只是清理axes内容\n",
    "* 绘图plot\n",
    "* 用jupyter的display来显示\n",
    "* 保持yupyter上的display直至下一次展示再清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印图片耗时： 2.1650073528289795 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def dl_plot(x, y):\n",
    "    '''再jupyter中持续刷新展示图片'''\n",
    "    plt.close()                                 # close figure （推荐）\n",
    "    fig = plt.figure(figsize=(3.5, 2.5))\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "\n",
    "    # plt.show()                                # 普通展示\n",
    "    display.display(fig)                        # 在jupyter中展示 （推荐）\n",
    "    display.clear_output(wait=True)             # 等待 （必须）\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(50):\n",
    "    x = torch.arange(0, epoch+1, 0.1)\n",
    "    y = torch.sin(x)\n",
    "    if epoch % 2 == 0:\n",
    "        dl_plot(x, y)\n",
    "stop = time.time()\n",
    "print(f\"打印图片耗时： {stop - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10: \t train_loss=0.8999999761581421 \t train_acc=0.7833268642425537\n",
      "2/10: \t train_loss=1.899999976158142 \t train_acc=0.9463000893592834\n",
      "3/10: \t train_loss=2.9000000953674316 \t train_acc=0.23924924433231354\n",
      "4/10: \t train_loss=3.9000000953674316 \t train_acc=-0.6877662539482117\n",
      "5/10: \t train_loss=4.900000095367432 \t train_acc=-0.9824525713920593\n",
      "6/10: \t train_loss=5.900000095367432 \t train_acc=-0.37387657165527344\n",
      "7/10: \t train_loss=6.900000095367432 \t train_acc=0.5784398317337036\n",
      "8/10: \t train_loss=7.899999618530273 \t train_acc=0.9989413619041443\n",
      "9/10: \t train_loss=8.899999618530273 \t train_acc=0.5010212063789368\n",
      "10/10: \t train_loss=9.899999618530273 \t train_acc=-0.4575355648994446\n",
      "打印数值耗时： 0.0011034011840820312 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(10):\n",
    "    x = torch.arange(0, epoch+1, 0.1)\n",
    "    y = torch.sin(x)\n",
    "    # dl_plot(x, y)\n",
    "    print(f\"{epoch+1}/{10}: \\t train_loss={x[-1]} \\t train_acc={y[-1]}\")\n",
    "    \n",
    "stop = time.time()\n",
    "print(f\"打印数值耗时： {stop - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. <a id='toc9_'></a>[在 GPU 上训练](#toc0_)\n",
    "- 要实行运算的Tensor`必须`在同一张GPU卡上：\n",
    "\n",
    "|操作|函数|\n",
    "|:-|:-|\n",
    "|1. 张量传到GPU上 |x_gpu = x`.to`('cuda:0')|\n",
    "|2. 神经网络传到GPU上|net = net`.to`('cuda:0')|\n",
    "\n",
    "- CPU和GPU之间数据传输总结：\n",
    "\n",
    "|对象|方法一|方法二|\n",
    "|:-|:-|:-|\n",
    "|模型上GPU：|model.cuda()|model.`to(device)`|\n",
    "|数据上GPU：|data.cuda()|data.`to(device)`|\n",
    "|输出下GPU：|output=model(data)|output`.detach().cpu().numpy()`|\n",
    "||解释：||\n",
    "||output`.detach()`|将变量output从计算图中分离，使其不具有梯度，不进行反向传播|\n",
    "||`.cpu()`|将GPU数据转CPU|\n",
    "||.numpy()|将Tensor转numpy|\n",
    "||`.item()`|将Tensor转为python数值|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. <a id='toc9_1_'></a>[查看GPU配置](#toc0_)\n",
    "都在`torch.cuda`模块中."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 是否有可用的GPU\n",
    "torch.cuda.is_available()           \n",
    "# True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可用的GPU数量\n",
    "torch.cuda.device_count()     \n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA A100-SXM4-40GB'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回gpu名字，设备索引默认从0开始；\n",
    "torch.cuda.get_device_name(0)\n",
    "# \"Tesla T4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回当前设备索引；\n",
    "torch.cuda.current_device()\n",
    "# 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单机2卡: ['NVIDIA A100-SXM4-40GB', 'NVIDIA A100-SXM4-40GB']\n"
     ]
    }
   ],
   "source": [
    "def check_device():\n",
    "    '''判断是否有GPU，并列出GPU的代号/名称'''\n",
    "    if torch.cuda.is_available(): # 判断是否支持cuda/GPU\n",
    "        gpu_num = torch.cuda.device_count() # cuda/GPU计数\n",
    "        if gpu_num == 1:\n",
    "            print(f\"单机单卡: {[torch.cuda.get_device_name(gpu_name) for gpu_name in range(gpu_num)]}\")\n",
    "        else:\n",
    "            print(f\"单机{gpu_num}卡: {[torch.cuda.get_device_name(gpu_name) for gpu_name in range(gpu_num)]}\")\n",
    "    else:\n",
    "        print(f\"只有CPU\")\n",
    "    return None \n",
    "\n",
    "check_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cuda:0', 'cuda:1']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = [ 'cpu' if not torch.cuda.is_available() else ]\n",
    "device = [f'cuda:{i}' for i in range(torch.cuda.device_count())] if torch.cuda.is_available() else ['cpu']\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. <a id='toc9_2_'></a>[单机单卡（GPU）](#toc0_)\n",
    "所有的张量必须存在于同一个设备上（同一个CPU或同一个GPU），才能正确计算，否则可能会出现异常错误。  \n",
    "1. 模型上GPU：model.cuda() 或 model.to(device)   \n",
    "2. 数据上GPU：data_gpu = data.cuda() 或 data_gpu = data.to(device)   \n",
    "3. 输出下GPU：output = model(data)  output.detach().cpu().numpy()，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.]]),\n",
       " tensor([[1.],\n",
       "         [1.]]),\n",
       " device(type='cpu'),\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((2, 1))\n",
    "y = torch.ones((2, 1))\n",
    "x, y, x.device, y.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.]], device='cuda:0'),\n",
       " tensor([[1.],\n",
       "         [1.]], device='cuda:0'),\n",
       " device(type='cuda', index=0),\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x.to(device)\n",
    "y1 = y.to(device)\n",
    "x1, y1, x1.device, y1.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3. <a id='toc9_3_'></a>[单机多卡（GPU）](#toc0_)\n",
    "\n",
    "目前PyTorch的单机多卡训练，主要有两种方式：\n",
    "\n",
    "|方法|函数|注释|\n",
    "|:-|:-|:-|\n",
    "|第一种：|torch.nn.`DataParallel`(module=net, device_ids=[0, 1], output_device=[0])|# 单机两卡|\n",
    "|第二种：|torch.nn.parallel.`DistributedDataParallel`()|# 单机多卡、多机多卡|\n",
    "\n",
    "\n",
    "DataParallel (DP) 和 DistributedDataParallel (DDP) 都是用于在多GPU上进行训练的工具，但它们有一些关键的区别：\n",
    "\n",
    "1. **目标环境：**\n",
    "   - `DataParallel` 适用于单机多卡的情况，通过将模型复制到每个GPU上，每个GPU计算不同的批次，最后通过梯度累积或平均来更新模型参数。\n",
    "   - `DistributedDataParallel` 适用于分布式环境，可以在单机或多台机器上的多个GPU上运行，每个GPU计算不同的批次，并通过分布式通信来同步梯度和更新模型参数。\n",
    "\n",
    "2. **通信方式：**\n",
    "   - `DataParallel` 使用单个进程内的多个GPU，通信相对较简单，仅涉及到进程内的数据传输。\n",
    "   - `DistributedDataParallel` 通过分布式通信协议，如NCCL或Gloo，实现跨进程和可能跨机器的通信，因此需要更复杂的设置。\n",
    "\n",
    "3. **启动方式：**\n",
    "   - `DataParallel` 只需在模型实例上调用 `nn.DataParallel(model)` 即可。\n",
    "   - `DistributedDataParallel` 需要在训练脚本中设置分布式环境变量，如`torch.distributed.launch` 或手动设置`os.environ`。\n",
    "\n",
    "4. **维护性：**\n",
    "   - `DataParallel` 更容易使用，因为它不涉及复杂的分布式设置。\n",
    "   - `DistributedDataParallel` 适用于更复杂的分布式场景，但需要更多的设置和管理。\n",
    "\n",
    "在单机多卡的情况下，如果简单性和易用性是首要考虑的因素，可以使用 DataParallel。在需要更高级的分布式设置时，或者在多机多卡的环境中，DistributedDataParallel 提供了更大的灵活性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.1. <a id='toc9_3_1_'></a>[DP](#toc0_)\n",
    "- 单机多线程\n",
    "\n",
    "- 参数详情\n",
    "```shell\n",
    "torch.nn.DataParallel(module, device_ids, output_device)  \n",
    "\n",
    "Parameters\n",
    "    module (Module) – module to be parallelized                                                 # 神经网络\n",
    "    device_ids (list of int or torch.device) – CUDA devices (default: all devices)              # 默认使用所用GPU\n",
    "    output_device (int or torch.device) – device location of output (default: device_ids[0])    # 在cuda:0上进行参数分配、计算、汇总、更新\n",
    "Variables\n",
    "    module (Module) – the module to be parallelized\n",
    "```\n",
    "\n",
    "- 前提\n",
    " \n",
    "    1. 有一个前提: net模型被复制到cuda:[0, 1, 2等等]上，但是X, y必须提前在cuda:0上，而不能在cuda:1、cuda:2等等上；\n",
    "\n",
    "    2. 那如果cuda:0有其他人占满了，怎么办？那就需要手动指定其他GPU为cuda:0了：\n",
    "\n",
    "        - os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"      # 一定一定要放在所有访问显卡的代码之前，否则则无效，给我困扰了好一段时间才发现了。我之前看到有一个说法是放到import os之后并且在import torch之前。\n",
    "\n",
    "        - os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2, 3\"         # 只识别2、3而抛弃了其他GPU，把2当成pytorch逻辑上的cuda:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Runing on cuda:0 \n",
      " ====================================================================================================\n",
      "epoch 1/10: train_loss=1.5717055797576904, train_acc=90.85833740234375, test_acc=90.91999816894531\n",
      "epoch 2/10: train_loss=1.5450035333633423, train_acc=92.63500213623047, test_acc=92.77999877929688\n",
      "epoch 3/10: train_loss=1.5318394899368286, train_acc=93.75666809082031, test_acc=93.83999633789062\n",
      "epoch 4/10: train_loss=1.5233505964279175, train_acc=94.5, test_acc=94.18000030517578\n",
      "epoch 5/10: train_loss=1.5167455673217773, train_acc=95.13500213623047, test_acc=94.83999633789062\n",
      "epoch 6/10: train_loss=1.5123507976531982, train_acc=95.55833435058594, test_acc=95.25\n",
      "epoch 7/10: train_loss=1.5058631896972656, train_acc=96.14500427246094, test_acc=95.44000244140625\n",
      "epoch 8/10: train_loss=1.502568006515503, train_acc=96.41999816894531, test_acc=95.80000305175781\n",
      "epoch 9/10: train_loss=1.4993404150009155, train_acc=96.69999694824219, test_acc=96.18000030517578\n",
      "epoch 10/10: train_loss=1.4963492155075073, train_acc=97.02667236328125, test_acc=96.30000305175781\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 5.24815821647644 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, batch_size=128,  shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 10), nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "    print('='*100, '\\n', f\"Runing on {device}\", '\\n','='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net = nn.DataParallel(module=net)\n",
    "    # net = nn.DataParallel(module=net, device_ids=[0, 1], output_device=[0]) # 多GPU并行计算，等价于net = nn.DataParallel(module=net)\n",
    "    net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.2. <a id='toc9_3_2_'></a>[DDP](#toc0_)\n",
    "```shell\n",
    "1. 与 DataParallel 的单进程控制多 GPU 不同，在 distributed 的帮助下，我们只需要编写一份代码，torch 就会自动将其分配给 \n",
    " 个进程，分别在 n 个 GPU 上运行。\n",
    "2. 单机多进程\n",
    "```\n",
    "```python\n",
    "详解\n",
    "torch.nn.parallel.DistributedDataParallel(module, device_ids, output_device)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import os \n",
    "\n",
    "def ddp_setup(rank, world_size):\n",
    "    '''\n",
    "    Args:\n",
    "        rank: unique identifier of each process\n",
    "        world_size: Total number of process\n",
    "    '''\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12357\"\n",
    "    dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3.2.1. <a id='toc9_3_2_1_'></a>[在colab上测试可用](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.multiprocessing import Process\n",
    "import os\n",
    "\n",
    "# 定义卷积神经网络模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train(local_rank, world_size):\n",
    "  \n",
    "  os.environ[\"MASTER_PORT\"] = \"12357\"\n",
    "  os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "\n",
    "  # 设置每个进程的GPU\n",
    "  torch.cuda.set_device(local_rank)\n",
    "  device = torch.device(\"cuda\", local_rank)\n",
    "\n",
    "  # 初始化进程组\n",
    "  dist.init_process_group(backend='nccl', world_size=world_size, rank=local_rank)\n",
    "\n",
    "  # 数据预处理和加载\n",
    "  transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "  trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "  # 使用DistributedSampler来对数据进行分布式采样\n",
    "  train_sampler = torch.utils.data.distributed.DistributedSampler(trainset)\n",
    "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=False, sampler=train_sampler)\n",
    "\n",
    "  # 创建CNN模型实例，并放入多个GPU上\n",
    "  model = CNN().to(device)\n",
    "  model = nn.parallel.DistributedDataParallel(model, device_ids=[local_rank])\n",
    "\n",
    "  # 定义损失函数和优化器\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "  # 训练模型\n",
    "  num_epochs = 5\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "      model.train()\n",
    "      running_loss = 0.0\n",
    "\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "          inputs, labels = data\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          running_loss += loss.item()\n",
    "\n",
    "      print(f\"Local Rank {local_rank}, Epoch {epoch + 1}/{num_epochs}, Training Loss: {running_loss / len(trainloader):.4f}\")\n",
    "\n",
    "  dist.destroy_process_group()\n",
    "\n",
    "# Process格式：\n",
    "if __name__ == \"__main__\":\n",
    "  # size = torch.cuda.device_count()\n",
    "  size = 10\n",
    "  processes = []\n",
    "  world_size = 1\n",
    "  for rank in range(size):\n",
    "      p = Process(target=train, args=(rank, world_size))\n",
    "      p.start()\n",
    "      processes.append(p)\n",
    "\n",
    "  for p in processes:\n",
    "      p.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4. <a id='toc9_4_'></a>[多机多卡（GPU）- 分布式训练](#toc0_)\n",
    "```shell\n",
    "目前PyTorch的多机多卡训练，主要有两种方式：   \n",
    "    1. torch.nn.parallel.DistributedDataParallel()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. <a id='toc10_'></a>[模型和参数的保存与加载](#toc0_)\n",
    "\n",
    "* torch.save( 张量名, 位置 )\n",
    "\n",
    "* 张量名称 = torch.load( 位置 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1. <a id='toc10_1_'></a>[加载和保存-张量](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.ones((3, 5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save()\n",
    "torch.save(x, './Pytorch_params/x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.load()\n",
    "x1 = torch.load('./Pytorch_params/x-file')\n",
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2. <a id='toc10_2_'></a>[加载和保存-模型参数](#toc0_)\n",
    "保存单个权重向量（或其他张量）确实有用， 但是如果我们想保存整个模型，并在以后加载它们， 单独保存每个向量则会变得很麻烦。 毕竟，我们可能有数百个参数散布在各处。 因此，深度学习框架提供了内置函数来保存和加载整个网络。 需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。 例如，如果我们有一个3层多层感知机，我们需要单独指定架构。 因为模型本身可以包含任意代码，所以模型本身难以序列化。 因此，为了恢复模型，我们需要用代码生成架构， 然后从磁盘加载参数。\n",
    "\n",
    "1. save和load函数可用于张量对象的文件读写。\n",
    "2. 我们可以通过参数字典保存和加载网络的全部参数。\n",
    "3. 保存架构必须在代码中完成，而不是在参数中完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save()\n",
    "# 接下来，我们将模型的参数存储在一个叫做“mlp.params”的文件中。\n",
    "torch.save(net.state_dict(), './Pytorch_params/mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.load()\n",
    "# 为了恢复模型，我们实例化了原始多层感知机模型的一个备份。 \n",
    "# 这里我们不需要随机初始化模型参数，而是直接读取文件中存储的参数。\n",
    "net_params = torch.load('./Pytorch_params/mlp.params')\n",
    "clone = MLP()\n",
    "\n",
    "clone.load_state_dict(net_params)\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 完整的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存\n",
    "torch.save(\n",
    "    {\n",
    "        'epoch': '10', \n",
    "        'model_state_dict': net.state_dict(), \n",
    "        # 'opt_state_dict': opt.state_dict(), \n",
    "        'loss': 'loss'\n",
    "    }, \n",
    "    './Pytorch_params/test.pt'\n",
    ")\n",
    "\n",
    "# 重载\n",
    "check_point = torch.load('./Pytorch_params/test.pt')\n",
    "\n",
    "check_point['model_state_dict']\n",
    "check_point['loss']\n",
    "check_point['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. <a id='toc11_'></a>[神经网络类型](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. <a id='toc11_1_'></a>[CNN](#toc0_)\n",
    "\n",
    "CBAPD: 卷积，批量归一化，激活，池化，丢弃\n",
    "\n",
    "卷积层就是特征提取，随后将特征传入FC（全连接层）；\n",
    "\n",
    "卷积本身是线性的，但是经过激活函数后可以编程非线性的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 11.1.1. <a id='toc11_1_1_'></a>[概述](#toc0_)\n",
    "\n",
    "- 为什么要用CNN？\n",
    "  - 利用MLP处理图片像素矩阵，太占内存\n",
    "  - 解决办法，顶层设计一个新的算法具备如下特点：\n",
    "    - 局部性\n",
    "    - 平移不变性\n",
    "  - 刚好来自“信号处理中的卷积”符合此类特征：\n",
    "    - 局部性 （固定/通用的卷积核）\n",
    "    - 平移不变性 （特征图在整个图片的位置不固定，可以平移）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.2. <a id='toc11_1_2_'></a>[简单CNN](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2.1. <a id='toc11_1_2_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11.1.2.1.1. <a id='toc11_1_2_1_1_'></a>[卷积计算过程](#toc0_)\n",
    "\n",
    " <img src=\"./Pytorch_Pictures/convolution/conv.gif\" width = \"500\" height = \"300\" alt=\"图片名称\" align=center />\n",
    "\n",
    "- 内积后求和\n",
    "\n",
    "- 输出大小：(Xh - Kh + 1, Xw - Kw + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def cov2d(X, kernel)-> torch.Tensor:\n",
    "    '''\n",
    "    手写二维convolution计算过程 (二维互关运算)\n",
    "\n",
    "    Args: \n",
    "        X (2d): 输入图片像素矩阵\n",
    "        kernel (int): 卷积核\n",
    "\n",
    "    Return: \n",
    "        Y: 卷积计算结果\n",
    "    '''\n",
    "\n",
    "    h, w = kernel.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))   # 输出形状，暂时用0填充\n",
    "    # print(Y)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * kernel).sum()      # X取子集 * kernel 最后在求和\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.],\n",
       "        [6., 7., 8.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(9, dtype=torch.float32).reshape(3, 3)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = torch.arange(4, dtype=torch.float32).reshape(2, 2)\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov2d(X=X, kernel=kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11.1.2.1.2. <a id='toc11_1_2_1_2_'></a>[从头卷积层](#toc0_)\n",
    "- 卷积层对输入和卷积核进行互关运算，并添加偏置；\n",
    "- 所以卷积层中两个被训练的参数是卷积核与偏置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Cov2d(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return cov2d(X, self.weight) + self.bias                   # 将conv2d计算添加进来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.9126,  5.9625],\n",
       "        [10.0622, 12.1121]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov2d1 = Cov2d(kernel_size=(2, 2))\n",
    "cov2d1(X=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2.2. <a id='toc11_1_2_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0601,  0.0402],\n",
       "          [ 0.2407,  0.3410]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "conv2d = nn.Conv2d(\n",
    "    in_channels = 1, \n",
    "    out_channels = 1, \n",
    "    kernel_size = (2, 2), \n",
    "    bias = True\n",
    ")\n",
    "\n",
    "# nn.Conv2d的输入和输出都是：批量大小、通道数、高度和宽度\n",
    "conv2d(X.reshape((1,1,3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2.3. <a id='toc11_1_2_3_'></a>[填充和步幅](#toc0_)\n",
    "\n",
    "- 填充 (padding)\n",
    "\n",
    "  - 输出大小：(Xh - Kh + Ph + 1, Xw - Kw + Pw + 1)\n",
    "\n",
    "  - 一般情况下Kh和Kw为奇数(1,3,5,7) 可得 (输入和输出形状一致)：\n",
    "\n",
    "    - Ph设置为：Kh - 1\n",
    "\n",
    "    - Pw设置为：Kw - 1\n",
    "\n",
    "  - padding填写时写一半 (输入和输出形状一致)：\n",
    "    - padding = (Ph/2, Pw/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.],\n",
       "         [6., 7., 8.]]),\n",
       " torch.Size([1, 1, 3, 3]),\n",
       " tensor([[[[-0.3299, -0.8171,  0.1535],\n",
       "           [-1.3427, -2.3634, -0.2771],\n",
       "           [-1.2391, -2.3088, -2.5213]]]], grad_fn=<ConvolutionBackward0>),\n",
       " torch.Size([1, 1, 3, 3]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "conv2d1 = nn.Conv2d(\n",
    "    in_channels = 1, \n",
    "    out_channels = 1, \n",
    "    kernel_size = (3, 3), \n",
    "    bias = True, \n",
    "    padding = (1, 1),           # ((3 - 1)/2, (3 - 1)/2)\n",
    "    stride = 1\n",
    ")\n",
    "\n",
    "# nn.Conv2d的输入和输出都是：批量大小、通道数、高度和宽度\n",
    "X = torch.arange(9, dtype=torch.float32).reshape(3, 3)\n",
    "Y = conv2d1(X.reshape((1,1,3,3)))\n",
    "X, X.reshape((1,1,3,3)).shape, Y, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 步幅 (stride)\n",
    "\n",
    "  - 输出大小为：( (Xh - Kh + Ph + Sh)/Sh, (Xw - Kw + Pw + Sw)/Sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11., 12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19., 20., 21., 22., 23.],\n",
       "         [24., 25., 26., 27., 28., 29., 30., 31.],\n",
       "         [32., 33., 34., 35., 36., 37., 38., 39.],\n",
       "         [40., 41., 42., 43., 44., 45., 46., 47.],\n",
       "         [48., 49., 50., 51., 52., 53., 54., 55.],\n",
       "         [56., 57., 58., 59., 60., 61., 62., 63.]]),\n",
       " torch.Size([1, 1, 8, 8]),\n",
       " tensor([[[[  0.4318,  -2.9064,  -3.9838,  -5.0611],\n",
       "           [ -3.0204, -13.3529, -14.7837, -16.2145],\n",
       "           [ -6.1843, -24.7991, -26.2299, -27.6607],\n",
       "           [ -9.3481, -36.2454, -37.6762, -39.1069]]]],\n",
       "        grad_fn=<ConvolutionBackward0>),\n",
       " torch.Size([1, 1, 4, 4]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "conv2d1 = nn.Conv2d(\n",
    "    in_channels = 1, \n",
    "    out_channels = 1, \n",
    "    kernel_size = (3, 3), \n",
    "    bias = True, \n",
    "    padding = (1, 1),           # ((3 - 1)/2, (3 - 1)/2)\n",
    "    stride = 2                  # (8 - 3 + 1 + 2 )/2 = 4\n",
    ")\n",
    "\n",
    "# nn.Conv2d的输入和输出都是：批量大小、通道数、高度和宽度\n",
    "X = torch.arange(64, dtype=torch.float32).reshape(8, 8)\n",
    "Y = conv2d1(X.reshape((1,1,8,8)))\n",
    "X, X.reshape((1,1,8,8)).shape, Y, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2.4. <a id='toc11_1_2_4_'></a>[多输入和多输出通道](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11., 12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19., 20., 21., 22., 23.],\n",
       "         [24., 25., 26., 27., 28., 29., 30., 31.],\n",
       "         [32., 33., 34., 35., 36., 37., 38., 39.],\n",
       "         [40., 41., 42., 43., 44., 45., 46., 47.],\n",
       "         [48., 49., 50., 51., 52., 53., 54., 55.],\n",
       "         [56., 57., 58., 59., 60., 61., 62., 63.]]),\n",
       " torch.Size([1, 1, 8, 8]),\n",
       " tensor([[[[ -3.1349,  -3.0231,  -4.5567,  -6.0904],\n",
       "           [-15.0264, -16.0034, -17.6924, -19.3814],\n",
       "           [-26.5322, -29.5155, -31.2045, -32.8935],\n",
       "           [-38.0381, -43.0276, -44.7166, -46.4056]],\n",
       " \n",
       "          [[  1.8246,   4.3984,   5.4487,   6.4991],\n",
       "           [  0.2586,  11.0692,  11.8181,  12.5670],\n",
       "           [ -1.3924,  17.0604,  17.8093,  18.5582],\n",
       "           [ -3.0434,  23.0516,  23.8005,  24.5494]],\n",
       " \n",
       "          [[ -3.0677,  -2.4633,  -2.2421,  -2.0210],\n",
       "           [-12.1480,  -5.0198,  -5.5860,  -6.1523],\n",
       "           [-24.6482,  -9.5497, -10.1159, -10.6822],\n",
       "           [-37.1485, -14.0796, -14.6459, -15.2121]]]],\n",
       "        grad_fn=<ConvolutionBackward0>),\n",
       " torch.Size([1, 3, 4, 4]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "conv2d1 = nn.Conv2d(\n",
    "    in_channels = 1, \n",
    "    out_channels = 3, \n",
    "    kernel_size = (3, 3), \n",
    "    bias = True, \n",
    "    padding = (1, 1),           # ((3 - 1)/2, (3 - 1)/2)\n",
    "    stride = 2                  # (8 - 3 + 1 + 2 )/2 = 4\n",
    ")\n",
    "\n",
    "# nn.Conv2d的输入和输出都是：批量大小、通道数、高度和宽度\n",
    "X = torch.arange(64, dtype=torch.float32).reshape(8, 8)\n",
    "Y = conv2d1(X.reshape((1,1,8,8)))\n",
    "X, X.reshape((1,1,8,8)).shape, Y, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2.5. <a id='toc11_1_2_5_'></a>[Pooling (汇聚层)](#toc0_)\n",
    "\n",
    "- pooling层不包含参数\n",
    "\n",
    "\n",
    "##### 11.1.2.5.1. <a id='toc11_1_2_5_1_'></a>[平均Pooling](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AvgPool2d(kernel_size=(2, 2), stride=1, padding=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "nn.AvgPool2d(\n",
    "    kernel_size = (2, 2), \n",
    "    padding = 0, \n",
    "    stride = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11.1.2.5.2. <a id='toc11_1_2_5_2_'></a>[最大Pooling](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool2d(kernel_size=(2, 2), stride=1, padding=0, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "nn.MaxPool2d(\n",
    "    kernel_size = (2, 2), \n",
    "    padding = 0, \n",
    "    stride = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.3. <a id='toc11_1_3_'></a>[LeNet](#toc0_)\n",
    "\n",
    "- 最早被Yann LeCun用来识别手写数字的算法\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/convolution/LeNet.jpg\" width = \"700\" height = \"300\" alt=\"图片名称\" align=center >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1736, -0.2433,  0.1071,  0.7213, -0.1392,  0.1065,  0.1411,  0.4583,\n",
       "          0.1942,  0.0054]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), \n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5), \n",
    "            nn.Sigmoid(), \n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(16 * 5 * 5, 120), \n",
    "            nn.Sigmoid(), \n",
    "            nn.Linear(120, 84), \n",
    "            nn.Sigmoid(), \n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "lenet = LeNet()\n",
    "\n",
    "X = torch.arange(28*28, dtype=torch.float32).reshape((1, 1, 28, 28))\n",
    "# X = torch.rand(size=(1,1,28,28), dtype=torch.float32)\n",
    "# X.shape\n",
    "lenet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.4. <a id='toc11_1_4_'></a>[AlexNet](#toc0_)\n",
    "\n",
    "- 第一个在大规模视觉比赛 (ImageNet) 中战胜传统给算法 (如支持向量机 supportvectormachines) 的**大型神经网络**\n",
    "\n",
    "- 证明算法学习的特征可以超越手动设计的特征\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/convolution/AlexNet.jpg\" width = \"500\" height = \"700\" alt=\"图片名称\" align=center >  \n",
    "\n",
    "- LeNet VS AlexNet：\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/convolution/LeNetVSAlexNet.jpg\" width = \"1000\" height = \"300\" alt=\"图片名称\" align=center >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import AlexNet\n",
    "\n",
    "alexnet = AlexNet()\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.5. <a id='toc11_1_5_'></a>[VGG](#toc0_)\n",
    "\n",
    "- 利用重复的神经网络块\n",
    "\n",
    "  - 卷积层，如Conv2d()\n",
    "  - 非线性激活，如nn.Relu()\n",
    "  - 汇聚层，如nn.MaxPooling()\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/convolution/VGG.jpg\" width = \"500\" height = \"500\" alt=\"图片名称\" align=center >  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模块设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (5): Flatten(start_dim=1, end_dim=-1)\n",
       "  (6): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Dropout(p=0.5, inplace=False)\n",
       "  (9): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.5, inplace=False)\n",
       "  (12): Linear(in_features=4096, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "conv_arch = (\n",
    "    (1, 64), \n",
    "    (1, 128), \n",
    "    (2, 256), \n",
    "    (2, 512), \n",
    "    (2, 512)\n",
    ")\n",
    "\n",
    "def vgg(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    # 卷积部分\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "        \n",
    "    return nn.Sequential(\n",
    "        *conv_blks, \n",
    "        nn.Flatten(), \n",
    "        # 全连接部分\n",
    "        nn.Linear(out_channels*7*7, 4096), \n",
    "        nn.ReLU(), \n",
    "        nn.Dropout(p=0.5), \n",
    "        nn.Linear(4096, 4096), \n",
    "        nn.ReLU(), \n",
    "        nn.Dropout(p=0.5), \n",
    "        nn.Linear(4096, 10)\n",
    "    )\n",
    "\n",
    "net = vgg(conv_arch)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vgg11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import vgg11\n",
    "\n",
    "vgg = vgg11()\n",
    "vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.6. <a id='toc11_1_6_'></a>[NiN](#toc0_)\n",
    "\n",
    "- 使用1 x 1卷积层来替代全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.7. <a id='toc11_1_7_'></a>[GoogLeNet](#toc0_)\n",
    "\n",
    "- 2014年的ImageNet挑战赛中，GoogLeNet大放异彩；\n",
    "\n",
    "- 解决了到底选多大的卷积核的问题？结论是：使用不同大小的卷积核组合更加有利。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.8. <a id='toc11_1_8_'></a>[批量规范化](#toc0_)\n",
    "\n",
    "- batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BatchNorm2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.9. <a id='toc11_1_9_'></a>[ResNet](#toc0_)\n",
    "```shell\n",
    "如果，CNN只需要弄懂一个神经网络模型的话，那就是ResNet。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.9.1. <a id='toc11_1_9_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.LSTM(), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet34 \n",
    "\n",
    "resnet = resnet34()\n",
    "resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2. <a id='toc11_2_'></a>[序列数据](#toc0_)\n",
    "### 11.2.1. <a id='toc11_2_1_'></a>[什么是序列](#toc0_)\n",
    "\n",
    "在深度学习中，**序列**是一段具有连续关系的数据，通常带有时间先后顺序。例如，文本、语音、股票价格、气温、DNA序列等都可以被视为序列数据。为了处理不定长的数据，我们常常使用循环神经网络（RNN）来处理序列信息。总之，序列数据在许多领域中都有广泛的应用，包括自然语言处理、时间序列分析、音频处理和图像处理等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.2. <a id='toc11_2_2_'></a>[语言模型](#toc0_)\n",
    "\n",
    "语言模型 (language model) 是定义在单词序列上的概率模型，可以用来计算一个句子或一段文字的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.3. <a id='toc11_2_3_'></a>[文本预处理](#toc0_)\n",
    "* token：最小单位（字符/单词/词组）\n",
    "* vocab：（token：indice）对照（查询）列表\n",
    "* cropus：token转化为indice后的文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.3.1. <a id='toc11_2_3_1_'></a>[下载《Time machine》并读取数据](#toc0_)\n",
    "首先，我们从H.G.Well的[时光机器](https://www.gutenberg.org/ebooks/35)中加载文本。\n",
    "这是一个相当小的语料库，只有30000多个单词，但足够我们小试牛刀，\n",
    "而现实中的文档集合可能会包含数十亿个单词。\n",
    "下面的函数 (**将数据集读取到由多条文本行组成的列表中**)，其中每条文本行都是一个字符串。\n",
    "为简单起见，我们在这里忽略了标点符号和字母大写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 文本总行数: 3221\n",
      "the time machine by h g wells\n",
      "\n",
      "twinkled and his usually pale face was flushed and animated the\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import re\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#@save\n",
    "# 下载到../data/timemachine.txt\n",
    "d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt', '090b5e7e70c295757f55df93cb0a180b9691891a')\n",
    "\n",
    "def read_time_machine():  #@save\n",
    "    \"\"\"将时间机器数据集加载到文本行的列表中\"\"\"\n",
    "    with open(d2l.download('time_machine'), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
    "\n",
    "lines = read_time_machine()\n",
    "print(f'# 文本总行数: {len(lines)}')\n",
    "print(lines[0])\n",
    "print(lines[1]) # 空的\n",
    "print(lines[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.3.2. <a id='toc11_2_3_2_'></a>[词元化（Token）](#toc0_)\n",
    "* 按照char/word等拆分成列表格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['i']\n",
      "[]\n",
      "[]\n",
      "['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him']\n",
      "['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']\n",
      "['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n"
     ]
    }
   ],
   "source": [
    "# 按照word\n",
    "def tokenize(lines, token='word'):  #@save\n",
    "    \"\"\"将文本行拆分为单词或字符词元\"\"\"\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('错误：未知词元类型：' + token)\n",
    "\n",
    "tokens = tokenize(lines)\n",
    "for i in range(11):\n",
    "    print(tokens[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.3.3. <a id='toc11_2_3_3_'></a>[词表（vocab）](#toc0_)\n",
    "* 构建(token：索引)查询元组\n",
    "* 并将文本的token替换成索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:\t [('<unk>', 0), ('the', 1), ('i', 2), ('and', 3), ('of', 4), ('a', 5), ('to', 6), ('was', 7), ('in', 8), ('that', 9)]\n",
      "文本: ['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
      "索引: [1, 19, 50, 40, 2183, 2184, 400]\n",
      "文本: ['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n",
      "索引: [2186, 3, 25, 1044, 362, 113, 7, 1421, 3, 1045, 1]\n"
     ]
    }
   ],
   "source": [
    "class Vocab:  #@save\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # 按出现频率排序\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # 未知词元的索引为0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "\n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    # 这里的tokens是1D列表或2D列表\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # 将词元列表展平成一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "vocab = Vocab(tokens)\n",
    "print('vocab:\\t', list(vocab.token_to_idx.items())[:10])\n",
    "\n",
    "for i in [0, 10]:\n",
    "    print('文本:', tokens[i])\n",
    "    print('索引:', vocab[tokens[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.3.4. <a id='toc11_2_3_4_'></a>[整合所有功能](#toc0_)\n",
    "* 读取数据\n",
    "* 分割成token\n",
    "* 并构建(token, indice)查询表并替换token成indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170580, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按照char进行词元化 \n",
    "\n",
    "def load_corpus_time_machine(max_tokens=-1):  #@save\n",
    "    \"\"\"返回时光机器数据集的词元索引列表和词表\"\"\"\n",
    "    lines = read_time_machine()\n",
    "    tokens = tokenize(lines, 'char')\n",
    "    vocab = Vocab(tokens)\n",
    "    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n",
    "    # 所以将所有文本行展平到一个列表中\n",
    "    corpus = [vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[:max_tokens]\n",
    "    return corpus, vocab\n",
    "\n",
    "corpus, vocab = load_corpus_time_machine()\n",
    "len(corpus), len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.4. <a id='toc11_2_4_'></a>[语言模型数据集](#toc0_)\n",
    "#### 11.2.4.1. <a id='toc11_2_4_1_'></a>[顺序采样](#toc0_)\n",
    "\n",
    "- 顺序采样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_iter_sequential(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用顺序分区生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始划分序列\n",
    "    offset = random.randint(0, num_steps)\n",
    "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
    "    Xs = torch.tensor(corpus[offset: offset + num_tokens])\n",
    "    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
    "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
    "    num_batches = Xs.shape[1] // num_steps\n",
    "    \n",
    "    for i in range(0, num_steps * num_batches, num_steps):\n",
    "        X = Xs[:, i: i + num_steps]\n",
    "        Y = Ys[:, i: i + num_steps]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):\n",
    "#     print('X: ', X, '\\nY:', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.4.2. <a id='toc11_2_4_2_'></a>[随机采样](#toc0_)\n",
    "\n",
    "- 随机采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seq_data_iter_random(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用随机抽样生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n",
    "    corpus = corpus[random.randint(0, num_steps - 1):]\n",
    "    # 减去1，是因为我们需要考虑标签\n",
    "    num_subseqs = (len(corpus) - 1) // num_steps\n",
    "    # 长度为num_steps的子序列的起始索引\n",
    "    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "    # 在随机抽样的迭代过程中，\n",
    "    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n",
    "    random.shuffle(initial_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        # 返回从pos位置开始的长度为num_steps的序列\n",
    "        return corpus[pos: pos + num_steps]\n",
    "\n",
    "    num_batches = num_subseqs // batch_size\n",
    "    for i in range(0, batch_size * num_batches, batch_size):\n",
    "        # 在这里，initial_indices包含子序列的随机起始索引\n",
    "        initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
    "        X = [data(j) for j in initial_indices_per_batch]\n",
    "        Y = [data(j + 1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(X), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_seq = list(range(35))\n",
    "# for X, Y in seq_data_iter_random(my_seq, batch_size=2, num_steps=5):\n",
    "#     print('X: ', X, '\\nY:', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.4.3. <a id='toc11_2_4_3_'></a>[包装](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataLoader:  #@save\n",
    "    \"\"\"加载序列数据的迭代器\"\"\"\n",
    "    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n",
    "        if use_random_iter:\n",
    "            # self.data_iter_fn = d2l.seq_data_iter_random\n",
    "            self.data_iter_fn = seq_data_iter_random\n",
    "        else:\n",
    "            # self.data_iter_fn = d2l.seq_data_iter_sequential\n",
    "            self.data_iter_fn = seq_data_iter_sequential\n",
    "        # self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)\n",
    "        self.corpus, self.vocab = load_corpus_time_machine(max_tokens)\n",
    "        self.batch_size, self.num_steps = batch_size, num_steps\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_time_machine(\n",
    "        batch_size, num_steps, \n",
    "        use_random_iter=False, \n",
    "        max_tokens=10000\n",
    "    ):\n",
    "    \"\"\"\n",
    "    返回时光机器数据集的迭代器和词表\n",
    "    \"\"\"\n",
    "    data_iter = SeqDataLoader(\n",
    "        batch_size, num_steps, use_random_iter, max_tokens\n",
    "    )\n",
    "    \n",
    "    return data_iter, data_iter.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3. <a id='toc11_3_'></a>[RNN](#toc0_)\n",
    "* 可以处理有顺序的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.1. <a id='toc11_3_1_'></a>[RNN-循环神经网络原理](#toc0_)\n",
    "* 结构：\n",
    "    * 有一层（或多层）隐藏结构；\n",
    "    * 当前隐藏结构由上一侧隐藏结构和当前输入决定\n",
    "    * 依次类推\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/RNN//RNN.jpg\" width = \"500\" height = \"300\" alt=\"图片名称\" align=center />\n",
    "\n",
    "更新隐藏状态：      \n",
    "$\\mathbf{h}_t=\\phi(\\mathbf{W}_{hh}\\mathbf{h}_{t-1}+\\mathbf{W}_{hx}\\mathbf{x}_{t-1}+\\mathbf{b}_h)$  \n",
    "输出：             \n",
    "$\\mathbf{o}_t=\\phi(\\mathbf{W}_\\textit{ho}\\mathbf{h}_t+\\mathbf{b}_o)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1.1. <a id='toc11_3_1_1_'></a>[从头实现网络](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 28]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网络结构\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 初始化模型\n",
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = normal((num_inputs, num_hiddens))\n",
    "    W_hh = normal((num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 附加梯度\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params\n",
    "\n",
    "def init_rnn_state(batch_size, num_hiddens, device):                        # 初始化第一个隐变量的值\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )\n",
    "\n",
    "def rnn(inputs, state, params):\n",
    "    # inputs的形状：(时间步数量，批量大小，词表大小)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    # X的形状：(批量大小，词表大小)\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)         # 隐藏变量\n",
    "        Y = torch.mm(H, W_hq) + b_q                                         # 输出\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H,)\n",
    "\n",
    "class RNNModelScratch: #@save\n",
    "    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, device,\n",
    "                 get_params, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "\n",
    "    def __call__(self, X, state):\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)\n",
    "    \n",
    "# 测试一下\n",
    "X = torch.arange(10).reshape((2, 5))\n",
    "F.one_hot(X.T, 28).shape\n",
    "\n",
    "num_hiddens = 512\n",
    "net = RNNModelScratch(\n",
    "    len(vocab), \n",
    "    num_hiddens, \n",
    "    d2l.try_gpu(), \n",
    "    get_params,\n",
    "    init_rnn_state, \n",
    "    rnn\n",
    ")\n",
    "\n",
    "state = net.begin_state(X.shape[0], d2l.try_gpu())\n",
    "Y, new_state = net(X.to(d2l.try_gpu()), state)\n",
    "Y.shape, len(new_state), new_state[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1.2. <a id='toc11_3_1_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (rnn): RNN(28, 512)\n",
       "  (linear): Linear(in_features=512, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, rnn_layer, vocab_size, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_hiddens = self.rnn.hidden_size\n",
    "        # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1\n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions = 1\n",
    "            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
    "        else:\n",
    "            self.num_directions = 2\n",
    "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        X = F.one_hot(inputs.T.long(), self.vocab_size)\n",
    "        X = X.to(torch.float32)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)\n",
    "        # 它的输出形状是(时间步数*批量大小,词表大小)。\n",
    "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        if not isinstance(self.rnn, nn.LSTM):\n",
    "            # nn.GRU以张量作为隐状态\n",
    "            return  torch.zeros((self.num_directions * self.rnn.num_layers,\n",
    "                                 batch_size, self.num_hiddens),\n",
    "                                device=device)\n",
    "        else:\n",
    "            # nn.LSTM以元组作为隐状态\n",
    "            return (torch.zeros((\n",
    "                self.num_directions * self.rnn.num_layers,\n",
    "                batch_size, self.num_hiddens), device=device),\n",
    "                    torch.zeros((\n",
    "                        self.num_directions * self.rnn.num_layers,\n",
    "                        batch_size, self.num_hiddens), \n",
    "                        device=device))\n",
    "\n",
    "batch_size, num_steps, num_hiddens = 32, 35, 512\n",
    "rnn_layer = nn.RNN(len(vocab), num_hiddens)\n",
    "# 我们(**使用张量来初始化隐状态**)，它的形状是（隐藏层数，批量大小，隐藏单元数）。\n",
    "state = torch.zeros((1, batch_size, num_hiddens))\n",
    "state.shape\n",
    "# [**通过一个隐状态和一个输入，我们就可以用更新后的隐状态计算输出。**]\n",
    "# 需要强调的是，`rnn_layer`的“输出”（`Y`）不涉及输出层的计算：\n",
    "# 它是指每个时间步的隐状态，这些隐状态可以用作后续输出层的输入。\n",
    "X = torch.rand(size=(num_steps, batch_size, len(vocab)))\n",
    "Y, state_new = rnn_layer(X, state)\n",
    "Y.shape, state_new.shape\n",
    "\n",
    "device = d2l.try_gpu()\n",
    "net = RNNModel(rnn_layer, vocab_size=len(vocab))\n",
    "net = net.to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1.3. <a id='toc11_3_1_3_'></a>[训练和预测](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time traveller lcjt cjt c'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测\n",
    "def predict_ch8(prefix, num_preds, net, vocab, device):  #@save\n",
    "    \"\"\"在prefix后面生成新字符\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])\n",
    "\n",
    "# 测试以下\n",
    "predict_ch8('time traveller ', 10, net, vocab, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度剪裁\n",
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "困惑度 1.0, 36068.3 词元/秒 cpu\n",
      "time travelleryou can show black is white by argument said filby\n",
      "travellerywi can anowhs astoun thives sat ancarauina soroun\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"252.646875pt\" height=\"183.35625pt\" viewBox=\"0 0 252.646875 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-06-12T14:07:01.405734</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 252.646875 183.35625 \n",
       "L 252.646875 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 235.903125 145.8 \n",
       "L 235.903125 7.2 \n",
       "L 40.603125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 76.474554 145.8 \n",
       "L 76.474554 7.2 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m9fafbe1039\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9fafbe1039\" x=\"76.474554\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(66.930804 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 116.331696 145.8 \n",
       "L 116.331696 7.2 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9fafbe1039\" x=\"116.331696\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(106.787946 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 156.188839 145.8 \n",
       "L 156.188839 7.2 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9fafbe1039\" x=\"156.188839\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(146.645089 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 196.045982 145.8 \n",
       "L 196.045982 7.2 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9fafbe1039\" x=\"196.045982\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(186.502232 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 235.903125 145.8 \n",
       "L 235.903125 7.2 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9fafbe1039\" x=\"235.903125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 500 -->\n",
       "      <g transform=\"translate(226.359375 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(123.025 174.076563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 40.603125 127.479182 \n",
       "L 235.903125 127.479182 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <defs>\n",
       "       <path id=\"m6c4242c9f0\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6c4242c9f0\" x=\"40.603125\" y=\"127.479182\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(27.240625 131.278401) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 40.603125 102.799364 \n",
       "L 235.903125 102.799364 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6c4242c9f0\" x=\"40.603125\" y=\"102.799364\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(27.240625 106.598583) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 40.603125 78.119546 \n",
       "L 235.903125 78.119546 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6c4242c9f0\" x=\"40.603125\" y=\"78.119546\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(27.240625 81.918765) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 40.603125 53.439729 \n",
       "L 235.903125 53.439729 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6c4242c9f0\" x=\"40.603125\" y=\"53.439729\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(27.240625 57.238947) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 40.603125 28.759911 \n",
       "L 235.903125 28.759911 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6c4242c9f0\" x=\"40.603125\" y=\"28.759911\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(20.878125 32.55913) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- perplexity -->\n",
       "     <g transform=\"translate(14.798437 101.626563) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \n",
       "L 2247 1797 \n",
       "L 3578 0 \n",
       "L 2900 0 \n",
       "L 1881 1375 \n",
       "L 863 0 \n",
       "L 184 0 \n",
       "L 1544 1831 \n",
       "L 300 3500 \n",
       "L 978 3500 \n",
       "L 1906 2253 \n",
       "L 2834 3500 \n",
       "L 3513 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"166.113281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"229.589844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"257.373047\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-78\" x=\"317.146484\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"376.326172\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"404.109375\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"443.318359\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 40.603125 13.5 \n",
       "L 44.588839 38.903188 \n",
       "L 48.574554 50.823382 \n",
       "L 52.560268 55.790138 \n",
       "L 56.545982 57.979064 \n",
       "L 60.531696 57.558539 \n",
       "L 64.517411 65.476167 \n",
       "L 68.503125 68.177691 \n",
       "L 72.488839 77.919137 \n",
       "L 76.474554 92.27673 \n",
       "L 80.460268 104.465713 \n",
       "L 84.445982 115.727056 \n",
       "L 88.431696 122.01171 \n",
       "L 92.417411 127.543307 \n",
       "L 96.403125 130.95291 \n",
       "L 100.388839 133.308078 \n",
       "L 104.374554 134.310327 \n",
       "L 108.360268 134.545716 \n",
       "L 112.345982 135.311029 \n",
       "L 116.331696 136.272286 \n",
       "L 120.317411 136.81972 \n",
       "L 124.303125 136.784054 \n",
       "L 128.288839 136.797256 \n",
       "L 132.274554 138.226705 \n",
       "L 136.260268 138.596783 \n",
       "L 140.245982 138.618342 \n",
       "L 144.231696 139.42294 \n",
       "L 148.217411 139.059762 \n",
       "L 152.203125 138.926626 \n",
       "L 156.188839 139.254369 \n",
       "L 160.174554 138.732718 \n",
       "L 164.160268 139.382934 \n",
       "L 168.145982 139.472775 \n",
       "L 172.131696 139.244456 \n",
       "L 176.117411 139.136444 \n",
       "L 180.103125 137.627235 \n",
       "L 184.088839 137.367193 \n",
       "L 188.074554 137.377273 \n",
       "L 192.060268 137.639637 \n",
       "L 196.045982 138.961781 \n",
       "L 200.031696 139.049954 \n",
       "L 204.017411 138.823063 \n",
       "L 208.003125 139.247419 \n",
       "L 211.988839 139.194583 \n",
       "L 215.974554 139.460182 \n",
       "L 219.960268 139.5 \n",
       "L 223.945982 139.381636 \n",
       "L 227.931696 139.320266 \n",
       "L 231.917411 139.292692 \n",
       "L 235.903125 139.28429 \n",
       "\" clip-path=\"url(#p7dcae8e3b8)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 40.603125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 235.903125 145.8 \n",
       "L 235.903125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 235.903125 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 40.603125 7.2 \n",
       "L 235.903125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 173.628125 29.878125 \n",
       "L 228.903125 29.878125 \n",
       "Q 230.903125 29.878125 230.903125 27.878125 \n",
       "L 230.903125 14.2 \n",
       "Q 230.903125 12.2 228.903125 12.2 \n",
       "L 173.628125 12.2 \n",
       "Q 171.628125 12.2 171.628125 14.2 \n",
       "L 171.628125 27.878125 \n",
       "Q 171.628125 29.878125 173.628125 29.878125 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_22\">\n",
       "     <path d=\"M 175.628125 20.298438 \n",
       "L 185.628125 20.298438 \n",
       "L 195.628125 20.298438 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- train -->\n",
       "     <g transform=\"translate(203.628125 23.798438) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p7dcae8e3b8\">\n",
       "   <rect x=\"40.603125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练\n",
    "import math \n",
    "\n",
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    \"\"\"训练网络一个迭代周期（定义见第8章）\"\"\"\n",
    "    state, timer = None, d2l.Timer()\n",
    "    metric = d2l.Accumulator(2)  # 训练损失之和,词元数量\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # 在第一次迭代或使用随机抽样时初始化state\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # state对于nn.GRU是个张量\n",
    "                state.detach_()\n",
    "            else:\n",
    "                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            # 因为已经调用了mean函数\n",
    "            updater(batch_size=1)\n",
    "        metric.add(l * y.numel(), y.numel())\n",
    "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()\n",
    "\n",
    "#@save\n",
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n",
    "              use_random_iter=False):\n",
    "    \"\"\"训练模型（定义见第8章）\"\"\"\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',\n",
    "                            legend=['train'], xlim=[10, num_epochs])\n",
    "    # 初始化\n",
    "    if isinstance(net, nn.Module):\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "    else:\n",
    "        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)\n",
    "    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
    "    # 训练和预测\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch_ch8(\n",
    "            net, train_iter, loss, updater, device, use_random_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(predict('time traveller'))\n",
    "            animator.add(epoch + 1, [ppl])\n",
    "    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))\n",
    "\n",
    "# 加载数据\n",
    "batch_size, num_steps = 32, 35\n",
    "# train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)\n",
    "train_iter, vocab = load_data_time_machine(batch_size, num_steps)\n",
    "\n",
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1.4. <a id='toc11_3_1_4_'></a>[深层RNN](#toc0_)\n",
    "* 有多个隐藏层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "rnn_layer = nn.RNN(\n",
    "    input_size=3,            # 输入大小\n",
    "    hidden_size=3,           # 隐藏层大小\n",
    "    bidirectional=False,     # 双向神经网络，默认是单向\n",
    "    num_layers=1             # 深层神经网络，默认是1层\n",
    ")\n",
    "# dir(rnn_layer)      # 查看属性\n",
    "# help(rnn_layer)   # 查看方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1.5. <a id='toc11_3_1_5_'></a>[双向RNN](#toc0_)\n",
    "* 双向（其实就是将输入倒过来再输入）\n",
    "* 不能用双向循环神经网络来预测未来，因为从一开始就透露未来的信息。\n",
    "* 那实际引用场景是什么？\n",
    "    * 翻译\n",
    "    * 文本句子分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "rnn_layer = nn.RNN(\n",
    "    input_size=3,            # 输入大小\n",
    "    hidden_size=3,           # 隐藏层大小\n",
    "    bidirectional=False,     # 双向神经网络，默认是单向\n",
    "    num_layers=1             # 深层神经网络，默认是1层\n",
    ")\n",
    "# dir(rnn_layer)      # 查看属性\n",
    "# help(rnn_layer)   # 查看方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.2. <a id='toc11_3_2_'></a>[GRU](#toc0_)\n",
    "* GRU实际晚于LSTM，但是作用效果相当而更容易理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.2.1. <a id='toc11_3_2_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.2.2. <a id='toc11_3_2_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "gru_layer = nn.GRU(\n",
    "    input_size=3, \n",
    "    hidden_size=3, \n",
    "    num_layers=2, \n",
    "    bidirectional=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.3. <a id='toc11_3_3_'></a>[LSTM](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.3.1. <a id='toc11_3_3_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.3.2. <a id='toc11_3_3_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "lstm_layer = nn.LSTM(\n",
    "    input_size=3, \n",
    "    hidden_size=3, \n",
    "    num_layers=2, \n",
    "    bidirectional=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.4. <a id='toc11_3_4_'></a>[Encoder-Decoder框架](#toc0_)\n",
    "```shell\n",
    "输入-Encoder-中间状态-Decoder-输出\n",
    "                       输入\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.4.1. <a id='toc11_3_4_1_'></a>[Encoder部分](#toc0_)\n",
    "```shell\n",
    "可变长度的输入，固定长度的输出中间状态\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "#@save\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.4.2. <a id='toc11_3_4_2_'></a>[Decoder部分](#toc0_)\n",
    "```shell\n",
    "固定长度中间状态\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.4.3. <a id='toc11_3_4_3_'></a>[Encoder-Decoder（合并编码器和解码器）](#toc0_)\n",
    "```shell\n",
    "Encoder-Decoder\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.5. <a id='toc11_3_5_'></a>[seq2seq (Sequence to sequence learning)](#toc0_)\n",
    "```shell\n",
    "基于RNN的编码器-解码器框架(Encoder-Decoder)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.5.1. <a id='toc11_3_5_1_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4. <a id='toc11_4_'></a>[Attention](#toc0_)\n",
    "\n",
    "- 不是一个新的概念，很早之前就已经出现，只是在Google发表论文Attention is all you need后，越来越知名； \n",
    "- 如果非要找一个依据，从心理学上讲： \n",
    " \n",
    "    1. 之前学习的神经网络（CNN、RNN等）都是提取特征->全连接网络，属于“非随意识注意力”-即非主观，如一排黑色咖啡杯中有一个红色的就会很吸引人；  \n",
    "    2. Attention提出的是“随意识注意力”即主观的去注意那个物体，如喝完咖啡后想去找一本关于Attention方面的书去看。\n",
    "\n",
    "        Query:人主动去查询（注意）  \n",
    "        Key:  物体的属性  \n",
    "        Value:  物体的属性  \n",
    "\n",
    "- `说白了，注意力就是加权平均数，首先计算query与key的相似度，越相似就给越高的权重，最后用权重乘以value再求和，即得注意力值`\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/Attention//Attention_principle.jpg\" width = \"700\" height = \"300\" alt=\"图片名称\" align=center />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.1. <a id='toc11_4_1_'></a>[非参数注意力汇聚（Attention Pooling）-计算q和k相似度](#toc0_)\n",
    "在以前，统计学家计算机用的不是很溜。用统计模型进行预测，而不是利用计算机的计算资源进行迭代优化逼近真实分布。所得的结果就是只是利用统计模型进行预测的曲线会比较平滑但是准确性不高，可能随着数据量的增高可以提高准确性，但是，现实中能有那么多够用的数据吗？而利用计算迭代优化逼近的方法可以很准确的拟合现有的数据，虽然不是很平滑，优点是数据虽少但可以被充分利用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f(x) = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.2. <a id='toc11_4_2_'></a>[参数注意力汇聚（Attention Pooling）-计算q和k相似度](#toc0_)\n",
    "```shell\n",
    "加入可学习的参数w。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.3. <a id='toc11_4_3_'></a>[注意力分数函数-计算q和k相似度](#toc0_)\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/Attention/Attention_score.jpg\" width = \"500\" height = \"300\" alt=\"图片名称\" align=center />\n",
    "\n",
    "- 本质上`Attention机制是Source中元素的Value值进行加权求和，而Query和Key用来计算对应Value的权重系数`；\n",
    "- 首先利用`注意力分数函数`计算`Query`和`Key`的`相似度 (注意力分数)`；\n",
    "- 利用`softmax`计算相似度 (注意力分数)后，得到`加权数值` (`注意力权重`，query和key越相似该权重越大，即获取的注意力越大)；\n",
    "- 利用注意力权重对value进行`加权求和`，即最终的`注意力值`。\n",
    "\n",
    "- 解释：\n",
    "\n",
    "    |注释|公式|\n",
    "    |:-|:-|\n",
    "    |注意力评分函数|$a(q, k)$|\n",
    "    |注意力权重|$softmax( a(q, k) )$|\n",
    "    |注意力|$softmax( a(q, k) ) * v$|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.4.3.1. <a id='toc11_4_3_1_'></a>[加性注意力](#toc0_)\n",
    "\n",
    "- 当`查询`和`键`是`不同长度`的`矢量`时，可以使用`加性注意力作为评分函数`。\n",
    "- 注意力评分函数：$a(\\mathbf{q},\\mathbf{k})=\\mathbf{w}_v^\\top\\tanh(\\mathbf{W}_q\\mathbf{q}+\\mathbf{W}_k\\mathbf{k})\\in\\mathbb{R}$\n",
    "- $\\mathbf{q}\\in\\mathbb{R}^q\\text{和 键}\\mathbf{k}\\in\\mathbb{R}^k,$\n",
    "- $\\mathbf{W}_q\\in\\mathbb{R}^{h\\times q}\\mathrm{、}\\mathbf{W}_k\\in\\mathbb{R}^{h\\times k}\\text{和 }\\mathbf{w}_v\\in\\mathbb{R}^h$, `投影`到`相同维度h`上\n",
    "- `有可学习的参数`，效果会好一些。\n",
    "\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/Attention/Additive_attention.jpg\" />\n",
    "\n",
    "\n",
    "- 使用:\n",
    "```python\n",
    "# summary \n",
    "    # Input:\n",
    "            # queries:                  (batch_size, num_query, query_size)\n",
    "            # keys:                     (batch_size, k_v_pair_num,  key_size)\n",
    "            # values:                   (batch_size, k_v_pair_num, value_size)\n",
    "    # Output:                           (batch_size, num_query, value_size)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参考案例-李沐\n",
    "  - 带有掩码和Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#@save\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\"\"\"\n",
    "    # X:3D张量，valid_lens:1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = d2l.sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                              value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "#@save\n",
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"加性注意力\"\"\"\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n",
    "        super(AdditiveAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # 在维度扩展后，\n",
    "        # queries的形状：(batch_size，查询的个数，1，num_hidden)\n",
    "        # key的形状：(batch_size，1，“键－值”对的个数，num_hiddens)\n",
    "        # 使用广播方式进行求和\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        # self.w_v仅有一个输出，因此从形状中移除最后那个维度。\n",
    "        # scores的形状：(batch_size，查询的个数，“键-值”对的个数)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "    \n",
    "queries, keys = torch.normal(0, 1, (2, 1, 20)), torch.ones((2, 10, 2))\n",
    "# values的小批量，两个值矩阵是相同的\n",
    "values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(\n",
    "    2, 1, 1)\n",
    "valid_lens = torch.tensor([2, 6])\n",
    "\n",
    "attention = AdditiveAttention(key_size=2, query_size=20, num_hiddens=8,\n",
    "                              dropout=0.1)\n",
    "attention.eval()\n",
    "attention(queries, keys, values, valid_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参考案例-ChatGPT生成\n",
    "  - 带有掩码和Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 1, 4])\n",
      "Attention weights shape: torch.Size([2, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout=0.0):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # Additive attention mechanism\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        \n",
    "        # Masked softmax, ensuring the attention only considers valid lengths\n",
    "        if valid_lens is not None:\n",
    "            mask = torch.arange(keys.shape[1])[None, :] < valid_lens[:, None]\n",
    "            mask = mask.unsqueeze(1).to(scores.device)  # Shape: (batch_size, 1, key_size)\n",
    "            scores.masked_fill_(~mask, -1e9)\n",
    "        \n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        \n",
    "        # Weighted sum of values\n",
    "        output = torch.bmm(attention_weights, values)\n",
    "        return output, attention_weights\n",
    "\n",
    "# 测试该加性注意力机制\n",
    "# batch_size, num_queries, num_kv_pairs, key_dim, query_dim, value_dim, num_hiddens = 2, 3, 4, 5, 6, 7, 8\n",
    "batch_size, num_queries, num_kv_pairs, key_dim, query_dim, value_dim, num_hiddens = 2, 1, 10, 2, 10, 4, 4\n",
    "\n",
    "queries = torch.randn(batch_size, num_queries, query_dim)\n",
    "keys = torch.randn(batch_size, num_kv_pairs, key_dim)\n",
    "values = torch.randn(batch_size, num_kv_pairs, value_dim)\n",
    "valid_lens = torch.tensor([3, 2])\n",
    "\n",
    "attention = AdditiveAttention(key_dim, query_dim, num_hiddens, dropout=0.1)\n",
    "output, attention_weights = attention(queries, keys, values, valid_lens)\n",
    "\n",
    "print(\"Output shape:\", output.shape)  \n",
    "# (batch_size, num_queries, value_dim)\n",
    "print(\"Attention weights shape:\", attention_weights.shape)  \n",
    "# (batch_size, num_queries, num_kv_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (详细) 从头手写-逐步分析“加性注意力机制代码”\n",
    "  - 无掩码和Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries size:  torch.Size([2, 1, 20])\n",
      "keys size:  torch.Size([2, 10, 2])\n",
      "values size:  torch.Size([2, 10, 4])\n",
      "Q size:  torch.Size([2, 1, 1, 4])\n",
      "K size:  torch.Size([2, 1, 10, 4])\n",
      "features size:  torch.Size([2, 1, 10, 4])\n",
      "features size (tanh):  torch.Size([2, 1, 10, 4])\n",
      "scores size:  torch.Size([2, 1, 10, 1])\n",
      "scores size squeeze:  torch.Size([2, 1, 10])\n",
      "attention_weights:  torch.Size([2, 1, 10])\n",
      "attention:  torch.Size([2, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "########################################################\n",
    "# 测试数据\n",
    "########################################################\n",
    "batch_size = 2\n",
    "num_query = 1\n",
    "query_size = 20             # 一个query的向量长度\n",
    "\n",
    "num_key = 10                # “键－值”对的个数\n",
    "key_size = 2                # 一个key的向量长度\n",
    "\n",
    "num_value = num_key         # “键－值”对的个数\n",
    "value_size = 4              # 一个value的向量长度\n",
    "\n",
    "queries = torch.randn(size=(batch_size, num_query, query_size))\n",
    "print('queries size: ', queries.size())\n",
    "# batch_size, num_query, query_size\n",
    "# 2, 1, 20\n",
    "\n",
    "keys = torch.randn(size=(batch_size, num_key, key_size))\n",
    "print('keys size: ', keys.size())\n",
    "# batch_size, kv_pair_num, key_size\n",
    "# 2, 10, 2\n",
    "\n",
    "values = torch.randn(size=(batch_size, num_value, value_size))\n",
    "print('values size: ', values.size())\n",
    "# batch_size, kv_pair_num, value_size\n",
    "# 2, 10, 4\n",
    "\n",
    "########################################################\n",
    "# 投影 (可学习的参数W)\n",
    "########################################################\n",
    "\n",
    "## 全部投影到value_size一致的维度，便于计算\n",
    "num_hiddens = value_size\n",
    "bias = False\n",
    "W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "w_v = nn.Linear(num_hiddens, 1, bias=bias)\n",
    "\n",
    "Q = W_q(queries)                    # (batch_size，查询的个数，num_hidden) 3维\n",
    "# 2, 1, 4\n",
    "Q = Q.unsqueeze(2)                  # (batch_size，查询的个数，1，num_hidden) 插入一个维度  (重要) 4维\n",
    "# 2, 1, 1, 4                        # 为什么要插入一个维度？便于后续做广播\n",
    "print('Q size: ', Q.size())\n",
    "\n",
    "K = W_k(keys)                       # (batch_size，“键－值”对的个数，num_hiddens)   3维\n",
    "# 2, 10, 4\n",
    "K = K.unsqueeze(1)                  # (batch_size，1，“键－值”对的个数，num_hiddens) 插入一个维度 (重要) 4维度\n",
    "# 2, 1, 10, 4                       # 为什么要插入一个维度？便于后续做广播\n",
    "print('K size: ', K.size())\n",
    "\n",
    "\n",
    "features = Q + K                    # 自动做广播后做加法    (重要)                                  (2,1,1,4) + (2,1,10,4) = (2,1,10,4)\n",
    "# 2, 1, 10, 4                       # (batch_size，查询个数，“键－值”对的个数，num_hiddens) 广播后   (2,1,10,4)+ (2,1,10,4) = (2,1,10,4)\n",
    "print('features size: ', features.size())\n",
    "features = torch.tanh(features)\n",
    "# 2, 1, 10, 4\n",
    "print('features size (tanh): ', features.size())\n",
    "\n",
    "scores = w_v(features)              # 自动做广播后做乘法    (2,1,10,4) @ (    4,1) = (2,1,10,1)\n",
    "                                    #                      (2,1,10,4) @ (2,1,4,1) = (2,1,10,1)\n",
    "# 2, 1, 10, 1\n",
    "print('scores size: ', scores.size())\n",
    "\n",
    "# w_v仅有一个输出，因此从形状中移除最后那个维度\n",
    "# scores的形状：(batch_size，查询的个数，“键-值”对的个数)\n",
    "scores = scores.squeeze(-1)\n",
    "# 2, 1, 10\n",
    "print('scores size squeeze: ', scores.size())\n",
    "\n",
    "attention_weights = torch.softmax(scores, dim=-1)\n",
    "# 2, 1, 10\n",
    "print('attention_weights: ', attention_weights.size())\n",
    "# attention_weights\n",
    "\n",
    "attention = torch.bmm(attention_weights, values)    # (2,1,10) @ (  10,4) = (2,1,4)\n",
    "                                                    # (2,1,10) @ (2,10,4) = (2,1,4) 广播后\n",
    "print('attention: ', attention.size())\n",
    "# batch_size, num_query, value_size\n",
    "# 2, 1, 4\n",
    "\n",
    "# summary \n",
    "    # Input:\n",
    "            # queries:                  (batch_size, num_query, query_size)\n",
    "            # keys:                     (batch_size, k_v_pair_num,  key_size)\n",
    "            # values:                   (batch_size, k_v_pair_num, value_size)\n",
    "    # Output:                           (batch_size, num_query, value_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从头写“加性注意力机制”\n",
    "  - 无掩码和Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries size:  torch.Size([2, 1, 20])\n",
      "keys size:  torch.Size([2, 10, 2])\n",
      "values size:  torch.Size([2, 10, 4])\n",
      "result size:  torch.Size([2, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn \n",
    "\n",
    "class AddiAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 query_size, \n",
    "                 key_size, \n",
    "                 value_size,\n",
    "                 exitBias=False):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(query_size, value_size, bias=exitBias)\n",
    "        self.W_k = nn.Linear(key_size, value_size, bias=exitBias)\n",
    "        self.w_v = nn.Linear(value_size, 1, bias=exitBias)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        Q = self.W_q(queries)\n",
    "        K = self.W_k(keys)\n",
    "        features = Q.unsqueeze(2) + K.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        scores = self.w_v(features)\n",
    "        scores = scores.squeeze(-1)\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        self.attention_weights_numpy = attention_weights.detach().cpu().numpy()   # 存起来，后面可视化看看\n",
    "        batch_attention = torch.bmm(attention_weights, values)\n",
    "        return batch_attention\n",
    "    \n",
    "    def addAttention_weights(self):\n",
    "        return self.attention_weights_numpy\n",
    "\n",
    "\n",
    "# 示例数据  \n",
    "batch_size = 2\n",
    "num_query = 1\n",
    "query_size = 20             # 一个query的向量长度\n",
    "\n",
    "num_key = 10                    # “键－值”对的个数\n",
    "key_size = 2                # 一个key的向量长度\n",
    "\n",
    "num_value = num_key             # “键－值”对的个数\n",
    "value_size = 4              # 一个value的向量长度\n",
    "\n",
    "queries = torch.randn(size=(batch_size, num_query, query_size))\n",
    "print('queries size: ', queries.size())\n",
    "# (2, 1, 20)\n",
    "\n",
    "keys = torch.randn(size=(batch_size, num_key, key_size))\n",
    "print('keys size: ', keys.size())\n",
    "# (2, 10, 2)\n",
    "\n",
    "values = torch.randn(size=(batch_size, num_value, value_size))\n",
    "print('values size: ', values.size())\n",
    "# (2, 10, 4)\n",
    "\n",
    "# 实例化\n",
    "addAttention = AddiAttention(\n",
    "    query_size = query_size,\n",
    "    key_size = key_size,\n",
    "    value_size = value_size,\n",
    "    exitBias=False)\n",
    "attention_values = addAttention(queries, keys, values)\n",
    "print('result size: ', attention_values.size())\n",
    "# (2, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addAttention.attention_weights_numpy: \n",
      " [[[0.09647817 0.15244135 0.09336501 0.1083491  0.09707744 0.0848025\n",
      "   0.08933608 0.0865904  0.08653206 0.10502791]]\n",
      "\n",
      " [[0.11488204 0.09333597 0.08784864 0.09357826 0.10593394 0.08723343\n",
      "   0.1140158  0.09077008 0.12360674 0.08879507]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f54755f8140>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print(\"addAttention.attention_weights_numpy: \\n\", addAttention.attention_weights_numpy)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(addAttention.attention_weights_numpy[0,:])\n",
    "plt.title('batch 0')\n",
    "plt.xlabel('k-v pair')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(addAttention.attention_weights_numpy[1,:])\n",
    "plt.title('batch 1')\n",
    "plt.xlabel('k-v pair')\n",
    "plt.colorbar()\n",
    "\n",
    "# 权重越高，越吸引注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.4.3.2. <a id='toc11_4_3_2_'></a>[缩放点积注意力](#toc0_)\n",
    "\n",
    "- q和k的长度`一致`，为`d`\n",
    "- 注意力评分函数：$a(\\mathbf{q},\\mathbf{k})=\\mathbf{q}^\\top\\mathbf{k}/\\sqrt{d}$\n",
    "- 向量版本注意力权重：$\\mathrm{softmax}\\left(\\frac{\\mathrm{QK}^\\top}{\\sqrt{d}}\\right)\\mathbf{V}\\in\\mathbb{R}^{n\\times v}$\n",
    "- $\\text{查询}\\mathbf{Q}\\in\\mathbb{R}^{n\\times d}\\text{、键}\\mathbf{K}\\in\\mathbb{R}^{m\\times d}\\text{和 值}\\mathbf{V}\\in\\mathbb{R}^{m\\times v}$\n",
    "- `无可学习`参数\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./Pytorch_Pictures/Attention/scale-dot-product.png\" width = \"300\" height = \"300\" alt=\"图片名称\" align=center />\n",
    "\n",
    "- 使用：\n",
    "```python\n",
    "# summary \n",
    "    # Input:\n",
    "            # queries:                  (batch_size, num_query, query_size)\n",
    "            # keys:                     (batch_size, k_v_pair_num,  key_size)\n",
    "            # values:                   (batch_size, k_v_pair_num, value_size)\n",
    "    # Output:                           (batch_size, num_query, value_size)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 案例-李沐\n",
    "  - 掩码和Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "    \n",
    "queries = torch.normal(0, 1, (2, 1, 2))\n",
    "attention = DotProductAttention(dropout=0.5)\n",
    "attention.eval()\n",
    "attention(queries, keys, values, valid_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (详细) 从头手写\n",
    "  - 无掩码和Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries size:  torch.Size([2, 1, 20])\n",
      "keys size:  torch.Size([2, 10, 20])\n",
      "values size:  torch.Size([2, 10, 4])\n",
      "features size: torch.Size([2, 1, 10])\n",
      "scores size: torch.Size([2, 1, 10])\n",
      "attention_weights size: torch.Size([2, 1, 10])\n",
      "attention size: torch.Size([2, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn \n",
    "\n",
    "\n",
    "# 示例数据  \n",
    "batch_size = 2\n",
    "num_query = 1\n",
    "query_size = 20             # 一个query的向量长度，d\n",
    "\n",
    "num_key = 10                    # “键－值”对的个数，m\n",
    "key_size = 20                # 一个key的向量长度，d\n",
    "\n",
    "num_value = num_key             # “键－值”对的个数，m\n",
    "value_size = 4              # 一个value的向量长度，v\n",
    "\n",
    "queries = torch.randn(size=(batch_size, num_query, query_size))\n",
    "print('queries size: ', queries.size())\n",
    "# (batch_size, num_query, query_size)\n",
    "# (2, 1, 20)\n",
    "\n",
    "keys = torch.randn(size=(batch_size, num_key, key_size))\n",
    "print('keys size: ', keys.size())\n",
    "# (batch_size, num_key, key_size)\n",
    "# (2, 10, 20)\n",
    "\n",
    "values = torch.randn(size=(batch_size, num_value, value_size))\n",
    "print('values size: ', values.size())\n",
    "# (batch_size, num_value, value_size)\n",
    "# (2, 10, 4)\n",
    "\n",
    "features = (queries @ keys.transpose(1, 2)) \n",
    "# features = torch.bmm(queries, keys.transpose(1, 2))               # 同上，都可以\n",
    "# (2, 1, 20) @ (2, 20, 10) = (2, 1, 10)\n",
    "print(f'features size: {features.shape}')\n",
    "\n",
    "scores = features / torch.sqrt(torch.tensor(queries.shape[2]))\n",
    "# (2, 1, 10)\n",
    "print(f'scores size: {scores.shape}')\n",
    "\n",
    "attention_weights = torch.softmax(scores, dim=-1)\n",
    "# (2, 1, 10) / 标量 = (2, 1, 10)\n",
    "print(f'attention_weights size: {attention_weights.shape}')\n",
    "\n",
    "attention = torch.bmm(attention_weights, values)\n",
    "# (2, 1, 4)\n",
    "print(f'attention size: {attention.shape}')\n",
    "\n",
    "# summary \n",
    "    # Input:\n",
    "            # queries:                  (batch_size, num_query, query_size)\n",
    "            # keys:                     (batch_size, k_v_pair_num,  key_size)\n",
    "            # values:                   (batch_size, k_v_pair_num, value_size)\n",
    "    # Output:                           (batch_size, num_query, value_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "\n",
    "class DotAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # features = (queries @ keys.transpose(1, 2)) \n",
    "        featrues = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        scores = features / torch.sqrt(torch.tensor(queries.shape[2]))\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        self.attention_weights_numpy = attention_weights.detach().cpu().numpy()\n",
    "        attention = torch.bmm(attention_weights, values)\n",
    "        return attention\n",
    "    \n",
    "    def dotAttention_weights(self):\n",
    "        return self.attention_weights_numpy\n",
    "    \n",
    "\n",
    "# 示例数据  \n",
    "batch_size = 2\n",
    "num_query = 1\n",
    "query_size = 20             # 一个query的向量长度，d\n",
    "\n",
    "num_key = 10                    # “键－值”对的个数，m\n",
    "key_size = 20                # 一个key的向量长度，d\n",
    "\n",
    "num_value = num_key             # “键－值”对的个数，m\n",
    "value_size = 4              # 一个value的向量长度，v\n",
    "\n",
    "queries = torch.randn(size=(batch_size, num_query, query_size))\n",
    "print('queries size: ', queries.size())\n",
    "# (2, 1, 20)\n",
    "\n",
    "keys = torch.randn(size=(batch_size, num_key, key_size))\n",
    "print('keys size: ', keys.size())\n",
    "# (2, 10, 20)\n",
    "\n",
    "values = torch.randn(size=(batch_size, num_value, value_size))\n",
    "print('values size: ', values.size())\n",
    "# (2, 10, 4)\n",
    "\n",
    "dotAttention = DotAttention()\n",
    "attention_values = dotAttention(queries=queries, keys=keys, values=values)\n",
    "attention_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.04985159, 0.05334752, 0.09109451, 0.05134343, 0.28254676,\n",
       "         0.03270705, 0.06674033, 0.11863098, 0.1836128 , 0.07012501]],\n",
       "\n",
       "       [[0.13796079, 0.06152954, 0.14528   , 0.08120591, 0.04767546,\n",
       "         0.04191732, 0.12780628, 0.02460011, 0.11363557, 0.21838896]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotAttention.dotAttention_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dotAttention.dotAttention_weights(): \n",
      " [[[0.04985159 0.05334752 0.09109451 0.05134343 0.28254676 0.03270705\n",
      "   0.06674033 0.11863098 0.1836128  0.07012501]]\n",
      "\n",
      " [[0.13796079 0.06152954 0.14528    0.08120591 0.04767546 0.04191732\n",
      "   0.12780628 0.02460011 0.11363557 0.21838896]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fa6a8223260>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print(\"dotAttention.dotAttention_weights(): \\n\", dotAttention.dotAttention_weights())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(dotAttention.dotAttention_weights()[0,:])\n",
    "plt.title('batch 0')\n",
    "plt.xlabel('k-v pair')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(dotAttention.dotAttention_weights()[1,:])\n",
    "plt.title('batch 1')\n",
    "plt.xlabel('k-v pair')\n",
    "plt.colorbar()\n",
    "\n",
    "# 权重越高，越吸引注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.4. <a id='toc11_4_4_'></a>[自注意力机制](#toc0_)\n",
    "\n",
    "自注意力机制：就是用同一个`X`分别于`W_q`、`W_k`和`W_v`矩阵相乘得到`Q`、`K`和`V` `向量/矩阵`。因为用的是同一个X同时作为q、k和v，所以得名为 `自注意力` 。\n",
    "\n",
    "- 使用：\n",
    "```python\n",
    "# self-attention:                       queries = keys = values\n",
    "    # Input:\n",
    "            # queries:                  (batch_size, num_query, query_size)\n",
    "            # keys:                     (batch_size, k_v_pair_num,  key_size)\n",
    "            # values:                   (batch_size, k_v_pair_num, value_size)\n",
    "    # Output:                           (batch_size, num_query, value_size)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Runing on cuda:0 \n",
      " ====================================================================================================\n",
      "epoch 1/10: train_loss=0.12752601504325867, train_acc=96.22000122070312, test_acc=96.16999816894531\n",
      "epoch 2/10: train_loss=0.0828862413764, train_acc=97.41999816894531, test_acc=96.8499984741211\n",
      "epoch 3/10: train_loss=0.0710381269454956, train_acc=97.73333740234375, test_acc=97.33000183105469\n",
      "epoch 4/10: train_loss=0.04808149114251137, train_acc=98.47666931152344, test_acc=97.38999938964844\n",
      "epoch 5/10: train_loss=0.0647362694144249, train_acc=97.86833190917969, test_acc=96.59000396728516\n",
      "epoch 6/10: train_loss=0.03491692245006561, train_acc=98.86500549316406, test_acc=97.62999725341797\n",
      "epoch 7/10: train_loss=0.039316173642873764, train_acc=98.66166687011719, test_acc=97.2699966430664\n",
      "epoch 8/10: train_loss=0.027984920889139175, train_acc=99.07833099365234, test_acc=97.63999938964844\n",
      "epoch 9/10: train_loss=0.0323726050555706, train_acc=98.86666870117188, test_acc=97.23999786376953\n",
      "epoch 10/10: train_loss=0.02307908982038498, train_acc=99.22000122070312, test_acc=97.78999328613281\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 12.094844102859497 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, batch_size=128,  shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构1:CNN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 10), nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 构建模型2:Additive attention\n",
    "class AddAttentionMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(28 * 28, 128), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.attention = AddiAttention(\n",
    "            query_size=128, \n",
    "            key_size=128,\n",
    "            value_size=128, \n",
    "            exitBias=False\n",
    "        )\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = x.unsqueeze(1)  # dim=1增加一个维度\n",
    "        x = self.attention(queries=x, keys=x, values=x).squeeze(1) # dim=1的维度取消\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# 构建模型3:DotAttention\n",
    "class SelfDotAttention(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.W_q = nn.Linear(self.dim, self.dim)\n",
    "        self.W_k = nn.Linear(self.dim, self.dim)\n",
    "        self.W_v = nn.Linear(self.dim, self.dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 准备Q K V\n",
    "        queries = self.W_q(X)\n",
    "        keys = self.W_k(X)\n",
    "        values = self.W_v(X)\n",
    "        # print(X.shape)\n",
    "        # 计算权重\n",
    "        features = torch.bmm(queries, keys.transpose(1, 2))        # 点积\n",
    "        scores = features / torch.sqrt(torch.tensor(self.dim))    # 缩放\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        attention = torch.bmm(attention_weights, values)\n",
    "        return attention\n",
    "\n",
    "class DotAttentionMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.adjust = nn.Linear(128, 128)\n",
    "        self.attention = SelfDotAttention(dim=128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.input(X)\n",
    "        # print('raw X size: ', x.shape)\n",
    "        x = x.unsqueeze(1)      # 增加dim=1维度\n",
    "        # print('x.unsqueeze(1) size: ', x.shape)\n",
    "        x = self.attention(x)\n",
    "        x = x.squeeze(1)        # 去除dim=1维度\n",
    "        # print('x.squeeze(1) size: ', x.shape)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "    print('='*100, '\\n', f\"Runing on {device}\", '\\n','='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net = nn.DataParallel(module=net)\n",
    "    # net = nn.DataParallel(module=net, device_ids=[0, 1], output_device=[0]) # 多GPU并行计算，等价于net = nn.DataParallel(module=net)\n",
    "    net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "# net = Net()  \n",
    "# net = AddAttentionMNISTModel()\n",
    "net = DotAttentionMNISTModel()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.5. <a id='toc11_4_5_'></a>[多头注意力机制](#toc0_)\n",
    "上述只求一次注意力的过程可以叫做单头注意力。多头注意力就是对同样的Q, K, V求多次注意力，并行计算h个得到h个不同的attention，再把这些不同的h个attention连接起来得到最终的attentions，每一个attention都是一个head（头），总共有h个head（头）。  \n",
    "\n",
    "<img src=\"./Pytorch_Pictures/Attention/multi_head.jpg\" width = \"300\" height = \"350\" alt=\"多头注意力机制\" align=center />\n",
    "\n",
    "在实现过程中通常选择`缩放点积注意力`作为每一个注意力头，除以根号d可以使计算数值减小。\n",
    "\n",
    "```python\n",
    "# summary \n",
    "    # Input:\n",
    "            # queries:                  (batch_size, num_query, query_size)\n",
    "            # keys:                     (batch_size, k_v_pair_num,  key_size)\n",
    "            # values:                   (batch_size, k_v_pair_num, value_size)\n",
    "    # Output:                           (batch_size, num_query, value_size)\n",
    "\n",
    "# 先 transpose_input()\n",
    "# 后 transpose_output()\n",
    "# 终 self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=exitBias)   # 最后concat所有head的结果 (其实就是投影)\n",
    "```\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 案例-李沐 (修改)\n",
    "  - 去除掩码和Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw queries size:  torch.Size([2, 4, 100])\n",
      "raw keys/values size : torch.Size([2, 6, 100])\n",
      "Q size: torch.Size([2, 4, 100])\n",
      "Q transpose_input size: torch.Size([10, 4, 20])\n",
      "K size: torch.Size([2, 6, 100])\n",
      "K transpose_input size: torch.Size([10, 6, 20])\n",
      "V size: torch.Size([2, 6, 100])\n",
      "V transpose_input size: torch.Size([10, 6, 20])\n",
      "output size: torch.Size([10, 4, 20])\n",
      "attention_values size:  torch.Size([2, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "\n",
    "# DotAttention\n",
    "class DotAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # features = (queries @ keys.transpose(1, 2)) \n",
    "        features = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        scores = features / torch.sqrt(torch.tensor(queries.shape[-1]))\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        self.attention_weights_numpy = attention_weights.detach().cpu().numpy()\n",
    "        attention = torch.bmm(attention_weights, values)\n",
    "        return attention\n",
    "    \n",
    "    def dotAttention_weights(self):\n",
    "        return self.attention_weights_numpy\n",
    "\n",
    "# 多头注意力机制\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_heads, \n",
    "                 query_size, \n",
    "                 num_hiddens, \n",
    "                 key_size, \n",
    "                 value_size, \n",
    "                 exitBias=False):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotAttention()\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=exitBias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=exitBias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=exitBias)\n",
    "\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=exitBias)   # 最后concat所有head的结果 (其实就是投影)\n",
    "\n",
    "    def transpose_input(self, X, num_heads):\n",
    "        \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "        # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # 输出X的形状:(batch_size，查询或者“键－值”对的个数，`num_heads`，num_hiddens/num_heads)\n",
    "        X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "        # 输出X的形状:(batch_size，`num_heads`，查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        X = X.permute(0, 2, 1, 3)                                                                   # 调整顺序以便做广播 (向量化并行计算multi heads)\n",
    "\n",
    "        # 最终输出的形状:(batch_size*`num_heads`,查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "    def transpose_output(self, X, num_heads):\n",
    "        \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "        # 输入X的形状:(batch_size*`num_heads`,查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        # 输出X的形状:(batch_size,`num_heads``,查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "\n",
    "        # 输出X的形状:(batch_size查询或者“键－值”对的个数，`num_heads``,num_hiddens/num_heads)                                        # 不改变顺序\n",
    "        X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "        # 最终输出X的形状:(batch_size,`num_heads`,查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # queries，keys，values的形状:\n",
    "            # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "            # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "            # (batch_size*num_heads，查询或者“键－值”对的个数，num_hiddens/num_heads) ##############\n",
    "        queries = self.W_q(queries)\n",
    "        print(f'Q size: {queries.shape}')\n",
    "        queries = self.transpose_input(queries, self.num_heads)\n",
    "        print(f'Q transpose_input size: {queries.shape}')\n",
    "\n",
    "        keys = self.W_k(keys)\n",
    "        print(f'K size: {keys.shape}')\n",
    "        keys = self.transpose_input(keys, self.num_heads)\n",
    "        print(f'K transpose_input size: {keys.shape}')\n",
    "\n",
    "        values = self.W_v(values)\n",
    "        print(f'V size: {values.shape}')\n",
    "        values = self.transpose_input(values, self.num_heads)\n",
    "        print(f'V transpose_input size: {values.shape}')\n",
    "\n",
    "        # output的形状:(batch_size*num_heads，查询的个数，num_hiddens/num_heads) ##############\n",
    "        output = self.attention(queries=queries, keys=keys, values=values)\n",
    "        print(f'output size: {output.shape}')\n",
    "\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens) ##############\n",
    "        output_concat = self.transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)\n",
    "\n",
    "# 实例化\n",
    "num_hiddens, num_heads = 100, 5\n",
    "multiHeadAttention = MultiHeadAttention(\n",
    "    num_heads = num_heads, \n",
    "    query_size = num_hiddens, \n",
    "    num_hiddens = num_hiddens, \n",
    "    key_size = num_hiddens, \n",
    "    value_size = num_hiddens, \n",
    "    exitBias=False\n",
    ")\n",
    "\n",
    "# 传参\n",
    "batch_size, num_queries = 2, 4\n",
    "num_kvpairs =  6\n",
    "X = torch.ones((batch_size, num_queries, num_hiddens)); print('raw queries size: ', X.shape)\n",
    "# (batch_size, num_queries, num_hiddens)\n",
    "# 2, 4, 100\n",
    "\n",
    "Y = torch.ones((batch_size, num_kvpairs, num_hiddens)); print('raw keys/values size :', Y.shape)\n",
    "# (batch_size, num_kvpairs, num_hiddens)\n",
    "# 2, 6, 100\n",
    "\n",
    "attention_values = multiHeadAttention(X, Y, Y); print('attention_values size: ', attention_values.shape)\n",
    "# (batch_size, num_queries, num_hiddens)\n",
    "# 2, 4, 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从头手写\n",
    "  - 无掩码和Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Runing on cuda:0 \n",
      " ====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bmp/backup/zhaosy/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10: train_loss=0.2031008005142212, train_acc=93.56666564941406, test_acc=93.64999389648438\n",
      "epoch 2/10: train_loss=0.08679258823394775, train_acc=97.34833526611328, test_acc=96.33000183105469\n",
      "epoch 3/10: train_loss=0.07397859543561935, train_acc=97.67333221435547, test_acc=96.94999694824219\n",
      "epoch 4/10: train_loss=0.06289227306842804, train_acc=97.98500061035156, test_acc=96.94000244140625\n",
      "epoch 5/10: train_loss=0.04933113232254982, train_acc=98.45999908447266, test_acc=97.1199951171875\n",
      "epoch 6/10: train_loss=0.04422649368643761, train_acc=98.58833312988281, test_acc=97.23999786376953\n",
      "epoch 7/10: train_loss=0.04513872414827347, train_acc=98.55333709716797, test_acc=96.97000122070312\n",
      "epoch 8/10: train_loss=0.06883847713470459, train_acc=97.73999786376953, test_acc=96.20999908447266\n",
      "epoch 9/10: train_loss=0.03226908668875694, train_acc=98.91000366210938, test_acc=97.2699966430664\n",
      "epoch 10/10: train_loss=0.06508824974298477, train_acc=97.91333770751953, test_acc=96.27999877929688\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 2.0 m/ 37.413596391677856 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(), \n",
    "            #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, batch_size=128,  shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构1:CNN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 10), nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 构建模型2:Additive attention\n",
    "class AddAttentionMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(28 * 28, 128), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.attention = AddiAttention(\n",
    "            query_size=128, \n",
    "            key_size=128,\n",
    "            value_size=128, \n",
    "            exitBias=False\n",
    "        )\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = x.unsqueeze(1)  # dim=1增加一个维度\n",
    "        x = self.attention(queries=x, keys=x, values=x).squeeze(1) # dim=1的维度取消\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# 构建模型3:DotAttention\n",
    "class SelfDotAttention(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.W_q = nn.Linear(self.dim, self.dim)\n",
    "        self.W_k = nn.Linear(self.dim, self.dim)\n",
    "        self.W_v = nn.Linear(self.dim, self.dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 准备Q K V\n",
    "        queries = self.W_q(X)\n",
    "        keys = self.W_k(X)\n",
    "        values = self.W_v(X)\n",
    "        # print(X.shape)\n",
    "        # 计算权重\n",
    "        features = torch.bmm(queries, keys.transpose(1, 2))        # 点积\n",
    "        scores = features / torch.sqrt(torch.tensor(self.dim))    # 缩放\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        attention = torch.bmm(attention_weights, values)\n",
    "        return attention\n",
    "\n",
    "class DotAttentionMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.adjust = nn.Linear(128, 128)\n",
    "        self.attention = SelfDotAttention(dim=128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.input(X)\n",
    "        # print('raw X size: ', x.shape)\n",
    "        x = x.unsqueeze(1)      # 增加dim=1维度\n",
    "        # print('x.unsqueeze(1) size: ', x.shape)\n",
    "        x = self.attention(x)\n",
    "        x = x.squeeze(1)        # 去除dim=1维度\n",
    "        # print('x.squeeze(1) size: ', x.shape)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 4\n",
    "class MultiHeadAttentionMNISTModel(nn.Module):\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "        self.input = nn.Sequential(\n",
    "                nn.Flatten(), \n",
    "                nn.Linear(28 * 28, 128),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        num_hiddens = 128\n",
    "        self.attention = multiHeadAttention = MultiHeadAttention(\n",
    "            num_heads = num_heads, \n",
    "            query_size = num_hiddens, \n",
    "            num_hiddens = num_hiddens, \n",
    "            key_size = num_hiddens, \n",
    "            value_size = num_hiddens, \n",
    "            exitBias=False\n",
    "        )\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.input(X)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.attention(queries=x, keys=x, values=x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "    print('='*100, '\\n', f\"Runing on {device}\", '\\n','='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net = nn.DataParallel(module=net)\n",
    "    net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "# net = Net()  \n",
    "# net = AddAttentionMNISTModel()\n",
    "# net = DotAttentionMNISTModel()\n",
    "net = MultiHeadAttentionMNISTModel(num_heads=4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(\n",
    "    epochs=10, \n",
    "    train_dataset=train_dataset, \n",
    "    train_iter=train_iter, \n",
    "    test_dataset=test_dataset, \n",
    "    net=net,                        \n",
    "    loss_fn=loss_fn, \n",
    "    opt=opt, \n",
    "    device=device \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.6. <a id='toc11_4_6_'></a>[attention-seq2seq](#toc0_)\n",
    "\n",
    "- 加入attention机制的Seq2Seq；\n",
    "\n",
    "- 基于Attention的Seq2Seq。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5. <a id='toc11_5_'></a>[Transformer](#toc0_)\n",
    "```shell\n",
    "完全基于注意力机制的Encoder-Decoder架构。\n",
    "1.多头自注意力机制；\n",
    "2.掩码；\n",
    "3.Encoder-Decoder框架。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.1. <a id='toc11_5_1_'></a>[位置编码](#toc0_)\n",
    "```shell\n",
    "由于Transformer并行运算，没有顺序信息；\n",
    "Google一帮人发明了利用sin和cos函数编码位置信息并添加到输入X中；\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f54e6556a50>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#@save\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 创建一个足够长的P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "encoding_dim, num_steps = 32, 60\n",
    "pos_encoding = PositionalEncoding(encoding_dim, 0)\n",
    "pos_encoding.eval()\n",
    "X = pos_encoding(torch.zeros((1, num_steps, encoding_dim)))\n",
    "P = pos_encoding.P[:, :X.shape[1], :]\n",
    "\n",
    "# Draw a plot picture\n",
    "plt.figure(figsize=(6, 2.5))\n",
    "plt.plot(torch.arange(num_steps), P[0, :, 6:10].T[0], label='col 6')\n",
    "plt.plot(torch.arange(num_steps), P[0, :, 6:10].T[1], label='col 7')\n",
    "plt.plot(torch.arange(num_steps), P[0, :, 6:10].T[2], label='col 8')\n",
    "plt.plot(torch.arange(num_steps), P[0, :, 6:10].T[3], label='col 9')\n",
    "plt.xlabel('Row (position)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.2. <a id='toc11_5_2_'></a>[基于位置的前馈网络](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0985, -0.0769,  0.4326, -0.7424,  0.5790, -0.0797, -0.2331, -0.1805],\n",
       "        [-0.0985, -0.0769,  0.4326, -0.7424,  0.5790, -0.0797, -0.2331, -0.1805],\n",
       "        [-0.0985, -0.0769,  0.4326, -0.7424,  0.5790, -0.0797, -0.2331, -0.1805]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "#@save\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n",
    "\n",
    "ffn = PositionWiseFFN(4, 4, 8)\n",
    "ffn.eval()\n",
    "ffn(torch.ones((2, 3, 4)))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.3. <a id='toc11_5_3_'></a>[残差连接和层规范化](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer norm: tensor([[-1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>) \n",
      "batch norm: tensor([[-1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = nn.LayerNorm(2)\n",
    "bn = nn.BatchNorm1d(2)\n",
    "\n",
    "X = torch.tensor([[1, 2], [2, 3]], dtype=torch.float32)\n",
    "# 在训练模式下计算X的均值和方差\n",
    "print('layer norm:', ln(X), '\\nbatch norm:', bn(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)\n",
    "\n",
    "add_norm = AddNorm([3, 4], 0.5)\n",
    "add_norm.eval()\n",
    "add_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.4. <a id='toc11_5_4_'></a>[编码器](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "\n",
    "# DotAttention\n",
    "class DotAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # features = (queries @ keys.transpose(1, 2)) \n",
    "        features = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        scores = features / torch.sqrt(torch.tensor(queries.shape[-1]))\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        self.attention_weights_numpy = attention_weights.detach().cpu().numpy()\n",
    "        attention = torch.bmm(attention_weights, values)\n",
    "        return attention\n",
    "    \n",
    "    def dotAttention_weights(self):\n",
    "        return self.attention_weights_numpy\n",
    "\n",
    "# 多头注意力机制\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_heads, \n",
    "                 query_size, \n",
    "                 num_hiddens, \n",
    "                 key_size, \n",
    "                 value_size, \n",
    "                 exitBias=False):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotAttention()\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=exitBias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=exitBias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=exitBias)\n",
    "\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=exitBias)   # 最后concat所有head的结果 (其实就是投影)\n",
    "\n",
    "    def transpose_input(self, X, num_heads):\n",
    "        \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "        # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # 输出X的形状:(batch_size，查询或者“键－值”对的个数，`num_heads`，num_hiddens/num_heads)\n",
    "        X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "        # 输出X的形状:(batch_size，`num_heads`，查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        X = X.permute(0, 2, 1, 3)                                                                   # 调整顺序以便做广播 (向量化并行计算multi heads)\n",
    "\n",
    "        # 最终输出的形状:(batch_size*`num_heads`,查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "    def transpose_output(self, X, num_heads):\n",
    "        \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "        # 输入X的形状:(batch_size*`num_heads`,查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        # 输出X的形状:(batch_size,`num_heads``,查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "\n",
    "        # 输出X的形状:(batch_size查询或者“键－值”对的个数，`num_heads``,num_hiddens/num_heads)                                        # 不改变顺序\n",
    "        X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "        # 最终输出X的形状:(batch_size,`num_heads`,查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # queries，keys，values的形状:\n",
    "            # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "            # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "            # (batch_size*num_heads，查询或者“键－值”对的个数，num_hiddens/num_heads) ##############\n",
    "        queries = self.W_q(queries)\n",
    "        print(f'Q size: {queries.shape}')\n",
    "        queries = self.transpose_input(queries, self.num_heads)\n",
    "        print(f'Q transpose_input size: {queries.shape}')\n",
    "\n",
    "        keys = self.W_k(keys)\n",
    "        print(f'K size: {keys.shape}')\n",
    "        keys = self.transpose_input(keys, self.num_heads)\n",
    "        print(f'K transpose_input size: {keys.shape}')\n",
    "\n",
    "        values = self.W_v(values)\n",
    "        print(f'V size: {values.shape}')\n",
    "        values = self.transpose_input(values, self.num_heads)\n",
    "        print(f'V transpose_input size: {values.shape}')\n",
    "\n",
    "        # output的形状:(batch_size*num_heads，查询的个数，num_hiddens/num_heads) ##############\n",
    "        output = self.attention(queries=queries, keys=keys, values=values)\n",
    "        print(f'output size: {output.shape}')\n",
    "\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens) ##############\n",
    "        output_concat = self.transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q size: torch.Size([2, 100, 24])\n",
      "Q transpose_input size: torch.Size([16, 100, 3])\n",
      "K size: torch.Size([2, 100, 24])\n",
      "K transpose_input size: torch.Size([16, 100, 3])\n",
      "V size: torch.Size([2, 100, 24])\n",
      "V transpose_input size: torch.Size([16, 100, 3])\n",
      "output size: torch.Size([16, 100, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "#@save\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        # self.attention = d2l.MultiHeadAttention(\n",
    "        #     key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "        #     use_bias)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            num_heads, \n",
    "            query_size, \n",
    "            num_hiddens, \n",
    "            key_size, \n",
    "            value_size, \n",
    "            exitBias=False)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X))\n",
    "        return self.addnorm2(Y, self.ffn(Y))\n",
    "\n",
    "X = torch.ones((2, 100, 24))\n",
    "encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
    "encoder_blk.eval()\n",
    "encoder_blk(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q size: torch.Size([2, 100, 24])\n",
      "Q transpose_input size: torch.Size([16, 100, 3])\n",
      "K size: torch.Size([2, 100, 24])\n",
      "K transpose_input size: torch.Size([16, 100, 3])\n",
      "V size: torch.Size([2, 100, 24])\n",
      "V transpose_input size: torch.Size([16, 100, 3])\n",
      "output size: torch.Size([16, 100, 3])\n",
      "Q size: torch.Size([2, 100, 24])\n",
      "Q transpose_input size: torch.Size([16, 100, 3])\n",
      "K size: torch.Size([2, 100, 24])\n",
      "K transpose_input size: torch.Size([16, 100, 3])\n",
      "V size: torch.Size([2, 100, 24])\n",
      "V transpose_input size: torch.Size([16, 100, 3])\n",
      "output size: torch.Size([16, 100, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        # X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        X = self.pos_encoding(self.embedding(X) * torch.sqrt(torch.tensor(self.num_hiddens)))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X)\n",
    "            self.attention_weights[\n",
    "                i] = blk.attention.attention.attention_weights_numpy\n",
    "        return X\n",
    "\n",
    "encoder = TransformerEncoder(\n",
    "    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
    "encoder.eval()\n",
    "encoder(torch.ones((2, 100), dtype=torch.long)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.5. <a id='toc11_5_5_'></a>[解码器](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q size: torch.Size([2, 100, 24])\n",
      "Q transpose_input size: torch.Size([16, 100, 3])\n",
      "K size: torch.Size([2, 100, 24])\n",
      "K transpose_input size: torch.Size([16, 100, 3])\n",
      "V size: torch.Size([2, 100, 24])\n",
      "V transpose_input size: torch.Size([16, 100, 3])\n",
      "output size: torch.Size([16, 100, 3])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[221], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m24\u001b[39m))\n\u001b[1;32m     50\u001b[0m state \u001b[38;5;241m=\u001b[39m [encoder_blk(X), [\u001b[38;5;28;01mNone\u001b[39;00m]]\n\u001b[0;32m---> 51\u001b[0m \u001b[43mdecoder_blk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[221], line 24\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, X, state)\u001b[0m\n\u001b[1;32m     19\u001b[0m enc_outputs, enc_valid_lens \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;241m0\u001b[39m], state[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 训练阶段，输出序列的所有词元都在同一时间处理，\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 因此state[2][self.i]初始化为None。\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 预测阶段，输出序列是通过词元一个接着一个解码的，\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     key_values \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "                                   num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此state[2][self.i]初始化为None。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            # dec_valid_lens的开头:(batch_size,num_steps),\n",
    "            # 其中每一行是[1,2,...,num_steps]\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "\n",
    "        # 自注意力\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # 编码器－解码器注意力。\n",
    "        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state\n",
    "\n",
    "decoder_blk = DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0)\n",
    "decoder_blk.eval()\n",
    "X = torch.ones((2, 100, 24))\n",
    "state = [encoder_blk(X), [None]]\n",
    "decoder_blk(X, state)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.6. <a id='toc11_5_6_'></a>[基于Attention的Seq2Seq网络](#toc0_)\n",
    "```shell\n",
    "基于Attention的Seq2Seq神经网络框架。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return \n",
    "\n",
    "class MySeq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.7. <a id='toc11_5_7_'></a>[BERT](#toc0_)\n",
    "```shell\n",
    "就是Encoder部分\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.8. <a id='toc11_5_8_'></a>[GPT](#toc0_)\n",
    "```shell\n",
    "就是Transformer的Decoder部分。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. <a id='toc12_'></a>[炼丹心得](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1. <a id='toc12_1_'></a>[关于改变形状](#toc0_)\n",
    "\n",
    "- .reshape((1, 1, 28, 28))\n",
    "\n",
    "- .view()\n",
    "\n",
    "- .transpose()\n",
    "\n",
    "- .permute((0, 1, 2, 3))\n",
    "\n",
    "- .unsqueeze()\n",
    "\n",
    "- .squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1,28, 28))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.reshape((1, 28, 28, 1)).shape     # 重塑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 1, 1, 28])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.permute((3, 0, 1, 2)).shape       # 迁移"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2. <a id='toc12_2_'></a>[关于调参](#toc0_)\n",
    "1. Pytorch没有变量、常量之分，不需要定义说明什么是变量，全部都是张量；\n",
    "\n",
    "2. 因为变量定义后需要初始化，就相当于常量；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3751])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyLayer(nn.Module):\n",
    "    '''带参数的，自定义层'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(2, requires_grad=True))  # 变量，立即初始化，相当于常量\n",
    "        self.bias = nn.Parameter(torch.zeros(1, requires_grad=True))    # 同上\n",
    "    \n",
    "    def forward(self, X):\n",
    "        y_hat = self.weight.data@X + self.bias.data\n",
    "        # y_hat = torch.matmul(self.weight.data, X) + self.bias.data    # 同上\n",
    "        return F.relu(y_hat)\n",
    "\n",
    "myLayer = MyLayer()\n",
    "X = torch.ones(2)\n",
    "myLayer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([-1.2126,  0.9969])), ('bias', tensor([0.]))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.state_dict() # 访问神经网络参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3. <a id='toc12_3_'></a>[模型选择](#toc0_)\n",
    "```shell\n",
    "模型的复杂度应该合适，不能太大，也不能太小。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4. <a id='toc12_4_'></a>[one-hot](#toc0_)\n",
    "```shell\n",
    "有向量无偏差表示；\n",
    "简单，但可能占空间\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32820/3359500813.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(col_raw == raw) # 只是bool\n",
      "/tmp/ipykernel_32820/3359500813.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  one_hot = torch.tensor(col_raw == raw, dtype=torch.float32) # bool -> torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]]),\n",
       " tensor([[1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "col_raw = raw.reshape(5, 1); col_raw\n",
    "col_raw == raw # （5， 1） 和 （1， 5）先广播后比较\n",
    "torch.tensor(col_raw == raw) # 只是bool\n",
    "one_hot = torch.tensor(col_raw == raw, dtype=torch.float32) # bool -> torch.float32\n",
    "col_raw, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "\n",
    "# help(F.one_hot)\n",
    "F.one_hot(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.5. <a id='toc12_5_'></a>[embedding](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "# 第一种\n",
    "# help(F.embedding)\n",
    "# F.embedding(raw)\n",
    "\n",
    "# 第二种\n",
    "# help(nn.Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.6. <a id='toc12_6_'></a>[BN和LN](#toc0_)\n",
    "Batch norm和Layer norm之间的区别  \n",
    "\n",
    "* BatchNorm：在同一特征（同一列），不同样品之间（不同行）之间做的normalization？ standerlization？\n",
    "\n",
    "* LayerNorm：在同一样品（同一行），不同特征（不同列）之间做的normalization？ standerlization？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "torch.nn.BatchNorm1d()\n",
    "torch.nn.LayerNorm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.7. <a id='toc12_7_'></a>[MLP、FC、FNN、CNN、RNN](#toc0_)\n",
    "Linear()：线性网络，即没有非线性激活函数  \n",
    "MLP()：多层感知机，有非线性激活函数  \n",
    "FNN()：前馈神经网络，同MLP（）  \n",
    "CNN()：卷积神经网络    \n",
    "RNN()：循环神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.8. <a id='toc12_8_'></a>[机器学习](#toc0_)\n",
    "```shell\n",
    "1. 监督学习  \n",
    "    自监督学习  \n",
    "    \n",
    "2. 半监督学习  \n",
    "3. 无监督学习  \n",
    "4. 强化学习  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. <a id='toc13_'></a>[PyTorch做迁移学习](#toc0_)\n",
    "- 在今后的很长时间，深度学习的模型创新上会有很大的难度，基于已有的模型的微调（Fine-tuning）应用于新的可解决的问题是趋势。\n",
    "\n",
    "- Fine-tuning in CV：\n",
    "\n",
    "    - 1.用Pre-trained的参数初始化特征提取器如Encoder的参数，而不是随机初始化；\n",
    "\n",
    "    - 2.用小的lerning-rate和小的epochs；\n",
    "\n",
    "    - 3.固定模型层的（其实就是learning-rate为0）。\n",
    "\n",
    "- 如何找到Pre-trained model？\n",
    "\n",
    "    - TIMM（pytorch）-一个叫Ross的小哥自己维护的；\n",
    "\n",
    "    - HugginFace - 一个早期只是东抄抄西抄抄的公司，逐渐发展为比较好的社区公司。\n",
    "\n",
    "- Fine-tuning in NLP：\n",
    "\n",
    "    - 1.Self-supervised pre-training;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1. <a id='toc13_1_'></a>[Fine-tuning](#toc0_)\n",
    "- 目前已知两种方式进行Fine-tuning:\n",
    "    - 设置非常小的lr\n",
    "    - param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1.1. <a id='toc13_1_1_'></a>[小的lr](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim \n",
    "from torch import nn \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(2, 1)\n",
    "        self.hidden = nn.Linear(1, 128)\n",
    "        self.output = nn.Linear(128, 10)\n",
    "        self.fc = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        y = self.input(X)\n",
    "        y = self.hidden(y)\n",
    "        y = self.output(y)\n",
    "        y = self.fc(y)\n",
    "        return y\n",
    "\n",
    "net = Net()\n",
    "\n",
    "param_1x = [param for name, param in net.named_parameters() if name not in ['fc.weight', 'fc.bias']]    # 提取出fc以外的所有参数\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "opt = optim.SGD(\n",
    "    params=[\n",
    "        {'params': param_1x},                                           # lr不变\n",
    "        {'params': net.fc.parameters(), 'lr': learning_rate * 0.001}    # lr缩小\n",
    "    ], \n",
    "    lr=learning_rate, \n",
    "    weight_decay=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1.2. <a id='toc13_1_2_'></a>[停止计算梯度](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默认参数信息：\n",
      "input.weight >>> True\n",
      "input.bias >>> True\n",
      "hidden.weight >>> True\n",
      "hidden.bias >>> True\n",
      "output.weight >>> True\n",
      "output.bias >>> True\n",
      "fc.weight >>> True\n",
      "fc.bias >>> True\n",
      "========== \n",
      " 修改后参数信息：\n",
      "input.weight >>> False\n",
      "input.bias >>> False\n",
      "hidden.weight >>> False\n",
      "hidden.bias >>> False\n",
      "output.weight >>> False\n",
      "output.bias >>> False\n",
      "fc.weight >>> True\n",
      "fc.bias >>> True\n"
     ]
    }
   ],
   "source": [
    "from torch import optim \n",
    "from torch import nn \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(2, 1)\n",
    "        self.hidden = nn.Linear(1, 128)\n",
    "        self.output = nn.Linear(128, 10)\n",
    "        self.fc = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        y = self.input(X)\n",
    "        y = self.hidden(y)\n",
    "        y = self.output(y)\n",
    "        y = self.fc(y)\n",
    "        return y\n",
    "\n",
    "net = Net()\n",
    "\n",
    "print('默认参数信息：')\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, '>>>', param.requires_grad)\n",
    "\n",
    "print('='*10, '\\n', '修改后参数信息：')\n",
    "for name, param in net.named_parameters():\n",
    "    if name not in ['fc.weight', 'fc.bias']:\n",
    "        param.requires_grad = False\n",
    "    print(name, '>>>', param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2. <a id='toc13_2_'></a>[torchvision的应用案例](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3. <a id='toc13_3_'></a>[迁移学习案例](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    '''重载torch.utils.data.Dataset类'''\n",
    "    def __init__(self, dirname, transform=None):\n",
    "        super(MyDataset, self).__init__() # 要不要都行\n",
    "        self.classes = os.listdir(dirname)\n",
    "        self.images = []\n",
    "        self.transform = transform\n",
    "        for i, classes in enumerate(self.classes):\n",
    "            classes_path = os.path.join(dirname, classes)\n",
    "            for image_name in os.listdir(classes_path):\n",
    "                self.images.append((os.path.join(classes_path, image_name), i))\n",
    "\n",
    "    def __len__(self):\n",
    "        '''改写__len__()方法'''\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''改写__getitem__()方法'''\n",
    "        image_name, classes = self.images[idx]\n",
    "        image = Image.open(image_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, classes\n",
    "    \n",
    "    def get_claesses(self):\n",
    "        return self.classes\n",
    "    \n",
    "# 分布实现训练和预测的transform\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.RandomResizedCrop(224), #随机裁剪一个area然后再resize\n",
    "        transforms.RandomHorizontalFlip(), #随机水平翻转\n",
    "        transforms.Resize(size=(256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.Resize(size=(256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 分别实现loader\n",
    "# ws = 'Pytorch_datasets/hymenoptera_data/'\n",
    "train_dataset = MyDataset('Pytorch_datasets/hymenoptera_data/train/', train_transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
    "\n",
    "val_dataset = MyDataset('Pytorch_datasets/hymenoptera_data/val/', val_transform)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 选择预训练的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bmp/backup/zhaosy/miniconda3/envs/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的模型\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0026, -0.0350, -0.0355,  ...,  0.0068,  0.0349,  0.0407],\n",
      "        [-0.0257,  0.0340, -0.0237,  ..., -0.0052, -0.0351,  0.0249]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0364,  0.0310], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 停止权重更新，并将model最后一层替换掉\n",
    "only_train_fc = True\n",
    "if only_train_fc:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(False)\n",
    "        \n",
    "fc_in_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(fc_in_features, 2, bias=True)\n",
    "\n",
    "# 查看\n",
    "for i in model.parameters():\n",
    "    if i.requires_grad:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练主体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.31711972 0.88244045\n",
      "1 0.30389076 0.85200006\n",
      "0 0.33484977 0.858817\n",
      "1 0.4615616 0.80550003\n",
      "0.85200006\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "device = 'cuda:0'\n",
    "\n",
    "epochs = 2\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(lr=0.01, params=model.parameters())\n",
    "opt_step = torch.optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.1)\n",
    "max_acc = 0\n",
    "epoch_acc = []\n",
    "epoch_loss = []\n",
    "for epoch in range(epochs):\n",
    "    for type_id, loader in enumerate([train_loader, val_loader]):\n",
    "        # print('type_id:',type_id)\n",
    "        mean_loss = []\n",
    "        mean_acc = []\n",
    "        for images, labels in loader:\n",
    "            if type_id == 0:\n",
    "                # opt_step.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "            opt.zero_grad()\n",
    "            with torch.set_grad_enabled(type_id==0):\n",
    "                outputs = model(images)\n",
    "                _, pre_labels = torch.max(outputs, 1)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "            if type_id == 0:\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            acc = torch.sum(pre_labels==labels) / torch.tensor(labels.shape[0], dtype=torch.float32)        \n",
    "            mean_loss.append(loss.detach().cpu().numpy())\n",
    "            mean_acc.append(acc.detach().cpu().numpy())\n",
    "        if type_id == 1:\n",
    "            epoch_acc.append(np.mean(mean_acc))\n",
    "            epoch_loss.append(np.mean(mean_loss))\n",
    "            if max_acc < np.mean(mean_acc):\n",
    "                max_acc = np.mean(mean_acc)\n",
    "        print(type_id, np.mean(mean_loss),np.mean(mean_acc))\n",
    "print(max_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. <a id='toc14_'></a>[PyTorch lightning训练框架](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1. <a id='toc14_1_'></a>[训练逻辑](#toc0_)\n",
    "- PyTorch lightning官方给的`PyTorch lightning`教程：[https://lightning.ai/docs/pytorch/stable/expertise_levels.html](https://lightning.ai/docs/pytorch/stable/expertise_levels.html)\n",
    "- PyTorch lightning给的`PyTorch`教程：[https://lightning.ai/docs/pytorch/stable/tutorials.html](https://lightning.ai/docs/pytorch/stable/tutorials.html)\n",
    "- PuTorch lightning给的`PyTorch code to PyTorchLightning`：[https://lightning.ai/docs/pytorch/stable/starter/converting.html](https://lightning.ai/docs/pytorch/stable/starter/converting.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Frame](./Pytorch_Pictures/PyTorch_lightning/Frame1.jpg)\n",
    "![Frame2](./Pytorch_Pictures/PyTorch_lightning/Frame2.jpg)\n",
    "![Frame3](./Pytorch_Pictures/PyTorch_lightning/Frame3.jpg)\n",
    "![Frame4](./Pytorch_Pictures/PyTorch_lightning/Frame4.jpg)\n",
    "![Frame5](./Pytorch_Pictures/PyTorch_lightning/Frame5.jpg)\n",
    "<!-- <img src=\"./Pytorch_Pictures/PyTorch_lightning/Frame1.jpg\" width = 600 height = 600 /> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch lightning version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "print(f'Pytorch lightning version: {L.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2. <a id='toc14_2_'></a>[Data.py](#toc0_)\n",
    "数据部分应该单独处理，便于以后管理和维护。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 2]),\n",
       " torch.Size([10000, 1]),\n",
       " tensor([ 0.1441, -0.0539]),\n",
       " tensor([3.7984]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 虚拟出一些数据\n",
    "# 仅供参考\n",
    "\n",
    "import torch \n",
    "\n",
    "def syn_datas(\n",
    "    w = torch.tensor([2.0, -3.0]),\n",
    "    b = torch.tensor([3.4]), \n",
    "    nums = 10000):\n",
    "    X = torch.normal(mean=0, std=0.1, size=(nums, w.shape[0]), dtype=torch.float32)\n",
    "    y = X @ w + b\n",
    "    y += torch.normal(mean=0, std=0.1, size=y.shape, dtype=torch.float)\n",
    "    return X, y \n",
    "\n",
    "# 预设参数，注意 形状/维度\n",
    "preset_weight = torch.tensor([2.0, -3.0], dtype=torch.float32).reshape(2, 1)\n",
    "preset_bias = torch.tensor([3.4], dtype=torch.float32)\n",
    "\n",
    "# 虚拟数据\n",
    "features, labels = syn_datas(w=preset_weight, b=preset_bias, nums=10000)\n",
    "\n",
    "# 初步查看\n",
    "features.shape, labels.shape, features[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data \n",
    "\n",
    "datasets = data.TensorDataset(features, labels)\n",
    "\n",
    "train_iter = data.DataLoader(dataset=datasets, shuffle=True, batch_size=128, num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3. <a id='toc14_3_'></a>[Model.py](#toc0_)\n",
    "模型部分应该用纯PyTorch编写以便于理解和后续的维护。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用纯PyTorch构建模型的网络结构\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class AlphaFold2(nn.Module):\n",
    "    def __init__(self, in_features=2, out_features=1):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Sequential(nn.Linear(in_features, out_features))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.hidden(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.4. <a id='toc14_4_'></a>[ModelWrapper.py](#toc0_)\n",
    "利用PyTorch lightning训练框架进行训练只是方便调用，最后进行模型`魔改`后最好还是用纯PyTorch进行学习。  \n",
    "都是固定框架（API信息如下）\n",
    "- [L.LightningModule API](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#backward)\n",
    "- [Trainer API](https://lightning.ai/docs/pytorch/stable/common/trainer.html)\n",
    "    - Automatically enabling/disabling grads\n",
    "    - Running the training, validation and test dataloaders\n",
    "    - Calling the Callbacks at the appropriate times\n",
    "    - Putting batches and computations on the correct devices\n",
    "    \n",
    "![Trainer_API](./Pytorch_Pictures/PyTorch_lightning/Trainer_API.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# 用PyTorch lightning构建训练步骤\n",
    "\n",
    "from torch import nn \n",
    "from torch import optim\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "class AlphaFold2Wrapper(L.LightningModule):\n",
    "    def __init__(self, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "        ## save hyperparameters\n",
    "        self.save_hyperparameters()                                 # 超参数保存\n",
    "        self.learning_rate = learning_rate                          # 超参数\n",
    "        ## model initiate from model constructed by pure PyTorch\n",
    "        self.demo_model = AlphaFold2(in_features=2, out_features=1)      ## 模型\n",
    "        ## loss_fn\n",
    "        self.loss_fn = torch.nn.MSELoss()                           ## 损失函数\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.demo_model(X)\n",
    "\n",
    "    def configure_optimizers(self):                                 ## 优化函数\n",
    "        opt = optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        return opt\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        '''训练步骤'''\n",
    "        X, y = batch \n",
    "        y_hat = self.forward(X)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)                 # 在进度条上显示出来\n",
    "\n",
    "        self.training_step_outputs.append(loss)                     # 保存结果，以备后续使用 (on_train_epoch_end(self))\n",
    "        return loss\n",
    "    \n",
    "    # def on_train_batch_start(self, batch, batch_idx):\n",
    "    #     '''\n",
    "    #     Called in the training loop before anything happens for that batch.\n",
    "    #     If you return -1 here, you will skip training for the rest of the current epoch.\n",
    "    #     '''\n",
    "    #     pass\n",
    "\n",
    "    # def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "    #     '''\n",
    "    #     Called in the training loop after the batch.\n",
    "    #     Parameters:\n",
    "    #             outputs (Union[Tensor, Mapping[str, Any], None]) – The outputs of training_step(x)\n",
    "    #             batch (Any) – The batched data as it is returned by the training DataLoader.\n",
    "    #             batch_idx (int) – the index of the batch\n",
    "    #     '''\n",
    "    #     pass\n",
    "\n",
    "    # def on_train_epoch_start(self):\n",
    "    #     '''Called in the training loop at the very beginning of the epoch.'''\n",
    "    #     pass\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        '''\n",
    "        Called in the training loop at the very end of the epoch.\n",
    "        To access all batch outputs at the end of the epoch, \n",
    "        you can cache step outputs as an attribute of the LightningModule and access them in this hook:\n",
    "        '''\n",
    "        # do something with all training_step outputs, for example:\n",
    "        epoch_mean = torch.stack(self.training_step_outputs).mean() # 来自于training_step()计算结果\n",
    "        self.log(\"training_epoch_mean\", epoch_mean)\n",
    "        # free up the memory\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        '''验证步骤'''\n",
    "        X, y = batch \n",
    "        y_hat = self.forward(X) \n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    # def on_validation_batch_start(self, batch, batch_idx, dataloader_idx=0):\n",
    "    #     '''Called in the validation loop before anything happens for that batch.'''\n",
    "    #     pass \n",
    "\n",
    "    # def on_validation_batch_end(self, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "    #     '''Called in the validation loop after the batch.\n",
    "    #     Parameters:\n",
    "    #             outputs (Union[Tensor, Mapping[str, Any], None]) – The outputs of validation_step(x)\n",
    "    #             batch (Any) – The batched data as it is returned by the validation DataLoader.\n",
    "    #             batch_idx (int) – the index of the batch\n",
    "    #             dataloader_idx (int) – the index of the dataloader\n",
    "    #     '''\n",
    "    #     pass\n",
    "\n",
    "    # def on_validation_epoch_start(self):\n",
    "    #     '''Called in the validation loop at the very beginning of the epoch.'''\n",
    "    #     pass\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        '''Called in the validation loop at the very end of the epoch.'''\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        '''测试步骤'''\n",
    "        X, y = batch \n",
    "        y_hat = self.forward(X) \n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def prediction_step(self, batch, batch_idx):\n",
    "        '''预测步骤'''\n",
    "        X, y = batch \n",
    "        y_hat = self.forward(X) \n",
    "        self.log('y_hat', y_hat)\n",
    "        return y_hat\n",
    "\n",
    "## 实例化一个对象\n",
    "alphafold2 = AlphaFold2Wrapper(learning_rate=0.01)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",              # cpu, gpu, tpu, auto\n",
    "    devices=1, \n",
    "    # strategy=\"ddp\",\n",
    "    # num_nodes=1,                    # Number of GPU nodes for distributed training.\n",
    "\n",
    "    # precision=\"32-true\",            # There are two different techniques to set the mixed precision. “True” precision and “Mixed” precision.\n",
    "\n",
    "    # callbacks = ,\n",
    "    \n",
    "    # min_epochs=1,\n",
    "    max_epochs=10, \n",
    "    # min_steps=None,                 # Force training for at least this number of global steps. Trainer will train model for at least min_steps or min_epochs (latest).\n",
    "    max_steps=-1,                   # Stop training after this number of global steps. Training will stop if max_steps or max_epochs have reached (earliest).\n",
    "    log_every_n_steps=50,           ## How often to add logging rows (does not write to disk)\n",
    "    check_val_every_n_epoch=1,      # default used by the Trainer\n",
    "\n",
    "    # default_root_dir=os.getcwd(),   # os.getcwd()\n",
    "    # enable_progress_bar=True,       # Whether to enable or disable the progress bar. Defaults to True.\n",
    "    # enable_model_summary=True,      # Whether to enable or disable the model summarization. Defaults to True.\n",
    "\n",
    "    profiler=None,                  # simple, advanced, None: To profile individual steps during training and assist in identifying bottlenecks.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.1. <a id='toc14_4_1_'></a>[Training and vlidation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type       | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | demo_model | AlphaFold2 | 3      | train\n",
      "1 | loss_fn    | MSELoss    | 0      | train\n",
      "--------------------------------------------------\n",
      "3         Trainable params\n",
      "0         Non-trainable params\n",
      "3         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bmp/backup/zhaosy/miniconda3/envs/pytorch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 79/79 [00:01<00:00, 75.30it/s, v_num=0, train_loss=0.217, val_loss=0.133] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 79/79 [00:01<00:00, 74.95it/s, v_num=0, train_loss=0.217, val_loss=0.133]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=alphafold2, \n",
    "    train_dataloaders=train_iter, \n",
    "    val_dataloaders=train_iter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.2. <a id='toc14_4_2_'></a>[Validation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 79/79 [00:00<00:00, 359.93it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val_loss            0.13269878923892975\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.13269878923892975}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model=alphafold2, dataloaders=train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.3. <a id='toc14_4_3_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/bmp/backup/zhaosy/miniconda3/envs/pytorch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 79/79 [00:00<00:00, 404.56it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.13269877433776855\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.13269877433776855}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=alphafold2, dataloaders=train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.4. <a id='toc14_4_4_'></a>[Prediction](#toc0_)\n",
    "\n",
    "![Prediction summary](./Pytorch_Pictures/PyTorch_lightning/Frame4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.4.4.1. <a id='toc14_4_4_1_'></a>[PyTorch lightning自身Trainer直接predict](#toc0_)\n",
    "调用PyTorch lightning自身Trainer的predict，程序会自动使用：  \n",
    "- model.eval()\n",
    "- with torch.no_grad():\n",
    "- 或 torch.set_grad_enable(True/False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 10000/10000 [00:08<00:00, 1224.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([3.4124]),\n",
       " tensor([3.3868]),\n",
       " tensor([3.3909]),\n",
       " tensor([3.3817]),\n",
       " tensor([3.4208]),\n",
       " tensor([3.3964]),\n",
       " tensor([3.3973]),\n",
       " tensor([3.3862]),\n",
       " tensor([3.3966]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.4066]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.3932]),\n",
       " tensor([3.3774]),\n",
       " tensor([3.3949]),\n",
       " tensor([3.3956]),\n",
       " tensor([3.3845]),\n",
       " tensor([3.3931]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.3898]),\n",
       " tensor([3.4090]),\n",
       " tensor([3.4059]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.3881]),\n",
       " tensor([3.3913]),\n",
       " tensor([3.4166]),\n",
       " tensor([3.3755]),\n",
       " tensor([3.4028]),\n",
       " tensor([3.4021]),\n",
       " tensor([3.4224]),\n",
       " tensor([3.3956]),\n",
       " tensor([3.3914]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.3889]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.4049]),\n",
       " tensor([3.4014]),\n",
       " tensor([3.3925]),\n",
       " tensor([3.3970]),\n",
       " tensor([3.4043]),\n",
       " tensor([3.4050]),\n",
       " tensor([3.4055]),\n",
       " tensor([3.4033]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3934]),\n",
       " tensor([3.4031]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.3942]),\n",
       " tensor([3.3713]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3886]),\n",
       " tensor([3.4044]),\n",
       " tensor([3.3781]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.4258]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3782]),\n",
       " tensor([3.3928]),\n",
       " tensor([3.4193]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.3984]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.4131]),\n",
       " tensor([3.4129]),\n",
       " tensor([3.4034]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.3870]),\n",
       " tensor([3.4152]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.3938]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3921]),\n",
       " tensor([3.3895]),\n",
       " tensor([3.3981]),\n",
       " tensor([3.3871]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.4051]),\n",
       " tensor([3.3864]),\n",
       " tensor([3.4033]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.4010]),\n",
       " tensor([3.3961]),\n",
       " tensor([3.3918]),\n",
       " tensor([3.3886]),\n",
       " tensor([3.4129]),\n",
       " tensor([3.3801]),\n",
       " tensor([3.3956]),\n",
       " tensor([3.3981]),\n",
       " tensor([3.3972]),\n",
       " tensor([3.3699]),\n",
       " tensor([3.3770]),\n",
       " tensor([3.4040]),\n",
       " tensor([3.3986]),\n",
       " tensor([3.3855]),\n",
       " tensor([3.3998]),\n",
       " tensor([3.4040]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.3966]),\n",
       " tensor([3.4106]),\n",
       " tensor([3.4038]),\n",
       " tensor([3.4075]),\n",
       " tensor([3.3972]),\n",
       " tensor([3.3843]),\n",
       " tensor([3.3849]),\n",
       " tensor([3.3885]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.3865]),\n",
       " tensor([3.3973]),\n",
       " tensor([3.3804]),\n",
       " tensor([3.3916]),\n",
       " tensor([3.3607]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.3984]),\n",
       " tensor([3.3910]),\n",
       " tensor([3.4078]),\n",
       " tensor([3.4075]),\n",
       " tensor([3.3888]),\n",
       " tensor([3.3929]),\n",
       " tensor([3.3968]),\n",
       " tensor([3.3875]),\n",
       " tensor([3.3859]),\n",
       " tensor([3.3864]),\n",
       " tensor([3.4090]),\n",
       " tensor([3.3977]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.4120]),\n",
       " tensor([3.4087]),\n",
       " tensor([3.3966]),\n",
       " tensor([3.3961]),\n",
       " tensor([3.3787]),\n",
       " tensor([3.3978]),\n",
       " tensor([3.3952]),\n",
       " tensor([3.3897]),\n",
       " tensor([3.4006]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.4146]),\n",
       " tensor([3.4132]),\n",
       " tensor([3.3967]),\n",
       " tensor([3.3859]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3895]),\n",
       " tensor([3.4091]),\n",
       " tensor([3.3953]),\n",
       " tensor([3.3847]),\n",
       " tensor([3.3809]),\n",
       " tensor([3.4056]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.3968]),\n",
       " tensor([3.3890]),\n",
       " tensor([3.4088]),\n",
       " tensor([3.4081]),\n",
       " tensor([3.4046]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.3803]),\n",
       " tensor([3.3998]),\n",
       " tensor([3.4051]),\n",
       " tensor([3.4086]),\n",
       " tensor([3.3976]),\n",
       " tensor([3.3843]),\n",
       " tensor([3.4084]),\n",
       " tensor([3.3904]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3869]),\n",
       " tensor([3.3834]),\n",
       " tensor([3.4043]),\n",
       " tensor([3.4136]),\n",
       " tensor([3.4164]),\n",
       " tensor([3.3850]),\n",
       " tensor([3.3986]),\n",
       " tensor([3.3877]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.4094]),\n",
       " tensor([3.3838]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.3938]),\n",
       " tensor([3.4015]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3943]),\n",
       " tensor([3.4021]),\n",
       " tensor([3.3885]),\n",
       " tensor([3.3933]),\n",
       " tensor([3.4221]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.3702]),\n",
       " tensor([3.3849]),\n",
       " tensor([3.3721]),\n",
       " tensor([3.4130]),\n",
       " tensor([3.4109]),\n",
       " tensor([3.3931]),\n",
       " tensor([3.4006]),\n",
       " tensor([3.3931]),\n",
       " tensor([3.3830]),\n",
       " tensor([3.4076]),\n",
       " tensor([3.4150]),\n",
       " tensor([3.3928]),\n",
       " tensor([3.3854]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.3804]),\n",
       " tensor([3.3996]),\n",
       " tensor([3.3997]),\n",
       " tensor([3.3945]),\n",
       " tensor([3.3966]),\n",
       " tensor([3.3844]),\n",
       " tensor([3.4151]),\n",
       " tensor([3.3878]),\n",
       " tensor([3.4081]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.3918]),\n",
       " tensor([3.3909]),\n",
       " tensor([3.3790]),\n",
       " tensor([3.3976]),\n",
       " tensor([3.3993]),\n",
       " tensor([3.3754]),\n",
       " tensor([3.3959]),\n",
       " tensor([3.4031]),\n",
       " tensor([3.3949]),\n",
       " tensor([3.3995]),\n",
       " tensor([3.4028]),\n",
       " tensor([3.3978]),\n",
       " tensor([3.3845]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.4012]),\n",
       " tensor([3.4248]),\n",
       " tensor([3.4041]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.3819]),\n",
       " tensor([3.3824]),\n",
       " tensor([3.4074]),\n",
       " tensor([3.4040]),\n",
       " tensor([3.3797]),\n",
       " tensor([3.3876]),\n",
       " tensor([3.3864]),\n",
       " tensor([3.3888]),\n",
       " tensor([3.3748]),\n",
       " tensor([3.3762]),\n",
       " tensor([3.3839]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.4012]),\n",
       " tensor([3.4112]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3846]),\n",
       " tensor([3.3814]),\n",
       " tensor([3.4060]),\n",
       " tensor([3.3960]),\n",
       " tensor([3.3785]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.3812]),\n",
       " tensor([3.4179]),\n",
       " tensor([3.3958]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.3811]),\n",
       " tensor([3.3881]),\n",
       " tensor([3.3697]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.4057]),\n",
       " tensor([3.4168]),\n",
       " tensor([3.4068]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.3939]),\n",
       " tensor([3.3898]),\n",
       " tensor([3.4055]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.3825]),\n",
       " tensor([3.3823]),\n",
       " tensor([3.3900]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.3910]),\n",
       " tensor([3.3669]),\n",
       " tensor([3.4105]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.3930]),\n",
       " tensor([3.3747]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.4129]),\n",
       " tensor([3.3842]),\n",
       " tensor([3.4011]),\n",
       " tensor([3.3984]),\n",
       " tensor([3.3772]),\n",
       " tensor([3.4038]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.3911]),\n",
       " tensor([3.4013]),\n",
       " tensor([3.4021]),\n",
       " tensor([3.3991]),\n",
       " tensor([3.3840]),\n",
       " tensor([3.4171]),\n",
       " tensor([3.4068]),\n",
       " tensor([3.4061]),\n",
       " tensor([3.3943]),\n",
       " tensor([3.4080]),\n",
       " tensor([3.3757]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3848]),\n",
       " tensor([3.3827]),\n",
       " tensor([3.4070]),\n",
       " tensor([3.4035]),\n",
       " tensor([3.3793]),\n",
       " tensor([3.3813]),\n",
       " tensor([3.4006]),\n",
       " tensor([3.3937]),\n",
       " tensor([3.3855]),\n",
       " tensor([3.3849]),\n",
       " tensor([3.3879]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.3842]),\n",
       " tensor([3.4141]),\n",
       " tensor([3.3924]),\n",
       " tensor([3.3830]),\n",
       " tensor([3.4130]),\n",
       " tensor([3.3903]),\n",
       " tensor([3.3871]),\n",
       " tensor([3.4162]),\n",
       " tensor([3.4080]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.4070]),\n",
       " tensor([3.4014]),\n",
       " tensor([3.3858]),\n",
       " tensor([3.3889]),\n",
       " tensor([3.3913]),\n",
       " tensor([3.4134]),\n",
       " tensor([3.3972]),\n",
       " tensor([3.4066]),\n",
       " tensor([3.4012]),\n",
       " tensor([3.3954]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.3966]),\n",
       " tensor([3.3846]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.4278]),\n",
       " tensor([3.4167]),\n",
       " tensor([3.3849]),\n",
       " tensor([3.4030]),\n",
       " tensor([3.3895]),\n",
       " tensor([3.3883]),\n",
       " tensor([3.3797]),\n",
       " tensor([3.3906]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3998]),\n",
       " tensor([3.3837]),\n",
       " tensor([3.3906]),\n",
       " tensor([3.3814]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.3900]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.3977]),\n",
       " tensor([3.3841]),\n",
       " tensor([3.4076]),\n",
       " tensor([3.4021]),\n",
       " tensor([3.3867]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.3875]),\n",
       " tensor([3.3883]),\n",
       " tensor([3.3954]),\n",
       " tensor([3.4117]),\n",
       " tensor([3.3833]),\n",
       " tensor([3.4028]),\n",
       " tensor([3.3847]),\n",
       " tensor([3.3911]),\n",
       " tensor([3.4061]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.4028]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.4019]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.3714]),\n",
       " tensor([3.3898]),\n",
       " tensor([3.4068]),\n",
       " tensor([3.3961]),\n",
       " tensor([3.4316]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.3967]),\n",
       " tensor([3.4210]),\n",
       " tensor([3.4201]),\n",
       " tensor([3.4086]),\n",
       " tensor([3.3852]),\n",
       " tensor([3.3954]),\n",
       " tensor([3.4149]),\n",
       " tensor([3.4019]),\n",
       " tensor([3.4001]),\n",
       " tensor([3.3926]),\n",
       " tensor([3.4000]),\n",
       " tensor([3.4079]),\n",
       " tensor([3.3977]),\n",
       " tensor([3.3997]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.4179]),\n",
       " tensor([3.4061]),\n",
       " tensor([3.3923]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3904]),\n",
       " tensor([3.4022]),\n",
       " tensor([3.3988]),\n",
       " tensor([3.3825]),\n",
       " tensor([3.3840]),\n",
       " tensor([3.4073]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3830]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3870]),\n",
       " tensor([3.4090]),\n",
       " tensor([3.3719]),\n",
       " tensor([3.4009]),\n",
       " tensor([3.3729]),\n",
       " tensor([3.4007]),\n",
       " tensor([3.3830]),\n",
       " tensor([3.4080]),\n",
       " tensor([3.3862]),\n",
       " tensor([3.3794]),\n",
       " tensor([3.3971]),\n",
       " tensor([3.3994]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.3780]),\n",
       " tensor([3.4054]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.3879]),\n",
       " tensor([3.3838]),\n",
       " tensor([3.3832]),\n",
       " tensor([3.4018]),\n",
       " tensor([3.3888]),\n",
       " tensor([3.3988]),\n",
       " tensor([3.3934]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.4056]),\n",
       " tensor([3.3880]),\n",
       " tensor([3.3884]),\n",
       " tensor([3.4088]),\n",
       " tensor([3.3989]),\n",
       " tensor([3.3885]),\n",
       " tensor([3.4058]),\n",
       " tensor([3.4244]),\n",
       " tensor([3.4051]),\n",
       " tensor([3.4101]),\n",
       " tensor([3.3924]),\n",
       " tensor([3.4058]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.4103]),\n",
       " tensor([3.4106]),\n",
       " tensor([3.4228]),\n",
       " tensor([3.4213]),\n",
       " tensor([3.3915]),\n",
       " tensor([3.4078]),\n",
       " tensor([3.3992]),\n",
       " tensor([3.3945]),\n",
       " tensor([3.3877]),\n",
       " tensor([3.3812]),\n",
       " tensor([3.3730]),\n",
       " tensor([3.4031]),\n",
       " tensor([3.3698]),\n",
       " tensor([3.4008]),\n",
       " tensor([3.3902]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.3998]),\n",
       " tensor([3.4109]),\n",
       " tensor([3.4035]),\n",
       " tensor([3.3786]),\n",
       " tensor([3.3959]),\n",
       " tensor([3.3848]),\n",
       " tensor([3.4000]),\n",
       " tensor([3.3748]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.4022]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.3926]),\n",
       " tensor([3.3972]),\n",
       " tensor([3.4044]),\n",
       " tensor([3.4077]),\n",
       " tensor([3.3990]),\n",
       " tensor([3.3943]),\n",
       " tensor([3.3992]),\n",
       " tensor([3.3849]),\n",
       " tensor([3.4102]),\n",
       " tensor([3.3814]),\n",
       " tensor([3.4102]),\n",
       " tensor([3.3866]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.4128]),\n",
       " tensor([3.3874]),\n",
       " tensor([3.4031]),\n",
       " tensor([3.3985]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3875]),\n",
       " tensor([3.4017]),\n",
       " tensor([3.3998]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3932]),\n",
       " tensor([3.3958]),\n",
       " tensor([3.3973]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3947]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.4081]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.4067]),\n",
       " tensor([3.3806]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.4196]),\n",
       " tensor([3.3900]),\n",
       " tensor([3.3872]),\n",
       " tensor([3.3964]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.3981]),\n",
       " tensor([3.4003]),\n",
       " tensor([3.3864]),\n",
       " tensor([3.3797]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.4134]),\n",
       " tensor([3.4020]),\n",
       " tensor([3.3841]),\n",
       " tensor([3.3775]),\n",
       " tensor([3.3854]),\n",
       " tensor([3.3974]),\n",
       " tensor([3.3947]),\n",
       " tensor([3.4116]),\n",
       " tensor([3.4051]),\n",
       " tensor([3.3892]),\n",
       " tensor([3.4026]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.4023]),\n",
       " tensor([3.3904]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.4056]),\n",
       " tensor([3.4035]),\n",
       " tensor([3.3766]),\n",
       " tensor([3.3897]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.4063]),\n",
       " tensor([3.3832]),\n",
       " tensor([3.4096]),\n",
       " tensor([3.3850]),\n",
       " tensor([3.4216]),\n",
       " tensor([3.4043]),\n",
       " tensor([3.3882]),\n",
       " tensor([3.3908]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.3989]),\n",
       " tensor([3.4090]),\n",
       " tensor([3.3868]),\n",
       " tensor([3.3926]),\n",
       " tensor([3.3796]),\n",
       " tensor([3.3829]),\n",
       " tensor([3.4089]),\n",
       " tensor([3.3850]),\n",
       " tensor([3.3933]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3988]),\n",
       " tensor([3.4028]),\n",
       " tensor([3.3891]),\n",
       " tensor([3.4035]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.3858]),\n",
       " tensor([3.3911]),\n",
       " tensor([3.3868]),\n",
       " tensor([3.3836]),\n",
       " tensor([3.3964]),\n",
       " tensor([3.4149]),\n",
       " tensor([3.3960]),\n",
       " tensor([3.3946]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.3866]),\n",
       " tensor([3.4022]),\n",
       " tensor([3.3883]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.3981]),\n",
       " tensor([3.4169]),\n",
       " tensor([3.3975]),\n",
       " tensor([3.4144]),\n",
       " tensor([3.3744]),\n",
       " tensor([3.4058]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.3881]),\n",
       " tensor([3.3699]),\n",
       " tensor([3.4189]),\n",
       " tensor([3.3954]),\n",
       " tensor([3.3870]),\n",
       " tensor([3.3865]),\n",
       " tensor([3.3838]),\n",
       " tensor([3.3925]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.4019]),\n",
       " tensor([3.4072]),\n",
       " tensor([3.3948]),\n",
       " tensor([3.4002]),\n",
       " tensor([3.3793]),\n",
       " tensor([3.4097]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.3942]),\n",
       " tensor([3.3988]),\n",
       " tensor([3.3954]),\n",
       " tensor([3.3904]),\n",
       " tensor([3.4143]),\n",
       " tensor([3.3803]),\n",
       " tensor([3.4204]),\n",
       " tensor([3.3789]),\n",
       " tensor([3.3836]),\n",
       " tensor([3.4065]),\n",
       " tensor([3.3721]),\n",
       " tensor([3.3925]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.4049]),\n",
       " tensor([3.3764]),\n",
       " tensor([3.3928]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.4004]),\n",
       " tensor([3.3832]),\n",
       " tensor([3.4129]),\n",
       " tensor([3.4088]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3855]),\n",
       " tensor([3.3939]),\n",
       " tensor([3.3819]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.4249]),\n",
       " tensor([3.4143]),\n",
       " tensor([3.4135]),\n",
       " tensor([3.3960]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.3716]),\n",
       " tensor([3.3956]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.3983]),\n",
       " tensor([3.4125]),\n",
       " tensor([3.3915]),\n",
       " tensor([3.4220]),\n",
       " tensor([3.3756]),\n",
       " tensor([3.3922]),\n",
       " tensor([3.3857]),\n",
       " tensor([3.4030]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.3770]),\n",
       " tensor([3.3992]),\n",
       " tensor([3.4071]),\n",
       " tensor([3.4107]),\n",
       " tensor([3.4151]),\n",
       " tensor([3.4113]),\n",
       " tensor([3.4054]),\n",
       " tensor([3.4038]),\n",
       " tensor([3.3863]),\n",
       " tensor([3.4015]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.3857]),\n",
       " tensor([3.3983]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.3808]),\n",
       " tensor([3.4076]),\n",
       " tensor([3.4043]),\n",
       " tensor([3.3870]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3880]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3983]),\n",
       " tensor([3.3919]),\n",
       " tensor([3.4050]),\n",
       " tensor([3.3837]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.3585]),\n",
       " tensor([3.4139]),\n",
       " tensor([3.3854]),\n",
       " tensor([3.4070]),\n",
       " tensor([3.3916]),\n",
       " tensor([3.3823]),\n",
       " tensor([3.3984]),\n",
       " tensor([3.4058]),\n",
       " tensor([3.3818]),\n",
       " tensor([3.4084]),\n",
       " tensor([3.3786]),\n",
       " tensor([3.3798]),\n",
       " tensor([3.3991]),\n",
       " tensor([3.3876]),\n",
       " tensor([3.3987]),\n",
       " tensor([3.4036]),\n",
       " tensor([3.4024]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.3973]),\n",
       " tensor([3.3846]),\n",
       " tensor([3.4137]),\n",
       " tensor([3.3864]),\n",
       " tensor([3.3943]),\n",
       " tensor([3.3881]),\n",
       " tensor([3.3978]),\n",
       " tensor([3.4078]),\n",
       " tensor([3.3929]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.3995]),\n",
       " tensor([3.4120]),\n",
       " tensor([3.4318]),\n",
       " tensor([3.3795]),\n",
       " tensor([3.3785]),\n",
       " tensor([3.3924]),\n",
       " tensor([3.3759]),\n",
       " tensor([3.3997]),\n",
       " tensor([3.3840]),\n",
       " tensor([3.4264]),\n",
       " tensor([3.4175]),\n",
       " tensor([3.3834]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.3997]),\n",
       " tensor([3.4206]),\n",
       " tensor([3.3871]),\n",
       " tensor([3.3845]),\n",
       " tensor([3.4004]),\n",
       " tensor([3.3881]),\n",
       " tensor([3.3914]),\n",
       " tensor([3.4153]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.4035]),\n",
       " tensor([3.3940]),\n",
       " tensor([3.3738]),\n",
       " tensor([3.3919]),\n",
       " tensor([3.3889]),\n",
       " tensor([3.3880]),\n",
       " tensor([3.3940]),\n",
       " tensor([3.4042]),\n",
       " tensor([3.4017]),\n",
       " tensor([3.4033]),\n",
       " tensor([3.4213]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.3788]),\n",
       " tensor([3.3851]),\n",
       " tensor([3.3969]),\n",
       " tensor([3.3791]),\n",
       " tensor([3.3855]),\n",
       " tensor([3.3906]),\n",
       " tensor([3.3865]),\n",
       " tensor([3.3909]),\n",
       " tensor([3.3916]),\n",
       " tensor([3.3898]),\n",
       " tensor([3.3884]),\n",
       " tensor([3.3852]),\n",
       " tensor([3.3982]),\n",
       " tensor([3.4141]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.4094]),\n",
       " tensor([3.3684]),\n",
       " tensor([3.4163]),\n",
       " tensor([3.3763]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.3932]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.4012]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.4031]),\n",
       " tensor([3.3958]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3865]),\n",
       " tensor([3.4221]),\n",
       " tensor([3.4161]),\n",
       " tensor([3.3898]),\n",
       " tensor([3.3983]),\n",
       " tensor([3.3923]),\n",
       " tensor([3.4119]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3876]),\n",
       " tensor([3.3926]),\n",
       " tensor([3.3767]),\n",
       " tensor([3.4065]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.4100]),\n",
       " tensor([3.3970]),\n",
       " tensor([3.3796]),\n",
       " tensor([3.4057]),\n",
       " tensor([3.3976]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3911]),\n",
       " tensor([3.3922]),\n",
       " tensor([3.3937]),\n",
       " tensor([3.3938]),\n",
       " tensor([3.3969]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.3967]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.3775]),\n",
       " tensor([3.4075]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3970]),\n",
       " tensor([3.3836]),\n",
       " tensor([3.4081]),\n",
       " tensor([3.3845]),\n",
       " tensor([3.3839]),\n",
       " tensor([3.3944]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.3913]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.3920]),\n",
       " tensor([3.3838]),\n",
       " tensor([3.4055]),\n",
       " tensor([3.4126]),\n",
       " tensor([3.4025]),\n",
       " tensor([3.3967]),\n",
       " tensor([3.4007]),\n",
       " tensor([3.3952]),\n",
       " tensor([3.3953]),\n",
       " tensor([3.4139]),\n",
       " tensor([3.4124]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.4197]),\n",
       " tensor([3.3932]),\n",
       " tensor([3.3995]),\n",
       " tensor([3.3759]),\n",
       " tensor([3.3923]),\n",
       " tensor([3.3989]),\n",
       " tensor([3.3915]),\n",
       " tensor([3.3882]),\n",
       " tensor([3.4209]),\n",
       " tensor([3.3956]),\n",
       " tensor([3.3979]),\n",
       " tensor([3.3857]),\n",
       " tensor([3.4188]),\n",
       " tensor([3.3918]),\n",
       " tensor([3.4094]),\n",
       " tensor([3.3897]),\n",
       " tensor([3.3953]),\n",
       " tensor([3.3892]),\n",
       " tensor([3.3970]),\n",
       " tensor([3.3870]),\n",
       " tensor([3.3946]),\n",
       " tensor([3.3978]),\n",
       " tensor([3.3755]),\n",
       " tensor([3.4047]),\n",
       " tensor([3.4014]),\n",
       " tensor([3.4015]),\n",
       " tensor([3.3726]),\n",
       " tensor([3.3975]),\n",
       " tensor([3.4013]),\n",
       " tensor([3.4140]),\n",
       " tensor([3.3905]),\n",
       " tensor([3.3780]),\n",
       " tensor([3.3963]),\n",
       " tensor([3.4032]),\n",
       " tensor([3.3950]),\n",
       " tensor([3.3960]),\n",
       " tensor([3.3978]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.4156]),\n",
       " tensor([3.4089]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.3753]),\n",
       " tensor([3.3867]),\n",
       " tensor([3.4000]),\n",
       " tensor([3.4068]),\n",
       " tensor([3.4117]),\n",
       " tensor([3.4168]),\n",
       " tensor([3.3935]),\n",
       " tensor([3.4048]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.3758]),\n",
       " tensor([3.4010]),\n",
       " tensor([3.4005]),\n",
       " tensor([3.3967]),\n",
       " tensor([3.4026]),\n",
       " tensor([3.3929]),\n",
       " tensor([3.3893]),\n",
       " tensor([3.3895]),\n",
       " tensor([3.4025]),\n",
       " tensor([3.3774]),\n",
       " tensor([3.3910]),\n",
       " tensor([3.3889]),\n",
       " tensor([3.4063]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.3971]),\n",
       " tensor([3.3923]),\n",
       " tensor([3.4122]),\n",
       " tensor([3.3859]),\n",
       " tensor([3.3962]),\n",
       " tensor([3.3989]),\n",
       " tensor([3.3804]),\n",
       " tensor([3.4029]),\n",
       " tensor([3.3983]),\n",
       " tensor([3.3745]),\n",
       " tensor([3.4155]),\n",
       " tensor([3.3889]),\n",
       " tensor([3.3940]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.3784]),\n",
       " tensor([3.4200]),\n",
       " tensor([3.3796]),\n",
       " tensor([3.3854]),\n",
       " tensor([3.3860]),\n",
       " tensor([3.4193]),\n",
       " tensor([3.4039]),\n",
       " tensor([3.4040]),\n",
       " tensor([3.4007]),\n",
       " tensor([3.3829]),\n",
       " tensor([3.3982]),\n",
       " tensor([3.3808]),\n",
       " tensor([3.4081]),\n",
       " tensor([3.3952]),\n",
       " tensor([3.4156]),\n",
       " tensor([3.4112]),\n",
       " tensor([3.4128]),\n",
       " tensor([3.4121]),\n",
       " tensor([3.3957]),\n",
       " tensor([3.3943]),\n",
       " tensor([3.3799]),\n",
       " tensor([3.3915]),\n",
       " tensor([3.4176]),\n",
       " tensor([3.3785]),\n",
       " tensor([3.3834]),\n",
       " tensor([3.4043]),\n",
       " tensor([3.3938]),\n",
       " tensor([3.3826]),\n",
       " tensor([3.4024]),\n",
       " tensor([3.3841]),\n",
       " tensor([3.3795]),\n",
       " tensor([3.3810]),\n",
       " tensor([3.3850]),\n",
       " tensor([3.3951]),\n",
       " tensor([3.3959]),\n",
       " tensor([3.3843]),\n",
       " tensor([3.3688]),\n",
       " tensor([3.3970]),\n",
       " tensor([3.4021]),\n",
       " tensor([3.3768]),\n",
       " tensor([3.4121]),\n",
       " tensor([3.3758]),\n",
       " tensor([3.3795]),\n",
       " tensor([3.3867]),\n",
       " tensor([3.3911]),\n",
       " tensor([3.4070]),\n",
       " tensor([3.3904]),\n",
       " tensor([3.4122]),\n",
       " tensor([3.4100]),\n",
       " tensor([3.3890]),\n",
       " tensor([3.4108]),\n",
       " tensor([3.3873]),\n",
       " tensor([3.3842]),\n",
       " tensor([3.3999]),\n",
       " tensor([3.4127]),\n",
       " tensor([3.3960]),\n",
       " tensor([3.4027]),\n",
       " tensor([3.3887]),\n",
       " tensor([3.4074]),\n",
       " tensor([3.3842]),\n",
       " tensor([3.3875]),\n",
       " tensor([3.3933]),\n",
       " tensor([3.3945]),\n",
       " tensor([3.3959]),\n",
       " tensor([3.3963]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.4010]),\n",
       " tensor([3.3924]),\n",
       " tensor([3.4082]),\n",
       " tensor([3.3833]),\n",
       " tensor([3.3936]),\n",
       " tensor([3.3899]),\n",
       " tensor([3.3990]),\n",
       " tensor([3.3942]),\n",
       " tensor([3.3891]),\n",
       " tensor([3.3880]),\n",
       " tensor([3.4155]),\n",
       " tensor([3.3919]),\n",
       " tensor([3.3955]),\n",
       " tensor([3.3861]),\n",
       " tensor([3.4238]),\n",
       " tensor([3.3786]),\n",
       " tensor([3.4097]),\n",
       " tensor([3.4214]),\n",
       " tensor([3.3743]),\n",
       " tensor([3.3897]),\n",
       " tensor([3.4080]),\n",
       " tensor([3.4082]),\n",
       " tensor([3.3964]),\n",
       " tensor([3.3845]),\n",
       " tensor([3.4070]),\n",
       " tensor([3.3896]),\n",
       " tensor([3.4056]),\n",
       " tensor([3.3756]),\n",
       " tensor([3.3853]),\n",
       " tensor([3.4129]),\n",
       " tensor([3.4044]),\n",
       " tensor([3.3836]),\n",
       " tensor([3.3902]),\n",
       " tensor([3.3959]),\n",
       " tensor([3.3827]),\n",
       " tensor([3.4051]),\n",
       " tensor([3.3900]),\n",
       " ...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(model=alphafold2, dataloaders=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.4.4.2. <a id='toc14_4_4_2_'></a>[PyTorch lightning加载权重后预测](#toc0_)\n",
    "需要手动：\n",
    "- model.eval()\n",
    "- with torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4124],\n",
       "        [3.3868],\n",
       "        [3.3909],\n",
       "        ...,\n",
       "        [3.4022],\n",
       "        [3.3898],\n",
       "        [3.3934]], device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_alphafold2 = AlphaFold2Wrapper.load_from_checkpoint('./lightning_logs/version_0/checkpoints/epoch=9-step=790.ckpt')\n",
    "\n",
    "# 进行预测/推理\n",
    "pretrained_alphafold2.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = pretrained_alphafold2(features.to('cuda:0'))\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.4.4.3. <a id='toc14_4_4_3_'></a>[提取权重后加载至纯PyTorch模型](#toc0_)\n",
    "从checkpoint中`提取模型的权重参数`，`修改相关格式`后再加载到纯PyTorch的模型中，就是普通又熟悉的PyTorch的预测方式了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_268120/3329860571.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 9,\n",
       " 'global_step': 790,\n",
       " 'pytorch-lightning_version': '2.4.0',\n",
       " 'state_dict': OrderedDict([('demo_model.hidden.0.weight',\n",
       "               tensor([[ 0.0967, -0.0567]], device='cuda:0')),\n",
       "              ('demo_model.hidden.0.bias',\n",
       "               tensor([3.3954], device='cuda:0'))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 790},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 790,\n",
       "     'completed': 790,\n",
       "     'started': 790,\n",
       "     'processed': 790},\n",
       "    'current': {'ready': 79, 'completed': 79, 'started': 79, 'processed': 79},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 790,\n",
       "       'completed': 790},\n",
       "      'current': {'ready': 79, 'completed': 79}},\n",
       "     'zero_grad': {'total': {'ready': 790, 'completed': 790, 'started': 790},\n",
       "      'current': {'ready': 79, 'completed': 79, 'started': 79}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 79,\n",
       "     'completed': 79,\n",
       "     'started': 79,\n",
       "     'processed': 79},\n",
       "    'current': {'ready': 79, 'completed': 79, 'started': 79, 'processed': 79},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_progress': {'total': {'ready': 10,\n",
       "     'completed': 9,\n",
       "     'started': 10,\n",
       "     'processed': 10},\n",
       "    'current': {'ready': 10, 'completed': 9, 'started': 10, 'processed': 10}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': None,\n",
       "   'best_model_score': None,\n",
       "   'best_model_path': '/bmp/backup/zhaosy/ws/PyTorch_learning/lightning_logs/version_0/checkpoints/epoch=9-step=790.ckpt',\n",
       "   'current_score': None,\n",
       "   'dirpath': '/bmp/backup/zhaosy/ws/PyTorch_learning/lightning_logs/version_0/checkpoints',\n",
       "   'best_k_models': {},\n",
       "   'kth_best_model_path': '',\n",
       "   'kth_value': tensor(inf),\n",
       "   'last_model_path': ''}},\n",
       " 'optimizer_states': [{'state': {},\n",
       "   'param_groups': [{'lr': 0.01,\n",
       "     'momentum': 0,\n",
       "     'dampening': 0,\n",
       "     'weight_decay': 0,\n",
       "     'nesterov': False,\n",
       "     'maximize': False,\n",
       "     'foreach': None,\n",
       "     'differentiable': False,\n",
       "     'fused': None,\n",
       "     'params': [0, 1]}]}],\n",
       " 'lr_schedulers': [],\n",
       " 'hparams_name': 'kwargs',\n",
       " 'hyper_parameters': {'learning_rate': 0.01}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = './lightning_logs/version_0/checkpoints/epoch=9-step=790.ckpt'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "checkpoint  # checkpoint的贮存格式，其中 'state_dict'就是模型权重信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AlphaFold2Wrapper(\n",
       "   (demo_model): AlphaFold2(\n",
       "     (hidden): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "     )\n",
       "   )\n",
       "   (loss_fn): MSELoss()\n",
       " ),\n",
       " OrderedDict([('demo_model.hidden.0.weight',\n",
       "               tensor([[ 0.0967, -0.0567]], device='cuda:0')),\n",
       "              ('demo_model.hidden.0.bias',\n",
       "               tensor([3.3954], device='cuda:0'))]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphafold2, checkpoint['state_dict']    # with AlphaFold2Wrapper, 多了demo_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_model.hidden.0.weight\n",
      "demo_model.hidden.0.bias\n"
     ]
    }
   ],
   "source": [
    "for param in checkpoint['state_dict']:\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `纯PyTorch的state_dict`如下，`如上的checkpoint`中的state_dict`不符合`相应格式，需要进行更改："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AlphaFold2(\n",
       "   (hidden): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "   )\n",
       " ),\n",
       " OrderedDict([('hidden.0.weight', tensor([[-0.5207,  0.0861]])),\n",
       "              ('hidden.0.bias', tensor([0.0467]))]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphafold_with_pure_pytorch = AlphaFold2()\n",
    "alphafold_with_pure_pytorch, alphafold_with_pure_pytorch.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 更改操作如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = checkpoint['state_dict']\n",
    "\n",
    "# 把demo_model.删除即可\n",
    "for key in model_weights:\n",
    "    model_weights[key.replace(\"demo_model.\", \"\")] = model_weights.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('hidden.0.weight',\n",
       "               tensor([[ 0.0967, -0.0567]], device='cuda:0')),\n",
       "              ('hidden.0.bias', tensor([3.3954], device='cuda:0'))]),\n",
       " OrderedDict([('hidden.0.weight',\n",
       "               tensor([[ 0.0967, -0.0567]], device='cuda:0')),\n",
       "              ('hidden.0.bias', tensor([3.3954], device='cuda:0'))]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['state_dict'], model_weights # 都更改了，什么鬼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4124],\n",
       "        [3.3868],\n",
       "        [3.3909],\n",
       "        ...,\n",
       "        [3.4022],\n",
       "        [3.3898],\n",
       "        [3.3934]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重新实例化一个新的对象\n",
    "alphafold_with_pure_pytorch = AlphaFold2()\n",
    "\n",
    "# 加载修改后的权重\n",
    "alphafold_with_pure_pytorch.load_state_dict(model_weights)  # 加载修改后的model_weights\n",
    "\n",
    "# 进行预测/推理\n",
    "alphafold_with_pure_pytorch.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = alphafold_with_pure_pytorch(features)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. <a id='toc15_'></a>[L做迁移学习](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.1. <a id='toc15_1_'></a>[项目一：](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. <a id='toc16_'></a>[Torchvision教程](#toc0_)\n",
    "Torchvision Docs: [https://pytorch.org/vision/stable/models.html](https://pytorch.org/vision/stable/models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchvision version: 0.19.0\n"
     ]
    }
   ],
   "source": [
    "import torchvision \n",
    "print('torchvision version:', torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1. <a id='toc16_1_'></a>[Models](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.1.1. <a id='toc16_1_1_'></a>[可用模型](#toc0_)\n",
    "可用`模型`见：[https://pytorch.org/vision/stable/models.html](https://pytorch.org/vision/stable/models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'convnext_base',\n",
       " 'convnext_large',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'deeplabv3_mobilenet_v3_large',\n",
       " 'deeplabv3_resnet101',\n",
       " 'deeplabv3_resnet50',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_v2_l',\n",
       " 'efficientnet_v2_m',\n",
       " 'efficientnet_v2_s',\n",
       " 'fasterrcnn_mobilenet_v3_large_320_fpn',\n",
       " 'fasterrcnn_mobilenet_v3_large_fpn',\n",
       " 'fasterrcnn_resnet50_fpn',\n",
       " 'fasterrcnn_resnet50_fpn_v2',\n",
       " 'fcn_resnet101',\n",
       " 'fcn_resnet50',\n",
       " 'fcos_resnet50_fpn',\n",
       " 'googlenet',\n",
       " 'inception_v3',\n",
       " 'keypointrcnn_resnet50_fpn',\n",
       " 'lraspp_mobilenet_v3_large',\n",
       " 'maskrcnn_resnet50_fpn',\n",
       " 'maskrcnn_resnet50_fpn_v2',\n",
       " 'maxvit_t',\n",
       " 'mc3_18',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'mvit_v1_b',\n",
       " 'mvit_v2_s',\n",
       " 'quantized_googlenet',\n",
       " 'quantized_inception_v3',\n",
       " 'quantized_mobilenet_v2',\n",
       " 'quantized_mobilenet_v3_large',\n",
       " 'quantized_resnet18',\n",
       " 'quantized_resnet50',\n",
       " 'quantized_resnext101_32x8d',\n",
       " 'quantized_resnext101_64x4d',\n",
       " 'quantized_shufflenet_v2_x0_5',\n",
       " 'quantized_shufflenet_v2_x1_0',\n",
       " 'quantized_shufflenet_v2_x1_5',\n",
       " 'quantized_shufflenet_v2_x2_0',\n",
       " 'r2plus1d_18',\n",
       " 'r3d_18',\n",
       " 'raft_large',\n",
       " 'raft_small',\n",
       " 'regnet_x_16gf',\n",
       " 'regnet_x_1_6gf',\n",
       " 'regnet_x_32gf',\n",
       " 'regnet_x_3_2gf',\n",
       " 'regnet_x_400mf',\n",
       " 'regnet_x_800mf',\n",
       " 'regnet_x_8gf',\n",
       " 'regnet_y_128gf',\n",
       " 'regnet_y_16gf',\n",
       " 'regnet_y_1_6gf',\n",
       " 'regnet_y_32gf',\n",
       " 'regnet_y_3_2gf',\n",
       " 'regnet_y_400mf',\n",
       " 'regnet_y_800mf',\n",
       " 'regnet_y_8gf',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'resnext50_32x4d',\n",
       " 'retinanet_resnet50_fpn',\n",
       " 'retinanet_resnet50_fpn_v2',\n",
       " 's3d',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'ssd300_vgg16',\n",
       " 'ssdlite320_mobilenet_v3_large',\n",
       " 'swin3d_b',\n",
       " 'swin3d_s',\n",
       " 'swin3d_t',\n",
       " 'swin_b',\n",
       " 'swin_s',\n",
       " 'swin_t',\n",
       " 'swin_v2_b',\n",
       " 'swin_v2_s',\n",
       " 'swin_v2_t',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'vit_b_16',\n",
       " 'vit_b_32',\n",
       " 'vit_h_14',\n",
       " 'vit_l_16',\n",
       " 'vit_l_32',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models \n",
    "\n",
    "models.list_models()    # List all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.1.2. <a id='toc16_1_2_'></a>[下载模型和权重](#toc0_)\n",
    "可用`权重`见：[https://pytorch.org/vision/stable/models.html](https://pytorch.org/vision/stable/models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model\n",
    "alexnet = models.get_model(name='alexnet')\n",
    "\n",
    "# 1. Get weight\n",
    "weights = models.get_weight('AlexNet_Weights.IMAGENET1K_V1')\n",
    "# weights = models.get_weight('ResNet50_Weights.IMAGENET1K_V1')\n",
    "# weights = models.get_weight('ResNet50_Weights.IMAGENET1K_V2')\n",
    "\n",
    "# 2. (Recommendation) Get weight with model name\n",
    "weights = models.get_model_weights(name='alexnet')\n",
    "\n",
    "# Get the state_dict parameters from loaded weights wrapper\n",
    "state_dict = weights.IMAGENET1K_V1.get_state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.1.3. <a id='toc16_1_3_'></a>[模型加载权重](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "alexnet.load_state_dict(state_dict=state_dict)\n",
    "alexnet.eval()\n",
    "with torch.no_grad():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.1.4. <a id='toc16_1_4_'></a>[总结](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrapper to the following:\n",
    "def get_pretrained_model(model_name:str)-> torch.nn.Module:\n",
    "    '''Default to get: IMAGENET1K_V1'''\n",
    "    model = models.get_model(name=model_name)\n",
    "    weight_wrapper = models.get_model_weights(name=model_name)\n",
    "    state_dict = weight_wrapper.IMAGENET1K_V1.get_state_dict()\n",
    "    model.load_state_dict(state_dict=state_dict)\n",
    "    return model\n",
    "\n",
    "# pretrained_model = get_pretrained_model(model_name='resnet50')\n",
    "pretrained_model = get_pretrained_model(model_name='alexnet')\n",
    "pretrained_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2. <a id='toc16_2_'></a>[Dataset](#toc0_)\n",
    "torchvision Docs: [https://pytorch.org/vision/stable/datasets.html](https://pytorch.org/vision/stable/datasets.html)  \n",
    "\n",
    "1. torchvision的datasets有很多，如：\n",
    "  \n",
    "    - Image classification\n",
    "        - FashionMNIST(root[, train, transform, ...])\n",
    "        - MNIST(root[, train, transform, ...])\n",
    "    - Image detection or segmentation\n",
    "        - CocoDetection(root, annFile[, transform, ...])\n",
    "    - Video classification\n",
    "        - HMDB51(root, annotation_path, frames_per_clip)\n",
    "    - Video prediction\n",
    "        - MovingMNIST(root[, split, split_ratio, ...])\n",
    "\n",
    "2. 另外，还可以自定义数据集，函数如下：\n",
    "\n",
    "    - Base classes for custom datasets\n",
    "        - `DatasetFolder`(root, loader[, extensions, ...])    # A generic data loader.\n",
    "        - `ImageFolder`(root, transform, ...)                 # A generic data loader where the images are arranged in this way by default: .\n",
    "        - `VisionDataset`([root, transforms, transform, ...]) # Base Class For making datasets which are compatible with torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torchvision.datasets.mnist.FashionMNIST,\n",
       " torchvision.datasets.mnist.FashionMNIST)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "dbs = './Pytorch_datasets/'\n",
    "\n",
    "trans = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),                  # PIL转换为tensor格式\n",
    "        torchvision.transforms.Normalize((0.5,), (1.0,))    # 标准化\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dbs, \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=trans, \n",
    "#   target_transform=False\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dbs, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=trans, \n",
    "#   target_transform=False\n",
    ")\n",
    "type(train_dataset), type(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. <a id='toc17_'></a>[Degub pdb](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
