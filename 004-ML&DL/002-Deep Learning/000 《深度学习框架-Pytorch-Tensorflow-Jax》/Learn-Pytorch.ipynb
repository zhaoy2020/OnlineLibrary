{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [概述](#toc1_)    \n",
    "- 2. [utils](#toc2_)    \n",
    "- 3. [安装GPU驱动](#toc3_)    \n",
    "  - 3.1. [安装策略](#toc3_1_)    \n",
    "  - 3.2. [首先确认内核版本和发行版本，再确认显卡型号](#toc3_2_)    \n",
    "  - 3.3. [安装驱动-CUDA Driver](#toc3_3_)    \n",
    "    - 3.3.1. [下载CUDA Driver](#toc3_3_1_)    \n",
    "    - 3.3.2. [禁用nouveau](#toc3_3_2_)    \n",
    "    - 3.3.3. [安装CUDA Driver](#toc3_3_3_)    \n",
    "    - 3.3.4. [查看显卡是否安装成功](#toc3_3_4_)    \n",
    "    - 3.3.5. [查看nvcc](#toc3_3_5_)    \n",
    "  - 3.4. [CUDA Toolkit和CuDNN](#toc3_4_)    \n",
    "    - 3.4.1. [下载对应的CUDA Toolkit版本](#toc3_4_1_)    \n",
    "    - 3.4.2. [安装CUDA Toolkit](#toc3_4_2_)    \n",
    "    - 3.4.3. [下载对应的CuDNN](#toc3_4_3_)    \n",
    "    - 3.4.4. [安装CuDNN](#toc3_4_4_)    \n",
    "  - 3.5. [安装对应版本的Pytorch](#toc3_5_)    \n",
    "  - 3.6. [GPU测试程序](#toc3_6_)    \n",
    "    - 3.6.1. [测试单机单卡GPU性能](#toc3_6_1_)    \n",
    "    - 3.6.2. [测试单机多卡GPU性能](#toc3_6_2_)    \n",
    "    - 3.6.3. [GPU burn压力测试](#toc3_6_3_)    \n",
    "- 4. [Pytorch模块介绍](#toc4_)    \n",
    "  - 4.1. [导入模块](#toc4_1_)    \n",
    "- 5. [数据加载](#toc5_)    \n",
    "  - 5.1. [现成的数据库-torchvison](#toc5_1_)    \n",
    "  - 5.2. [自定义数据库](#toc5_2_)    \n",
    "  - 5.3. [Pytorch数据加载](#toc5_3_)    \n",
    "    - 5.3.1. [估计数据加载时间](#toc5_3_1_)    \n",
    "- 6. [张量(Tensors)](#toc6_)    \n",
    "  - 6.1. [Tensors定义](#toc6_1_)    \n",
    "  - 6.2. [Tensors属性](#toc6_2_)    \n",
    "  - 6.3. [Tensors操作](#toc6_3_)    \n",
    "    - 6.3.1. [索引和切片](#toc6_3_1_)    \n",
    "    - 6.3.2. [转置](#toc6_3_2_)    \n",
    "  - 6.4. [线性代数运算](#toc6_4_)    \n",
    "    - 6.4.1. [点积（Dot Product）](#toc6_4_1_)    \n",
    "    - 6.4.2. [矩阵向量积](#toc6_4_2_)    \n",
    "    - 6.4.3. [矩阵乘法](#toc6_4_3_)    \n",
    "  - 6.5. [自动微积-autograd](#toc6_5_)    \n",
    "    - 6.5.1. [自己探索](#toc6_5_1_)    \n",
    "      - 6.5.1.1. [标量-一阶导数（得标量）](#toc6_5_1_1_)    \n",
    "      - 6.5.1.2. [标量/向量-一阶导数（得向量）](#toc6_5_1_2_)    \n",
    "      - 6.5.1.3. [向量/向量-一阶导数（得举证）](#toc6_5_1_3_)    \n",
    "    - 6.5.2. [一个简单的例子](#toc6_5_2_)    \n",
    "    - 6.5.3. [计算另一个](#toc6_5_3_)    \n",
    "    - 6.5.4. [非标量变量的反向传播](#toc6_5_4_)    \n",
    "    - 6.5.5. [分离计算](#toc6_5_5_)    \n",
    "    - 6.5.6. [Python控制流的梯度计算](#toc6_5_6_)    \n",
    "  - 6.6. [概率论](#toc6_6_)    \n",
    "- 7. [神经网络-训练八股](#toc7_)    \n",
    "  - 7.1. [现线性回归模型于训练过程-从零开始](#toc7_1_)    \n",
    "    - 7.1.1. [虚拟出数据](#toc7_1_1_)    \n",
    "    - 7.1.2. [读取数据](#toc7_1_2_)    \n",
    "    - 7.1.3. [初始化模型参数](#toc7_1_3_)    \n",
    "    - 7.1.4. [定义模型](#toc7_1_4_)    \n",
    "    - 7.1.5. [定义损失函数](#toc7_1_5_)    \n",
    "    - 7.1.6. [定义优化算法](#toc7_1_6_)    \n",
    "    - 7.1.7. [训练](#toc7_1_7_)    \n",
    "  - 7.2. [现线性回归模型于训练过程-简洁实现](#toc7_2_)    \n",
    "    - 7.2.1. [虚拟数据](#toc7_2_1_)    \n",
    "    - 7.2.2. [读取数据](#toc7_2_2_)    \n",
    "    - 7.2.3. [定义模型](#toc7_2_3_)    \n",
    "    - 7.2.4. [初始化模型参数](#toc7_2_4_)    \n",
    "    - 7.2.5. [定义损失函数](#toc7_2_5_)    \n",
    "    - 7.2.6. [定义优化算法](#toc7_2_6_)    \n",
    "    - 7.2.7. [训练](#toc7_2_7_)    \n",
    "  - 7.3. [专题-模型定义（计算预测值）](#toc7_3_)    \n",
    "    - 7.3.1. [torch.nn模块](#toc7_3_1_)    \n",
    "    - 7.3.2. [自定义-块](#toc7_3_2_)    \n",
    "      - 7.3.2.1. [自定义块](#toc7_3_2_1_)    \n",
    "      - 7.3.2.2. [顺序块](#toc7_3_2_2_)    \n",
    "      - 7.3.2.3. [效率](#toc7_3_2_3_)    \n",
    "    - 7.3.3. [参数管理](#toc7_3_3_)    \n",
    "      - 7.3.3.1. [参数访问](#toc7_3_3_1_)    \n",
    "      - 7.3.3.2. [参数初始化](#toc7_3_3_2_)    \n",
    "        - 7.3.3.2.1. [内置初始化](#toc7_3_3_2_1_)    \n",
    "        - 7.3.3.2.2. [自定义初始化](#toc7_3_3_2_2_)    \n",
    "        - 7.3.3.2.3. [参数绑定](#toc7_3_3_2_3_)    \n",
    "    - 7.3.4. [自定义-层](#toc7_3_4_)    \n",
    "      - 7.3.4.1. [不带参数的层](#toc7_3_4_1_)    \n",
    "      - 7.3.4.2. [带参数的层](#toc7_3_4_2_)    \n",
    "  - 7.4. [专题-损失函数](#toc7_4_)    \n",
    "    - 7.4.1. [均方误差](#toc7_4_1_)    \n",
    "    - 7.4.2. [交叉熵](#toc7_4_2_)    \n",
    "    - 7.4.3. [自定义](#toc7_4_3_)    \n",
    "  - 7.5. [专题-反向传播（求梯度）](#toc7_5_)    \n",
    "  - 7.6. [专题-更新权重（优化算法）](#toc7_6_)    \n",
    "    - 7.6.1. [小批量梯度下降（SGD）](#toc7_6_1_)    \n",
    "    - 7.6.2. [adam](#toc7_6_2_)    \n",
    "    - 7.6.3. [RMSprop](#toc7_6_3_)    \n",
    "  - 7.7. [专题-训练](#toc7_7_)    \n",
    "    - 7.7.1. [开始训练](#toc7_7_1_)    \n",
    "    - 7.7.2. [自己探索](#toc7_7_2_)    \n",
    "      - 7.7.2.1. [lr的影响](#toc7_7_2_1_)    \n",
    "      - 7.7.2.2. [不同模型的效率](#toc7_7_2_2_)    \n",
    "    - 7.7.3. [K折交叉验证](#toc7_7_3_)    \n",
    "- 8. [在 GPU 上训练](#toc8_)    \n",
    "  - 8.1. [查看GPU配置](#toc8_1_)    \n",
    "  - 8.2. [单机单卡（GPU）](#toc8_2_)    \n",
    "  - 8.3. [单机多卡（GPU）](#toc8_3_)    \n",
    "    - 8.3.1. [DP](#toc8_3_1_)    \n",
    "    - 8.3.2. [DDP](#toc8_3_2_)    \n",
    "      - 8.3.2.1. [在colab上测试可用](#toc8_3_2_1_)    \n",
    "  - 8.4. [多机多卡（GPU）- 分布式训练](#toc8_4_)    \n",
    "- 9. [模型和参数的保存与加载](#toc9_)    \n",
    "  - 9.1. [加载和保存-张量](#toc9_1_)    \n",
    "  - 9.2. [加载和保存-模型参数](#toc9_2_)    \n",
    "- 10. [神经网络类型](#toc10_)    \n",
    "  - 10.1. [CNN](#toc10_1_)    \n",
    "    - 10.1.1. [简单CNN](#toc10_1_1_)    \n",
    "      - 10.1.1.1. [从头实现](#toc10_1_1_1_)    \n",
    "      - 10.1.1.2. [简介实现](#toc10_1_1_2_)    \n",
    "    - 10.1.2. [ResNet](#toc10_1_2_)    \n",
    "      - 10.1.2.1. [从头实现](#toc10_1_2_1_)    \n",
    "      - 10.1.2.2. [简洁实现](#toc10_1_2_2_)    \n",
    "  - 10.2. [序列数据](#toc10_2_)    \n",
    "    - 10.2.1. [序列](#toc10_2_1_)    \n",
    "    - 10.2.2. [语言模型](#toc10_2_2_)    \n",
    "  - 10.3. [RNN](#toc10_3_)    \n",
    "    - 10.3.1. [简单RNN](#toc10_3_1_)    \n",
    "      - 10.3.1.1. [从头实现](#toc10_3_1_1_)    \n",
    "      - 10.3.1.2. [简洁实现](#toc10_3_1_2_)    \n",
    "    - 10.3.2. [GRU](#toc10_3_2_)    \n",
    "      - 10.3.2.1. [从头实现](#toc10_3_2_1_)    \n",
    "      - 10.3.2.2. [简洁实现](#toc10_3_2_2_)    \n",
    "    - 10.3.3. [LSTM](#toc10_3_3_)    \n",
    "      - 10.3.3.1. [从头实现](#toc10_3_3_1_)    \n",
    "      - 10.3.3.2. [简洁实现](#toc10_3_3_2_)    \n",
    "    - 10.3.4. [深层RNN-深层循环神经网络](#toc10_3_4_)    \n",
    "      - 10.3.4.1. [简洁实现](#toc10_3_4_1_)    \n",
    "    - 10.3.5. [双向RNN-双向循环神经网络](#toc10_3_5_)    \n",
    "      - 10.3.5.1. [简洁实现](#toc10_3_5_1_)    \n",
    "    - 10.3.6. [Encoder-Decoder框架](#toc10_3_6_)    \n",
    "      - 10.3.6.1. [Encoder部分](#toc10_3_6_1_)    \n",
    "      - 10.3.6.2. [Decoder部分](#toc10_3_6_2_)    \n",
    "      - 10.3.6.3. [Encoder-Decoder（合并编码器和解码器）](#toc10_3_6_3_)    \n",
    "    - 10.3.7. [seq2seq (Sequence to sequence learning)](#toc10_3_7_)    \n",
    "      - 10.3.7.1. [简洁实现](#toc10_3_7_1_)    \n",
    "  - 10.4. [Attention](#toc10_4_)    \n",
    "    - 10.4.1. [非参数注意力汇聚（Attention Pooling）](#toc10_4_1_)    \n",
    "    - 10.4.2. [参数注意力汇聚（Attention Pooling）](#toc10_4_2_)    \n",
    "    - 10.4.3. [注意力分数函数](#toc10_4_3_)    \n",
    "      - 10.4.3.1. [加性注意力](#toc10_4_3_1_)    \n",
    "      - 10.4.3.2. [缩放点积注意力](#toc10_4_3_2_)    \n",
    "    - 10.4.4. [自注意力机制](#toc10_4_4_)    \n",
    "    - 10.4.5. [多头注意力机制](#toc10_4_5_)    \n",
    "    - 10.4.6. [attention-seq2seq](#toc10_4_6_)    \n",
    "    - 10.4.7. [Transformer](#toc10_4_7_)    \n",
    "      - 10.4.7.1. [Test](#toc10_4_7_1_)    \n",
    "      - 10.4.7.2. [基于Attention的Seq2Seq网络](#toc10_4_7_2_)    \n",
    "    - 10.4.8. [BERT](#toc10_4_8_)    \n",
    "    - 10.4.9. [GPT](#toc10_4_9_)    \n",
    "- 11. [CV](#toc11_)    \n",
    "  - 11.1. [数据增广](#toc11_1_)    \n",
    "- 12. [NLP](#toc12_)    \n",
    "- 13. [炼丹心得](#toc13_)    \n",
    "  - 13.1. [关于调参](#toc13_1_)    \n",
    "  - 13.2. [模型选择](#toc13_2_)    \n",
    "  - 13.3. [数据增广](#toc13_3_)    \n",
    "  - 13.4. [one-hot](#toc13_4_)    \n",
    "  - 13.5. [embedding](#toc13_5_)    \n",
    "  - 13.6. [encode decode架构](#toc13_6_)    \n",
    "  - 13.7. [BN和LN](#toc13_7_)    \n",
    "  - 13.8. [MLP、FC、FNN、CNN、RNN](#toc13_8_)    \n",
    "  - 13.9. [机器学习](#toc13_9_)    \n",
    "  - 13.10. [迁移学习-Transfer learning](#toc13_10_)    \n",
    "    - 13.10.1. [Fine-tuning](#toc13_10_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[概述](#toc0_)\n",
    "写这本书的主要目的是作为学些过程中知识的总结、归纳和反思。作为一个非科班出生的生物人，仅凭着热爱开始了自学深度学习这条路，前路漫漫不敢想，也不曾觉着以后能端这碗饭。只是，羡慕网上像智慧君、李沐这样的人，能够从事如此炫酷的工作，能把自己的热爱开发成一生从事的职业。仔细想想如果自己不做点什么或是不为此努力点什么，就觉得坐立不、安难以入眠。同时深知，这个过程会是无比艰辛，在百无聊赖之际，记录学习的过程或许会是一种苦中作乐的方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id='toc2_'></a>[utils](#toc0_)\n",
    "```shell\n",
    "自定义的一些使用的脚本。\n",
    "```\n",
    "```sehll\n",
    "__init__(self) # 初始化实例时就会执行\n",
    "_call__(self) # 再次调用时，自动执行\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 0.03098917007446289 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "class MyTimer():\n",
    "    '''一个计时器'''\n",
    "    def __init__(self):\n",
    "        self.start = time.time()\n",
    "\n",
    "    def __call__(self):\n",
    "        self.stop = time.time()\n",
    "        seconds = self.stop - self.start\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        print('='*100, '\\n', f\"Total：\\n {days} d \\n {hours} h \\n {minutes} m \\n {remaining_seconds} s\")\n",
    "        \n",
    "# MyTiemr使用\n",
    "timer = MyTimer()\n",
    "for i in range(3):\n",
    "    time.sleep(0.01)\n",
    "timer()\n",
    "\n",
    "class TrainPicture():\n",
    "    '''记录train loss、train acc和test acc的训练过程'''\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id='toc3_'></a>[安装GPU驱动](#toc0_)\n",
    "```shell\n",
    "以CentOS8安装NVIDIA Tesla A100为例；\n",
    "下载CUDA Toolkit和CuDNN，需要注意cudnn的版本必须与cuda的版本相匹配。\n",
    "    1.NVIDIA Driver：NVIDIA驱动是NVIDIA显卡的驱动程序，它是CUDA和CuDNN的前提条件。显卡驱动下载地址：https://www.nvidia.com/Download/index.aspx\n",
    "    2.CUDA Toolkit：CUDA Toolkit是一个开发工具包，其中包含了CUDA编译器、IDE、调试器等工具，以及CUDA程序所需的各种库文件和头文件。CUDA Toolkit还包括NVIDIA驱动程序，但不包括CuDNN1，每个版本的CUDA Toolkit 都对应一个最低版本的显卡驱动版本（CUDA Driver）。\n",
    "    3.NVCC：其实就是CUDA的编译器,可以从CUDA Toolkit的/bin目录中获取,类似于gcc就是c语言的编译器。\n",
    "    4.CUDA Deep Neural Network (cuDNN)：CuDNN是NVIDIA提供的一个深度神经网络加速库，它包含了一系列高性能的基本函数和算法，用于加速深度学习任务的计算。CuDNN需要与CUDA Toolkit一起使用，以优化深度学习任务。\n",
    "```\n",
    "## 3.1. <a id='toc3_1_'></a>[安装策略](#toc0_)\n",
    "```shell\n",
    "方式一：\n",
    "    只安装NVIDIA Tesla A100的driver，每个用户自己利用conda安装CUDA Toolkit、cuDNN和对应的Pytorch版本（推荐），但是得注意选择兼容型号。（推荐）\n",
    "方式二：\n",
    "    安装Driver、CUDA Toolkit (全局安装)\n",
    "方式三：\n",
    "    安装Driver、NVIDIA docker (docker虚拟容器)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. <a id='toc3_2_'></a>[首先确认内核版本和发行版本，再确认显卡型号](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "echo 查看linux内核版本、架构\n",
    "uname -a\n",
    "# Linux 135.91.205.202.cau.edu.cn 4.18.0-147.el8.x86_64 #1 SMP Wed Dec 4 21:51:45 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\n",
    "# x86_64\n",
    "\n",
    "echo 发行版本\n",
    "cat /etc/redhat-release\n",
    "# CentOS Linux release 8.1.1911 (Core)\n",
    "# CentOS\n",
    "\n",
    "echo 显卡型号 （硬件层面）\n",
    "lspci | grep -i nvidia\n",
    "# 04:00.0 3D controller: NVIDIA Corporation GK208M [GeForce GT 730M] (rev a1)\n",
    "\n",
    "echo 验证系统是否安装gcc编译器\n",
    "gcc --version\n",
    "\n",
    "sudo yum install kernel-devel-$(uname -r) kernel-headers-$(uname -r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. <a id='toc3_3_'></a>[安装驱动-CUDA Driver](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. <a id='toc3_3_1_'></a>[下载CUDA Driver](#toc0_)\n",
    "![image.png](attachment:image.png) ![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 从NVIDIA官网下辖\n",
    "# https://www.nvidia.cn/Download/index.aspx?lang=cn\n",
    "\n",
    "# 2. 通过dnf search nvidia*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. <a id='toc3_3_2_'></a>[禁用nouveau](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 貌似在centos8上默认就禁用了，我没改，直接查看了lsmod | grep nouveau命令，发现没有输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. <a id='toc3_3_3_'></a>[安装CUDA Driver](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod a+x *.run\n",
    "!sudo ./*.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4. <a id='toc3_3_4_'></a>[查看显卡是否安装成功](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5. <a id='toc3_3_5_'></a>[查看nvcc](#toc0_)\n",
    "```shell\n",
    "nvcc只是CUDA Toolkit中的一个软件。此时，只是安装了驱动程序，没有安装CUDA Toolkit，所以无法查看nvcc。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvcc' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. <a id='toc3_4_'></a>[CUDA Toolkit和CuDNN](#toc0_)\n",
    "```shell\n",
    "不推荐一开始作为root为Linux全局配置CUDA Toolkit，每个用户和软件使用的CUDA Toolkit版本可能不一样。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. <a id='toc3_4_1_'></a>[下载对应的CUDA Toolkit版本](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc -V # 查看是否安装好CUDA Toolkit\n",
    "\n",
    "wget https://us.download.nvidia.cn/tesla/535.129.03/NVIDIA-Linux-x86_64-535.129.03.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2. <a id='toc3_4_2_'></a>[安装CUDA Toolkit](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# 卸载之前安装的cuda\n",
    "sudo dnf remove nvidia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "chmod +x NVIDIA-Linux-x86_64-535.129.03.run\n",
    "sudo sh NVIDIA-Linux-x86_64-535.129.03.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3. <a id='toc3_4_3_'></a>[下载对应的CuDNN](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://link.zhihu.com/?target=https%3A//developer.nvidia.com/rdp/cudnn-download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4. <a id='toc3_4_4_'></a>[安装CuDNN](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. <a id='toc3_5_'></a>[安装对应版本的Pytorch](#toc0_)\n",
    "```shell\n",
    "在Pytorch的官网进行查询，按照条件检索符合要求的软件版本，最主要的是对应的cuda版本号。\n",
    "```\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# https://pytorch.org/\n",
    "# CUDA 12.1\n",
    "conda create -n pytorch-gpu -y\n",
    "conda activate pytorch-gpu \n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia # CUDA 12.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. <a id='toc3_6_'></a>[GPU测试程序](#toc0_)\n",
    "### 3.6.1. <a id='toc3_6_1_'></a>[测试单机单卡GPU性能](#toc0_)\n",
    "```shell\n",
    "net.to('cuda:0')\n",
    "x_gpu = x.to('cuda:0')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Runing on cpu\n",
      "====================================================================================================\n",
      "epoch 1/10: train_loss=1.5738927125930786, train_acc=90.72000122070312, test_acc=90.97999572753906\n",
      "epoch 2/10: train_loss=1.5443825721740723, train_acc=92.78333282470703, test_acc=92.79000091552734\n",
      "epoch 3/10: train_loss=1.5314069986343384, train_acc=93.82333374023438, test_acc=93.76000213623047\n",
      "epoch 4/10: train_loss=1.5214900970458984, train_acc=94.72167205810547, test_acc=94.36000061035156\n",
      "epoch 5/10: train_loss=1.5167791843414307, train_acc=95.18167114257812, test_acc=94.66000366210938\n",
      "epoch 6/10: train_loss=1.5097272396087646, train_acc=95.79332733154297, test_acc=95.31000518798828\n",
      "epoch 7/10: train_loss=1.5060046911239624, train_acc=96.20333099365234, test_acc=95.59000396728516\n",
      "epoch 8/10: train_loss=1.501900315284729, train_acc=96.54166412353516, test_acc=96.08000183105469\n",
      "epoch 9/10: train_loss=1.4985731840133667, train_acc=96.80833435058594, test_acc=96.34000396728516\n",
      "epoch 10/10: train_loss=1.4947923421859741, train_acc=97.20166778564453, test_acc=96.55999755859375\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 57.46119689941406 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=True, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "test_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=False, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, \n",
    "                             batch_size=128, \n",
    "                             shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "                                     nn.Linear(1024, 10), nn.Softmax())\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device \n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2. <a id='toc3_6_2_'></a>[测试单机多卡GPU性能](#toc0_)\n",
    "```shell\n",
    "torch.nn.DataParallel()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Runing on cpu\n",
      "====================================================================================================\n",
      "epoch 1/10: train_loss=1.564773440361023, train_acc=91.1433334350586, test_acc=91.56999969482422\n",
      "epoch 2/10: train_loss=1.5450105667114258, train_acc=92.69833374023438, test_acc=92.77999877929688\n",
      "epoch 3/10: train_loss=1.5324627161026, train_acc=93.76666259765625, test_acc=93.5999984741211\n",
      "epoch 4/10: train_loss=1.5238758325576782, train_acc=94.40666198730469, test_acc=94.20999908447266\n",
      "epoch 5/10: train_loss=1.515897274017334, train_acc=95.2249984741211, test_acc=94.84000396728516\n",
      "epoch 6/10: train_loss=1.5111769437789917, train_acc=95.68499755859375, test_acc=95.06000518798828\n",
      "epoch 7/10: train_loss=1.5064157247543335, train_acc=96.02333068847656, test_acc=95.52000427246094\n",
      "epoch 8/10: train_loss=1.5023516416549683, train_acc=96.42500305175781, test_acc=95.77000427246094\n",
      "epoch 9/10: train_loss=1.500041127204895, train_acc=96.69667053222656, test_acc=96.02000427246094\n",
      "epoch 10/10: train_loss=1.49596107006073, train_acc=97.05166625976562, test_acc=96.4000015258789\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 26.067356824874878 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=True, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "test_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=False, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, \n",
    "                             batch_size=128, \n",
    "                             shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "                                     nn.Linear(1024, 10), nn.Softmax())\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net = nn.DataParallel(module=net)\n",
    "    net = net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(), y.to()   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device \n",
    "            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = [ 'cpu' if not torch.cuda.is_available() else ]\n",
    "device = [f'cuda:{i}' for i in range(torch.cuda.device_count())] if torch.cuda.is_available() else ['cpu']\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3. <a id='toc3_6_3_'></a>[GPU burn压力测试](#toc0_)\n",
    "```shell\n",
    "李沐在装机配置后，进行GPU压力测试所用的程序为GPU_burn（可从github上下载）\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# Building\n",
    "# To build GPU Burn:\n",
    "make\n",
    "# To remove artifacts built by GPU Burn:\n",
    "make clean\n",
    "# GPU Burn builds with a default Compute Capability of 5.0. To override this with a different value:\n",
    "make COMPUTE=<compute capability value>\n",
    "# CFLAGS can be added when invoking make to add to the default list of compiler flags:\n",
    "make CFLAGS=-Wall\n",
    "# LDFLAGS can be added when invoking make to add to the default list of linker flags:\n",
    "make LDFLAGS=-lmylib\n",
    "# NVCCFLAGS can be added when invoking make to add to the default list of nvcc flags:\n",
    "make NVCCFLAGS=-ccbin <path to host compiler>\n",
    "# CUDAPATH can be added to point to a non standard install or specific version of the cuda toolkit (default is /usr/local/cuda):\n",
    "make CUDAPATH=/usr/local/cuda-<version>\n",
    "# CCPATH can be specified to point to a specific gcc (default is /usr/bin):\n",
    "make CCPATH=/usr/local/bin\n",
    "# CUDA_VERSION and IMAGE_DISTRO can be used to override the base images used when building the Docker image target, while IMAGE_NAME can be set to change the resulting image tag:\n",
    "make IMAGE_NAME=myregistry.private.com/gpu-burn CUDA_VERSION=12.0.1 IMAGE_DISTRO=ubuntu22.04 image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id='toc4_'></a>[Pytorch模块介绍](#toc0_)\n",
    "## 4.1. <a id='toc4_1_'></a>[导入模块](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 线程的数据库\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "\n",
    "# 数据加载\n",
    "import torch.utils.data \n",
    "# import torch.utils.data.TensorDataset\n",
    "import torch.utils.data.dataloader\n",
    "\n",
    "# 神经网络结构\n",
    "import torch.nn \n",
    "import torch.nn.functional \n",
    "\n",
    "import torch.nn.DataParallel\n",
    "import torch.distributed as dist\n",
    "\n",
    "# 优化器\n",
    "import torch.optim \n",
    "\n",
    "import d2l\n",
    "\n",
    "print('pytorch version: ', torch.__version__)\n",
    "print(f\"torchvision version: {torchvision.__version__}\")\n",
    "print(f\"d2l version: {d2l.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. <a id='toc5_'></a>[数据加载](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. <a id='toc5_1_'></a>[现成的数据库-torchvison](#toc0_)\n",
    "```shell\n",
    "tochvision主要处理图像数据，包含一些常用的数据集、模型、转换函数等。  \n",
    "torchvision独立于PyTorch，需要专门安装。\n",
    "\n",
    "torchvision.models: 提供深度学习中各种经典的网络结构、预训练好的模型，如：Alex-Net、VGG、ResNet、Inception等。\n",
    "torchvision.datasets：提供常用的数据集，设计上继承 torch.utils.data.Dataset，主要包括：MNIST、CIFAR10/100、ImageNet、COCO等。\n",
    "torchvision.transforms：提供常用的数据预处理操作，主要包括对Tensor及PIL Image对象的操作。\n",
    "torchvision.utils：工具类，如保存张量作为图像到磁盘，给一个小批量创建一个图像网格。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./Pytorch_datasets/\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./Pytorch_datasets/\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "dbs = './Pytorch_datasets/'\n",
    "\n",
    "trans = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),  # PIL转换为tensor格式\n",
    "                                        # torchvision.transforms.Normalize((0.5,), (1.0,))\n",
    "                                        ])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root=dbs, \n",
    "                                          train=True, \n",
    "                                          download=True,\n",
    "                                          transform=trans, \n",
    "                                        #   target_transform=False\n",
    "                                          )\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root=dbs, \n",
    "                                          train=False, \n",
    "                                          download=True, \n",
    "                                          transform=trans, \n",
    "                                        #   target_transform=False\n",
    "                                          )\n",
    "train_dataset, test_dataset\n",
    "# 封装成torch使用的dataset格式数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       " tensor([9, 0, 0,  ..., 3, 0, 5]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data, train_dataset.targets # 访问"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. <a id='toc5_2_'></a>[自定义数据库](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "# 1. 自建数据集\n",
    "features = \n",
    "labels = \n",
    "\n",
    "# 构建dataset数据集\n",
    "datasets = data.TensorDataset(*(features, labels)) \n",
    "# 加载成batch数据\n",
    "data_iter = data.DataLoader(dataset=datasets, \n",
    "                            batch_size=256, \n",
    "                            shuffle=True, \n",
    "                            num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. <a id='toc5_3_'></a>[Pytorch数据加载](#toc0_)\n",
    "```shell\n",
    "1. 先将自制的数据集利用data.TensorDataset生成dataset；\n",
    "2. 再用data.DataLoader加载到dataset成最终可用的带有batch_size的格式，方便后续的训练\n",
    "\n",
    "3. 先测试以下数据加载的速度，必须比训练计算所耗的时间小，否则将降低训练效率；\n",
    "4. 当数据加载时间很长时可以预加载，缩短时间\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data \n",
    "\n",
    "# 2. 加载torchvison数据集（格式化好的torch.utils.data.Dataset）\n",
    "train_iter = data.DataLoader(dataset=train_dataset, \n",
    "                            batch_size=256, \n",
    "                            shuffle=True,           # 打乱顺序\n",
    "                            num_workers=3           # 线程数\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. <a id='toc5_3_1_'></a>[估计数据加载时间](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 5.080876111984253 s\n"
     ]
    }
   ],
   "source": [
    "# 读完一个epoch的一个batch，耗时\n",
    "timer = MyTimer()\n",
    "for X, y in train_iter:\n",
    "    break \n",
    "timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 7.888774394989014 s\n"
     ]
    }
   ],
   "source": [
    "# 读完一个epoch的所有batch，耗时\n",
    "timer = MyTimer()\n",
    "for X, y in train_iter:\n",
    "    continue \n",
    "timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. <a id='toc6_'></a>[张量(Tensors)](#toc0_)\n",
    "## 6.1. <a id='toc6_1_'></a>[Tensors定义](#toc0_)\n",
    "```\n",
    "Pytorch 的一大作用就是可以代替 Numpy 库，所以首先介绍 Tensors ，也就是张量，它相当于 Numpy 的多维数组(ndarrays)。\n",
    "两者的区别就是：\n",
    "    数学概念：张量Tensors\n",
    "    编程概念：数组Array\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.asarray([1.0, 2.0, 3.0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]]),\n",
       " tensor([[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14]], dtype=torch.int32))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy转tensor\n",
    "import numpy as np\n",
    "x = np.arange(0, 15).reshape(5, 3)\n",
    "x, torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9821e+28, 2.0417e-42, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5, 3) # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(5, 3) # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2723, 0.9452, 0.4822],\n",
       "        [0.5238, 0.9299, 0.5431],\n",
       "        [0.6608, 0.1720, 0.2721],\n",
       "        [0.9852, 0.2298, 0.0329],\n",
       "        [0.2947, 0.4694, 0.1787]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5, 3) # 随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1491,  2.0538,  0.6111,  1.7104,  0.8878, -0.3257,  0.7754,  0.4024,\n",
       "        -0.3722,  0.6816, -0.7800, -1.6328,  0.9139,  1.3536, -0.6945])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(15) # 标准正态分布随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(3) # 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(15).reshape(5, 3) # reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\2358321395.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  x = torch.tensor(torch.range(0, 14).reshape(5, 3))\n",
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\2358321395.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.range(0, 14).reshape(5, 3))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.],\n",
       "         [ 9., 10., 11.],\n",
       "         [12., 13., 14.]]),\n",
       " array([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.],\n",
       "        [12., 13., 14.]], dtype=float32))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor转化为numpy\n",
    "x = torch.tensor(torch.range(0, 14).reshape(5, 3))\n",
    "x, x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. <a id='toc6_2_'></a>[Tensors属性](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8939e-29,  2.1426e-42,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size() # shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. <a id='toc6_3_'></a>[Tensors操作](#toc0_)\n",
    "### 6.3.1. <a id='toc6_3_1_'></a>[索引和切片](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9825e+28, 2.0417e-42, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9825e+28, 2.0417e-42, 0.0000e+00])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # 0行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1] # 1行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9825e+28, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0] # 0列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0417e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1] # 1列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2. <a id='toc6_3_2_'></a>[转置](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.9823e+28, 2.0417e-42, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]),\n",
       " torch.Size([5, 3]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "x, x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.9823e+28, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.0417e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]),\n",
       " torch.Size([3, 5]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.T, x.T.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. <a id='toc6_4_'></a>[线性代数运算](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\1780641904.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  y = torch.tensor(torch.range(0, 14).reshape(5, 3))\n",
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\1780641904.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(torch.range(0, 14).reshape(5, 3))\n",
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\1780641904.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  z = torch.tensor(torch.range(0, 14).reshape(3, 5))\n",
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\1780641904.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = torch.tensor(torch.range(0, 14).reshape(3, 5))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.],\n",
       "         [ 9., 10., 11.],\n",
       "         [12., 13., 14.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5, 3)\n",
    "y = torch.tensor(torch.range(0, 14).reshape(5, 3))\n",
    "z = torch.tensor(torch.range(0, 14).reshape(3, 5))\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [10., 11., 12.],\n",
       "         [13., 14., 15.]]),\n",
       " tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [10., 11., 12.],\n",
       "         [13., 14., 15.]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y, torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.,   0.,  -1.],\n",
       "         [ -2.,  -3.,  -4.],\n",
       "         [ -5.,  -6.,  -7.],\n",
       "         [ -8.,  -9., -10.],\n",
       "         [-11., -12., -13.]]),\n",
       " tensor([[  1.,   0.,  -1.],\n",
       "         [ -2.,  -3.,  -4.],\n",
       "         [ -5.,  -6.,  -7.],\n",
       "         [ -8.,  -9., -10.],\n",
       "         [-11., -12., -13.]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - y, torch.sub(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * 3 # 数乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x, z) # 矩阵相乘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 哈达玛积\n",
    "* 按照**元素**进行乘法\n",
    "* 乘前形状必须相同，乘后不改变形状\n",
    "* x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[ 0,  1,  4],\n",
       "         [ 9, 16, 25]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.arange(6).reshape(2, 3)\n",
    "x, x * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1. <a id='toc6_4_1_'></a>[点积（Dot Product）](#toc0_)\n",
    "* 按照元素进行乘法后相加\n",
    "* 乘前形状一样，乘后**标量**\n",
    "* torch.dot(x, x) # dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor([0, 1, 4]), tensor(5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(3)\n",
    "x, x * x, torch.dot(x, x) # 打印， 哈德玛积， 点积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2. <a id='toc6_4_2_'></a>[矩阵-向量积](#toc0_)\n",
    "* 矩阵乘法的特殊\n",
    "* 乘后**向量**\n",
    "* torch.mv(A, x) # matrix-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([4]), torch.Size([3]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "x = torch.ones(4, dtype=torch.float32)\n",
    "A.shape, x.shape, torch.mv(A, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]),)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * x).shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3. <a id='toc6_4_3_'></a>[矩阵-矩阵积](#toc0_)\n",
    "* 乘后**矩阵**\n",
    "* torch.matmul(X, Y)\n",
    "* torch.mm(X, Y) # matrix-mul\n",
    "* X @ Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]),\n",
       " torch.Size([5, 3]),\n",
       " torch.Size([3, 3]),\n",
       " torch.Size([3, 3]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(15).reshape(3, 5)\n",
    "Y = torch.arange(15).reshape(5, 3)\n",
    "X.shape, Y.shape, (X @ Y).shape, torch.mm(X, Y).shape, torch.matmul(X, Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 乘总结\n",
    "```shell\n",
    "* 哈德玛积      A * B\n",
    "* 点积          dot(A, B)\n",
    "* 矩阵-向量     mv(A, x)\n",
    "* 矩阵-矩阵     mm(A, B) 或 mm(A, B) 或 A @ B\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. <a id='toc6_5_'></a>[自动微积-autograd](#toc0_)\n",
    "```\n",
    "深度学习框架可以自动计算导数：\n",
    "    1. 我们首先将梯度附加到想要对其计算偏导数的变量上， \n",
    "        x.requires_grad_(True)\n",
    "    2. 然后记录目标值的计算，\n",
    "        y = x * x (grad_fn)\n",
    "    3. 执行它的反向传播函数(求梯度)，\n",
    "        y.backward()\n",
    "    4. 并访得到的梯度。 \n",
    "        x.grad\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1. <a id='toc6_5_1_'></a>[自己探索](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.1.1. <a id='toc6_5_1_1_'></a>[标量-一阶导数（得标量）](#toc0_)\n",
    "```shell\n",
    "好像不能求高阶导数，不如jax.grad()灵活\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2., requires_grad=True), tensor(4., grad_fn=<PowBackward0>))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2.0, dtype=torch.float32, requires_grad=True)  # 标量\n",
    "y = x**2                                                        # 标量\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为None\n",
    "x.grad, x.grad == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y对x进行求导\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为2 * 1 = 2\n",
    "x.grad                                                          # 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 2*x # y关于x的一阶导函数就是2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造新的关于x的函数：z = x**3\n",
    "z = x**2\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为：\n",
    "x.grad # 应该为0才对，需要手动清零# x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z关于x求导\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为：\n",
    "x.grad # 应该为4，但是残留的4 + 本次的4 = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.1.2. <a id='toc6_5_1_2_'></a>[标量/向量-一阶导数（得向量）](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0, dtype=torch.float32, requires_grad=True)  # 向量\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14., grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.dot(x,x)                                              # 标量\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad                                                          # 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 2*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.1.3. <a id='toc6_5_1_3_'></a>[向量/向量-一阶导数（得举证）](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2. <a id='toc6_5_2_'></a>[一个简单的例子](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在我们计算关于的梯度之前，需要一个地方来存储梯度。\n",
    "x.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)\n",
    "x.grad                  # 默认值是None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在计算。\n",
    "y = 2 * torch.dot(x, x)\n",
    "y                       # x是一个长度为4的向量，计算x和x的点积，得到了我们赋值给y的标量输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 接下来，通过调用反向传播函数来自动计算y关于x每个分量的梯度，并打印这些梯度。\n",
    "y.backward()            # [4x, 4x, 4x, 4x] 导函数\n",
    "x.grad                  # [4*0, 4*1, 4*2, 4*3] 导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x         # [4x, 4x, 4x, 4x] 导函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3. <a id='toc6_5_3_'></a>[计算另一个](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值\n",
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor(6., grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.4. <a id='toc6_5_4_'></a>[非标量变量的反向传播](#toc0_)\n",
    "```\n",
    "当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵。 对于高阶和高维的y和x，求导的结果可以是一个高阶张量。\n",
    "然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括深度学习中）， 但当调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n",
    "# 本例只想求偏导数的和，所以传递一个1的梯度是合适的\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "# 等价于y.backward(torch.ones(len(x)))\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x * x \n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0.]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad, x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([0., 2., 4., 6.]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum().backward(), x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.5. <a id='toc6_5_5_'></a>[分离计算](#toc0_)\n",
    "```\n",
    "有时，我们希望将某些计算移动到记录的计算图之外。 例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。 想象一下，我们想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数， 并且只考虑到x在y被计算后发挥的作用。\n",
    "\n",
    "这里可以分离y来返回一个新变量u，该变量与y具有相同的值， 但丢弃计算图中如何计算y的任何信息。 换句话说，梯度不会向后流经u到x。 因此，下面的反向传播函数计算z=u*x关于x的偏导数，同时将u作为常数处理， 而不是z=x*x*x关于x的偏导数。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x\n",
    "u = y.detach()\n",
    "z = u * x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由于记录了y的计算结果，我们可以随后在y上调用反向传播， 得到y=x*x关于的x的导数，即2*x。\n",
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.6. <a id='toc6_5_6_'></a>[Python控制流的梯度计算](#toc0_)\n",
    "```\n",
    "使用自动微分的一个好处是： 即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度。 在下面的代码中，while循环的迭代次数和if语句的结果都取决于输入a的值。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让我们计算梯度。\n",
    "a = torch.randn(size=(), requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们现在可以分析上面定义的f函数。 请注意，它在其输入a中是分段线性的。 换言之，对于任何a，存在某个常量标量k，使得f(a)=k*a，其中k的值取决于输入a，因此可以用d/a验证梯度是否正确。\n",
    "a.grad == d / a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6. <a id='toc6_6_'></a>[概率论](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. <a id='toc7_'></a>[神经网络-训练八股](#toc0_)\n",
    "```shell\n",
    "神经网络搭建八股：\n",
    "    1. 定义网络模型\n",
    "        ->计算出y_hat\n",
    "    2. 选择损失函数\n",
    "        ->计算loss值、求梯度\n",
    "    3. 选择优化器\n",
    "        ->更新网络权重参数\n",
    "    4. 训练\n",
    "        ->实施1、2、3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. <a id='toc7_1_'></a>[现线性回归模型于训练过程-从零开始](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1. <a id='toc7_1_1_'></a>[虚拟出数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([0.1456, 0.6208]) \n",
      "label: tensor([2.3813])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import random\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"生成y=Xw+b+噪声\"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "\n",
    "print('features:', features[0],'\\nlabel:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"231.442187pt\" height=\"169.678125pt\" viewBox=\"0 0 231.442187 169.678125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-12-24T22:06:12.221164</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 169.678125 \n",
       "L 231.442187 169.678125 \n",
       "L 231.442187 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "L 28.942188 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"mafb3b7f13b\" d=\"M 0 0.5 \n",
       "C 0.132602 0.5 0.25979 0.447317 0.353553 0.353553 \n",
       "C 0.447317 0.25979 0.5 0.132602 0.5 0 \n",
       "C 0.5 -0.132602 0.447317 -0.25979 0.353553 -0.353553 \n",
       "C 0.25979 -0.447317 0.132602 -0.5 0 -0.5 \n",
       "C -0.132602 -0.5 -0.25979 -0.447317 -0.353553 -0.353553 \n",
       "C -0.447317 -0.25979 -0.5 -0.132602 -0.5 0 \n",
       "C -0.5 0.132602 -0.447317 0.25979 -0.353553 0.353553 \n",
       "C -0.25979 0.447317 -0.132602 0.5 0 0.5 \n",
       "z\n",
       "\" style=\"stroke: #1f77b4\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p90ff8178db)\">\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.855178\" y=\"86.560171\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.77098\" y=\"100.444328\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.974742\" y=\"69.739166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.589452\" y=\"93.225276\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"156.128421\" y=\"97.857122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.877595\" y=\"67.832642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.381371\" y=\"75.165856\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"166.593137\" y=\"114.49919\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.629944\" y=\"110.827633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.043093\" y=\"66.330904\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.226529\" y=\"108.243491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.389337\" y=\"72.548968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.432001\" y=\"62.221611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.521325\" y=\"78.911158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"174.439984\" y=\"99.145236\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.316404\" y=\"75.310057\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.119424\" y=\"70.944081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.593353\" y=\"47.879469\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.550727\" y=\"81.875043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.726437\" y=\"77.629306\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.09976\" y=\"100.507817\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"156.366486\" y=\"104.420866\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.115416\" y=\"76.738185\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.112725\" y=\"69.484402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.191489\" y=\"54.72236\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.34944\" y=\"80.072299\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.216021\" y=\"79.283392\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.889322\" y=\"84.838633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.502982\" y=\"75.122788\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.619577\" y=\"99.847867\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.126936\" y=\"72.115602\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.797464\" y=\"99.84199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.895668\" y=\"53.330821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.416993\" y=\"68.33721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.064343\" y=\"87.477465\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.042363\" y=\"83.70824\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"75.969503\" y=\"42.379578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.590527\" y=\"96.997053\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.789533\" y=\"60.353805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.546723\" y=\"71.086023\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.43529\" y=\"95.525847\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.372278\" y=\"71.995264\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.941746\" y=\"68.148722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.761329\" y=\"66.32105\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"172.99687\" y=\"100.542334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"198.067272\" y=\"131.468994\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.544663\" y=\"37.657081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.974595\" y=\"82.797923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.390258\" y=\"85.100996\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.29525\" y=\"83.8968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.108296\" y=\"83.629538\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"80.70032\" y=\"52.771182\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.748066\" y=\"58.715203\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.549158\" y=\"65.098382\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.248799\" y=\"48.015701\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"181.728868\" y=\"121.994921\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.394642\" y=\"87.265383\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.182022\" y=\"65.475991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.703086\" y=\"86.255392\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.074063\" y=\"73.096907\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.415488\" y=\"85.65443\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.716789\" y=\"85.961071\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.572666\" y=\"70.794755\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.682733\" y=\"74.845712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.460722\" y=\"70.108676\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"174.018126\" y=\"117.798398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.554264\" y=\"86.968223\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"101.429928\" y=\"46.014455\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.276435\" y=\"87.941624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.463549\" y=\"106.992745\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"189.859793\" y=\"122.984031\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.373337\" y=\"60.722805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"178.884629\" y=\"105.882054\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"53.351693\" y=\"28.239491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"55.571112\" y=\"37.60902\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.869529\" y=\"76.269144\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.975431\" y=\"59.532278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.985322\" y=\"65.316468\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.257857\" y=\"92.847639\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.758244\" y=\"72.716884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.49281\" y=\"130.376514\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.216983\" y=\"61.45494\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.392418\" y=\"48.622394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"192.253483\" y=\"113.656616\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.571734\" y=\"73.427866\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.465782\" y=\"55.067106\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"193.050015\" y=\"116.038637\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.474827\" y=\"66.980975\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.067976\" y=\"61.221955\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.666821\" y=\"91.797638\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.082085\" y=\"97.556625\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"187.318643\" y=\"97.02529\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.722339\" y=\"64.011906\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.454779\" y=\"58.318228\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.791424\" y=\"113.935706\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.283623\" y=\"85.485447\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.832517\" y=\"65.484322\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"181.142563\" y=\"107.521857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"49.422117\" y=\"36.738685\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"91.678241\" y=\"53.498613\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.607011\" y=\"61.636102\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.037047\" y=\"57.373076\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.823989\" y=\"61.765317\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.507757\" y=\"91.195493\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.476326\" y=\"64.680833\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.124296\" y=\"77.225925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.050317\" y=\"51.776811\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.056592\" y=\"74.730062\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.703666\" y=\"99.898693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.974219\" y=\"95.475022\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.956885\" y=\"75.080933\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.546582\" y=\"76.166429\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"71.817981\" y=\"33.972126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.774171\" y=\"62.981683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.560983\" y=\"86.623165\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.610356\" y=\"73.286708\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.043526\" y=\"52.512241\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.650877\" y=\"53.505349\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.36819\" y=\"87.635155\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"123.300714\" y=\"60.364324\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.752003\" y=\"82.431614\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.089043\" y=\"64.55916\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"210.029656\" y=\"110.407538\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.999858\" y=\"86.947507\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"78.343746\" y=\"48.848016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.590804\" y=\"90.346289\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.46743\" y=\"71.133828\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.662841\" y=\"48.93122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.349625\" y=\"51.947957\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.740974\" y=\"91.27525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.822096\" y=\"100.475046\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.922944\" y=\"80.361628\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"165.032136\" y=\"93.740499\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.202188\" y=\"67.038157\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.828073\" y=\"92.918334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.714894\" y=\"84.307748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.394938\" y=\"82.12693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.271788\" y=\"88.997754\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.078977\" y=\"72.632487\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.974468\" y=\"83.739874\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.10531\" y=\"87.405128\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.831268\" y=\"74.08886\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"160.421842\" y=\"104.949148\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.484304\" y=\"71.55952\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"91.397035\" y=\"84.240968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.127325\" y=\"73.08601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.885075\" y=\"71.102861\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.717104\" y=\"63.270871\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.591864\" y=\"69.475626\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.023713\" y=\"95.644997\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.755591\" y=\"84.781609\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.298101\" y=\"73.883721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.123269\" y=\"85.492181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.406859\" y=\"94.801738\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.374251\" y=\"91.893735\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"71.58281\" y=\"50.022076\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.69833\" y=\"73.063769\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"166.726472\" y=\"102.655169\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.166001\" y=\"81.646603\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.425843\" y=\"69.342389\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.47983\" y=\"68.607274\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.316334\" y=\"77.608487\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.641091\" y=\"88.542797\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.281237\" y=\"67.828716\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.380281\" y=\"55.049052\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.569736\" y=\"73.457505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.727591\" y=\"67.844879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.239423\" y=\"80.679932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.758102\" y=\"63.648262\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.796691\" y=\"89.090325\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.557766\" y=\"78.837713\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.809626\" y=\"101.210202\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.062881\" y=\"105.662219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"185.942907\" y=\"118.908359\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.497911\" y=\"56.324936\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.450482\" y=\"85.032803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"160.075777\" y=\"96.929977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.69867\" y=\"90.174725\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.873647\" y=\"94.106053\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.534513\" y=\"89.233448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.280354\" y=\"54.503447\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.084685\" y=\"93.852838\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.277726\" y=\"66.694849\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.414944\" y=\"77.417695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.155378\" y=\"66.431945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.720155\" y=\"89.038361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"156.215759\" y=\"91.903109\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.77371\" y=\"78.987995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.83596\" y=\"75.614026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.331164\" y=\"77.898018\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.047103\" y=\"81.242846\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.745199\" y=\"92.745032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"69.72842\" y=\"49.653991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.457373\" y=\"88.976351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.605311\" y=\"54.6592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.071328\" y=\"93.808389\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.033176\" y=\"63.664637\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.493558\" y=\"85.452207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.092945\" y=\"81.256449\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.047198\" y=\"51.558937\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.348048\" y=\"39.61165\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.8802\" y=\"96.034834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"101.913393\" y=\"55.818987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.862653\" y=\"68.615784\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"186.681578\" y=\"101.835356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.880545\" y=\"74.289874\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.02702\" y=\"68.474065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.476797\" y=\"88.147544\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.740242\" y=\"86.522519\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.430283\" y=\"74.31225\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.659817\" y=\"33.156947\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.317171\" y=\"54.912356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.27287\" y=\"88.450929\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.194385\" y=\"76.143327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.92373\" y=\"85.797223\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.038232\" y=\"95.733247\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.073734\" y=\"50.027847\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"54.640735\" y=\"35.41094\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.089634\" y=\"91.994584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.080546\" y=\"107.182817\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.379525\" y=\"47.843787\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.585782\" y=\"90.871254\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.111644\" y=\"87.755626\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.648291\" y=\"72.692302\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.407254\" y=\"103.369901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.035908\" y=\"93.159714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.21035\" y=\"92.0972\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.361138\" y=\"92.906851\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.140984\" y=\"84.512175\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.966509\" y=\"92.704814\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.384542\" y=\"70.417031\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"86.436747\" y=\"54.841995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.64\" y=\"77.331586\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"87.665212\" y=\"60.697736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"179.928433\" y=\"120.73875\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.761417\" y=\"91.251022\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.336099\" y=\"54.359757\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.192027\" y=\"76.131913\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"160.789782\" y=\"99.364532\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.074054\" y=\"67.567098\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.218077\" y=\"52.454352\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.851752\" y=\"88.255752\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.670222\" y=\"88.004706\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.867695\" y=\"87.150704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.84146\" y=\"82.335199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.316621\" y=\"78.993743\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.326625\" y=\"58.733\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.099735\" y=\"55.103665\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.231236\" y=\"62.199428\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.735701\" y=\"67.280972\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.647281\" y=\"80.904412\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"86.169234\" y=\"61.602583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.234011\" y=\"72.853523\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.398689\" y=\"71.994761\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.633394\" y=\"97.133887\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.495644\" y=\"62.873499\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.136218\" y=\"111.853683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.882119\" y=\"92.053456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.860246\" y=\"89.68266\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.252076\" y=\"103.514292\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.471147\" y=\"54.509279\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.705965\" y=\"81.503291\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.320374\" y=\"94.0557\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"70.007271\" y=\"58.436724\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.425384\" y=\"84.967633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.398614\" y=\"68.925504\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.629152\" y=\"82.60452\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.836359\" y=\"61.686297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.823263\" y=\"81.09651\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.160508\" y=\"70.683557\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.052675\" y=\"97.712257\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.178\" y=\"75.291492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.719098\" y=\"57.050864\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"78.838824\" y=\"56.407414\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.413117\" y=\"105.811029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.35705\" y=\"39.427734\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.18858\" y=\"75.262173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.046664\" y=\"71.371556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.304945\" y=\"86.574687\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.087558\" y=\"72.845909\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.265709\" y=\"86.717398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.328266\" y=\"99.99668\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"91.504388\" y=\"63.832559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.521201\" y=\"90.461491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.67667\" y=\"79.711648\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.062092\" y=\"82.348441\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.123937\" y=\"73.257331\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"71.382936\" y=\"56.435486\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"92.930488\" y=\"80.031692\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"69.832452\" y=\"39.826381\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.262287\" y=\"91.333923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.894394\" y=\"70.213758\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.5975\" y=\"73.964499\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.488881\" y=\"109.360436\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.053755\" y=\"73.441148\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.199752\" y=\"63.649739\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.763355\" y=\"69.860579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.086244\" y=\"85.589296\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.712868\" y=\"74.00906\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.536567\" y=\"103.414602\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.622974\" y=\"97.621516\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.88117\" y=\"51.276698\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.601342\" y=\"63.240578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.040476\" y=\"93.285939\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.539296\" y=\"67.799196\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.053298\" y=\"79.092101\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.104001\" y=\"67.398136\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.991377\" y=\"112.984702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.145845\" y=\"76.288476\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.644547\" y=\"95.184044\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.3539\" y=\"108.570025\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.032948\" y=\"84.303226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.980176\" y=\"88.460122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.775706\" y=\"72.726118\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.778309\" y=\"70.672921\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.822453\" y=\"60.060502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.173974\" y=\"77.168622\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.134945\" y=\"93.978861\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.601208\" y=\"84.633759\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.200394\" y=\"81.927413\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.99422\" y=\"81.128843\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.492664\" y=\"78.838212\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.217204\" y=\"90.950346\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.91033\" y=\"56.163931\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.859701\" y=\"58.923157\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.022203\" y=\"70.114615\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"153.057224\" y=\"87.543799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.219294\" y=\"89.616032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.917526\" y=\"96.044954\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"186.920677\" y=\"115.134938\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.53031\" y=\"95.149919\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"153.009812\" y=\"77.895693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.366344\" y=\"87.351166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"156.167128\" y=\"85.771466\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.407892\" y=\"83.742721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.762337\" y=\"72.152111\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.318211\" y=\"97.315038\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.83494\" y=\"44.134327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.494669\" y=\"64.641583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.860221\" y=\"62.05387\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"203.649684\" y=\"125.680246\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.648903\" y=\"62.820517\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"178.65501\" y=\"90.017958\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.023363\" y=\"58.491047\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.27518\" y=\"74.793282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"123.50203\" y=\"82.541748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.417982\" y=\"64.552699\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.407499\" y=\"90.09559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.504912\" y=\"59.517263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.301841\" y=\"65.802786\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.133634\" y=\"66.033224\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.143215\" y=\"71.997197\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.440896\" y=\"81.281118\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.69893\" y=\"89.580945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.981898\" y=\"93.848166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.117522\" y=\"82.535379\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.982365\" y=\"74.528934\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.894864\" y=\"78.562288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.575206\" y=\"86.862247\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.158894\" y=\"39.707633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.11277\" y=\"79.014475\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.250241\" y=\"97.297373\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"80.551414\" y=\"48.62045\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"69.150047\" y=\"45.853712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.550173\" y=\"28.326482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"185.580207\" y=\"114.109405\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.464205\" y=\"90.327952\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.224301\" y=\"67.371505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.184582\" y=\"81.178304\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.063268\" y=\"64.392287\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.545451\" y=\"89.387934\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.873684\" y=\"57.870188\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.718786\" y=\"100.658835\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.418433\" y=\"76.655672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.769597\" y=\"95.430922\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"166.879986\" y=\"92.245573\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.434279\" y=\"86.758893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"56.934144\" y=\"38.980355\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.714151\" y=\"77.763025\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.766946\" y=\"80.900955\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.346628\" y=\"66.429213\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.179679\" y=\"88.116118\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.564632\" y=\"88.816355\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.911806\" y=\"84.751142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.063996\" y=\"93.478798\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.241849\" y=\"76.627511\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.040624\" y=\"57.804399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"193.270465\" y=\"109.099886\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.713542\" y=\"62.978292\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.717268\" y=\"63.47266\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.698091\" y=\"85.239161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.356281\" y=\"64.512591\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"180.373525\" y=\"104.50704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.4927\" y=\"60.412998\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.518992\" y=\"86.457387\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.68571\" y=\"98.994692\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.163265\" y=\"66.270813\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.244924\" y=\"120.613347\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.069954\" y=\"87.352016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.329299\" y=\"68.14482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.495904\" y=\"80.112351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.752566\" y=\"93.405455\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.604799\" y=\"66.410412\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.525774\" y=\"80.293978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.91489\" y=\"99.67341\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"85.345272\" y=\"50.540142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.264773\" y=\"80.731016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.747819\" y=\"71.987721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.313751\" y=\"101.119821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"59.850893\" y=\"45.081892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.049936\" y=\"71.462255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"180.994376\" y=\"117.695672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.545242\" y=\"103.760052\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.43372\" y=\"70.93977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"80.067053\" y=\"57.601496\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"85.872625\" y=\"43.786461\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"178.338119\" y=\"102.541064\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.184404\" y=\"65.51085\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.380472\" y=\"69.702594\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"73.860884\" y=\"56.27751\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.677165\" y=\"77.364903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.943663\" y=\"47.503995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"186.482778\" y=\"87.879143\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.457569\" y=\"94.46482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.13735\" y=\"73.737452\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.757528\" y=\"83.33317\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.65698\" y=\"102.529642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.747338\" y=\"102.857885\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.981687\" y=\"89.591659\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.121408\" y=\"80.705004\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.104164\" y=\"74.605814\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.780364\" y=\"69.5771\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.621896\" y=\"49.098704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.656078\" y=\"77.659877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"86.055945\" y=\"53.75328\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.722442\" y=\"104.21321\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.726726\" y=\"98.990361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.796008\" y=\"77.820071\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.796818\" y=\"63.838301\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.856553\" y=\"62.832816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.093813\" y=\"72.549384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.399527\" y=\"66.991257\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.131627\" y=\"90.962576\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.733067\" y=\"83.054664\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.253167\" y=\"92.703946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.167077\" y=\"56.12621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.570036\" y=\"102.002617\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.733622\" y=\"67.842124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"178.431948\" y=\"113.820624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.401344\" y=\"78.671175\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.34199\" y=\"95.182191\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.84666\" y=\"83.10226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.895487\" y=\"70.38906\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.533345\" y=\"55.814512\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.4651\" y=\"59.514054\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.502376\" y=\"63.199828\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.422421\" y=\"70.277575\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.222997\" y=\"101.642396\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"88.194028\" y=\"49.608191\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.011539\" y=\"107.254235\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.18125\" y=\"73.537885\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.256823\" y=\"52.417549\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"123.852231\" y=\"91.740915\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.549731\" y=\"67.596396\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.582907\" y=\"79.797749\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.476643\" y=\"93.748964\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.454348\" y=\"93.598672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"176.635087\" y=\"108.487228\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.077607\" y=\"86.630994\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.906575\" y=\"101.628971\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"167.797845\" y=\"106.790483\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"69.118458\" y=\"38.99948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.386105\" y=\"70.009451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.952056\" y=\"78.03741\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"92.150291\" y=\"48.013261\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"209.840512\" y=\"130.20145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.116943\" y=\"72.721918\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.811761\" y=\"54.267946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.005825\" y=\"74.775974\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.550855\" y=\"76.597755\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.529948\" y=\"95.241427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.977207\" y=\"83.329908\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"163.121682\" y=\"96.334464\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.988902\" y=\"44.435415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.730487\" y=\"95.688754\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.959448\" y=\"89.882028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.157453\" y=\"73.169269\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.282027\" y=\"78.880037\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.503006\" y=\"81.431474\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.956124\" y=\"27.066695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.891937\" y=\"100.357543\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.59888\" y=\"79.693753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"83.571003\" y=\"58.469216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"215.364915\" y=\"127.85492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.584849\" y=\"96.966151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.318089\" y=\"82.300135\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.510389\" y=\"79.794045\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.538687\" y=\"67.406444\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.031827\" y=\"83.226934\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.981032\" y=\"70.722808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"176.981523\" y=\"105.624911\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.61736\" y=\"58.931855\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"73.142329\" y=\"45.947931\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.718652\" y=\"96.008379\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.926972\" y=\"60.906942\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.881458\" y=\"60.288005\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.543753\" y=\"87.30287\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.268741\" y=\"83.600445\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"78.521069\" y=\"41.99808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.864474\" y=\"77.91869\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.017892\" y=\"80.481522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.455392\" y=\"73.696664\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.749503\" y=\"88.149684\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.567885\" y=\"63.129617\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.216146\" y=\"74.808058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.708365\" y=\"88.382695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.374763\" y=\"56.821364\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.191988\" y=\"70.76777\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.670422\" y=\"73.963499\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.110521\" y=\"90.500515\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.503507\" y=\"72.137806\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.192675\" y=\"83.592338\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"70.304373\" y=\"34.158846\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.12028\" y=\"72.573789\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.148157\" y=\"69.850139\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.210137\" y=\"79.472293\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.260159\" y=\"84.332827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.752112\" y=\"122.404292\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.623714\" y=\"79.17048\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.361534\" y=\"65.28977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.582777\" y=\"83.854131\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.154201\" y=\"85.206821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.588689\" y=\"64.619421\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.792243\" y=\"100.999558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.268801\" y=\"101.429823\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.666159\" y=\"64.416901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.88354\" y=\"87.216013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.820924\" y=\"60.267343\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.239587\" y=\"76.772531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.225785\" y=\"84.282976\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.058535\" y=\"75.479935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.386995\" y=\"63.77521\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.215501\" y=\"82.245668\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.246958\" y=\"66.944416\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.001543\" y=\"73.790225\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.206018\" y=\"53.694945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.635205\" y=\"67.862409\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.124865\" y=\"88.62203\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.274608\" y=\"82.745465\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.134912\" y=\"79.86842\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"210.120579\" y=\"139.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.635031\" y=\"82.551013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.595741\" y=\"84.691161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.406946\" y=\"96.506347\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.217814\" y=\"69.96511\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.000116\" y=\"52.049965\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.406702\" y=\"81.240142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"177.530131\" y=\"104.528011\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.855941\" y=\"63.703369\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.258559\" y=\"92.530693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.012702\" y=\"106.253605\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.064109\" y=\"70.662947\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.28221\" y=\"68.261259\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.96706\" y=\"65.18813\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"72.471718\" y=\"43.593602\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.568965\" y=\"63.756909\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"177.958253\" y=\"109.17915\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.284079\" y=\"78.1838\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.452006\" y=\"68.408543\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"75.953394\" y=\"35.373375\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.458822\" y=\"86.578298\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"87.528023\" y=\"46.755767\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.669687\" y=\"72.369525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.322236\" y=\"46.050664\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"91.539021\" y=\"60.500666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.873193\" y=\"105.755177\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.589007\" y=\"70.02036\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.324556\" y=\"61.009935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"80.010104\" y=\"32.551357\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"74.288624\" y=\"24.336056\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.201643\" y=\"67.316772\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.26351\" y=\"53.471221\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.14429\" y=\"56.730499\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.509687\" y=\"96.264392\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.556996\" y=\"83.28568\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.89438\" y=\"87.306244\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.615961\" y=\"100.286689\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.288729\" y=\"64.252809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.732226\" y=\"90.890571\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"85.778688\" y=\"47.970673\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.340655\" y=\"56.073742\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.889678\" y=\"58.131371\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.012367\" y=\"76.280917\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.425061\" y=\"64.320065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.351814\" y=\"96.494393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.491177\" y=\"66.847155\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.509008\" y=\"97.585068\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"92.321238\" y=\"67.105825\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.269392\" y=\"78.962391\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.626629\" y=\"78.264148\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.828677\" y=\"81.85782\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.21269\" y=\"57.428075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.885466\" y=\"106.110086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.925933\" y=\"72.17456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.594875\" y=\"71.462377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.2624\" y=\"68.158346\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"64.514532\" y=\"36.946933\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.091179\" y=\"99.726884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"174.253418\" y=\"93.23641\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.23\" y=\"75.255368\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"65.217911\" y=\"37.559002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.356088\" y=\"80.602058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.189968\" y=\"55.175359\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"62.96026\" y=\"50.057955\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.026718\" y=\"70.346498\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.527509\" y=\"90.640747\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.413088\" y=\"65.729884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.233924\" y=\"81.970409\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.577559\" y=\"67.505026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.772014\" y=\"82.899963\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.845821\" y=\"102.406688\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.562442\" y=\"114.534875\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"88.190116\" y=\"42.760153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.737993\" y=\"61.34062\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.250066\" y=\"92.234429\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.767617\" y=\"90.054583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.150306\" y=\"76.577412\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.479531\" y=\"94.614714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.008533\" y=\"91.436795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.5827\" y=\"95.058987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.918824\" y=\"72.379217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.073613\" y=\"69.515174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.568888\" y=\"64.961155\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.915916\" y=\"65.197114\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.78686\" y=\"52.868089\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"76.233259\" y=\"47.694624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"77.735619\" y=\"44.210211\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.950854\" y=\"74.838937\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.970388\" y=\"81.138806\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.429932\" y=\"78.538743\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.861431\" y=\"81.404076\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.169048\" y=\"82.227584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.100895\" y=\"79.798964\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.321305\" y=\"64.934147\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.453211\" y=\"74.611401\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.794146\" y=\"78.266666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.021139\" y=\"86.248369\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.718087\" y=\"80.8348\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.618833\" y=\"71.369759\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.37592\" y=\"64.315142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"46.253667\" y=\"26.163565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.394197\" y=\"83.863015\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.899078\" y=\"93.301888\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.639917\" y=\"104.231472\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.827474\" y=\"83.31291\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.239341\" y=\"85.240781\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.781298\" y=\"72.559714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.926605\" y=\"60.919121\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"163.906565\" y=\"122.878621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.832396\" y=\"64.024531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.109992\" y=\"40.011423\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.011091\" y=\"95.436527\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.134518\" y=\"87.521508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"83.403468\" y=\"29.530857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.304645\" y=\"66.774683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"77.249923\" y=\"51.523627\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.088311\" y=\"95.074449\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.994278\" y=\"90.65641\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.039313\" y=\"78.777321\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.000141\" y=\"113.628631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.449255\" y=\"57.140028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"174.859795\" y=\"91.043108\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.79393\" y=\"87.101574\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.746067\" y=\"33.022682\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"156.569381\" y=\"85.361997\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.793921\" y=\"93.841941\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.690685\" y=\"69.491607\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.437542\" y=\"45.81514\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.53944\" y=\"72.901315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.07235\" y=\"68.093603\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.920107\" y=\"71.426769\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"92.812769\" y=\"51.741378\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.665501\" y=\"85.759923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"180.871668\" y=\"92.58811\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.62019\" y=\"50.529159\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.193346\" y=\"79.457705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.053976\" y=\"55.322431\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.018184\" y=\"47.382136\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.33899\" y=\"64.804031\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.623402\" y=\"82.940039\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.166829\" y=\"66.291561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.092738\" y=\"72.767532\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.85284\" y=\"66.453866\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.139907\" y=\"104.484621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.777015\" y=\"103.843695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.27105\" y=\"74.040565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.066234\" y=\"68.200107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.266155\" y=\"85.337984\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.813781\" y=\"78.450493\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"52.85775\" y=\"20.126956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.26998\" y=\"60.072874\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.4008\" y=\"55.864695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.816233\" y=\"84.668693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.174204\" y=\"64.763244\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.572859\" y=\"83.204703\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.736658\" y=\"66.281297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.18742\" y=\"82.348732\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.304637\" y=\"61.956149\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"167.511118\" y=\"82.471174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.001409\" y=\"83.006589\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.526794\" y=\"95.271191\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.179198\" y=\"44.864344\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.799434\" y=\"69.191106\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.677328\" y=\"87.313417\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.882415\" y=\"76.918855\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"153.45697\" y=\"89.12334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.540933\" y=\"77.867091\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.14314\" y=\"90.085445\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.268725\" y=\"56.76761\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.199125\" y=\"55.49814\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.604844\" y=\"46.698911\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.75421\" y=\"95.917279\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.401362\" y=\"64.360735\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.690481\" y=\"87.852081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.78844\" y=\"114.784169\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"87.691288\" y=\"56.384999\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.851424\" y=\"109.662351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.268769\" y=\"75.839349\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"184.436989\" y=\"119.348842\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.67617\" y=\"103.423393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.864568\" y=\"83.560609\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.844234\" y=\"121.684714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"87.997471\" y=\"60.040637\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.583393\" y=\"59.730345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.379903\" y=\"84.822126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.063518\" y=\"107.025239\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.473541\" y=\"67.68576\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.108038\" y=\"78.170584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.052535\" y=\"94.73705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.294692\" y=\"98.723513\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.272066\" y=\"108.521956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"175.16134\" y=\"112.621842\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.496551\" y=\"64.704194\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"63.220077\" y=\"58.103042\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.338406\" y=\"54.251711\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.84368\" y=\"46.115888\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.303094\" y=\"58.253671\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.651029\" y=\"47.413254\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.875295\" y=\"101.766347\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.639938\" y=\"90.684068\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.547984\" y=\"100.947603\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"54.19993\" y=\"37.228854\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"37.81946\" y=\"13.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.320799\" y=\"62.212522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.026146\" y=\"79.576125\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.2641\" y=\"60.369902\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.178387\" y=\"96.161797\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.196468\" y=\"72.510704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.514879\" y=\"66.193771\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.10013\" y=\"62.539473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"168.331458\" y=\"108.062402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"61.654839\" y=\"30.370362\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.625664\" y=\"84.129354\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.937366\" y=\"68.164127\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.026724\" y=\"44.70901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"83.801555\" y=\"56.6427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.175146\" y=\"83.018071\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.862137\" y=\"75.776002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.243355\" y=\"81.56418\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.160526\" y=\"58.900636\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.285399\" y=\"80.091573\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.00158\" y=\"78.686854\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.387301\" y=\"90.981526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"168.375927\" y=\"106.039051\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.452521\" y=\"65.231451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.562604\" y=\"83.469644\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"63.322325\" y=\"43.465163\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.580982\" y=\"87.967192\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.605207\" y=\"105.955534\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.741936\" y=\"70.466967\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"185.3351\" y=\"100.834601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"160.492771\" y=\"94.752381\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.251341\" y=\"64.415833\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.619251\" y=\"95.306447\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.967609\" y=\"64.387757\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.830021\" y=\"64.411677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.087688\" y=\"97.156016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"76.280937\" y=\"50.618691\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.020354\" y=\"79.380221\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.333742\" y=\"88.730242\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.967983\" y=\"88.000783\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.553728\" y=\"92.764272\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.637162\" y=\"56.021096\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.256336\" y=\"96.232151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.717962\" y=\"82.777677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.646616\" y=\"107.424107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.163221\" y=\"95.247416\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.717959\" y=\"71.212125\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.309545\" y=\"85.84556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.059568\" y=\"55.979455\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.192151\" y=\"79.140434\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.976636\" y=\"68.722251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.549518\" y=\"93.772192\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.497996\" y=\"77.720104\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.860408\" y=\"78.704869\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"153.841274\" y=\"99.397877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.170461\" y=\"60.852135\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.979021\" y=\"73.46474\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.972798\" y=\"80.964895\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.239845\" y=\"82.494235\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.729652\" y=\"79.004252\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.574715\" y=\"74.512318\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.719282\" y=\"88.724309\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.682875\" y=\"63.402481\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.154448\" y=\"56.427495\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.559014\" y=\"94.818932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.592238\" y=\"78.837399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.977271\" y=\"72.226384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.031731\" y=\"61.079786\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"166.171529\" y=\"100.078199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"101.666235\" y=\"70.233892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.833515\" y=\"84.820575\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.223933\" y=\"72.385714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"184.178558\" y=\"111.211049\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.849727\" y=\"83.236522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.732939\" y=\"84.575377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"165.532339\" y=\"100.815533\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.1149\" y=\"83.879521\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.538848\" y=\"80.551326\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.570327\" y=\"59.245341\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"85.40019\" y=\"65.165079\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.249415\" y=\"98.157858\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.421797\" y=\"80.252616\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"74.975928\" y=\"37.16886\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.232533\" y=\"86.77948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.540874\" y=\"93.533399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.791999\" y=\"117.41122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.202544\" y=\"53.91224\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.192344\" y=\"70.148955\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.361993\" y=\"58.979796\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"185.134341\" y=\"113.606672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.662793\" y=\"75.891954\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.009735\" y=\"91.015395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.003778\" y=\"47.469871\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.773919\" y=\"67.407023\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.932252\" y=\"38.205126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.685057\" y=\"104.879705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.330928\" y=\"69.555583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"163.830973\" y=\"100.839111\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"92.531262\" y=\"50.374546\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.949728\" y=\"79.325563\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.968272\" y=\"55.536956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.058441\" y=\"94.663151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.21505\" y=\"74.944517\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.54402\" y=\"88.397437\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.662934\" y=\"106.625645\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.702914\" y=\"88.0265\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"49.455065\" y=\"26.7305\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.304487\" y=\"50.923667\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.427527\" y=\"70.465158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.489395\" y=\"64.11137\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"75.205949\" y=\"49.392472\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.706319\" y=\"59.095893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.558088\" y=\"99.410966\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.573135\" y=\"88.145579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"213.385792\" y=\"138.394026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.044429\" y=\"89.984565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.434731\" y=\"76.868931\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.367501\" y=\"75.691447\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.314283\" y=\"33.718198\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.894848\" y=\"41.419486\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.466441\" y=\"87.464103\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"160.842223\" y=\"95.155736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.599543\" y=\"52.933722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.949495\" y=\"95.746645\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.76022\" y=\"73.000899\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.866094\" y=\"60.962329\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.894822\" y=\"57.448225\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.369708\" y=\"87.892423\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"180.473547\" y=\"117.27612\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.833448\" y=\"69.093638\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.972878\" y=\"106.93397\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.7554\" y=\"107.802266\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.328711\" y=\"85.965351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.137213\" y=\"67.479179\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.860737\" y=\"63.044124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.979929\" y=\"101.270955\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.589389\" y=\"62.848237\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"73.357038\" y=\"35.67268\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.45552\" y=\"71.835404\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.726037\" y=\"82.974294\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"101.720395\" y=\"58.648073\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"70.340977\" y=\"28.163051\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.876799\" y=\"109.012584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.16379\" y=\"58.207545\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.664724\" y=\"75.628147\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.341011\" y=\"73.012979\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.595885\" y=\"85.706008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.817165\" y=\"93.673445\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.309918\" y=\"78.04203\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.331517\" y=\"46.485214\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.512833\" y=\"78.760711\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.15384\" y=\"102.733558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.489489\" y=\"90.786431\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.973636\" y=\"74.235309\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.58015\" y=\"79.823807\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.898748\" y=\"51.377557\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.971962\" y=\"85.681529\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.32055\" y=\"76.398744\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.905961\" y=\"75.38737\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.847861\" y=\"66.768525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.928662\" y=\"82.88218\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.475827\" y=\"71.748379\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.528036\" y=\"69.6817\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.684282\" y=\"97.994216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.298089\" y=\"78.611319\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.780943\" y=\"78.702865\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.005251\" y=\"77.471086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.835305\" y=\"102.397057\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"61.751121\" y=\"44.661418\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"69.14529\" y=\"52.520044\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.762191\" y=\"86.805402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.536152\" y=\"82.052106\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.919843\" y=\"77.139472\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.783722\" y=\"80.577177\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.113418\" y=\"53.643488\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.711354\" y=\"74.096883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"85.378121\" y=\"71.357359\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"83.552097\" y=\"70.715727\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"87.488727\" y=\"59.19274\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.487289\" y=\"84.93485\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.265432\" y=\"62.205567\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.779009\" y=\"78.027317\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"168.772017\" y=\"122.357308\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.025389\" y=\"55.106983\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.884292\" y=\"84.291331\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.586799\" y=\"70.900395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"52.862115\" y=\"28.092442\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.387588\" y=\"63.055993\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.700673\" y=\"85.032154\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"80.211638\" y=\"50.579127\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"198.452243\" y=\"132.496164\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.359344\" y=\"77.270526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.280226\" y=\"74.650122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.124056\" y=\"61.602047\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.453766\" y=\"110.942314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.983485\" y=\"78.602785\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.977449\" y=\"63.591785\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.883379\" y=\"96.845\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"189.351133\" y=\"112.396057\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.307679\" y=\"71.697136\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.519088\" y=\"97.573787\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.85076\" y=\"59.69533\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.786321\" y=\"65.924925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.127066\" y=\"76.553809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.177223\" y=\"86.151253\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.751736\" y=\"87.092739\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.494488\" y=\"83.407537\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"168.474458\" y=\"109.880623\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.932537\" y=\"100.908581\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.067888\" y=\"98.637226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.262552\" y=\"45.815816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.102066\" y=\"66.391877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.174481\" y=\"87.226272\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.04053\" y=\"70.275588\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.63542\" y=\"102.269978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.678134\" y=\"79.7729\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.024648\" y=\"94.470349\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.645212\" y=\"81.726621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"91.777503\" y=\"80.838136\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.074816\" y=\"72.584774\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.767426\" y=\"100.869221\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.899513\" y=\"91.902811\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.905126\" y=\"70.602808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.915794\" y=\"75.016032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"184.377851\" y=\"99.759433\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.537074\" y=\"83.325542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.301367\" y=\"74.92374\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.562863\" y=\"87.948231\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.270645\" y=\"85.473992\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.734637\" y=\"96.819429\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"86.330995\" y=\"53.182402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.659157\" y=\"95.947321\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.398753\" y=\"74.628479\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.05263\" y=\"72.79579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.774806\" y=\"90.766689\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"83.296372\" y=\"56.252595\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.838619\" y=\"87.391067\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.251315\" y=\"66.423905\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.557847\" y=\"99.084676\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.073461\" y=\"86.020093\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.490152\" y=\"109.058449\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.842628\" y=\"77.862149\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.229169\" y=\"51.556248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.255251\" y=\"49.013988\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.304509\" y=\"84.756756\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.527258\" y=\"81.853965\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"166.304664\" y=\"89.043998\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.951423\" y=\"61.169867\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.675938\" y=\"53.748602\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"md894f6968c\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#md894f6968c\" x=\"70.578725\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −2 -->\n",
       "      <g transform=\"translate(63.207631 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md894f6968c\" x=\"127.261257\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(124.080007 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md894f6968c\" x=\"183.94379\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(180.76254 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <defs>\n",
       "       <path id=\"mfee6049071\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfee6049071\" x=\"28.942188\" y=\"122.125913\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- −5 -->\n",
       "      <g transform=\"translate(7.2 125.925132) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfee6049071\" x=\"28.942188\" y=\"98.034106\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(15.579688 101.833325) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfee6049071\" x=\"28.942188\" y=\"73.9423\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(15.579688 77.741518) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfee6049071\" x=\"28.942188\" y=\"49.850493\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(9.217188 53.649712) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfee6049071\" x=\"28.942188\" y=\"25.758686\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(9.217188 29.557905) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 28.942188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 28.942187 145.8 \n",
       "L 224.242188 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 28.942187 7.2 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p90ff8178db\">\n",
       "   <rect x=\"28.942188\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘图，查看分布\n",
    "d2l.set_figsize()\n",
    "d2l.plt.scatter(features[:, (1)].detach().numpy(), \n",
    "                labels.detach().numpy(), 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2. <a id='toc7_1_2_'></a>[读取数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0441, -0.0882],\n",
      "        [-1.9142,  0.4381],\n",
      "        [-0.6126, -0.4002],\n",
      "        [ 0.7606,  1.2113],\n",
      "        [-0.9038, -0.1017],\n",
      "        [-1.9209, -0.3264],\n",
      "        [-1.8411,  0.8676],\n",
      "        [ 0.7096, -0.6971],\n",
      "        [-0.5313,  1.2168],\n",
      "        [-1.6005, -0.9617]]) \n",
      " tensor([[ 6.5817],\n",
      "        [-1.1185],\n",
      "        [ 4.3365],\n",
      "        [ 1.5955],\n",
      "        [ 2.7420],\n",
      "        [ 1.4567],\n",
      "        [-2.4133],\n",
      "        [ 7.9938],\n",
      "        [-1.0011],\n",
      "        [ 4.2676]])\n"
     ]
    }
   ],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # 这些样本是随机读取的，没有特定的顺序\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "batch_size = 10\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3. <a id='toc7_1_3_'></a>[初始化模型参数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.4. <a id='toc7_1_4_'></a>[定义模型](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b):  #@save\n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return torch.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.5. <a id='toc7_1_5_'></a>[定义损失函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):  #@save\n",
    "    \"\"\"均方损失\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.6. <a id='toc7_1_6_'></a>[定义优化算法](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):  #@save\n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.7. <a id='toc7_1_7_'></a>[训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000051\n",
      "epoch 2, loss 0.000051\n",
      "epoch 3, loss 0.000051\n",
      "w的估计误差: tensor([ 0.0002, -0.0002], grad_fn=<SubBackward0>)\n",
      "b的估计误差: tensor([-0.0002], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y)  # X和y的小批量损失\n",
    "        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n",
    "        # 并以此计算关于[w,b]的梯度\n",
    "        l.sum().backward()\n",
    "        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n",
    "\n",
    "print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')\n",
    "print(f'b的估计误差: {true_b - b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. <a id='toc7_2_'></a>[现线性回归模型于训练过程-简洁实现](#toc0_)\n",
    "### 7.2.1. <a id='toc7_2_1_'></a>[虚拟数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2. <a id='toc7_2_2_'></a>[读取数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3. <a id='toc7_2_3_'></a>[定义模型](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn是神经网络的缩写\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4. <a id='toc7_2_4_'></a>[初始化模型参数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.5. <a id='toc7_2_5_'></a>[定义损失函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.6. <a id='toc7_2_6_'></a>[定义优化算法](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "trainer = optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.7. <a id='toc7_2_7_'></a>[训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000110\n",
      "epoch 2, loss 0.000111\n",
      "epoch 3, loss 0.000111\n",
      "epoch 4, loss 0.000110\n",
      "epoch 5, loss 0.000110\n",
      "w的估计误差： tensor([ 3.5048e-05, -1.6689e-04])\n",
      "b的估计误差： tensor([0.0005])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        y_hat = net(X)                  # 1. 计算y_hat\n",
    "        loss = loss_fn(y_hat ,y)        # 2. 计算loss值\n",
    "        trainer.zero_grad()\n",
    "        loss.backward()                 # 2. 求梯度           \n",
    "        trainer.step()                  # 3. 更新网络权重参数\n",
    "    train_loss = loss_fn(net(features), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {train_loss:f}')\n",
    "\n",
    "w = net[0].weight.data\n",
    "print('w的估计误差：', true_w - w.reshape(true_w.shape))\n",
    "b = net[0].bias.data\n",
    "print('b的估计误差：', true_b - b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. <a id='toc7_3_'></a>[专题-模型定义（计算预测值）](#toc0_)\n",
    "```shell\n",
    "优点：\n",
    "    一般，pytorch的nn.Sequentail类就比较方便的快速构建神经网络的框架；\n",
    "    同时，nn也包含了很多完整的神经网络如：CNN、RNN等；\n",
    "缺点：\n",
    "    高度封装，需要复杂的自定义神经网络时就不适用了。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1. <a id='toc7_3_1_'></a>[torch.nn模块](#toc0_)\n",
    "```shell\n",
    "1. 简单、快速，但不够灵活\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(786, 256), nn.ReLU(), \n",
    "                    nn.Linear(256, 256), nn.Tanh(),\n",
    "                    nn.Linear(256, 10), nn.Softmax()\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2. <a id='toc7_3_2_'></a>[自定义-块](#toc0_)\n",
    "```shell\n",
    "2. 灵活，但麻烦\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.1. <a id='toc7_3_2_1_'></a>[自定义块](#toc0_)\n",
    "```\n",
    "从编程的角度看：块就是Class\n",
    "nn.Module会自动调用forward()方法，我们也可以重写该方法，从而实现更加灵活的计算\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.2. <a id='toc7_3_2_2_'></a>[顺序块](#toc0_)\n",
    "```\n",
    "Sequential就是顺序块，这里我们自己从头实现一边Sequential这个方法\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Sequential()\n",
    "\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "\n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.3. <a id='toc7_3_2_3_'></a>[效率](#toc0_)\n",
    "```shell\n",
    "1. 一个块可以由许多层组成；一个块可以由许多块组成。\n",
    "2. 块可以包含代码。\n",
    "3. 块负责大量的内部处理，包括参数初始化和反向传播。\n",
    "4. 层和块的顺序连接由Sequential块处理。\n",
    "```\n",
    "```shell\n",
    "读者可能会开始担心操作效率的问题。 毕竟，我们在一个高性能的深度学习库中进行了大量的字典查找、 代码执行和许多其他的Python代码。 Python的问题全局解释器锁 是众所周知的。 在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3. <a id='toc7_3_3_'></a>[参数管理](#toc0_)\n",
    "```shell\n",
    "其实可以将nn.Sequential视为Python的list数据结构，按顺序储存神经网络层\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2552],\n",
       "        [0.1761]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), \n",
    "                    nn.Linear(8, 1)\n",
    "                    )\n",
    "\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.3.1. <a id='toc7_3_3_1_'></a>[参数访问](#toc0_)\n",
    "```shell\n",
    "我们从已有模型中访问参数。 \n",
    "当通过Sequential类定义模型时，我们可以通过索引来访问模型的任意层。\n",
    "这就像模型是一个列表一样，每层的参数都在其属性中。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=4, out_features=8, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=8, out_features=1, bias=True))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0], net[1], net[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.2702,  0.1767,  0.1702, -0.2560, -0.2653, -0.3247,  0.2074, -0.3074]])),\n",
       "             ('bias', tensor([0.2297]))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].state_dict()\n",
    "# 输出的结果告诉我们一些重要的事情： 首先，这个全连接层包含两个参数，分别是该层的权重和偏置。 \n",
    "# 两者都存储为单精度浮点数（float32）。 \n",
    "# 注意，参数名称允许唯一标识每个参数，即使在包含数百个层的网络中也是如此。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2702,  0.1767,  0.1702, -0.2560, -0.2653, -0.3247,  0.2074, -0.3074]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2702,  0.1767,  0.1702, -0.2560, -0.2653, -0.3247,  0.2074, -0.3074]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.data # 访问目标参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.2297], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2297])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].bias.data # 访问目标参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.4454, -0.4623, -0.3067, -0.0497],\n",
       "                      [ 0.1329, -0.1107, -0.4162,  0.3473],\n",
       "                      [ 0.3310, -0.0126,  0.0427, -0.1092],\n",
       "                      [ 0.3724, -0.4427,  0.0750, -0.3512],\n",
       "                      [-0.0690,  0.2511, -0.1802, -0.3374],\n",
       "                      [-0.2838, -0.1675,  0.0303,  0.2524],\n",
       "                      [-0.2208,  0.4676,  0.2876,  0.4846],\n",
       "                      [ 0.4274, -0.4399, -0.4652, -0.4009]])),\n",
       "             ('0.bias',\n",
       "              tensor([-0.0445, -0.3657,  0.2953,  0.0962,  0.2330,  0.2524,  0.3320,  0.4832])),\n",
       "             ('2.weight',\n",
       "              tensor([[ 0.0723,  0.3215, -0.2724, -0.0400, -0.0260,  0.0734,  0.2320, -0.2839]])),\n",
       "             ('2.bias', tensor([-0.0304]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以直接输出神经网络的所有层参数信息，net[1]是relu激活函数，没有参数，所以就显示无\n",
    "net.state_dict() # 后续，torch.save(net.state_dict(), 'Pytorch_datasets/net_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.3.2. <a id='toc7_3_3_2_'></a>[参数初始化](#toc0_)\n",
    "```shell\n",
    "初始化，主要是为了不要再一开始训练就炸掉了，其实不用太迷信了。\n",
    "\n",
    "默认情况下，PyTorch会根据一个范围均匀地初始化权重和偏置矩阵， 这个范围是根据输入和输出维度计算出的。 \n",
    "PyTorch的nn.init模块提供了多种预置初始化方法。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.3.3.2.1. <a id='toc7_3_3_2_1_'></a>[内置初始化](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = net[0]\n",
    "nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.3.3.2.2. <a id='toc7_3_3_2_2_'></a>[自定义初始化](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.3.3.2.3. <a id='toc7_3_3_2_3_'></a>[参数绑定](#toc0_)\n",
    "```\n",
    "有时我们希望在多个层间共享参数： 我们可以定义一个稠密层，然后使用它的参数来设置另一个层的参数。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# 我们需要给共享层一个名称，以便可以引用它的参数\n",
    "shared = nn.Linear(8, 8)\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    nn.Linear(8, 1))\n",
    "net(X)\n",
    "# 检查参数是否相同\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "\n",
    "net[2].weight.data[0, 0] = 100\n",
    "\n",
    "# 确保它们实际上是同一个对象，而不只是有相同的值\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.4. <a id='toc7_3_4_'></a>[自定义-层](#toc0_)\n",
    "```shell\n",
    "深度学习成功背后的一个因素是神经网络的灵活性： \n",
    "我们可以用创造性的方式组合不同的层，从而设计出适用于各种任务的架构。 \n",
    "例如，研究人员发明了专门用于处理图像、文本、序列数据和执行动态规划的层。 \n",
    "有时我们会遇到或要自己发明一个现在在深度学习框架中还不存在的层。 \n",
    "在这些情况下，必须构建自定义层。本节将展示如何构建自定义层。\n",
    "```\n",
    "```shell\n",
    "块和层其实并无本质的区别，因为都是torch.nn.Module的子类\n",
    "\n",
    "e.g. \n",
    "    全连接层（FC）\n",
    "    池化层（Pooling）\n",
    "    BN层\n",
    "    Dropout层\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.4.1. <a id='toc7_3_4_1_'></a>[不带参数的层](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  0.,  1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()\n",
    "    \n",
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.5879e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在，我们可以将层作为组件合并到更复杂的模型中。\n",
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())\n",
    "\n",
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.4.2. <a id='toc7_3_4_2_'></a>[带参数的层](#toc0_)\n",
    "```shell\n",
    "用到nn.Parameter()可以将参数加入神经网络中，便于自动管理\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 2.6772],\n",
       "        [0.2502, 0.0000, 2.9337]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units)) \n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)\n",
    "    \n",
    "linear = MyLinear(5, 3)\n",
    "# linear.weight\n",
    "\n",
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.3980],\n",
       "        [19.6101]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们还可以使用自定义层构建模型，就像使用内置的全连接层一样使用自定义层。\n",
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. <a id='toc7_4_'></a>[专题-损失函数](#toc0_)\n",
    "```\n",
    "损失函数的输入是 (output, target) ，即网络输出和真实标签对的数据，然后返回一个数值表示网络输出和真实标签的差距。\n",
    "    1. 均方误差\n",
    "    2. 交叉熵\n",
    "    3. 自定义\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1. <a id='toc7_4_1_'></a>[均方误差](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2. <a id='toc7_4_2_'></a>[交叉熵](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3. <a id='toc7_4_3_'></a>[自定义](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y, y_hat):\n",
    "    '''例如真实值于预测值之差'''\n",
    "    error_values = y - y_hat\n",
    "    return error_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. <a id='toc7_5_'></a>[专题-反向传播（求梯度）](#toc0_)\n",
    "```\n",
    "求梯度（求偏导数）\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 见autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6. <a id='toc7_6_'></a>[专题-更新权重（优化算法）](#toc0_)\n",
    "```\n",
    "优化算法\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1. <a id='toc7_6_1_'></a>[小批量梯度下降（SGD）](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.SGD(params=net.parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2. <a id='toc7_6_2_'></a>[adam](#toc0_)\n",
    "```shell\n",
    "Adam对lr不敏感\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.Adam(params=net.parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.3. <a id='toc7_6_3_'></a>[RMSprop](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.RMSprop(params=net.parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7. <a id='toc7_7_'></a>[专题-训练](#toc0_)\n",
    "```shell\n",
    "训练的模板代码\n",
    "```\n",
    "```sehll\n",
    "net.train():\n",
    "    启用 Batch Normalization 和 Dropout。\n",
    "    如果模型中有BN层(Batch Normalization）和Dropout，需要在训练时添加model.train()\n",
    "    model.train()作用： 对BN层，保证BN层能够用到每一批数据的均值和方差，并进行计算更新；\n",
    "                        对于Dropout，model.train()是随机取一部分网络连接来训练更新参数。\n",
    "net.eval()\n",
    "    不启用 Batch Normalization 和 Dropout。\n",
    "    如果模型中有BN层(Batch Normalization）和Dropout，在测试时添加model.eval()。\n",
    "    model.eval()是保证BN层直接利用之前训练阶段得到的均值和方差，即测试过程中要保证BN层的均值和方差不变；\n",
    "                        对于Dropout，model.eval()是利用到了所有网络连接，即不进行随机舍弃神经元。\n",
    "with torch.no_grad():\n",
    "    pass\n",
    "    无论是train() 还是eval() 模式，各层的gradient计算和存储都在进行且完全一致，只是在eval模式下不会进行反向传播。\n",
    "    而with torch.no_grad()则主要是用于停止autograd模块的工作，以起到加速和节省显存的作用。\n",
    "    它的作用是将该with语句包裹起来的部分停止梯度的更新，从而节省了GPU算力和显存，但是并不会影响dropout和BN层的行为。\n",
    "    若想节约算力，可在test阶段带上torch.no_grad()，示例代码：\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# 数据准备\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "# import torch.nn.functional as F \n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=True, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "test_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=False, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, \n",
    "                             batch_size=128, \n",
    "                             shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(28*28, 256), nn.ReLU(),\n",
    "                                     nn.Linear(256, 10), nn.Softmax())\n",
    "    def forward(self, X):\n",
    "        return self.network(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程封装\n",
    "import time\n",
    "\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "    # 拷贝数据和模型到device上\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    ## 数据\n",
    "    train_all_data_gpu = train_dataset.data.to(device)                                      # .to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)                                # .to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)                                        # .to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)                                  # .to(device)\n",
    "    ## 模型\n",
    "    net.to(device)                                                                          # .to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   ## 复制到device（GPU/CPU）上                    # .to(device)\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "    stop = time.time()\n",
    "    print('='*100)\n",
    "    print(f\"耗时： {stop - start} seconds.\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.1. <a id='toc7_7_1_'></a>[开始训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Runing on cpu\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10: train_loss=2.2910618782043457, train_acc=36.06833267211914, test_acc=35.869998931884766\n",
      "epoch 2/10: train_loss=2.268610954284668, train_acc=40.1533317565918, test_acc=40.45000076293945\n",
      "epoch 3/10: train_loss=2.2109005451202393, train_acc=37.04999923706055, test_acc=37.43000030517578\n",
      "epoch 4/10: train_loss=2.126451253890991, train_acc=42.96999740600586, test_acc=42.709999084472656\n",
      "epoch 5/10: train_loss=2.0243027210235596, train_acc=54.25, test_acc=54.7599983215332\n",
      "epoch 6/10: train_loss=1.9418607950210571, train_acc=58.461666107177734, test_acc=59.40999984741211\n",
      "epoch 7/10: train_loss=1.8849422931671143, train_acc=65.4749984741211, test_acc=66.56999969482422\n",
      "epoch 8/10: train_loss=1.8414554595947266, train_acc=70.90666961669922, test_acc=71.9000015258789\n",
      "epoch 9/10: train_loss=1.7922749519348145, train_acc=77.82166290283203, test_acc=78.83999633789062\n",
      "epoch 10/10: train_loss=1.7590090036392212, train_acc=79.18999481201172, test_acc=80.1199951171875\n",
      "====================================================================================================\n",
      "耗时： 66.09929037094116 seconds.\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.01)\n",
    "\n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device\n",
    "            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Runing on cpu\n",
      "====================================================================================================\n",
      "epoch 1/10: train_loss=2.2895405292510986, train_acc=41.21500015258789, test_acc=41.19000244140625\n",
      "epoch 2/10: train_loss=2.2614905834198, train_acc=40.18000030517578, test_acc=39.96999740600586\n",
      "epoch 3/10: train_loss=2.205374240875244, train_acc=47.438331604003906, test_acc=47.72999954223633\n",
      "epoch 4/10: train_loss=2.1098668575286865, train_acc=50.63666534423828, test_acc=51.400001525878906\n",
      "epoch 5/10: train_loss=1.9959341287612915, train_acc=57.59000015258789, test_acc=58.34000015258789\n",
      "epoch 6/10: train_loss=1.9203170537948608, train_acc=63.44666290283203, test_acc=64.02000427246094\n",
      "epoch 7/10: train_loss=1.8799312114715576, train_acc=64.24666595458984, test_acc=64.95000457763672\n",
      "epoch 8/10: train_loss=1.8518180847167969, train_acc=65.47333526611328, test_acc=65.94999694824219\n",
      "epoch 9/10: train_loss=1.8119688034057617, train_acc=71.43000030517578, test_acc=72.22000122070312\n",
      "epoch 10/10: train_loss=1.7760218381881714, train_acc=77.42666625976562, test_acc=78.13999938964844\n",
      "====================================================================================================\n",
      "耗时： 81.27920389175415 seconds.\n"
     ]
    }
   ],
   "source": [
    "# 再试一次，会不会造成net的parameter的累加，结果表明不会\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()   \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.01)  \n",
    "    \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device\n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.2. <a id='toc7_7_2_'></a>[自己探索](#toc0_)\n",
    "#### 7.7.2.1. <a id='toc7_7_2_1_'></a>[lr的影响](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Runing on cpu\n",
      "====================================================================================================\n",
      "epoch 1/10: train_loss=1.5848428010940552, train_acc=90.0183334350586, test_acc=90.1300048828125\n",
      "epoch 2/10: train_loss=1.5482041835784912, train_acc=92.34666442871094, test_acc=92.5999984741211\n",
      "epoch 3/10: train_loss=1.537485122680664, train_acc=93.25333404541016, test_acc=93.0\n",
      "epoch 4/10: train_loss=1.5284011363983154, train_acc=94.00499725341797, test_acc=93.66000366210938\n",
      "epoch 5/10: train_loss=1.5208606719970703, train_acc=94.62666320800781, test_acc=94.16999816894531\n",
      "epoch 6/10: train_loss=1.5158812999725342, train_acc=95.16666412353516, test_acc=94.52000427246094\n",
      "epoch 7/10: train_loss=1.5115342140197754, train_acc=95.55500030517578, test_acc=94.94000244140625\n",
      "epoch 8/10: train_loss=1.5075434446334839, train_acc=95.93333435058594, test_acc=95.1300048828125\n",
      "epoch 9/10: train_loss=1.5057942867279053, train_acc=96.02166748046875, test_acc=95.49000549316406\n",
      "epoch 10/10: train_loss=1.5002691745758057, train_acc=96.62000274658203, test_acc=95.99000549316406\n",
      "====================================================================================================\n",
      "耗时： 68.49035549163818 seconds.\n"
     ]
    }
   ],
   "source": [
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()      \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "   \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device \n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7.2.2. <a id='toc7_7_2_2_'></a>[不同模型的效率](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10: train_loss=1.7712322473526, train_acc=78.33000183105469, test_acc=79.04999542236328\n",
      "epoch 2/10: train_loss=1.6643422842025757, train_acc=82.56666564941406, test_acc=83.37000274658203\n",
      "epoch 3/10: train_loss=1.6445097923278809, train_acc=83.44000244140625, test_acc=84.08000183105469\n",
      "epoch 4/10: train_loss=1.6352627277374268, train_acc=83.94000244140625, test_acc=84.47999572753906\n",
      "epoch 5/10: train_loss=1.628287672996521, train_acc=84.29833221435547, test_acc=84.75999450683594\n",
      "epoch 6/10: train_loss=1.5792657136917114, train_acc=90.32333374023438, test_acc=90.72000122070312\n",
      "epoch 7/10: train_loss=1.5659691095352173, train_acc=91.18833923339844, test_acc=91.3699951171875\n",
      "epoch 8/10: train_loss=1.5595906972885132, train_acc=91.55999755859375, test_acc=91.6199951171875\n",
      "epoch 9/10: train_loss=1.5547451972961426, train_acc=91.97000122070312, test_acc=92.02999877929688\n",
      "epoch 10/10: train_loss=1.551450252532959, train_acc=92.08333587646484, test_acc=92.1500015258789\n"
     ]
    }
   ],
   "source": [
    "# test_acc一直在92%左右，如何才能提高？\n",
    "# 使用CNN会好一点吗？\n",
    "# 我们来试一试：\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(28*28, 128), nn.ReLU(),\n",
    "                                     nn.Linear(128, 10), nn.Softmax())\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net1()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.1)   \n",
    "   \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device\n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.3. <a id='toc7_7_3_'></a>[K折交叉验证](#toc0_)\n",
    "```\n",
    "简述：把数据分成K份，分别只取1份做Test_data，（K-1）做Train_data，做K次，计算Test_acc的平均值\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_cross_eval():\n",
    "    data / k \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. <a id='toc8_'></a>[在 GPU 上训练](#toc0_)\n",
    "```shell\n",
    "要实行运算的Tensor必须在同一张GPU卡上：\n",
    "    1. 张量传到GPU上            x_gpu = x.to('cuda:0')\n",
    "    2. 神经网络传到GPU上        net.to('cuda:0')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. <a id='toc8_1_'></a>[查看GPU配置](#toc0_)\n",
    "```shell\n",
    "都在torch.cuda.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 是否有可用的GPU\n",
    "torch.cuda.is_available()           \n",
    "# True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可用的GPU数量\n",
    "torch.cuda.device_count()     \n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回gpu名字，设备索引默认从0开始；\n",
    "torch.cuda.get_device_name(0)\n",
    "# \"Tesla T4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回当前设备索引；\n",
    "torch.cuda.current_device()\n",
    "# 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "只有CPU\n"
     ]
    }
   ],
   "source": [
    "def check_device():\n",
    "    '''判断是否有GPU，并列出GPU的代号/名称'''\n",
    "    if torch.cuda.is_available(): # 判断是否支持cuda/GPU\n",
    "        gpu_num = torch.cuda.device_count() # cuda/GPU计数\n",
    "        if gpu_num == 1:\n",
    "            print(f\"单机单卡: {[torch.cuda.get_device_name(gpu_name) for gpu_name in range(gpu_num)]}\")\n",
    "        else:\n",
    "            print(f\"单机{gpu_num}卡: {[torch.cuda.get_device_name(gpu_name) for gpu_name in range(gpu_num)]}\")\n",
    "    else:\n",
    "        print(f\"只有CPU\")\n",
    "    return None \n",
    "\n",
    "check_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpu']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = [ 'cpu' if not torch.cuda.is_available() else ]\n",
    "device = [f'cuda:{i}' for i in range(torch.cuda.device_count())] if torch.cuda.is_available() else ['cpu']\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. <a id='toc8_2_'></a>[单机单卡（GPU）](#toc0_)\n",
    "```\n",
    "所有的张量必须存在于同一个设备上（同一个CPU或同一个GPU），才能正确计算，否则可能会出现异常错误。\n",
    "    1、模型上GPU：model.cuda() 或 model.to(device)   \n",
    "    2、数据上GPU：data_gpu = data.cuda() 或 data_gpu = data.to(device)   \n",
    "    3、输出下GPU：output = model(data)  output.detach().cpu().numpy()，\n",
    "\n",
    ".detach()的作用是将变量output从计算图中分离，使其不具有梯度，不进行反向传播。\n",
    ".cpu()是将GPU数据转CPU，\n",
    ".numpy()是将Tensor转numpy，\n",
    "如果需要继续反向传播，则不需要.detach().cpu().numpy()。\n",
    "一般如果要单独处理，如图像的显示，或者特征的保存，都需要做上述操作。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.]]),\n",
       " tensor([[1.],\n",
       "         [1.]]),\n",
       " device(type='cpu'),\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.ones((2, 1))\n",
    "y = torch.ones((2, 1))\n",
    "x, y, x.device, y.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.]]),\n",
       " tensor([[1.],\n",
       "         [1.]]),\n",
       " device(type='cpu'),\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x.to(device)\n",
    "y1 = y.to(device)\n",
    "x1, y1, x1.device, y1.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. <a id='toc8_3_'></a>[单机多卡（GPU）](#toc0_)\n",
    "```\n",
    "目前PyTorch的单机多卡训练，主要有两种方式：\n",
    "    # 第一种\n",
    "    torch.nn.DataParallel(module=net, device_ids=[0, 1], output_device=[0])    # 单机两卡\n",
    "    # 第二种\n",
    "    torch.nn.parallel.DistributedDataParallel()             # 单机多卡、多机多卡\n",
    "```\n",
    "\n",
    "```shell\n",
    "`DataParallel` (DP) 和 `DistributedDataParallel` (DDP) 都是用于在多GPU上进行训练的工具，但它们有一些关键的区别：\n",
    "\n",
    "1. **目标环境：**\n",
    "   - `DataParallel` 适用于单机多卡的情况，通过将模型复制到每个GPU上，每个GPU计算不同的批次，最后通过梯度累积或平均来更新模型参数。\n",
    "   - `DistributedDataParallel` 适用于分布式环境，可以在单机或多台机器上的多个GPU上运行，每个GPU计算不同的批次，并通过分布式通信来同步梯度和更新模型参数。\n",
    "\n",
    "2. **通信方式：**\n",
    "   - `DataParallel` 使用单个进程内的多个GPU，通信相对较简单，仅涉及到进程内的数据传输。\n",
    "   - `DistributedDataParallel` 通过分布式通信协议，如NCCL或Gloo，实现跨进程和可能跨机器的通信，因此需要更复杂的设置。\n",
    "\n",
    "3. **启动方式：**\n",
    "   - `DataParallel` 只需在模型实例上调用 `nn.DataParallel(model)` 即可。\n",
    "   - `DistributedDataParallel` 需要在训练脚本中设置分布式环境变量，如`torch.distributed.launch` 或手动设置`os.environ`。\n",
    "\n",
    "4. **维护性：**\n",
    "   - `DataParallel` 更容易使用，因为它不涉及复杂的分布式设置。\n",
    "   - `DistributedDataParallel` 适用于更复杂的分布式场景，但需要更多的设置和管理。\n",
    "\n",
    "在单机多卡的情况下，如果简单性和易用性是首要考虑的因素，可以使用 `DataParallel`。在需要更高级的分布式设置时，或者在多机多卡的环境中，`DistributedDataParallel` 提供了更大的灵活性。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1. <a id='toc8_3_1_'></a>[DP](#toc0_)\n",
    "```shell\n",
    "单机多线程\n",
    "```\n",
    "```python\n",
    "详解\n",
    "torch.nn.DataParallel(module, device_ids, output_device)  \n",
    "\n",
    "Parameters\n",
    "    module (Module) – module to be parallelized                                                 # 神经网络\n",
    "    device_ids (list of int or torch.device) – CUDA devices (default: all devices)              # 默认使用所用GPU\n",
    "    output_device (int or torch.device) – device location of output (default: device_ids[0])    # 在cuda:0上进行参数分配、计算、汇总、更新\n",
    "Variables\n",
    "    module (Module) – the module to be parallelized\n",
    "    \n",
    "1. 有一个前提: net模型被复制到cuda:[0, 1, 2等等]上，但是X, y必须提前在cuda:0上，而不能在cuda:1、cuda:2等等上；\n",
    "2. 那如果cuda:0有其他人占满了，怎么办？那就需要手动指定其他GPU为cuda:0了：\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"      # 一定一定要放在所有访问显卡的代码之前，否则则无效，给我困扰了好一段时间才发现了。我之前看到有一个说法是放到import os之后并且在import torch之前。\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2, 3\"         # 只识别2、3而抛弃了其他GPU，把2当成pytorch逻辑上的cuda:0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Runing on cpu \n",
      " ====================================================================================================\n",
      "epoch 1/10: train_loss=1.6323208808898926, train_acc=83.99833679199219, test_acc=84.13999938964844\n",
      "epoch 2/10: train_loss=1.5583083629608154, train_acc=91.48500061035156, test_acc=91.79000091552734\n",
      "epoch 3/10: train_loss=1.5336382389068604, train_acc=93.64500427246094, test_acc=93.69000244140625\n",
      "epoch 4/10: train_loss=1.5234729051589966, train_acc=94.54167175292969, test_acc=94.27999877929688\n",
      "epoch 5/10: train_loss=1.5158753395080566, train_acc=95.2316665649414, test_acc=94.86000061035156\n",
      "epoch 6/10: train_loss=1.5113998651504517, train_acc=95.62666320800781, test_acc=95.09000396728516\n",
      "epoch 7/10: train_loss=1.506333351135254, train_acc=96.07833862304688, test_acc=95.74000549316406\n",
      "epoch 8/10: train_loss=1.502449870109558, train_acc=96.51166534423828, test_acc=95.97000122070312\n",
      "epoch 9/10: train_loss=1.498482346534729, train_acc=96.83332824707031, test_acc=96.21000671386719\n",
      "epoch 10/10: train_loss=1.49517023563385, train_acc=97.17500305175781, test_acc=96.43000030517578\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 35.65645790100098 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=True, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "test_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=False, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, \n",
    "                             batch_size=128, \n",
    "                             shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "                                     nn.Linear(1024, 10), nn.Softmax())\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "    print('='*100, '\\n', f\"Runing on {device}\", '\\n','='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net = nn.DataParallel(module=net)\n",
    "    # net = nn.DataParallel(module=net, device_ids=[0, 1], output_device=[0]) # 多GPU并行计算，等价于net = nn.DataParallel(module=net)\n",
    "    net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device \n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2. <a id='toc8_3_2_'></a>[DDP](#toc0_)\n",
    "```shell\n",
    "1. 与 DataParallel 的单进程控制多 GPU 不同，在 distributed 的帮助下，我们只需要编写一份代码，torch 就会自动将其分配给 \n",
    " 个进程，分别在 n 个 GPU 上运行。\n",
    "2. 单机多进程\n",
    "```\n",
    "```python\n",
    "详解\n",
    "torch.nn.parallel.DistributedDataParallel(module, device_ids, output_device)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import os \n",
    "\n",
    "def ddp_setup(rank, world_size):\n",
    "    '''\n",
    "    Args:\n",
    "        rank: unique identifier of each process\n",
    "        world_size: Total number of process\n",
    "    '''\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12357\"\n",
    "    dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2.1. <a id='toc8_3_2_1_'></a>[在colab上测试可用](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.multiprocessing import Process\n",
    "import os\n",
    "\n",
    "# 定义卷积神经网络模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train(local_rank, world_size):\n",
    "  \n",
    "  os.environ[\"MASTER_PORT\"] = \"12357\"\n",
    "  os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "\n",
    "  # 设置每个进程的GPU\n",
    "  torch.cuda.set_device(local_rank)\n",
    "  device = torch.device(\"cuda\", local_rank)\n",
    "\n",
    "  # 初始化进程组\n",
    "  dist.init_process_group(backend='nccl', world_size=world_size, rank=local_rank)\n",
    "\n",
    "  # 数据预处理和加载\n",
    "  transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "  trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "  # 使用DistributedSampler来对数据进行分布式采样\n",
    "  train_sampler = torch.utils.data.distributed.DistributedSampler(trainset)\n",
    "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=False, sampler=train_sampler)\n",
    "\n",
    "  # 创建CNN模型实例，并放入多个GPU上\n",
    "  model = CNN().to(device)\n",
    "  model = nn.parallel.DistributedDataParallel(model, device_ids=[local_rank])\n",
    "\n",
    "  # 定义损失函数和优化器\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "  # 训练模型\n",
    "  num_epochs = 5\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "      model.train()\n",
    "      running_loss = 0.0\n",
    "\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "          inputs, labels = data\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          running_loss += loss.item()\n",
    "\n",
    "      print(f\"Local Rank {local_rank}, Epoch {epoch + 1}/{num_epochs}, Training Loss: {running_loss / len(trainloader):.4f}\")\n",
    "\n",
    "  dist.destroy_process_group()\n",
    "\n",
    "# Process格式：\n",
    "if __name__ == \"__main__\":\n",
    "  # size = torch.cuda.device_count()\n",
    "  size = 10\n",
    "  processes = []\n",
    "  world_size = 1\n",
    "  for rank in range(size):\n",
    "      p = Process(target=train, args=(rank, world_size))\n",
    "      p.start()\n",
    "      processes.append(p)\n",
    "\n",
    "  for p in processes:\n",
    "      p.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4. <a id='toc8_4_'></a>[多机多卡（GPU）- 分布式训练](#toc0_)\n",
    "```shell\n",
    "目前PyTorch的多机多卡训练，主要有两种方式：   \n",
    "    1. torch.nn.parallel.DistributedDataParallel()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. <a id='toc9_'></a>[模型和参数的保存与加载](#toc0_)\n",
    "\n",
    "```shell\n",
    "torch.save(张量名, 位置)\n",
    "张量名称 = torch.load(位置)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. <a id='toc9_1_'></a>[加载和保存-张量](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.ones((3, 5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save()\n",
    "torch.save(x, './Pytorch_params/x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.load()\n",
    "x1 = torch.load('./Pytorch_params/x-file')\n",
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. <a id='toc9_2_'></a>[加载和保存-模型参数](#toc0_)\n",
    "```shell\n",
    "保存单个权重向量（或其他张量）确实有用， 但是如果我们想保存整个模型，并在以后加载它们， 单独保存每个向量则会变得很麻烦。 毕竟，我们可能有数百个参数散布在各处。 因此，深度学习框架提供了内置函数来保存和加载整个网络。 需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。 例如，如果我们有一个3层多层感知机，我们需要单独指定架构。 因为模型本身可以包含任意代码，所以模型本身难以序列化。 因此，为了恢复模型，我们需要用代码生成架构， 然后从磁盘加载参数。\n",
    "```\n",
    "```shell\n",
    "1. save和load函数可用于张量对象的文件读写。\n",
    "2. 我们可以通过参数字典保存和加载网络的全部参数。\n",
    "3. 保存架构必须在代码中完成，而不是在参数中完成。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save()\n",
    "# 接下来，我们将模型的参数存储在一个叫做“mlp.params”的文件中。\n",
    "torch.save(net.state_dict(), './Pytorch_params/mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.load()\n",
    "# 为了恢复模型，我们实例化了原始多层感知机模型的一个备份。 \n",
    "# 这里我们不需要随机初始化模型参数，而是直接读取文件中存储的参数。\n",
    "net_params = torch.load('./Pytorch_params/mlp.params')\n",
    "clone = MLP()\n",
    "\n",
    "clone.load_state_dict(net_params)\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. <a id='toc10_'></a>[神经网络类型](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1. <a id='toc10_1_'></a>[CNN](#toc0_)\n",
    "```\n",
    "CBAPD: 卷积，批量归一化，激活，池化，丢弃\n",
    "卷积层就是特征提取，随后将特征传入FC（全连接层）；\n",
    "卷积本身是线性的，但是经过激活函数后可以编程非线性的。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.1. <a id='toc10_1_1_'></a>[简单CNN](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1.1.1. <a id='toc10_1_1_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1.1.2. <a id='toc10_1_1_2_'></a>[简介实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.con = nn.Conv2d(in_channels=1, out_channels=2)\n",
    "        self.bn = nn.BatchNorm2d()\n",
    "        self.ave = nn.AvgPool2d()\n",
    "        self.dr = nn.Dropout()\n",
    "        self.fc = nn.Linear()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.fc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.2. <a id='toc10_1_2_'></a>[ResNet](#toc0_)\n",
    "```shell\n",
    "如果，CNN只需要弄懂一个神经网络模型的话，那就是ResNet。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1.2.1. <a id='toc10_1_2_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Flatten(), \n",
    "                                 nn.LSTM(), nn.ReLU()\n",
    "                                 )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1.2.2. <a id='toc10_1_2_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2. <a id='toc10_2_'></a>[序列数据](#toc0_)\n",
    "### 10.2.1. <a id='toc10_2_1_'></a>[序列](#toc0_)\n",
    "```sehll\n",
    "马尔可夫模型\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.2. <a id='toc10_2_2_'></a>[语言模型](#toc0_)\n",
    "语言模型 (language model)是定义在单词序列上的概率模型，可以用来计算一个句子或一段文字的概率\n",
    "```shell\n",
    "马尔可夫模型\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本预处理\n",
    "* token：最小单位（字符/单词/词组）\n",
    "* vocab：（token：indice）对照（查询）列表\n",
    "* cropus：token转化为indice后的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3. <a id='toc10_3_'></a>[RNN](#toc0_)\n",
    "* 可以处理有顺序的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.1. <a id='toc10_3_1_'></a>[RNN-循环神经网络](#toc0_)\n",
    "* 结构：\n",
    "    * 有一层（或多层）隐藏结构；\n",
    "    * 当前隐藏结构由上一侧隐藏结构和当前输入决定\n",
    "    * 依次类推"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.1.1. <a id='toc10_3_1_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.1.2. <a id='toc10_3_1_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on RNN in module torch.nn.modules.rnn object:\n",
      "\n",
      "class RNN(RNNBase)\n",
      " |  RNN(*args, **kwargs)\n",
      " |  \n",
      " |  __init__(self,input_size,hidden_size,num_layers=1,nonlinearity='tanh',bias=True,batch_first=False,dropout=0.0,bidirectional=False,device=None,dtype=None)\n",
      " |  \n",
      " |  Applies a multi-layer Elman RNN with :math:`\\tanh` or :math:`\\text{ReLU}` non-linearity to an\n",
      " |  input sequence.\n",
      " |  \n",
      " |  For each element in the input sequence, each layer computes the following\n",
      " |  function:\n",
      " |  \n",
      " |  .. math::\n",
      " |      h_t = \\tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh})\n",
      " |  \n",
      " |  where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is\n",
      " |  the input at time `t`, and :math:`h_{(t-1)}` is the hidden state of the\n",
      " |  previous layer at time `t-1` or the initial hidden state at time `0`.\n",
      " |  If :attr:`nonlinearity` is ``'relu'``, then :math:`\\text{ReLU}` is used instead of :math:`\\tanh`.\n",
      " |  \n",
      " |  Args:\n",
      " |      input_size: The number of expected features in the input `x`\n",
      " |      hidden_size: The number of features in the hidden state `h`\n",
      " |      num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
      " |          would mean stacking two RNNs together to form a `stacked RNN`,\n",
      " |          with the second RNN taking in outputs of the first RNN and\n",
      " |          computing the final results. Default: 1\n",
      " |      nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n",
      " |      bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
      " |          Default: ``True``\n",
      " |      batch_first: If ``True``, then the input and output tensors are provided\n",
      " |          as `(batch, seq, feature)` instead of `(seq, batch, feature)`.\n",
      " |          Note that this does not apply to hidden or cell states. See the\n",
      " |          Inputs/Outputs sections below for details.  Default: ``False``\n",
      " |      dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
      " |          RNN layer except the last layer, with dropout probability equal to\n",
      " |          :attr:`dropout`. Default: 0\n",
      " |      bidirectional: If ``True``, becomes a bidirectional RNN. Default: ``False``\n",
      " |  \n",
      " |  Inputs: input, h_0\n",
      " |      * **input**: tensor of shape :math:`(L, H_{in})` for unbatched input,\n",
      " |        :math:`(L, N, H_{in})` when ``batch_first=False`` or\n",
      " |        :math:`(N, L, H_{in})` when ``batch_first=True`` containing the features of\n",
      " |        the input sequence.  The input can also be a packed variable length sequence.\n",
      " |        See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n",
      " |        :func:`torch.nn.utils.rnn.pack_sequence` for details.\n",
      " |      * **h_0**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` for unbatched input or\n",
      " |        :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the initial hidden\n",
      " |        state for the input sequence batch. Defaults to zeros if not provided.\n",
      " |  \n",
      " |      where:\n",
      " |  \n",
      " |      .. math::\n",
      " |          \\begin{aligned}\n",
      " |              N ={} & \\text{batch size} \\\\\n",
      " |              L ={} & \\text{sequence length} \\\\\n",
      " |              D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n",
      " |              H_{in} ={} & \\text{input\\_size} \\\\\n",
      " |              H_{out} ={} & \\text{hidden\\_size}\n",
      " |          \\end{aligned}\n",
      " |  \n",
      " |  Outputs: output, h_n\n",
      " |      * **output**: tensor of shape :math:`(L, D * H_{out})` for unbatched input,\n",
      " |        :math:`(L, N, D * H_{out})` when ``batch_first=False`` or\n",
      " |        :math:`(N, L, D * H_{out})` when ``batch_first=True`` containing the output features\n",
      " |        `(h_t)` from the last layer of the RNN, for each `t`. If a\n",
      " |        :class:`torch.nn.utils.rnn.PackedSequence` has been given as the input, the output\n",
      " |        will also be a packed sequence.\n",
      " |      * **h_n**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` for unbatched input or\n",
      " |        :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the final hidden state\n",
      " |        for each element in the batch.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight_ih_l[k]: the learnable input-hidden weights of the k-th layer,\n",
      " |          of shape `(hidden_size, input_size)` for `k = 0`. Otherwise, the shape is\n",
      " |          `(hidden_size, num_directions * hidden_size)`\n",
      " |      weight_hh_l[k]: the learnable hidden-hidden weights of the k-th layer,\n",
      " |          of shape `(hidden_size, hidden_size)`\n",
      " |      bias_ih_l[k]: the learnable input-hidden bias of the k-th layer,\n",
      " |          of shape `(hidden_size)`\n",
      " |      bias_hh_l[k]: the learnable hidden-hidden bias of the k-th layer,\n",
      " |          of shape `(hidden_size)`\n",
      " |  \n",
      " |  .. note::\n",
      " |      All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
      " |      where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
      " |  \n",
      " |  .. note::\n",
      " |      For bidirectional RNNs, forward and backward are directions 0 and 1 respectively.\n",
      " |      Example of splitting the output layers when ``batch_first=False``:\n",
      " |      ``output.view(seq_len, batch, num_directions, hidden_size)``.\n",
      " |  \n",
      " |  .. note::\n",
      " |      ``batch_first`` argument is ignored for unbatched inputs.\n",
      " |  \n",
      " |  .. include:: ../cudnn_rnn_determinism.rst\n",
      " |  \n",
      " |  .. include:: ../cudnn_persistent_rnn.rst\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> rnn = nn.RNN(10, 20, 2)\n",
      " |      >>> input = torch.randn(5, 3, 10)\n",
      " |      >>> h0 = torch.randn(2, 3, 20)\n",
      " |      >>> output, hn = rnn(input, h0)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RNN\n",
      " |      RNNBase\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  forward(self, input, hx=None)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RNNBase:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setattr__(self, attr, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, d)\n",
      " |  \n",
      " |  check_forward_args(self, input: torch.Tensor, hidden: torch.Tensor, batch_sizes: Optional[torch.Tensor])\n",
      " |  \n",
      " |  check_hidden_size(self, hx: torch.Tensor, expected_hidden_size: Tuple[int, int, int], msg: str = 'Expected hidden size {}, got {}') -> None\n",
      " |  \n",
      " |  check_input(self, input: torch.Tensor, batch_sizes: Optional[torch.Tensor]) -> None\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  flatten_parameters(self) -> None\n",
      " |      Resets parameter data pointer so that they can use faster code paths.\n",
      " |      \n",
      " |      Right now, this works only if the module is on the GPU and cuDNN is enabled.\n",
      " |      Otherwise, it's a no-op.\n",
      " |  \n",
      " |  get_expected_hidden_size(self, input: torch.Tensor, batch_sizes: Optional[torch.Tensor]) -> Tuple[int, int, int]\n",
      " |  \n",
      " |  permute_hidden(self, hx: torch.Tensor, permutation: Optional[torch.Tensor])\n",
      " |  \n",
      " |  reset_parameters(self) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from RNNBase:\n",
      " |  \n",
      " |  all_weights\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from RNNBase:\n",
      " |  \n",
      " |  __constants__ = ['mode', 'input_size', 'hidden_size', 'num_layers', 'b...\n",
      " |  \n",
      " |  __jit_unused_properties__ = ['all_weights']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _wrapped_call_impl(self, *args, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Any\n",
      " |      # On the return type:\n",
      " |      # We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\n",
      " |      # This is done for better interop with various type checkers for the end users.\n",
      " |      # Having a stricter return type doesn't play nicely with `register_buffer()` and forces\n",
      " |      # people to excessively use type-ignores, asserts, casts, etc.\n",
      " |      # See full discussion on the problems with returning `Union` here\n",
      " |      # https://github.com/microsoft/pyright/issues/4213\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  compile(self, *args, **kwargs)\n",
      " |      Compile this Module's forward using :func:`torch.compile`.\n",
      " |      \n",
      " |      This Module's `__call__` method is compiled and all arguments are passed as-is\n",
      " |      to :func:`torch.compile`.\n",
      " |      \n",
      " |      See :func:`torch.compile` for details on the arguments for this function.\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Returns the buffer given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Returns any extra state to include in the module's state_dict.\n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be picklable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Returns the parameter given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Returns the submodule given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block:: text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the IPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True, assign: bool = False)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          If :attr:`assign` is ``True`` the optimizer must be created after\n",
      " |          the call to :attr:`load_state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |          assign (bool, optional): whether to assign items in the state\n",
      " |              dictionary to their corresponding keys in the module instead\n",
      " |              of copying them inplace into the module's current parameters and buffers.\n",
      " |              When ``False``, the properties of the tensors in the current\n",
      " |              module are preserved while when ``True``, the properties of the\n",
      " |              Tensors in the state dict are preserved.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool, optional): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module. Defaults to True.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated buffers in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>     if name in ['running_var']:\n",
      " |          >>>         print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated\n",
      " |              parameters in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>     if name in ['bias']:\n",
      " |          >>>         print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...], Any], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``False`` or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      output. It can modify the input inplace but it will not have effect on\n",
      " |      forward since this is called after :func:`forward` is called. The hook\n",
      " |      should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, output) -> None or modified output\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``True``, the forward hook will be passed the\n",
      " |      ``kwargs`` given to the forward function and be expected to return the\n",
      " |      output possibly modified. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs, output) -> None or modified output\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If ``True``, the provided ``hook`` will be fired\n",
      " |              before all existing ``forward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward`` hooks registered with\n",
      " |              :func:`register_module_forward_hook` will fire before all hooks\n",
      " |              registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If ``True``, the ``hook`` will be passed the\n",
      " |              kwargs given to the forward function.\n",
      " |              Default: ``False``\n",
      " |          always_call (bool): If ``True`` the ``hook`` will be run regardless of\n",
      " |              whether an exception is raised while calling the Module.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...]], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Any, Dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      \n",
      " |      \n",
      " |      If ``with_kwargs`` is false or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      input. User can either return a tuple or a single modified value in the\n",
      " |      hook. We will wrap the value into a tuple if a single value is returned\n",
      " |      (unless that value is already a tuple). The hook should have the\n",
      " |      following signature::\n",
      " |      \n",
      " |          hook(module, args) -> None or modified input\n",
      " |      \n",
      " |      If ``with_kwargs`` is true, the forward pre-hook will be passed the\n",
      " |      kwargs given to the forward function. And if the hook modifies the\n",
      " |      input, both the args and kwargs should be returned. The hook should have\n",
      " |      the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs) -> None or a tuple of modified input and kwargs\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``forward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward_pre`` hooks registered with\n",
      " |              :func:`register_module_forward_pre_hook` will fire before all\n",
      " |              hooks registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If true, the ``hook`` will be passed the kwargs\n",
      " |              given to the forward function.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to a module\n",
      " |      are computed, i.e. the hook will execute if and only if the gradients with\n",
      " |      respect to module outputs are computed. The hook should have the following\n",
      " |      signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward`` hooks registered with\n",
      " |              :func:`register_module_full_backward_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_pre_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients for the module are computed.\n",
      " |      The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_output) -> tuple[Tensor] or None\n",
      " |      \n",
      " |      The :attr:`grad_output` is a tuple. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the output that will be used in place of :attr:`grad_output` in\n",
      " |      subsequent computations. Entries in :attr:`grad_output` will be ``None`` for\n",
      " |      all non-Tensor arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward_pre`` hooks registered with\n",
      " |              :func:`register_module_full_backward_pre_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Registers a post hook to be run after module's ``load_state_dict``\n",
      " |      is called.\n",
      " |      \n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |      \n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |      \n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |      \n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearing out both missing and unexpected keys will avoid an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  register_state_dict_pre_hook(self, hook)\n",
      " |      These hooks will be called with arguments: ``self``, ``prefix``,\n",
      " |      and ``keep_vars`` before calling ``state_dict`` on ``self``. The registered\n",
      " |      hooks can be used to perform pre-processing before the ``state_dict``\n",
      " |      call is made.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any)\n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`\n",
      " |  \n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing references to the whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      .. note::\n",
      " |          The returned object is a shallow copy. It contains references\n",
      " |          to the module's parameters and buffers.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[str, torch.device], recurse: bool = True) -> ~T\n",
      " |      Moves the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |          recurse (bool): Whether parameters and buffers of submodules should\n",
      " |              be recursively moved to the specified device.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = True) -> None\n",
      " |      Resets gradients of all model parameters. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  call_super_init = False\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "rnn_layer = nn.RNN(input_size=3,            # 输入大小\n",
    "                   hidden_size=3,           # 隐藏层大小\n",
    "                   bidirectional=False,     # 双向神经网络，默认是单向\n",
    "                   num_layers=1             # 深层神经网络，默认是1层\n",
    "                   )\n",
    "# dir(rnn_layer)      # 查看属性\n",
    "help(rnn_layer)   # 查看方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 深层RNN\n",
    "* 有多个隐藏层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "rnn_layer = nn.RNN(input_size=3, \n",
    "                   hidden_size=3, \n",
    "                   num_layers=1             # 深层神经网络\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 双向RNN\n",
    "* 双向（其实就是将输入倒过来再输入）\n",
    "* 不能用双向循环神经网络来预测未来，因为从一开始就透露未来的信息。\n",
    "* 那实际引用场景是什么？\n",
    "    * 翻译\n",
    "    * 文本句子分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "rnn_layer = nn.RNN(input_size=3, \n",
    "                   hidden_size=3, \n",
    "                   num_layers=2             # 深层神经网络\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.2. <a id='toc10_3_2_'></a>[GRU](#toc0_)\n",
    "* GRU实际晚于LSTM，但是作用效果相当而更容易理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.2.1. <a id='toc10_3_2_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.2.2. <a id='toc10_3_2_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "gru_layer = nn.GRU(input_size=3, \n",
    "                   hidden_size=3, \n",
    "                   num_layers=2, \n",
    "                   bidirectional=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.3. <a id='toc10_3_3_'></a>[LSTM](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.3.1. <a id='toc10_3_3_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.3.2. <a id='toc10_3_3_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "lstm_layer = nn.LSTM(input_size=3, \n",
    "                     hidden_size=3, \n",
    "                     num_layers=2, \n",
    "                     bidirectional=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.6. <a id='toc10_3_6_'></a>[Encoder-Decoder框架](#toc0_)\n",
    "```shell\n",
    "输入-Encoder-中间状态-Decoder-输出\n",
    "                       输入\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.6.1. <a id='toc10_3_6_1_'></a>[Encoder部分](#toc0_)\n",
    "```shell\n",
    "可变长度的输入，固定长度的输出中间状态\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "#@save\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.6.2. <a id='toc10_3_6_2_'></a>[Decoder部分](#toc0_)\n",
    "```shell\n",
    "固定长度中间状态\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.6.3. <a id='toc10_3_6_3_'></a>[Encoder-Decoder（合并编码器和解码器）](#toc0_)\n",
    "```shell\n",
    "Encoder-Decoder\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.7. <a id='toc10_3_7_'></a>[seq2seq (Sequence to sequence learning)](#toc0_)\n",
    "```shell\n",
    "基于RNN的编码器-解码器框架(Encoder-Decoder)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.7.1. <a id='toc10_3_7_1_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4. <a id='toc10_4_'></a>[Attention](#toc0_)\n",
    "不是一个新的概念，很早之前就已经出现，只是在Google发表论文Attention is all you need后，越来越知名。  \n",
    "如果非要找一个依据，从心理学上讲： \n",
    " \n",
    "    1. 之前学习的神经网络（CNN、RNN等）都是提取特征->全连接网络，属于“非随意识注意力”-即非主观，如一排黑色水杯中有一个红色的就会很吸引人；  \n",
    "    2. Attention提出的是“随意识注意力”即主观的去注意那个物体。\n",
    "\n",
    "Query:主动去查询（注意）  \n",
    "Key:  \n",
    "Value:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.1. <a id='toc10_4_1_'></a>[非参数注意力汇聚（Attention Pooling）](#toc0_)\n",
    "在以前，统计学家计算机用的不是很溜。用统计模型进行预测，而不是利用计算机的计算资源进行迭代优化逼近真实分布。所得的结果就是只是利用统计模型进行预测的曲线会比较平滑但是准确性不高，可能随着数据量的增高可以提高准确性，但是，现实中能有那么多够用的数据吗？而利用计算迭代优化逼近的方法可以很准确的拟合现有的数据，虽然不是很平滑，优点是数据虽少但可以被充分利用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f(x) = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.2. <a id='toc10_4_2_'></a>[参数注意力汇聚（Attention Pooling）](#toc0_)\n",
    "```shell\n",
    "加入可学习的参数w。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.3. <a id='toc10_4_3_'></a>[注意力分数函数](#toc0_)\n",
    "#### 10.4.3.1. <a id='toc10_4_3_1_'></a>[加性注意力](#toc0_)\n",
    "```shell\n",
    "q和k的长度不一致。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.4.3.2. <a id='toc10_4_3_2_'></a>[缩放点积注意力](#toc0_)\n",
    "```shell\n",
    "q和k的长度一致。\n",
    "```\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.4. <a id='toc10_4_4_'></a>[自注意力机制](#toc0_)\n",
    "```shell\n",
    "自注意力机制：就是用同一个X分别于Wq、Wk和Wv矩阵相乘得到Q、K和V向量/矩阵。因为用的是同一个X同时作为q、k和v，所以得名为自注意力。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.5. <a id='toc10_4_5_'></a>[多头注意力机制](#toc0_)\n",
    "上述只求一次注意力的过程可以叫做单头注意力。多头注意力就是对同样的Q, K, V求多次注意力，并行计算h个得到h个不同的attention，再把这些不同的h个attention连接起来得到最终的attentions，每一个attention都是一个head（头），总共有h个head（头）。  \n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.6. <a id='toc10_4_6_'></a>[attention-seq2seq](#toc0_)\n",
    "```shell\n",
    "加入attention机制的Seq2Seq；\n",
    "基于Attention的Seq2Seq。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.7. <a id='toc10_4_7_'></a>[Transformer](#toc0_)\n",
    "```shell\n",
    "完全基于注意力机制的Encoder-Decoder架构。\n",
    "1.多头自注意力机制；\n",
    "2.掩码；\n",
    "3.Encoder-Decoder框架。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 位置编码\n",
    "```shell\n",
    "由于Transformer并行运算，没有顺序信息；\n",
    "Google一帮人发明了利用sin和cos函数编码位置信息并添加到输入X中；\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "max_len = 10\n",
    "num_hiddens = 3\n",
    "torch.zeros((1, max_len, num_hiddens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.4.7.1. <a id='toc10_4_7_1_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class Evoformer(nn.Module):\n",
    "    '''Encoder'''\n",
    "    def __init__(self):\n",
    "        self. \n",
    "\n",
    "    def forward(self, X):\n",
    "        return X \n",
    "    \n",
    "class Structure(nn.Module):\n",
    "    '''Decoder'''\n",
    "    def __init__(self):\n",
    "        self. \n",
    "\n",
    "    def forward(self, X):\n",
    "        return X \n",
    "\n",
    "class AlphaFold2(nn.Module):\n",
    "    '''The network of Encoder-Decoder'''\n",
    "    def __init__(self):\n",
    "        self.evoformer = Evoformer()\n",
    "        self.structure = Structure()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.4.7.2. <a id='toc10_4_7_2_'></a>[基于Attention的Seq2Seq网络](#toc0_)\n",
    "```shell\n",
    "基于Attention的Seq2Seq神经网络框架。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return \n",
    "\n",
    "class MySeq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.8. <a id='toc10_4_8_'></a>[BERT](#toc0_)\n",
    "```shell\n",
    "就是Encoder部分\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.9. <a id='toc10_4_9_'></a>[GPT](#toc0_)\n",
    "```shell\n",
    "就是Transformer的Decoder部分。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. <a id='toc11_'></a>[CV](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. <a id='toc11_1_'></a>[数据增广](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. <a id='toc12_'></a>[NLP](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. <a id='toc13_'></a>[炼丹心得](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1. <a id='toc13_1_'></a>[关于调参](#toc0_)\n",
    "1. Pytorch没有变量、常量之分，不需要定义说明什么是变量，全部都是张量；\n",
    "2. 因为变量定义后需要初始化，就相当于常量；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyLayer(nn.Module):\n",
    "    '''带参数的，自定义层'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(2, requires_grad=True))  # 变量，立即初始化，相当于常量\n",
    "        self.bias = nn.Parameter(torch.zeros(1, requires_grad=True))    # 同上\n",
    "    \n",
    "    def forward(self, X):\n",
    "        y_hat = self.weight.data@X + self.bias.data\n",
    "        # y_hat = torch.matmul(self.weight.data, X) + self.bias.data    # 同上\n",
    "        return F.relu(y_hat)\n",
    "\n",
    "myLayer = MyLayer()\n",
    "X = torch.ones(2)\n",
    "myLayer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([-1.2126,  0.9969])), ('bias', tensor([0.]))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.state_dict() # 访问神经网络参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2. <a id='toc13_2_'></a>[模型选择](#toc0_)\n",
    "```shell\n",
    "模型的复杂度应该合适，不能太大，也不能太小。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.4. <a id='toc13_4_'></a>[one-hot](#toc0_)\n",
    "```shell\n",
    "有向量无偏差表示；\n",
    "简单，但可能占空间\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_12228\\256218798.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(col_raw == raw) # 只是bool\n",
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_12228\\256218798.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  one_hot = torch.tensor(col_raw == raw, dtype=torch.float32) # bool -> torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]]),\n",
       " tensor([[1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "col_raw = raw.reshape(5, 1); col_raw\n",
    "col_raw == raw # （5， 1） 和 （1， 5）先广播后比较\n",
    "torch.tensor(col_raw == raw) # 只是bool\n",
    "one_hot = torch.tensor(col_raw == raw, dtype=torch.float32) # bool -> torch.float32\n",
    "col_raw, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "\n",
    "# help(F.one_hot)\n",
    "F.one_hot(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.5. <a id='toc13_5_'></a>[embedding](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "# 第一种\n",
    "# help(F.embedding)\n",
    "# F.embedding(raw)\n",
    "\n",
    "# 第二种\n",
    "# help(nn.Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.7. <a id='toc13_7_'></a>[BN和LN](#toc0_)\n",
    "Batch norm和Layer norm之间的区别  \n",
    "* BatchNorm：在同一特征（同一列），不同样品之间（不同行）之间做的normalization？ standerlization？\n",
    "* LayerNorm：在同一样品（同一行），不同特征（不同列）之间做的normalization？ standerlization？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "torch.nn.BatchNorm1d()\n",
    "torch.nn.LayerNorm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.8. <a id='toc13_8_'></a>[MLP、FC、FNN、CNN、RNN](#toc0_)\n",
    "Linear()：线性网络，即没有非线性激活函数  \n",
    "MLP()：多层感知机，有非线性激活函数  \n",
    "FNN()：前馈神经网络，同MLP（）  \n",
    "CNN()：卷积神经网络    \n",
    "RNN()：循环神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.9. <a id='toc13_9_'></a>[机器学习](#toc0_)\n",
    "```shell\n",
    "1. 监督学习  \n",
    "    自监督学习  \n",
    "    \n",
    "2. 半监督学习  \n",
    "3. 无监督学习  \n",
    "4. 强化学习  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.10. <a id='toc13_10_'></a>[迁移学习-Transfer learning](#toc0_)\n",
    "### 13.10.1. <a id='toc13_10_1_'></a>[Fine-tuning](#toc0_)\n",
    "```shell\n",
    "在今后的很长时间，深度学习的模型创新上会有很大的难度，基于已有的模型的微调（Fine-tuning）应用于新的可解决的问题是趋势。\n",
    "Fine-tuning in CV：\n",
    "    1.用Pre-trained的参数初始化特征提取器如Encoder的参数，而不是随机初始化；\n",
    "    2.用小的lerning-rate和小的epochs；\n",
    "    3.固定模型层的（其实就是learning-rate为0）。\n",
    "如何找到Pre-trained model？\n",
    "    TIMM（pytorch）-一个叫Ross的小哥自己维护的；\n",
    "    HugginFace - 一个早期只是东抄抄西抄抄的公司，逐渐发展为比较好的社区公司。\n",
    "Fine-tuning in NLP：\n",
    "    1.Self-supervised pre-training;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
