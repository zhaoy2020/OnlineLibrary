{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [概述](#toc1_)    \n",
    "- 2. [utils](#toc2_)    \n",
    "- 3. [安装GPU驱动](#toc3_)    \n",
    "  - 3.1. [安装策略](#toc3_1_)    \n",
    "  - 3.2. [首先确认内核版本和发行版本，再确认显卡型号](#toc3_2_)    \n",
    "  - 3.3. [安装驱动-CUDA Driver](#toc3_3_)    \n",
    "    - 3.3.1. [下载CUDA Driver](#toc3_3_1_)    \n",
    "    - 3.3.2. [禁用nouveau](#toc3_3_2_)    \n",
    "    - 3.3.3. [安装CUDA Driver](#toc3_3_3_)    \n",
    "    - 3.3.4. [查看显卡是否安装成功](#toc3_3_4_)    \n",
    "    - 3.3.5. [查看nvcc](#toc3_3_5_)    \n",
    "  - 3.4. [CUDA Toolkit和CuDNN](#toc3_4_)    \n",
    "    - 3.4.1. [下载对应的CUDA Toolkit版本](#toc3_4_1_)    \n",
    "    - 3.4.2. [安装CUDA Toolkit](#toc3_4_2_)    \n",
    "    - 3.4.3. [下载对应的CuDNN](#toc3_4_3_)    \n",
    "    - 3.4.4. [安装CuDNN](#toc3_4_4_)    \n",
    "  - 3.5. [安装对应版本的Pytorch](#toc3_5_)    \n",
    "  - 3.6. [GPU测试程序](#toc3_6_)    \n",
    "    - 3.6.1. [测试单机单卡GPU性能](#toc3_6_1_)    \n",
    "    - 3.6.2. [测试单机多卡GPU性能](#toc3_6_2_)    \n",
    "    - 3.6.3. [GPU burn压力测试](#toc3_6_3_)    \n",
    "- 4. [Pytorch模块介绍](#toc4_)    \n",
    "  - 4.1. [导入模块](#toc4_1_)    \n",
    "- 5. [数据加载](#toc5_)    \n",
    "  - 5.1. [现成的数据库-torchvison](#toc5_1_)    \n",
    "  - 5.2. [自定义数据库](#toc5_2_)    \n",
    "  - 5.3. [Pytorch数据加载](#toc5_3_)    \n",
    "    - 5.3.1. [估计数据加载时间](#toc5_3_1_)    \n",
    "- 6. [张量(Tensors)](#toc6_)    \n",
    "  - 6.1. [Tensors定义](#toc6_1_)    \n",
    "  - 6.2. [Tensors属性](#toc6_2_)    \n",
    "  - 6.3. [Tensors操作](#toc6_3_)    \n",
    "    - 6.3.1. [索引和切片](#toc6_3_1_)    \n",
    "    - 6.3.2. [转置](#toc6_3_2_)    \n",
    "  - 6.4. [线性代数运算](#toc6_4_)    \n",
    "    - 6.4.1. [哈达玛积](#toc6_4_1_)    \n",
    "    - 6.4.2. [点积（Dot Product）](#toc6_4_2_)    \n",
    "    - 6.4.3. [矩阵-向量积](#toc6_4_3_)    \n",
    "    - 6.4.4. [矩阵-矩阵积](#toc6_4_4_)    \n",
    "    - 6.4.5. [乘总结](#toc6_4_5_)    \n",
    "  - 6.5. [自动微积-autograd](#toc6_5_)    \n",
    "    - 6.5.1. [自己探索](#toc6_5_1_)    \n",
    "      - 6.5.1.1. [标量-一阶导数（得标量）](#toc6_5_1_1_)    \n",
    "      - 6.5.1.2. [标量/向量-一阶导数（得向量）](#toc6_5_1_2_)    \n",
    "      - 6.5.1.3. [向量/向量-一阶导数（得举证）](#toc6_5_1_3_)    \n",
    "    - 6.5.2. [一个简单的例子](#toc6_5_2_)    \n",
    "    - 6.5.3. [计算另一个](#toc6_5_3_)    \n",
    "    - 6.5.4. [非标量变量的反向传播](#toc6_5_4_)    \n",
    "    - 6.5.5. [分离计算](#toc6_5_5_)    \n",
    "    - 6.5.6. [Python控制流的梯度计算](#toc6_5_6_)    \n",
    "  - 6.6. [概率论](#toc6_6_)    \n",
    "- 7. [神经网络-训练八股](#toc7_)    \n",
    "  - 7.1. [现线性回归模型于训练过程-从零开始](#toc7_1_)    \n",
    "    - 7.1.1. [虚拟出数据](#toc7_1_1_)    \n",
    "    - 7.1.2. [读取数据](#toc7_1_2_)    \n",
    "    - 7.1.3. [初始化模型参数](#toc7_1_3_)    \n",
    "    - 7.1.4. [定义模型](#toc7_1_4_)    \n",
    "    - 7.1.5. [定义损失函数](#toc7_1_5_)    \n",
    "    - 7.1.6. [定义优化算法](#toc7_1_6_)    \n",
    "    - 7.1.7. [训练](#toc7_1_7_)    \n",
    "  - 7.2. [现线性回归模型于训练过程-简洁实现](#toc7_2_)    \n",
    "    - 7.2.1. [虚拟数据](#toc7_2_1_)    \n",
    "    - 7.2.2. [读取数据](#toc7_2_2_)    \n",
    "    - 7.2.3. [定义模型](#toc7_2_3_)    \n",
    "    - 7.2.4. [初始化模型参数](#toc7_2_4_)    \n",
    "    - 7.2.5. [定义损失函数](#toc7_2_5_)    \n",
    "    - 7.2.6. [定义优化算法](#toc7_2_6_)    \n",
    "    - 7.2.7. [训练](#toc7_2_7_)    \n",
    "  - 7.3. [专题-模型定义（计算预测值）](#toc7_3_)    \n",
    "    - 7.3.1. [torch.nn模块](#toc7_3_1_)    \n",
    "    - 7.3.2. [自定义-块](#toc7_3_2_)    \n",
    "      - 7.3.2.1. [自定义块](#toc7_3_2_1_)    \n",
    "      - 7.3.2.2. [顺序块](#toc7_3_2_2_)    \n",
    "      - 7.3.2.3. [效率](#toc7_3_2_3_)    \n",
    "    - 7.3.3. [参数管理](#toc7_3_3_)    \n",
    "      - 7.3.3.1. [参数访问](#toc7_3_3_1_)    \n",
    "      - 7.3.3.2. [参数初始化](#toc7_3_3_2_)    \n",
    "        - 7.3.3.2.1. [内置初始化](#toc7_3_3_2_1_)    \n",
    "        - 7.3.3.2.2. [自定义初始化](#toc7_3_3_2_2_)    \n",
    "        - 7.3.3.2.3. [参数绑定](#toc7_3_3_2_3_)    \n",
    "    - 7.3.4. [自定义-层](#toc7_3_4_)    \n",
    "      - 7.3.4.1. [不带参数的层](#toc7_3_4_1_)    \n",
    "      - 7.3.4.2. [带参数的层](#toc7_3_4_2_)    \n",
    "  - 7.4. [专题-损失函数](#toc7_4_)    \n",
    "    - 7.4.1. [均方误差](#toc7_4_1_)    \n",
    "    - 7.4.2. [交叉熵](#toc7_4_2_)    \n",
    "    - 7.4.3. [自定义](#toc7_4_3_)    \n",
    "  - 7.5. [专题-反向传播（求梯度）](#toc7_5_)    \n",
    "  - 7.6. [专题-更新权重（优化算法）](#toc7_6_)    \n",
    "    - 7.6.1. [小批量梯度下降（SGD）](#toc7_6_1_)    \n",
    "    - 7.6.2. [adam](#toc7_6_2_)    \n",
    "    - 7.6.3. [RMSprop](#toc7_6_3_)    \n",
    "  - 7.7. [专题-训练](#toc7_7_)    \n",
    "    - 7.7.1. [开始训练](#toc7_7_1_)    \n",
    "    - 7.7.2. [自己探索](#toc7_7_2_)    \n",
    "      - 7.7.2.1. [lr的影响](#toc7_7_2_1_)    \n",
    "      - 7.7.2.2. [不同模型的效率](#toc7_7_2_2_)    \n",
    "    - 7.7.3. [K折交叉验证](#toc7_7_3_)    \n",
    "  - 7.8. [可视化训练过程](#toc7_8_)    \n",
    "- 8. [在 GPU 上训练](#toc8_)    \n",
    "  - 8.1. [查看GPU配置](#toc8_1_)    \n",
    "  - 8.2. [单机单卡（GPU）](#toc8_2_)    \n",
    "  - 8.3. [单机多卡（GPU）](#toc8_3_)    \n",
    "    - 8.3.1. [DP](#toc8_3_1_)    \n",
    "    - 8.3.2. [DDP](#toc8_3_2_)    \n",
    "      - 8.3.2.1. [在colab上测试可用](#toc8_3_2_1_)    \n",
    "  - 8.4. [多机多卡（GPU）- 分布式训练](#toc8_4_)    \n",
    "- 9. [模型和参数的保存与加载](#toc9_)    \n",
    "  - 9.1. [加载和保存-张量](#toc9_1_)    \n",
    "  - 9.2. [加载和保存-模型参数](#toc9_2_)    \n",
    "- 10. [神经网络类型](#toc10_)    \n",
    "  - 10.1. [CNN](#toc10_1_)    \n",
    "    - 10.1.1. [简单CNN](#toc10_1_1_)    \n",
    "      - 10.1.1.1. [从头实现](#toc10_1_1_1_)    \n",
    "      - 10.1.1.2. [简介实现](#toc10_1_1_2_)    \n",
    "    - 10.1.2. [ResNet](#toc10_1_2_)    \n",
    "      - 10.1.2.1. [从头实现](#toc10_1_2_1_)    \n",
    "      - 10.1.2.2. [简洁实现](#toc10_1_2_2_)    \n",
    "  - 10.2. [序列数据](#toc10_2_)    \n",
    "    - 10.2.1. [序列](#toc10_2_1_)    \n",
    "    - 10.2.2. [语言模型](#toc10_2_2_)    \n",
    "    - 10.2.3. [文本预处理](#toc10_2_3_)    \n",
    "      - 10.2.3.1. [下载《Time machine》并读取数据](#toc10_2_3_1_)    \n",
    "      - 10.2.3.2. [词元化（Token）](#toc10_2_3_2_)    \n",
    "      - 10.2.3.3. [词表（vocab）](#toc10_2_3_3_)    \n",
    "      - 10.2.3.4. [整合所有功能](#toc10_2_3_4_)    \n",
    "    - 10.2.4. [语言模型数据集](#toc10_2_4_)    \n",
    "      - 10.2.4.1. [顺序采样](#toc10_2_4_1_)    \n",
    "      - 10.2.4.2. [随机采样](#toc10_2_4_2_)    \n",
    "      - 10.2.4.3. [包装](#toc10_2_4_3_)    \n",
    "  - 10.3. [RNN](#toc10_3_)    \n",
    "    - 10.3.1. [RNN-循环神经网络原理](#toc10_3_1_)    \n",
    "      - 10.3.1.1. [从头实现网络](#toc10_3_1_1_)    \n",
    "      - 10.3.1.2. [简洁实现](#toc10_3_1_2_)    \n",
    "      - 10.3.1.3. [训练和预测](#toc10_3_1_3_)    \n",
    "      - 10.3.1.4. [深层RNN](#toc10_3_1_4_)    \n",
    "      - 10.3.1.5. [双向RNN](#toc10_3_1_5_)    \n",
    "    - 10.3.2. [GRU](#toc10_3_2_)    \n",
    "      - 10.3.2.1. [从头实现](#toc10_3_2_1_)    \n",
    "      - 10.3.2.2. [简洁实现](#toc10_3_2_2_)    \n",
    "    - 10.3.3. [LSTM](#toc10_3_3_)    \n",
    "      - 10.3.3.1. [从头实现](#toc10_3_3_1_)    \n",
    "      - 10.3.3.2. [简洁实现](#toc10_3_3_2_)    \n",
    "    - 10.3.4. [Encoder-Decoder框架](#toc10_3_4_)    \n",
    "      - 10.3.4.1. [Encoder部分](#toc10_3_4_1_)    \n",
    "      - 10.3.4.2. [Decoder部分](#toc10_3_4_2_)    \n",
    "      - 10.3.4.3. [Encoder-Decoder（合并编码器和解码器）](#toc10_3_4_3_)    \n",
    "    - 10.3.5. [seq2seq (Sequence to sequence learning)](#toc10_3_5_)    \n",
    "      - 10.3.5.1. [简洁实现](#toc10_3_5_1_)    \n",
    "  - 10.4. [Attention](#toc10_4_)    \n",
    "    - 10.4.1. [非参数注意力汇聚（Attention Pooling）](#toc10_4_1_)    \n",
    "    - 10.4.2. [参数注意力汇聚（Attention Pooling）](#toc10_4_2_)    \n",
    "    - 10.4.3. [注意力分数函数](#toc10_4_3_)    \n",
    "      - 10.4.3.1. [加性注意力](#toc10_4_3_1_)    \n",
    "      - 10.4.3.2. [缩放点积注意力](#toc10_4_3_2_)    \n",
    "    - 10.4.4. [自注意力机制](#toc10_4_4_)    \n",
    "    - 10.4.5. [多头注意力机制](#toc10_4_5_)    \n",
    "    - 10.4.6. [attention-seq2seq](#toc10_4_6_)    \n",
    "    - 10.4.7. [Transformer](#toc10_4_7_)    \n",
    "      - 10.4.7.1. [位置编码](#toc10_4_7_1_)    \n",
    "      - 10.4.7.2. [Test](#toc10_4_7_2_)    \n",
    "      - 10.4.7.3. [基于Attention的Seq2Seq网络](#toc10_4_7_3_)    \n",
    "    - 10.4.8. [BERT](#toc10_4_8_)    \n",
    "    - 10.4.9. [GPT](#toc10_4_9_)    \n",
    "- 11. [CV](#toc11_)    \n",
    "  - 11.1. [数据增广](#toc11_1_)    \n",
    "- 12. [NLP](#toc12_)    \n",
    "- 13. [炼丹心得](#toc13_)    \n",
    "  - 13.1. [关于调参](#toc13_1_)    \n",
    "  - 13.2. [模型选择](#toc13_2_)    \n",
    "  - 13.3. [one-hot](#toc13_3_)    \n",
    "  - 13.4. [embedding](#toc13_4_)    \n",
    "  - 13.5. [BN和LN](#toc13_5_)    \n",
    "  - 13.6. [MLP、FC、FNN、CNN、RNN](#toc13_6_)    \n",
    "  - 13.7. [机器学习](#toc13_7_)    \n",
    "  - 13.8. [迁移学习-Transfer learning](#toc13_8_)    \n",
    "    - 13.8.1. [Fine-tuning](#toc13_8_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[概述](#toc0_)\n",
    "写这本书的主要目的是作为学些过程中知识的总结、归纳和反思。作为一个非科班出生的生物人，仅凭着热爱开始了自学深度学习这条路，前路漫漫不敢想，也不曾觉着以后能端这碗饭。只是，羡慕网上像智慧君、李沐这样的人，能够从事如此炫酷的工作，能把自己的热爱开发成一生从事的职业。仔细想想如果自己不做点什么或是不为此努力点什么，就觉得坐立不、安难以入眠。同时深知，这个过程会是无比艰辛，在百无聊赖之际，记录学习的过程或许会是一种苦中作乐的方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id='toc2_'></a>[utils](#toc0_)\n",
    "```shell\n",
    "自定义的一些使用的脚本。\n",
    "```\n",
    "```sehll\n",
    "__init__(self) # 初始化实例时就会执行\n",
    "_call__(self) # 再次调用时，自动执行\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 0.03298544883728027 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "class MyTimer():\n",
    "    '''一个计时器'''\n",
    "    def __init__(self):\n",
    "        self.start = time.time()\n",
    "\n",
    "    def __call__(self):\n",
    "        self.stop = time.time()\n",
    "        seconds = self.stop - self.start\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        print('='*100, '\\n', f\"Total：\\n {days} d \\n {hours} h \\n {minutes} m \\n {remaining_seconds} s\")\n",
    "        \n",
    "# MyTiemr使用\n",
    "timer = MyTimer()\n",
    "for i in range(3):\n",
    "    time.sleep(0.01)\n",
    "timer()\n",
    "\n",
    "class TrainPicture():\n",
    "    '''记录train loss、train acc和test acc的训练过程'''\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id='toc3_'></a>[安装GPU驱动](#toc0_)\n",
    "```shell\n",
    "以CentOS8安装NVIDIA Tesla A100为例；\n",
    "下载CUDA Toolkit和CuDNN，需要注意cudnn的版本必须与cuda的版本相匹配。\n",
    "    1.NVIDIA Driver：NVIDIA驱动是NVIDIA显卡的驱动程序，它是CUDA和CuDNN的前提条件。显卡驱动下载地址：https://www.nvidia.com/Download/index.aspx\n",
    "    2.CUDA Toolkit：CUDA Toolkit是一个开发工具包，其中包含了CUDA编译器、IDE、调试器等工具，以及CUDA程序所需的各种库文件和头文件。CUDA Toolkit还包括NVIDIA驱动程序，但不包括CuDNN1，每个版本的CUDA Toolkit 都对应一个最低版本的显卡驱动版本（CUDA Driver）。\n",
    "    3.NVCC：其实就是CUDA的编译器,可以从CUDA Toolkit的/bin目录中获取,类似于gcc就是c语言的编译器。\n",
    "    4.CUDA Deep Neural Network (cuDNN)：CuDNN是NVIDIA提供的一个深度神经网络加速库，它包含了一系列高性能的基本函数和算法，用于加速深度学习任务的计算。CuDNN需要与CUDA Toolkit一起使用，以优化深度学习任务。\n",
    "```\n",
    "## 3.1. <a id='toc3_1_'></a>[安装策略](#toc0_)\n",
    "```shell\n",
    "方式一：\n",
    "    只安装NVIDIA Tesla A100的driver，每个用户自己利用conda安装CUDA Toolkit、cuDNN和对应的Pytorch版本（推荐），但是得注意选择兼容型号。（推荐）\n",
    "方式二：\n",
    "    安装Driver、CUDA Toolkit (全局安装)\n",
    "方式三：\n",
    "    安装Driver、NVIDIA docker (docker虚拟容器)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. <a id='toc3_2_'></a>[首先确认内核版本和发行版本，再确认显卡型号](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "echo 查看linux内核版本、架构\n",
    "uname -a\n",
    "# Linux 135.91.205.202.cau.edu.cn 4.18.0-147.el8.x86_64 #1 SMP Wed Dec 4 21:51:45 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\n",
    "# x86_64\n",
    "\n",
    "echo 发行版本\n",
    "cat /etc/redhat-release\n",
    "# CentOS Linux release 8.1.1911 (Core)\n",
    "# CentOS\n",
    "\n",
    "echo 显卡型号 （硬件层面）\n",
    "lspci | grep -i nvidia\n",
    "# 04:00.0 3D controller: NVIDIA Corporation GK208M [GeForce GT 730M] (rev a1)\n",
    "\n",
    "echo 验证系统是否安装gcc编译器\n",
    "gcc --version\n",
    "\n",
    "sudo yum install kernel-devel-$(uname -r) kernel-headers-$(uname -r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. <a id='toc3_3_'></a>[安装驱动-CUDA Driver](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. <a id='toc3_3_1_'></a>[下载CUDA Driver](#toc0_)\n",
    "![image.png](attachment:image.png) ![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 从NVIDIA官网下辖\n",
    "# https://www.nvidia.cn/Download/index.aspx?lang=cn\n",
    "\n",
    "# 2. 通过dnf search nvidia*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. <a id='toc3_3_2_'></a>[禁用nouveau](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 貌似在centos8上默认就禁用了，我没改，直接查看了lsmod | grep nouveau命令，发现没有输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. <a id='toc3_3_3_'></a>[安装CUDA Driver](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'chmod' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n",
      "'sudo' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!chmod a+x *.run\n",
    "!sudo ./*.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4. <a id='toc3_3_4_'></a>[查看显卡是否安装成功](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5. <a id='toc3_3_5_'></a>[查看nvcc](#toc0_)\n",
    "```shell\n",
    "nvcc只是CUDA Toolkit中的一个软件。此时，只是安装了驱动程序，没有安装CUDA Toolkit，所以无法查看nvcc。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvcc' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. <a id='toc3_4_'></a>[CUDA Toolkit和CuDNN](#toc0_)\n",
    "```shell\n",
    "不推荐一开始作为root为Linux全局配置CUDA Toolkit，每个用户和软件使用的CUDA Toolkit版本可能不一样。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. <a id='toc3_4_1_'></a>[下载对应的CUDA Toolkit版本](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc -V # 查看是否安装好CUDA Toolkit\n",
    "\n",
    "wget https://us.download.nvidia.cn/tesla/535.129.03/NVIDIA-Linux-x86_64-535.129.03.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2. <a id='toc3_4_2_'></a>[安装CUDA Toolkit](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# 卸载之前安装的cuda\n",
    "sudo dnf remove nvidia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "chmod +x NVIDIA-Linux-x86_64-535.129.03.run\n",
    "sudo sh NVIDIA-Linux-x86_64-535.129.03.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3. <a id='toc3_4_3_'></a>[下载对应的CuDNN](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://link.zhihu.com/?target=https%3A//developer.nvidia.com/rdp/cudnn-download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4. <a id='toc3_4_4_'></a>[安装CuDNN](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. <a id='toc3_5_'></a>[安装对应版本的Pytorch](#toc0_)\n",
    "```shell\n",
    "在Pytorch的官网进行查询，按照条件检索符合要求的软件版本，最主要的是对应的cuda版本号。\n",
    "```\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# https://pytorch.org/\n",
    "# CUDA 12.1\n",
    "conda create -n pytorch-gpu -y\n",
    "conda activate pytorch-gpu \n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia # CUDA 12.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. <a id='toc3_6_'></a>[GPU测试程序](#toc0_)\n",
    "### 3.6.1. <a id='toc3_6_1_'></a>[测试单机单卡GPU性能](#toc0_)\n",
    "```shell\n",
    "net.to('cuda:0')\n",
    "x_gpu = x.to('cuda:0')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Runing on cpu\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10: train_loss=1.5748493671417236, train_acc=90.50333404541016, test_acc=90.8499984741211\n",
      "epoch 2/10: train_loss=1.5482720136642456, train_acc=92.31500244140625, test_acc=92.51000213623047\n",
      "epoch 3/10: train_loss=1.5332448482513428, train_acc=93.66000366210938, test_acc=93.55999755859375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 115\u001b[0m\n\u001b[0;32m    113\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m    114\u001b[0m opt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(params\u001b[38;5;241m=\u001b[39mnet\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)   \n\u001b[1;32m--> 115\u001b[0m \u001b[43mtrain_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                        \u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[28], line 78\u001b[0m, in \u001b[0;36mtrain_steps\u001b[1;34m(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device)\u001b[0m\n\u001b[0;32m     76\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m net(X)          \u001b[38;5;66;03m# 计算y_hat\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_hat, y)\u001b[38;5;66;03m# 计算loss\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# 计算梯度\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     opt\u001b[38;5;241m.\u001b[39mstep()              \u001b[38;5;66;03m# 更新网络参数\u001b[39;00m\n\u001b[0;32m     81\u001b[0m net\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# 切换至评估模式\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramFiles\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramFiles\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=True, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "test_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=False, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, \n",
    "                             batch_size=128, \n",
    "                             shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "                                     nn.Linear(1024, 10), nn.Softmax())\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device \n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2. <a id='toc3_6_2_'></a>[测试单机多卡GPU性能](#toc0_)\n",
    "```shell\n",
    "torch.nn.DataParallel()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Runing on cpu\n",
      "====================================================================================================\n",
      "epoch 1/10: train_loss=1.564773440361023, train_acc=91.1433334350586, test_acc=91.56999969482422\n",
      "epoch 2/10: train_loss=1.5450105667114258, train_acc=92.69833374023438, test_acc=92.77999877929688\n",
      "epoch 3/10: train_loss=1.5324627161026, train_acc=93.76666259765625, test_acc=93.5999984741211\n",
      "epoch 4/10: train_loss=1.5238758325576782, train_acc=94.40666198730469, test_acc=94.20999908447266\n",
      "epoch 5/10: train_loss=1.515897274017334, train_acc=95.2249984741211, test_acc=94.84000396728516\n",
      "epoch 6/10: train_loss=1.5111769437789917, train_acc=95.68499755859375, test_acc=95.06000518798828\n",
      "epoch 7/10: train_loss=1.5064157247543335, train_acc=96.02333068847656, test_acc=95.52000427246094\n",
      "epoch 8/10: train_loss=1.5023516416549683, train_acc=96.42500305175781, test_acc=95.77000427246094\n",
      "epoch 9/10: train_loss=1.500041127204895, train_acc=96.69667053222656, test_acc=96.02000427246094\n",
      "epoch 10/10: train_loss=1.49596107006073, train_acc=97.05166625976562, test_acc=96.4000015258789\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 26.067356824874878 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=True, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "test_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=False, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, \n",
    "                             batch_size=128, \n",
    "                             shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "                                     nn.Linear(1024, 10), nn.Softmax())\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net = nn.DataParallel(module=net)\n",
    "    net = net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(), y.to()   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device \n",
    "            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = [ 'cpu' if not torch.cuda.is_available() else ]\n",
    "device = [f'cuda:{i}' for i in range(torch.cuda.device_count())] if torch.cuda.is_available() else ['cpu']\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3. <a id='toc3_6_3_'></a>[GPU burn压力测试](#toc0_)\n",
    "```shell\n",
    "李沐在装机配置后，进行GPU压力测试所用的程序为GPU_burn（可从github上下载）\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# Building\n",
    "# To build GPU Burn:\n",
    "make\n",
    "# To remove artifacts built by GPU Burn:\n",
    "make clean\n",
    "# GPU Burn builds with a default Compute Capability of 5.0. To override this with a different value:\n",
    "make COMPUTE=<compute capability value>\n",
    "# CFLAGS can be added when invoking make to add to the default list of compiler flags:\n",
    "make CFLAGS=-Wall\n",
    "# LDFLAGS can be added when invoking make to add to the default list of linker flags:\n",
    "make LDFLAGS=-lmylib\n",
    "# NVCCFLAGS can be added when invoking make to add to the default list of nvcc flags:\n",
    "make NVCCFLAGS=-ccbin <path to host compiler>\n",
    "# CUDAPATH can be added to point to a non standard install or specific version of the cuda toolkit (default is /usr/local/cuda):\n",
    "make CUDAPATH=/usr/local/cuda-<version>\n",
    "# CCPATH can be specified to point to a specific gcc (default is /usr/bin):\n",
    "make CCPATH=/usr/local/bin\n",
    "# CUDA_VERSION and IMAGE_DISTRO can be used to override the base images used when building the Docker image target, while IMAGE_NAME can be set to change the resulting image tag:\n",
    "make IMAGE_NAME=myregistry.private.com/gpu-burn CUDA_VERSION=12.0.1 IMAGE_DISTRO=ubuntu22.04 image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id='toc4_'></a>[Pytorch模块介绍](#toc0_)\n",
    "## 4.1. <a id='toc4_1_'></a>[导入模块](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 线程的数据库\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "\n",
    "# 数据加载\n",
    "import torch.utils.data \n",
    "# import torch.utils.data.TensorDataset\n",
    "import torch.utils.data.dataloader\n",
    "\n",
    "# 神经网络结构\n",
    "import torch.nn \n",
    "import torch.nn.functional \n",
    "\n",
    "import torch.nn.DataParallel\n",
    "import torch.distributed as dist\n",
    "\n",
    "# 优化器\n",
    "import torch.optim \n",
    "\n",
    "import d2l\n",
    "\n",
    "print('pytorch version: ', torch.__version__)\n",
    "print(f\"torchvision version: {torchvision.__version__}\")\n",
    "print(f\"d2l version: {d2l.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. <a id='toc5_'></a>[数据加载](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. <a id='toc5_1_'></a>[现成的数据库-torchvison](#toc0_)\n",
    "```shell\n",
    "tochvision主要处理图像数据，包含一些常用的数据集、模型、转换函数等。  \n",
    "torchvision独立于PyTorch，需要专门安装。\n",
    "\n",
    "torchvision.models: 提供深度学习中各种经典的网络结构、预训练好的模型，如：Alex-Net、VGG、ResNet、Inception等。\n",
    "torchvision.datasets：提供常用的数据集，设计上继承 torch.utils.data.Dataset，主要包括：MNIST、CIFAR10/100、ImageNet、COCO等。\n",
    "torchvision.transforms：提供常用的数据预处理操作，主要包括对Tensor及PIL Image对象的操作。\n",
    "torchvision.utils：工具类，如保存张量作为图像到磁盘，给一个小批量创建一个图像网格。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./Pytorch_datasets/\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./Pytorch_datasets/\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "dbs = './Pytorch_datasets/'\n",
    "\n",
    "trans = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),  # PIL转换为tensor格式\n",
    "                                        # torchvision.transforms.Normalize((0.5,), (1.0,))\n",
    "                                        ])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root=dbs, \n",
    "                                          train=True, \n",
    "                                          download=True,\n",
    "                                          transform=trans, \n",
    "                                        #   target_transform=False\n",
    "                                          )\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root=dbs, \n",
    "                                          train=False, \n",
    "                                          download=True, \n",
    "                                          transform=trans, \n",
    "                                        #   target_transform=False\n",
    "                                          )\n",
    "train_dataset, test_dataset\n",
    "# 封装成torch使用的dataset格式数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       " tensor([9, 0, 0,  ..., 3, 0, 5]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data, train_dataset.targets # 访问"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. <a id='toc5_2_'></a>[自定义数据库](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "# 1. 自建数据集\n",
    "features = \n",
    "labels = \n",
    "\n",
    "# 构建dataset数据集\n",
    "datasets = data.TensorDataset(*(features, labels)) \n",
    "# 加载成batch数据\n",
    "data_iter = data.DataLoader(dataset=datasets, \n",
    "                            batch_size=256, \n",
    "                            shuffle=True, \n",
    "                            num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. <a id='toc5_3_'></a>[Pytorch数据加载](#toc0_)\n",
    "```shell\n",
    "1. 先将自制的数据集利用data.TensorDataset生成dataset；\n",
    "2. 再用data.DataLoader加载到dataset成最终可用的带有batch_size的格式，方便后续的训练\n",
    "\n",
    "3. 先测试以下数据加载的速度，必须比训练计算所耗的时间小，否则将降低训练效率；\n",
    "4. 当数据加载时间很长时可以预加载，缩短时间\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data \n",
    "\n",
    "# 2. 加载torchvison数据集（格式化好的torch.utils.data.Dataset）\n",
    "train_iter = data.DataLoader(dataset=train_dataset, \n",
    "                            batch_size=256, \n",
    "                            shuffle=True,           # 打乱顺序\n",
    "                            num_workers=3           # 线程数\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. <a id='toc5_3_1_'></a>[估计数据加载时间](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 5.080876111984253 s\n"
     ]
    }
   ],
   "source": [
    "# 读完一个epoch的一个batch，耗时\n",
    "timer = MyTimer()\n",
    "for X, y in train_iter:\n",
    "    break \n",
    "timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Total：\n",
      " 0.0 d \n",
      " 0.0 h \n",
      " 0.0 m \n",
      " 7.888774394989014 s\n"
     ]
    }
   ],
   "source": [
    "# 读完一个epoch的所有batch，耗时\n",
    "timer = MyTimer()\n",
    "for X, y in train_iter:\n",
    "    continue \n",
    "timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. <a id='toc6_'></a>[张量(Tensors)](#toc0_)\n",
    "## 6.1. <a id='toc6_1_'></a>[Tensors定义](#toc0_)\n",
    "```\n",
    "Pytorch 的一大作用就是可以代替 Numpy 库，所以首先介绍 Tensors ，也就是张量，它相当于 Numpy 的多维数组(ndarrays)。\n",
    "两者的区别就是：\n",
    "    数学概念：张量Tensors\n",
    "    编程概念：数组Array\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.asarray([1.0, 2.0, 3.0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]]),\n",
       " tensor([[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14]], dtype=torch.int32))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy转tensor\n",
    "import numpy as np\n",
    "x = np.arange(0, 15).reshape(5, 3)\n",
    "x, torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9821e+28, 2.0417e-42, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5, 3) # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(5, 3) # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2723, 0.9452, 0.4822],\n",
       "        [0.5238, 0.9299, 0.5431],\n",
       "        [0.6608, 0.1720, 0.2721],\n",
       "        [0.9852, 0.2298, 0.0329],\n",
       "        [0.2947, 0.4694, 0.1787]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5, 3) # 随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1491,  2.0538,  0.6111,  1.7104,  0.8878, -0.3257,  0.7754,  0.4024,\n",
       "        -0.3722,  0.6816, -0.7800, -1.6328,  0.9139,  1.3536, -0.6945])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(15) # 标准正态分布随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(3) # 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(15).reshape(5, 3) # reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\2358321395.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  x = torch.tensor(torch.range(0, 14).reshape(5, 3))\n",
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\2358321395.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.range(0, 14).reshape(5, 3))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.],\n",
       "         [ 9., 10., 11.],\n",
       "         [12., 13., 14.]]),\n",
       " array([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.],\n",
       "        [12., 13., 14.]], dtype=float32))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor转化为numpy\n",
    "x = torch.tensor(torch.range(0, 14).reshape(5, 3))\n",
    "x, x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. <a id='toc6_2_'></a>[Tensors属性](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8939e-29,  2.1426e-42,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size() # shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. <a id='toc6_3_'></a>[Tensors操作](#toc0_)\n",
    "### 6.3.1. <a id='toc6_3_1_'></a>[索引和切片](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9825e+28, 2.0417e-42, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9825e+28, 2.0417e-42, 0.0000e+00])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # 0行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1] # 1行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9825e+28, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0] # 0列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0417e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1] # 1列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2. <a id='toc6_3_2_'></a>[转置](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.9823e+28, 2.0417e-42, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]),\n",
       " torch.Size([5, 3]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "x, x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.9823e+28, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.0417e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]),\n",
       " torch.Size([3, 5]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.T, x.T.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. <a id='toc6_4_'></a>[线性代数运算](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\1780641904.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  y = torch.tensor(torch.range(0, 14).reshape(5, 3))\n",
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\1780641904.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(torch.range(0, 14).reshape(5, 3))\n",
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\1780641904.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  z = torch.tensor(torch.range(0, 14).reshape(3, 5))\n",
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_19324\\1780641904.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = torch.tensor(torch.range(0, 14).reshape(3, 5))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.],\n",
       "         [ 9., 10., 11.],\n",
       "         [12., 13., 14.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5, 3)\n",
    "y = torch.tensor(torch.range(0, 14).reshape(5, 3))\n",
    "z = torch.tensor(torch.range(0, 14).reshape(3, 5))\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [10., 11., 12.],\n",
       "         [13., 14., 15.]]),\n",
       " tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [10., 11., 12.],\n",
       "         [13., 14., 15.]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y, torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.,   0.,  -1.],\n",
       "         [ -2.,  -3.,  -4.],\n",
       "         [ -5.,  -6.,  -7.],\n",
       "         [ -8.,  -9., -10.],\n",
       "         [-11., -12., -13.]]),\n",
       " tensor([[  1.,   0.,  -1.],\n",
       "         [ -2.,  -3.,  -4.],\n",
       "         [ -5.,  -6.,  -7.],\n",
       "         [ -8.,  -9., -10.],\n",
       "         [-11., -12., -13.]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - y, torch.sub(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * 3 # 数乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.],\n",
       "        [15., 18., 21., 24., 27.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x, z) # 矩阵相乘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1. <a id='toc6_4_1_'></a>[哈达玛积](#toc0_)\n",
    "* 按照**元素**进行乘法\n",
    "* 乘前形状必须相同，乘后不改变形状\n",
    "* x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[ 0,  1,  4],\n",
       "         [ 9, 16, 25]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.arange(6).reshape(2, 3)\n",
    "x, x * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2. <a id='toc6_4_2_'></a>[点积（Dot Product）](#toc0_)\n",
    "* 按照元素进行乘法后相加\n",
    "* 乘前形状一样，乘后**标量**\n",
    "* torch.dot(x, x) # dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor([0, 1, 4]), tensor(5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(3)\n",
    "x, x * x, torch.dot(x, x) # 打印， 哈德玛积， 点积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3. <a id='toc6_4_3_'></a>[矩阵-向量积](#toc0_)\n",
    "* 矩阵乘法的特殊\n",
    "* 乘后**向量**\n",
    "* torch.mv(A, x) # matrix-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([4]), torch.Size([3]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "x = torch.ones(4, dtype=torch.float32)\n",
    "A.shape, x.shape, torch.mv(A, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]),)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * x).shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.4. <a id='toc6_4_4_'></a>[矩阵-矩阵积](#toc0_)\n",
    "* 乘后**矩阵**\n",
    "* torch.matmul(X, Y)\n",
    "* torch.mm(X, Y) # matrix-mul\n",
    "* X @ Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]),\n",
       " torch.Size([5, 3]),\n",
       " torch.Size([3, 3]),\n",
       " torch.Size([3, 3]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(15).reshape(3, 5)\n",
    "Y = torch.arange(15).reshape(5, 3)\n",
    "X.shape, Y.shape, (X @ Y).shape, torch.mm(X, Y).shape, torch.matmul(X, Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.5. <a id='toc6_4_5_'></a>[乘总结](#toc0_)\n",
    "```shell\n",
    "* 哈德玛积      A * B\n",
    "* 点积          dot(A, B)\n",
    "* 矩阵-向量     mv(A, x)\n",
    "* 矩阵-矩阵     mm(A, B) 或 mm(A, B) 或 A @ B\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. <a id='toc6_5_'></a>[自动微积-autograd](#toc0_)\n",
    "```\n",
    "深度学习框架可以自动计算导数：\n",
    "    1. 我们首先将梯度附加到想要对其计算偏导数的变量上， \n",
    "        x.requires_grad_(True)\n",
    "    2. 然后记录目标值的计算，\n",
    "        y = x * x (grad_fn)\n",
    "    3. 执行它的反向传播函数(求梯度)，\n",
    "        y.backward()\n",
    "    4. 并访得到的梯度。 \n",
    "        x.grad\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1. <a id='toc6_5_1_'></a>[自己探索](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.1.1. <a id='toc6_5_1_1_'></a>[标量-一阶导数（得标量）](#toc0_)\n",
    "```shell\n",
    "好像不能求高阶导数，不如jax.grad()灵活\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2., requires_grad=True), tensor(4., grad_fn=<PowBackward0>))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2.0, dtype=torch.float32, requires_grad=True)  # 标量\n",
    "y = x**2                                                        # 标量\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为None\n",
    "x.grad, x.grad == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y对x进行求导\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为2 * 1 = 2\n",
    "x.grad                                                          # 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 2*x # y关于x的一阶导函数就是2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造新的关于x的函数：z = x**3\n",
    "z = x**2\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为：\n",
    "x.grad # 应该为0才对，需要手动清零# x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z关于x求导\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时x的导数为：\n",
    "x.grad # 应该为4，但是残留的4 + 本次的4 = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.1.2. <a id='toc6_5_1_2_'></a>[标量/向量-一阶导数（得向量）](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0, dtype=torch.float32, requires_grad=True)  # 向量\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14., grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.dot(x,x)                                              # 标量\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad                                                          # 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 2*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.1.3. <a id='toc6_5_1_3_'></a>[向量/向量-一阶导数（得举证）](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2. <a id='toc6_5_2_'></a>[一个简单的例子](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在我们计算关于的梯度之前，需要一个地方来存储梯度。\n",
    "x.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)\n",
    "x.grad                  # 默认值是None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在计算。\n",
    "y = 2 * torch.dot(x, x)\n",
    "y                       # x是一个长度为4的向量，计算x和x的点积，得到了我们赋值给y的标量输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 接下来，通过调用反向传播函数来自动计算y关于x每个分量的梯度，并打印这些梯度。\n",
    "y.backward()            # [4x, 4x, 4x, 4x] 导函数\n",
    "x.grad                  # [4*0, 4*1, 4*2, 4*3] 导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x         # [4x, 4x, 4x, 4x] 导函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3. <a id='toc6_5_3_'></a>[计算另一个](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值\n",
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor(6., grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.4. <a id='toc6_5_4_'></a>[非标量变量的反向传播](#toc0_)\n",
    "```\n",
    "当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵。 对于高阶和高维的y和x，求导的结果可以是一个高阶张量。\n",
    "然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括深度学习中）， 但当调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n",
    "# 本例只想求偏导数的和，所以传递一个1的梯度是合适的\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "# 等价于y.backward(torch.ones(len(x)))\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x * x \n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0.]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad, x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([0., 2., 4., 6.]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum().backward(), x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.5. <a id='toc6_5_5_'></a>[分离计算](#toc0_)\n",
    "```\n",
    "有时，我们希望将某些计算移动到记录的计算图之外。 例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。 想象一下，我们想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数， 并且只考虑到x在y被计算后发挥的作用。\n",
    "\n",
    "这里可以分离y来返回一个新变量u，该变量与y具有相同的值， 但丢弃计算图中如何计算y的任何信息。 换句话说，梯度不会向后流经u到x。 因此，下面的反向传播函数计算z=u*x关于x的偏导数，同时将u作为常数处理， 而不是z=x*x*x关于x的偏导数。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x\n",
    "u = y.detach()\n",
    "z = u * x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由于记录了y的计算结果，我们可以随后在y上调用反向传播， 得到y=x*x关于的x的导数，即2*x。\n",
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.6. <a id='toc6_5_6_'></a>[Python控制流的梯度计算](#toc0_)\n",
    "```\n",
    "使用自动微分的一个好处是： 即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度。 在下面的代码中，while循环的迭代次数和if语句的结果都取决于输入a的值。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让我们计算梯度。\n",
    "a = torch.randn(size=(), requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们现在可以分析上面定义的f函数。 请注意，它在其输入a中是分段线性的。 换言之，对于任何a，存在某个常量标量k，使得f(a)=k*a，其中k的值取决于输入a，因此可以用d/a验证梯度是否正确。\n",
    "a.grad == d / a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6. <a id='toc6_6_'></a>[概率论](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. <a id='toc7_'></a>[神经网络-训练八股](#toc0_)\n",
    "```shell\n",
    "神经网络搭建八股：\n",
    "    1. 定义网络模型\n",
    "        ->计算出y_hat\n",
    "    2. 选择损失函数\n",
    "        ->计算loss值、求梯度\n",
    "    3. 选择优化器\n",
    "        ->更新网络权重参数\n",
    "    4. 训练\n",
    "        ->实施1、2、3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. <a id='toc7_1_'></a>[现线性回归模型于训练过程-从零开始](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1. <a id='toc7_1_1_'></a>[虚拟出数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([0.1456, 0.6208]) \n",
      "label: tensor([2.3813])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import random\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"生成y=Xw+b+噪声\"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "\n",
    "print('features:', features[0],'\\nlabel:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"231.442187pt\" height=\"169.678125pt\" viewBox=\"0 0 231.442187 169.678125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-12-24T22:06:12.221164</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 169.678125 \n",
       "L 231.442187 169.678125 \n",
       "L 231.442187 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "L 28.942188 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"mafb3b7f13b\" d=\"M 0 0.5 \n",
       "C 0.132602 0.5 0.25979 0.447317 0.353553 0.353553 \n",
       "C 0.447317 0.25979 0.5 0.132602 0.5 0 \n",
       "C 0.5 -0.132602 0.447317 -0.25979 0.353553 -0.353553 \n",
       "C 0.25979 -0.447317 0.132602 -0.5 0 -0.5 \n",
       "C -0.132602 -0.5 -0.25979 -0.447317 -0.353553 -0.353553 \n",
       "C -0.447317 -0.25979 -0.5 -0.132602 -0.5 0 \n",
       "C -0.5 0.132602 -0.447317 0.25979 -0.353553 0.353553 \n",
       "C -0.25979 0.447317 -0.132602 0.5 0 0.5 \n",
       "z\n",
       "\" style=\"stroke: #1f77b4\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p90ff8178db)\">\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.855178\" y=\"86.560171\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.77098\" y=\"100.444328\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.974742\" y=\"69.739166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.589452\" y=\"93.225276\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"156.128421\" y=\"97.857122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.877595\" y=\"67.832642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.381371\" y=\"75.165856\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"166.593137\" y=\"114.49919\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.629944\" y=\"110.827633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.043093\" y=\"66.330904\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.226529\" y=\"108.243491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.389337\" y=\"72.548968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.432001\" y=\"62.221611\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.521325\" y=\"78.911158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"174.439984\" y=\"99.145236\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.316404\" y=\"75.310057\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.119424\" y=\"70.944081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.593353\" y=\"47.879469\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.550727\" y=\"81.875043\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.726437\" y=\"77.629306\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.09976\" y=\"100.507817\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"156.366486\" y=\"104.420866\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.115416\" y=\"76.738185\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.112725\" y=\"69.484402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.191489\" y=\"54.72236\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.34944\" y=\"80.072299\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.216021\" y=\"79.283392\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.889322\" y=\"84.838633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.502982\" y=\"75.122788\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.619577\" y=\"99.847867\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.126936\" y=\"72.115602\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.797464\" y=\"99.84199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.895668\" y=\"53.330821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.416993\" y=\"68.33721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.064343\" y=\"87.477465\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.042363\" y=\"83.70824\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"75.969503\" y=\"42.379578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.590527\" y=\"96.997053\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.789533\" y=\"60.353805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.546723\" y=\"71.086023\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.43529\" y=\"95.525847\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.372278\" y=\"71.995264\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.941746\" y=\"68.148722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.761329\" y=\"66.32105\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"172.99687\" y=\"100.542334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"198.067272\" y=\"131.468994\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.544663\" y=\"37.657081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.974595\" y=\"82.797923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.390258\" y=\"85.100996\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.29525\" y=\"83.8968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.108296\" y=\"83.629538\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"80.70032\" y=\"52.771182\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.748066\" y=\"58.715203\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.549158\" y=\"65.098382\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.248799\" y=\"48.015701\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"181.728868\" y=\"121.994921\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.394642\" y=\"87.265383\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.182022\" y=\"65.475991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.703086\" y=\"86.255392\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.074063\" y=\"73.096907\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.415488\" y=\"85.65443\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.716789\" y=\"85.961071\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.572666\" y=\"70.794755\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.682733\" y=\"74.845712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.460722\" y=\"70.108676\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"174.018126\" y=\"117.798398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.554264\" y=\"86.968223\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"101.429928\" y=\"46.014455\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.276435\" y=\"87.941624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.463549\" y=\"106.992745\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"189.859793\" y=\"122.984031\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.373337\" y=\"60.722805\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"178.884629\" y=\"105.882054\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"53.351693\" y=\"28.239491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"55.571112\" y=\"37.60902\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.869529\" y=\"76.269144\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.975431\" y=\"59.532278\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.985322\" y=\"65.316468\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.257857\" y=\"92.847639\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.758244\" y=\"72.716884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.49281\" y=\"130.376514\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.216983\" y=\"61.45494\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.392418\" y=\"48.622394\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"192.253483\" y=\"113.656616\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.571734\" y=\"73.427866\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.465782\" y=\"55.067106\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"193.050015\" y=\"116.038637\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.474827\" y=\"66.980975\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.067976\" y=\"61.221955\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.666821\" y=\"91.797638\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.082085\" y=\"97.556625\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"187.318643\" y=\"97.02529\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.722339\" y=\"64.011906\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.454779\" y=\"58.318228\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.791424\" y=\"113.935706\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.283623\" y=\"85.485447\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.832517\" y=\"65.484322\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"181.142563\" y=\"107.521857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"49.422117\" y=\"36.738685\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"91.678241\" y=\"53.498613\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.607011\" y=\"61.636102\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.037047\" y=\"57.373076\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.823989\" y=\"61.765317\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.507757\" y=\"91.195493\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.476326\" y=\"64.680833\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.124296\" y=\"77.225925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.050317\" y=\"51.776811\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.056592\" y=\"74.730062\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.703666\" y=\"99.898693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.974219\" y=\"95.475022\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.956885\" y=\"75.080933\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.546582\" y=\"76.166429\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"71.817981\" y=\"33.972126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.774171\" y=\"62.981683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.560983\" y=\"86.623165\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.610356\" y=\"73.286708\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.043526\" y=\"52.512241\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.650877\" y=\"53.505349\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.36819\" y=\"87.635155\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"123.300714\" y=\"60.364324\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.752003\" y=\"82.431614\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.089043\" y=\"64.55916\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"210.029656\" y=\"110.407538\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.999858\" y=\"86.947507\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"78.343746\" y=\"48.848016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.590804\" y=\"90.346289\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.46743\" y=\"71.133828\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.662841\" y=\"48.93122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.349625\" y=\"51.947957\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.740974\" y=\"91.27525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.822096\" y=\"100.475046\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.922944\" y=\"80.361628\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"165.032136\" y=\"93.740499\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.202188\" y=\"67.038157\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.828073\" y=\"92.918334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.714894\" y=\"84.307748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.394938\" y=\"82.12693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.271788\" y=\"88.997754\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.078977\" y=\"72.632487\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.974468\" y=\"83.739874\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.10531\" y=\"87.405128\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.831268\" y=\"74.08886\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"160.421842\" y=\"104.949148\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.484304\" y=\"71.55952\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"91.397035\" y=\"84.240968\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.127325\" y=\"73.08601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.885075\" y=\"71.102861\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.717104\" y=\"63.270871\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.591864\" y=\"69.475626\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.023713\" y=\"95.644997\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.755591\" y=\"84.781609\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.298101\" y=\"73.883721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.123269\" y=\"85.492181\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.406859\" y=\"94.801738\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.374251\" y=\"91.893735\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"71.58281\" y=\"50.022076\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.69833\" y=\"73.063769\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"166.726472\" y=\"102.655169\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.166001\" y=\"81.646603\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.425843\" y=\"69.342389\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.47983\" y=\"68.607274\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.316334\" y=\"77.608487\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.641091\" y=\"88.542797\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.281237\" y=\"67.828716\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.380281\" y=\"55.049052\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.569736\" y=\"73.457505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.727591\" y=\"67.844879\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.239423\" y=\"80.679932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.758102\" y=\"63.648262\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.796691\" y=\"89.090325\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.557766\" y=\"78.837713\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.809626\" y=\"101.210202\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.062881\" y=\"105.662219\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"185.942907\" y=\"118.908359\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.497911\" y=\"56.324936\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.450482\" y=\"85.032803\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"160.075777\" y=\"96.929977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.69867\" y=\"90.174725\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.873647\" y=\"94.106053\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.534513\" y=\"89.233448\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.280354\" y=\"54.503447\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.084685\" y=\"93.852838\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.277726\" y=\"66.694849\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.414944\" y=\"77.417695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.155378\" y=\"66.431945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.720155\" y=\"89.038361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"156.215759\" y=\"91.903109\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.77371\" y=\"78.987995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.83596\" y=\"75.614026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.331164\" y=\"77.898018\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.047103\" y=\"81.242846\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.745199\" y=\"92.745032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"69.72842\" y=\"49.653991\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.457373\" y=\"88.976351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.605311\" y=\"54.6592\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.071328\" y=\"93.808389\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.033176\" y=\"63.664637\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.493558\" y=\"85.452207\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.092945\" y=\"81.256449\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.047198\" y=\"51.558937\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.348048\" y=\"39.61165\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.8802\" y=\"96.034834\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"101.913393\" y=\"55.818987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.862653\" y=\"68.615784\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"186.681578\" y=\"101.835356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.880545\" y=\"74.289874\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.02702\" y=\"68.474065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.476797\" y=\"88.147544\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.740242\" y=\"86.522519\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.430283\" y=\"74.31225\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.659817\" y=\"33.156947\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.317171\" y=\"54.912356\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.27287\" y=\"88.450929\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.194385\" y=\"76.143327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.92373\" y=\"85.797223\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.038232\" y=\"95.733247\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.073734\" y=\"50.027847\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"54.640735\" y=\"35.41094\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.089634\" y=\"91.994584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.080546\" y=\"107.182817\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.379525\" y=\"47.843787\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.585782\" y=\"90.871254\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.111644\" y=\"87.755626\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.648291\" y=\"72.692302\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.407254\" y=\"103.369901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.035908\" y=\"93.159714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.21035\" y=\"92.0972\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.361138\" y=\"92.906851\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.140984\" y=\"84.512175\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.966509\" y=\"92.704814\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.384542\" y=\"70.417031\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"86.436747\" y=\"54.841995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.64\" y=\"77.331586\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"87.665212\" y=\"60.697736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"179.928433\" y=\"120.73875\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.761417\" y=\"91.251022\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.336099\" y=\"54.359757\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.192027\" y=\"76.131913\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"160.789782\" y=\"99.364532\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.074054\" y=\"67.567098\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.218077\" y=\"52.454352\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.851752\" y=\"88.255752\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.670222\" y=\"88.004706\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.867695\" y=\"87.150704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.84146\" y=\"82.335199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.316621\" y=\"78.993743\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.326625\" y=\"58.733\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.099735\" y=\"55.103665\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.231236\" y=\"62.199428\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.735701\" y=\"67.280972\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.647281\" y=\"80.904412\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"86.169234\" y=\"61.602583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.234011\" y=\"72.853523\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.398689\" y=\"71.994761\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.633394\" y=\"97.133887\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.495644\" y=\"62.873499\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.136218\" y=\"111.853683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.882119\" y=\"92.053456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.860246\" y=\"89.68266\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.252076\" y=\"103.514292\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.471147\" y=\"54.509279\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.705965\" y=\"81.503291\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.320374\" y=\"94.0557\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"70.007271\" y=\"58.436724\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.425384\" y=\"84.967633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.398614\" y=\"68.925504\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.629152\" y=\"82.60452\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.836359\" y=\"61.686297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.823263\" y=\"81.09651\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.160508\" y=\"70.683557\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.052675\" y=\"97.712257\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.178\" y=\"75.291492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.719098\" y=\"57.050864\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"78.838824\" y=\"56.407414\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.413117\" y=\"105.811029\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.35705\" y=\"39.427734\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.18858\" y=\"75.262173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.046664\" y=\"71.371556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.304945\" y=\"86.574687\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.087558\" y=\"72.845909\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.265709\" y=\"86.717398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.328266\" y=\"99.99668\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"91.504388\" y=\"63.832559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.521201\" y=\"90.461491\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.67667\" y=\"79.711648\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.062092\" y=\"82.348441\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.123937\" y=\"73.257331\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"71.382936\" y=\"56.435486\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"92.930488\" y=\"80.031692\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"69.832452\" y=\"39.826381\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.262287\" y=\"91.333923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.894394\" y=\"70.213758\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.5975\" y=\"73.964499\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.488881\" y=\"109.360436\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.053755\" y=\"73.441148\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.199752\" y=\"63.649739\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.763355\" y=\"69.860579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.086244\" y=\"85.589296\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.712868\" y=\"74.00906\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.536567\" y=\"103.414602\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.622974\" y=\"97.621516\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.88117\" y=\"51.276698\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.601342\" y=\"63.240578\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.040476\" y=\"93.285939\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.539296\" y=\"67.799196\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.053298\" y=\"79.092101\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.104001\" y=\"67.398136\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.991377\" y=\"112.984702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.145845\" y=\"76.288476\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.644547\" y=\"95.184044\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.3539\" y=\"108.570025\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.032948\" y=\"84.303226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.980176\" y=\"88.460122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.775706\" y=\"72.726118\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.778309\" y=\"70.672921\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.822453\" y=\"60.060502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.173974\" y=\"77.168622\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.134945\" y=\"93.978861\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.601208\" y=\"84.633759\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.200394\" y=\"81.927413\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.99422\" y=\"81.128843\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.492664\" y=\"78.838212\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.217204\" y=\"90.950346\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.91033\" y=\"56.163931\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.859701\" y=\"58.923157\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.022203\" y=\"70.114615\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"153.057224\" y=\"87.543799\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.219294\" y=\"89.616032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.917526\" y=\"96.044954\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"186.920677\" y=\"115.134938\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.53031\" y=\"95.149919\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"153.009812\" y=\"77.895693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.366344\" y=\"87.351166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"156.167128\" y=\"85.771466\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.407892\" y=\"83.742721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.762337\" y=\"72.152111\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.318211\" y=\"97.315038\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.83494\" y=\"44.134327\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.494669\" y=\"64.641583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.860221\" y=\"62.05387\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"203.649684\" y=\"125.680246\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.648903\" y=\"62.820517\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"178.65501\" y=\"90.017958\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.023363\" y=\"58.491047\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.27518\" y=\"74.793282\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"123.50203\" y=\"82.541748\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.417982\" y=\"64.552699\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.407499\" y=\"90.09559\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.504912\" y=\"59.517263\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.301841\" y=\"65.802786\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.133634\" y=\"66.033224\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.143215\" y=\"71.997197\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.440896\" y=\"81.281118\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.69893\" y=\"89.580945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.981898\" y=\"93.848166\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.117522\" y=\"82.535379\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.982365\" y=\"74.528934\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.894864\" y=\"78.562288\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.575206\" y=\"86.862247\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.158894\" y=\"39.707633\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.11277\" y=\"79.014475\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.250241\" y=\"97.297373\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"80.551414\" y=\"48.62045\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"69.150047\" y=\"45.853712\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.550173\" y=\"28.326482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"185.580207\" y=\"114.109405\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.464205\" y=\"90.327952\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.224301\" y=\"67.371505\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.184582\" y=\"81.178304\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.063268\" y=\"64.392287\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.545451\" y=\"89.387934\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.873684\" y=\"57.870188\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.718786\" y=\"100.658835\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.418433\" y=\"76.655672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.769597\" y=\"95.430922\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"166.879986\" y=\"92.245573\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.434279\" y=\"86.758893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"56.934144\" y=\"38.980355\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.714151\" y=\"77.763025\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.766946\" y=\"80.900955\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.346628\" y=\"66.429213\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.179679\" y=\"88.116118\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.564632\" y=\"88.816355\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.911806\" y=\"84.751142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.063996\" y=\"93.478798\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.241849\" y=\"76.627511\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.040624\" y=\"57.804399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"193.270465\" y=\"109.099886\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.713542\" y=\"62.978292\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.717268\" y=\"63.47266\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.698091\" y=\"85.239161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.356281\" y=\"64.512591\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"180.373525\" y=\"104.50704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.4927\" y=\"60.412998\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.518992\" y=\"86.457387\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.68571\" y=\"98.994692\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.163265\" y=\"66.270813\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.244924\" y=\"120.613347\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.069954\" y=\"87.352016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.329299\" y=\"68.14482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.495904\" y=\"80.112351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.752566\" y=\"93.405455\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.604799\" y=\"66.410412\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.525774\" y=\"80.293978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.91489\" y=\"99.67341\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"85.345272\" y=\"50.540142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.264773\" y=\"80.731016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.747819\" y=\"71.987721\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.313751\" y=\"101.119821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"59.850893\" y=\"45.081892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.049936\" y=\"71.462255\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"180.994376\" y=\"117.695672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.545242\" y=\"103.760052\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.43372\" y=\"70.93977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"80.067053\" y=\"57.601496\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"85.872625\" y=\"43.786461\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"178.338119\" y=\"102.541064\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.184404\" y=\"65.51085\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.380472\" y=\"69.702594\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"73.860884\" y=\"56.27751\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.677165\" y=\"77.364903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.943663\" y=\"47.503995\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"186.482778\" y=\"87.879143\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.457569\" y=\"94.46482\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.13735\" y=\"73.737452\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.757528\" y=\"83.33317\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.65698\" y=\"102.529642\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.747338\" y=\"102.857885\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.981687\" y=\"89.591659\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.121408\" y=\"80.705004\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.104164\" y=\"74.605814\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.780364\" y=\"69.5771\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.621896\" y=\"49.098704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.656078\" y=\"77.659877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"86.055945\" y=\"53.75328\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.722442\" y=\"104.21321\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.726726\" y=\"98.990361\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.796008\" y=\"77.820071\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.796818\" y=\"63.838301\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.856553\" y=\"62.832816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.093813\" y=\"72.549384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.399527\" y=\"66.991257\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.131627\" y=\"90.962576\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.733067\" y=\"83.054664\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.253167\" y=\"92.703946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.167077\" y=\"56.12621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.570036\" y=\"102.002617\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.733622\" y=\"67.842124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"178.431948\" y=\"113.820624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.401344\" y=\"78.671175\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.34199\" y=\"95.182191\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.84666\" y=\"83.10226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.895487\" y=\"70.38906\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.533345\" y=\"55.814512\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.4651\" y=\"59.514054\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.502376\" y=\"63.199828\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.422421\" y=\"70.277575\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.222997\" y=\"101.642396\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"88.194028\" y=\"49.608191\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.011539\" y=\"107.254235\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.18125\" y=\"73.537885\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.256823\" y=\"52.417549\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"123.852231\" y=\"91.740915\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.549731\" y=\"67.596396\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.582907\" y=\"79.797749\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.476643\" y=\"93.748964\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.454348\" y=\"93.598672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"176.635087\" y=\"108.487228\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.077607\" y=\"86.630994\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.906575\" y=\"101.628971\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"167.797845\" y=\"106.790483\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"69.118458\" y=\"38.99948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.386105\" y=\"70.009451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.952056\" y=\"78.03741\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"92.150291\" y=\"48.013261\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"209.840512\" y=\"130.20145\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.116943\" y=\"72.721918\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.811761\" y=\"54.267946\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.005825\" y=\"74.775974\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.550855\" y=\"76.597755\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.529948\" y=\"95.241427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.977207\" y=\"83.329908\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"163.121682\" y=\"96.334464\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.988902\" y=\"44.435415\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.730487\" y=\"95.688754\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.959448\" y=\"89.882028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.157453\" y=\"73.169269\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.282027\" y=\"78.880037\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.503006\" y=\"81.431474\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.956124\" y=\"27.066695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.891937\" y=\"100.357543\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.59888\" y=\"79.693753\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"83.571003\" y=\"58.469216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"215.364915\" y=\"127.85492\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.584849\" y=\"96.966151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.318089\" y=\"82.300135\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.510389\" y=\"79.794045\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.538687\" y=\"67.406444\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"148.031827\" y=\"83.226934\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.981032\" y=\"70.722808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"176.981523\" y=\"105.624911\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.61736\" y=\"58.931855\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"73.142329\" y=\"45.947931\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.718652\" y=\"96.008379\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.926972\" y=\"60.906942\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.881458\" y=\"60.288005\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.543753\" y=\"87.30287\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.268741\" y=\"83.600445\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"78.521069\" y=\"41.99808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.864474\" y=\"77.91869\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.017892\" y=\"80.481522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.455392\" y=\"73.696664\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.749503\" y=\"88.149684\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.567885\" y=\"63.129617\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.216146\" y=\"74.808058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.708365\" y=\"88.382695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.374763\" y=\"56.821364\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.191988\" y=\"70.76777\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.670422\" y=\"73.963499\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.110521\" y=\"90.500515\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.503507\" y=\"72.137806\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.192675\" y=\"83.592338\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"70.304373\" y=\"34.158846\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.12028\" y=\"72.573789\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.148157\" y=\"69.850139\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.210137\" y=\"79.472293\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.260159\" y=\"84.332827\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.752112\" y=\"122.404292\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.623714\" y=\"79.17048\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.361534\" y=\"65.28977\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.582777\" y=\"83.854131\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.154201\" y=\"85.206821\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.588689\" y=\"64.619421\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.792243\" y=\"100.999558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.268801\" y=\"101.429823\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.666159\" y=\"64.416901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.88354\" y=\"87.216013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.820924\" y=\"60.267343\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.239587\" y=\"76.772531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.225785\" y=\"84.282976\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.058535\" y=\"75.479935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.386995\" y=\"63.77521\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.215501\" y=\"82.245668\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.246958\" y=\"66.944416\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.001543\" y=\"73.790225\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.206018\" y=\"53.694945\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.635205\" y=\"67.862409\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.124865\" y=\"88.62203\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.274608\" y=\"82.745465\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.134912\" y=\"79.86842\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"210.120579\" y=\"139.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.635031\" y=\"82.551013\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.595741\" y=\"84.691161\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.406946\" y=\"96.506347\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.217814\" y=\"69.96511\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.000116\" y=\"52.049965\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.406702\" y=\"81.240142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"177.530131\" y=\"104.528011\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.855941\" y=\"63.703369\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.258559\" y=\"92.530693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.012702\" y=\"106.253605\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.064109\" y=\"70.662947\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.28221\" y=\"68.261259\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.96706\" y=\"65.18813\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"72.471718\" y=\"43.593602\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.568965\" y=\"63.756909\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"177.958253\" y=\"109.17915\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.284079\" y=\"78.1838\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.452006\" y=\"68.408543\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"75.953394\" y=\"35.373375\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.458822\" y=\"86.578298\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"87.528023\" y=\"46.755767\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.669687\" y=\"72.369525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.322236\" y=\"46.050664\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"91.539021\" y=\"60.500666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.873193\" y=\"105.755177\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.589007\" y=\"70.02036\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.324556\" y=\"61.009935\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"80.010104\" y=\"32.551357\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"74.288624\" y=\"24.336056\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.201643\" y=\"67.316772\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.26351\" y=\"53.471221\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.14429\" y=\"56.730499\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.509687\" y=\"96.264392\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.556996\" y=\"83.28568\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.89438\" y=\"87.306244\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.615961\" y=\"100.286689\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.288729\" y=\"64.252809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.732226\" y=\"90.890571\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"85.778688\" y=\"47.970673\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.340655\" y=\"56.073742\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.889678\" y=\"58.131371\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.012367\" y=\"76.280917\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.425061\" y=\"64.320065\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.351814\" y=\"96.494393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.491177\" y=\"66.847155\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"171.509008\" y=\"97.585068\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"92.321238\" y=\"67.105825\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.269392\" y=\"78.962391\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.626629\" y=\"78.264148\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.828677\" y=\"81.85782\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.21269\" y=\"57.428075\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.885466\" y=\"106.110086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.925933\" y=\"72.17456\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.594875\" y=\"71.462377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.2624\" y=\"68.158346\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"64.514532\" y=\"36.946933\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.091179\" y=\"99.726884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"174.253418\" y=\"93.23641\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.23\" y=\"75.255368\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"65.217911\" y=\"37.559002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.356088\" y=\"80.602058\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.189968\" y=\"55.175359\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"62.96026\" y=\"50.057955\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.026718\" y=\"70.346498\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.527509\" y=\"90.640747\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.413088\" y=\"65.729884\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.233924\" y=\"81.970409\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.577559\" y=\"67.505026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.772014\" y=\"82.899963\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.845821\" y=\"102.406688\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.562442\" y=\"114.534875\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"88.190116\" y=\"42.760153\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.737993\" y=\"61.34062\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.250066\" y=\"92.234429\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.767617\" y=\"90.054583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.150306\" y=\"76.577412\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.479531\" y=\"94.614714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.008533\" y=\"91.436795\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.5827\" y=\"95.058987\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.918824\" y=\"72.379217\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.073613\" y=\"69.515174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.568888\" y=\"64.961155\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.915916\" y=\"65.197114\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.78686\" y=\"52.868089\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"76.233259\" y=\"47.694624\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"77.735619\" y=\"44.210211\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.950854\" y=\"74.838937\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.970388\" y=\"81.138806\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.429932\" y=\"78.538743\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.861431\" y=\"81.404076\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.169048\" y=\"82.227584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.100895\" y=\"79.798964\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.321305\" y=\"64.934147\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.453211\" y=\"74.611401\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.794146\" y=\"78.266666\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.021139\" y=\"86.248369\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.718087\" y=\"80.8348\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.618833\" y=\"71.369759\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.37592\" y=\"64.315142\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"46.253667\" y=\"26.163565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.394197\" y=\"83.863015\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.899078\" y=\"93.301888\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.639917\" y=\"104.231472\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.827474\" y=\"83.31291\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.239341\" y=\"85.240781\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.781298\" y=\"72.559714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.926605\" y=\"60.919121\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"163.906565\" y=\"122.878621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.832396\" y=\"64.024531\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.109992\" y=\"40.011423\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.011091\" y=\"95.436527\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.134518\" y=\"87.521508\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"83.403468\" y=\"29.530857\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.304645\" y=\"66.774683\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"77.249923\" y=\"51.523627\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.088311\" y=\"95.074449\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.994278\" y=\"90.65641\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.039313\" y=\"78.777321\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.000141\" y=\"113.628631\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.449255\" y=\"57.140028\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"174.859795\" y=\"91.043108\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.79393\" y=\"87.101574\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.746067\" y=\"33.022682\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"156.569381\" y=\"85.361997\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.793921\" y=\"93.841941\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.690685\" y=\"69.491607\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"95.437542\" y=\"45.81514\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.53944\" y=\"72.901315\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.07235\" y=\"68.093603\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.920107\" y=\"71.426769\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"92.812769\" y=\"51.741378\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.665501\" y=\"85.759923\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"180.871668\" y=\"92.58811\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.62019\" y=\"50.529159\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.193346\" y=\"79.457705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.053976\" y=\"55.322431\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.018184\" y=\"47.382136\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.33899\" y=\"64.804031\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.623402\" y=\"82.940039\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.166829\" y=\"66.291561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.092738\" y=\"72.767532\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.85284\" y=\"66.453866\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.139907\" y=\"104.484621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.777015\" y=\"103.843695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.27105\" y=\"74.040565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.066234\" y=\"68.200107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.266155\" y=\"85.337984\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.813781\" y=\"78.450493\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"52.85775\" y=\"20.126956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.26998\" y=\"60.072874\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.4008\" y=\"55.864695\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.816233\" y=\"84.668693\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.174204\" y=\"64.763244\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.572859\" y=\"83.204703\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.736658\" y=\"66.281297\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.18742\" y=\"82.348732\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.304637\" y=\"61.956149\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"167.511118\" y=\"82.471174\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.001409\" y=\"83.006589\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.526794\" y=\"95.271191\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.179198\" y=\"44.864344\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.799434\" y=\"69.191106\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.677328\" y=\"87.313417\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.882415\" y=\"76.918855\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"153.45697\" y=\"89.12334\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.540933\" y=\"77.867091\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.14314\" y=\"90.085445\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.268725\" y=\"56.76761\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.199125\" y=\"55.49814\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.604844\" y=\"46.698911\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.75421\" y=\"95.917279\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.401362\" y=\"64.360735\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.690481\" y=\"87.852081\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.78844\" y=\"114.784169\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"87.691288\" y=\"56.384999\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.851424\" y=\"109.662351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.268769\" y=\"75.839349\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"184.436989\" y=\"119.348842\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.67617\" y=\"103.423393\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.864568\" y=\"83.560609\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.844234\" y=\"121.684714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"87.997471\" y=\"60.040637\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.583393\" y=\"59.730345\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.379903\" y=\"84.822126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.063518\" y=\"107.025239\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.473541\" y=\"67.68576\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.108038\" y=\"78.170584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.052535\" y=\"94.73705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.294692\" y=\"98.723513\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.272066\" y=\"108.521956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"175.16134\" y=\"112.621842\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.496551\" y=\"64.704194\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"63.220077\" y=\"58.103042\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.338406\" y=\"54.251711\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"84.84368\" y=\"46.115888\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.303094\" y=\"58.253671\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.651029\" y=\"47.413254\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"162.875295\" y=\"101.766347\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.639938\" y=\"90.684068\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.547984\" y=\"100.947603\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"54.19993\" y=\"37.228854\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"37.81946\" y=\"13.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.320799\" y=\"62.212522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.026146\" y=\"79.576125\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.2641\" y=\"60.369902\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.178387\" y=\"96.161797\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.196468\" y=\"72.510704\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.514879\" y=\"66.193771\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.10013\" y=\"62.539473\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"168.331458\" y=\"108.062402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"61.654839\" y=\"30.370362\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.625664\" y=\"84.129354\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"107.937366\" y=\"68.164127\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.026724\" y=\"44.70901\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"83.801555\" y=\"56.6427\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.175146\" y=\"83.018071\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.862137\" y=\"75.776002\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"131.243355\" y=\"81.56418\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.160526\" y=\"58.900636\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.285399\" y=\"80.091573\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.00158\" y=\"78.686854\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.387301\" y=\"90.981526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"168.375927\" y=\"106.039051\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.452521\" y=\"65.231451\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.562604\" y=\"83.469644\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"63.322325\" y=\"43.465163\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.580982\" y=\"87.967192\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.605207\" y=\"105.955534\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.741936\" y=\"70.466967\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"185.3351\" y=\"100.834601\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"160.492771\" y=\"94.752381\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.251341\" y=\"64.415833\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.619251\" y=\"95.306447\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.967609\" y=\"64.387757\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.830021\" y=\"64.411677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.087688\" y=\"97.156016\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"76.280937\" y=\"50.618691\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.020354\" y=\"79.380221\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.333742\" y=\"88.730242\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.967983\" y=\"88.000783\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.553728\" y=\"92.764272\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.637162\" y=\"56.021096\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.256336\" y=\"96.232151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.717962\" y=\"82.777677\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"149.646616\" y=\"107.424107\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.163221\" y=\"95.247416\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.717959\" y=\"71.212125\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"145.309545\" y=\"85.84556\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.059568\" y=\"55.979455\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.192151\" y=\"79.140434\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.976636\" y=\"68.722251\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.549518\" y=\"93.772192\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.497996\" y=\"77.720104\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.860408\" y=\"78.704869\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"153.841274\" y=\"99.397877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.170461\" y=\"60.852135\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.979021\" y=\"73.46474\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.972798\" y=\"80.964895\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.239845\" y=\"82.494235\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.729652\" y=\"79.004252\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.574715\" y=\"74.512318\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.719282\" y=\"88.724309\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.682875\" y=\"63.402481\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.154448\" y=\"56.427495\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.559014\" y=\"94.818932\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.592238\" y=\"78.837399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.977271\" y=\"72.226384\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"81.031731\" y=\"61.079786\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"166.171529\" y=\"100.078199\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"101.666235\" y=\"70.233892\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.833515\" y=\"84.820575\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.223933\" y=\"72.385714\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"184.178558\" y=\"111.211049\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.849727\" y=\"83.236522\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.732939\" y=\"84.575377\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"165.532339\" y=\"100.815533\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.1149\" y=\"83.879521\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"137.538848\" y=\"80.551326\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.570327\" y=\"59.245341\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"85.40019\" y=\"65.165079\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.249415\" y=\"98.157858\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.421797\" y=\"80.252616\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"74.975928\" y=\"37.16886\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.232533\" y=\"86.77948\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.540874\" y=\"93.533399\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.791999\" y=\"117.41122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.202544\" y=\"53.91224\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"99.192344\" y=\"70.148955\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.361993\" y=\"58.979796\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"185.134341\" y=\"113.606672\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.662793\" y=\"75.891954\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.009735\" y=\"91.015395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"93.003778\" y=\"47.469871\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.773919\" y=\"67.407023\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.932252\" y=\"38.205126\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.685057\" y=\"104.879705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"98.330928\" y=\"69.555583\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"163.830973\" y=\"100.839111\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"92.531262\" y=\"50.374546\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.949728\" y=\"79.325563\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.968272\" y=\"55.536956\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.058441\" y=\"94.663151\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.21505\" y=\"74.944517\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.54402\" y=\"88.397437\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.662934\" y=\"106.625645\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.702914\" y=\"88.0265\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"49.455065\" y=\"26.7305\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.304487\" y=\"50.923667\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.427527\" y=\"70.465158\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"112.489395\" y=\"64.11137\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"75.205949\" y=\"49.392472\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.706319\" y=\"59.095893\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.558088\" y=\"99.410966\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.573135\" y=\"88.145579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"213.385792\" y=\"138.394026\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"140.044429\" y=\"89.984565\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.434731\" y=\"76.868931\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.367501\" y=\"75.691447\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"79.314283\" y=\"33.718198\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.894848\" y=\"41.419486\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"133.466441\" y=\"87.464103\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"160.842223\" y=\"95.155736\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.599543\" y=\"52.933722\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.949495\" y=\"95.746645\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.76022\" y=\"73.000899\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"102.866094\" y=\"60.962329\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.894822\" y=\"57.448225\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.369708\" y=\"87.892423\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"180.473547\" y=\"117.27612\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.833448\" y=\"69.093638\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.972878\" y=\"106.93397\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"159.7554\" y=\"107.802266\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.328711\" y=\"85.965351\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"105.137213\" y=\"67.479179\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"106.860737\" y=\"63.044124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.979929\" y=\"101.270955\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"110.589389\" y=\"62.848237\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"73.357038\" y=\"35.67268\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"120.45552\" y=\"71.835404\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.726037\" y=\"82.974294\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"101.720395\" y=\"58.648073\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"70.340977\" y=\"28.163051\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.876799\" y=\"109.012584\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.16379\" y=\"58.207545\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.664724\" y=\"75.628147\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.341011\" y=\"73.012979\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"135.595885\" y=\"85.706008\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"132.817165\" y=\"93.673445\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"151.309918\" y=\"78.04203\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"90.331517\" y=\"46.485214\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.512833\" y=\"78.760711\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"164.15384\" y=\"102.733558\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.489489\" y=\"90.786431\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.973636\" y=\"74.235309\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.58015\" y=\"79.823807\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.898748\" y=\"51.377557\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.971962\" y=\"85.681529\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"116.32055\" y=\"76.398744\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.905961\" y=\"75.38737\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"104.847861\" y=\"66.768525\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.928662\" y=\"82.88218\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.475827\" y=\"71.748379\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.528036\" y=\"69.6817\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.684282\" y=\"97.994216\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"146.298089\" y=\"78.611319\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.780943\" y=\"78.702865\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.005251\" y=\"77.471086\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.835305\" y=\"102.397057\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"61.751121\" y=\"44.661418\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"69.14529\" y=\"52.520044\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.762191\" y=\"86.805402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.536152\" y=\"82.052106\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"115.919843\" y=\"77.139472\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"161.783722\" y=\"80.577177\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.113418\" y=\"53.643488\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"108.711354\" y=\"74.096883\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"85.378121\" y=\"71.357359\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"83.552097\" y=\"70.715727\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"87.488727\" y=\"59.19274\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.487289\" y=\"84.93485\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.265432\" y=\"62.205567\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.779009\" y=\"78.027317\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"168.772017\" y=\"122.357308\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.025389\" y=\"55.106983\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.884292\" y=\"84.291331\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.586799\" y=\"70.900395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"52.862115\" y=\"28.092442\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.387588\" y=\"63.055993\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.700673\" y=\"85.032154\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"80.211638\" y=\"50.579127\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"198.452243\" y=\"132.496164\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.359344\" y=\"77.270526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.280226\" y=\"74.650122\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.124056\" y=\"61.602047\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"169.453766\" y=\"110.942314\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"143.983485\" y=\"78.602785\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"126.977449\" y=\"63.591785\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"170.883379\" y=\"96.845\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"189.351133\" y=\"112.396057\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"125.307679\" y=\"71.697136\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.519088\" y=\"97.573787\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"144.85076\" y=\"59.69533\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"119.786321\" y=\"65.924925\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.127066\" y=\"76.553809\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"109.177223\" y=\"86.151253\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"134.751736\" y=\"87.092739\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"128.494488\" y=\"83.407537\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"168.474458\" y=\"109.880623\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"152.932537\" y=\"100.908581\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"147.067888\" y=\"98.637226\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.262552\" y=\"45.815816\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"111.102066\" y=\"66.391877\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.174481\" y=\"87.226272\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"100.04053\" y=\"70.275588\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"142.63542\" y=\"102.269978\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.678134\" y=\"79.7729\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"158.024648\" y=\"94.470349\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"150.645212\" y=\"81.726621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"91.777503\" y=\"80.838136\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"96.074816\" y=\"72.584774\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.767426\" y=\"100.869221\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"141.899513\" y=\"91.902811\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"114.905126\" y=\"70.602808\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"139.915794\" y=\"75.016032\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"184.377851\" y=\"99.759433\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"122.537074\" y=\"83.325542\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"103.301367\" y=\"74.92374\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"155.562863\" y=\"87.948231\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.270645\" y=\"85.473992\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"154.734637\" y=\"96.819429\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"86.330995\" y=\"53.182402\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"121.659157\" y=\"95.947321\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"127.398753\" y=\"74.628479\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"117.05263\" y=\"72.79579\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.774806\" y=\"90.766689\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"83.296372\" y=\"56.252595\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"138.838619\" y=\"87.391067\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"113.251315\" y=\"66.423905\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"173.557847\" y=\"99.084676\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"136.073461\" y=\"86.020093\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"157.490152\" y=\"109.058449\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"124.842628\" y=\"77.862149\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"118.229169\" y=\"51.556248\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"97.255251\" y=\"49.013988\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"130.304509\" y=\"84.756756\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"129.527258\" y=\"81.853965\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"166.304664\" y=\"89.043998\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"94.951423\" y=\"61.169867\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "     <use xlink:href=\"#mafb3b7f13b\" x=\"89.675938\" y=\"53.748602\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"md894f6968c\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#md894f6968c\" x=\"70.578725\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −2 -->\n",
       "      <g transform=\"translate(63.207631 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md894f6968c\" x=\"127.261257\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(124.080007 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md894f6968c\" x=\"183.94379\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(180.76254 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <defs>\n",
       "       <path id=\"mfee6049071\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfee6049071\" x=\"28.942188\" y=\"122.125913\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- −5 -->\n",
       "      <g transform=\"translate(7.2 125.925132) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfee6049071\" x=\"28.942188\" y=\"98.034106\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(15.579688 101.833325) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfee6049071\" x=\"28.942188\" y=\"73.9423\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(15.579688 77.741518) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfee6049071\" x=\"28.942188\" y=\"49.850493\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(9.217188 53.649712) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfee6049071\" x=\"28.942188\" y=\"25.758686\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(9.217188 29.557905) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 28.942188 145.8 \n",
       "L 28.942188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 224.242188 145.8 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 28.942187 145.8 \n",
       "L 224.242188 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 28.942187 7.2 \n",
       "L 224.242188 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p90ff8178db\">\n",
       "   <rect x=\"28.942188\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘图，查看分布\n",
    "d2l.set_figsize()\n",
    "d2l.plt.scatter(features[:, (1)].detach().numpy(), \n",
    "                labels.detach().numpy(), 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2. <a id='toc7_1_2_'></a>[读取数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0441, -0.0882],\n",
      "        [-1.9142,  0.4381],\n",
      "        [-0.6126, -0.4002],\n",
      "        [ 0.7606,  1.2113],\n",
      "        [-0.9038, -0.1017],\n",
      "        [-1.9209, -0.3264],\n",
      "        [-1.8411,  0.8676],\n",
      "        [ 0.7096, -0.6971],\n",
      "        [-0.5313,  1.2168],\n",
      "        [-1.6005, -0.9617]]) \n",
      " tensor([[ 6.5817],\n",
      "        [-1.1185],\n",
      "        [ 4.3365],\n",
      "        [ 1.5955],\n",
      "        [ 2.7420],\n",
      "        [ 1.4567],\n",
      "        [-2.4133],\n",
      "        [ 7.9938],\n",
      "        [-1.0011],\n",
      "        [ 4.2676]])\n"
     ]
    }
   ],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # 这些样本是随机读取的，没有特定的顺序\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "batch_size = 10\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3. <a id='toc7_1_3_'></a>[初始化模型参数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.4. <a id='toc7_1_4_'></a>[定义模型](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b):  #@save\n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return torch.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.5. <a id='toc7_1_5_'></a>[定义损失函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):  #@save\n",
    "    \"\"\"均方损失\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.6. <a id='toc7_1_6_'></a>[定义优化算法](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):  #@save\n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.7. <a id='toc7_1_7_'></a>[训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000051\n",
      "epoch 2, loss 0.000051\n",
      "epoch 3, loss 0.000051\n",
      "w的估计误差: tensor([ 0.0002, -0.0002], grad_fn=<SubBackward0>)\n",
      "b的估计误差: tensor([-0.0002], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y)  # X和y的小批量损失\n",
    "        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n",
    "        # 并以此计算关于[w,b]的梯度\n",
    "        l.sum().backward()\n",
    "        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n",
    "\n",
    "print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')\n",
    "print(f'b的估计误差: {true_b - b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. <a id='toc7_2_'></a>[现线性回归模型于训练过程-简洁实现](#toc0_)\n",
    "### 7.2.1. <a id='toc7_2_1_'></a>[虚拟数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2. <a id='toc7_2_2_'></a>[读取数据](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3. <a id='toc7_2_3_'></a>[定义模型](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn是神经网络的缩写\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4. <a id='toc7_2_4_'></a>[初始化模型参数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.5. <a id='toc7_2_5_'></a>[定义损失函数](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.6. <a id='toc7_2_6_'></a>[定义优化算法](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "trainer = optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.7. <a id='toc7_2_7_'></a>[训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000110\n",
      "epoch 2, loss 0.000111\n",
      "epoch 3, loss 0.000111\n",
      "epoch 4, loss 0.000110\n",
      "epoch 5, loss 0.000110\n",
      "w的估计误差： tensor([ 3.5048e-05, -1.6689e-04])\n",
      "b的估计误差： tensor([0.0005])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        y_hat = net(X)                  # 1. 计算y_hat\n",
    "        loss = loss_fn(y_hat ,y)        # 2. 计算loss值\n",
    "        trainer.zero_grad()\n",
    "        loss.backward()                 # 2. 求梯度           \n",
    "        trainer.step()                  # 3. 更新网络权重参数\n",
    "    train_loss = loss_fn(net(features), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {train_loss:f}')\n",
    "\n",
    "w = net[0].weight.data\n",
    "print('w的估计误差：', true_w - w.reshape(true_w.shape))\n",
    "b = net[0].bias.data\n",
    "print('b的估计误差：', true_b - b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. <a id='toc7_3_'></a>[专题-模型定义（计算预测值）](#toc0_)\n",
    "```shell\n",
    "优点：\n",
    "    一般，pytorch的nn.Sequentail类就比较方便的快速构建神经网络的框架；\n",
    "    同时，nn也包含了很多完整的神经网络如：CNN、RNN等；\n",
    "缺点：\n",
    "    高度封装，需要复杂的自定义神经网络时就不适用了。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1. <a id='toc7_3_1_'></a>[torch.nn模块](#toc0_)\n",
    "```shell\n",
    "1. 简单、快速，但不够灵活\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(786, 256), nn.ReLU(), \n",
    "                    nn.Linear(256, 256), nn.Tanh(),\n",
    "                    nn.Linear(256, 10), nn.Softmax()\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2. <a id='toc7_3_2_'></a>[自定义-块](#toc0_)\n",
    "```shell\n",
    "2. 灵活，但麻烦\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.1. <a id='toc7_3_2_1_'></a>[自定义块](#toc0_)\n",
    "```\n",
    "从编程的角度看：块就是Class\n",
    "nn.Module会自动调用forward()方法，我们也可以重写该方法，从而实现更加灵活的计算\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.2. <a id='toc7_3_2_2_'></a>[顺序块](#toc0_)\n",
    "```\n",
    "Sequential就是顺序块，这里我们自己从头实现一边Sequential这个方法\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Sequential()\n",
    "\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "\n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2.3. <a id='toc7_3_2_3_'></a>[效率](#toc0_)\n",
    "```shell\n",
    "1. 一个块可以由许多层组成；一个块可以由许多块组成。\n",
    "2. 块可以包含代码。\n",
    "3. 块负责大量的内部处理，包括参数初始化和反向传播。\n",
    "4. 层和块的顺序连接由Sequential块处理。\n",
    "```\n",
    "```shell\n",
    "读者可能会开始担心操作效率的问题。 毕竟，我们在一个高性能的深度学习库中进行了大量的字典查找、 代码执行和许多其他的Python代码。 Python的问题全局解释器锁 是众所周知的。 在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3. <a id='toc7_3_3_'></a>[参数管理](#toc0_)\n",
    "```shell\n",
    "其实可以将nn.Sequential视为Python的list数据结构，按顺序储存神经网络层\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2552],\n",
       "        [0.1761]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), \n",
    "                    nn.Linear(8, 1)\n",
    "                    )\n",
    "\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.3.1. <a id='toc7_3_3_1_'></a>[参数访问](#toc0_)\n",
    "```shell\n",
    "我们从已有模型中访问参数。 \n",
    "当通过Sequential类定义模型时，我们可以通过索引来访问模型的任意层。\n",
    "这就像模型是一个列表一样，每层的参数都在其属性中。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=4, out_features=8, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=8, out_features=1, bias=True))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0], net[1], net[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.2702,  0.1767,  0.1702, -0.2560, -0.2653, -0.3247,  0.2074, -0.3074]])),\n",
       "             ('bias', tensor([0.2297]))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].state_dict()\n",
    "# 输出的结果告诉我们一些重要的事情： 首先，这个全连接层包含两个参数，分别是该层的权重和偏置。 \n",
    "# 两者都存储为单精度浮点数（float32）。 \n",
    "# 注意，参数名称允许唯一标识每个参数，即使在包含数百个层的网络中也是如此。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2702,  0.1767,  0.1702, -0.2560, -0.2653, -0.3247,  0.2074, -0.3074]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2702,  0.1767,  0.1702, -0.2560, -0.2653, -0.3247,  0.2074, -0.3074]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.data # 访问目标参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.2297], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2297])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].bias.data # 访问目标参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.4454, -0.4623, -0.3067, -0.0497],\n",
       "                      [ 0.1329, -0.1107, -0.4162,  0.3473],\n",
       "                      [ 0.3310, -0.0126,  0.0427, -0.1092],\n",
       "                      [ 0.3724, -0.4427,  0.0750, -0.3512],\n",
       "                      [-0.0690,  0.2511, -0.1802, -0.3374],\n",
       "                      [-0.2838, -0.1675,  0.0303,  0.2524],\n",
       "                      [-0.2208,  0.4676,  0.2876,  0.4846],\n",
       "                      [ 0.4274, -0.4399, -0.4652, -0.4009]])),\n",
       "             ('0.bias',\n",
       "              tensor([-0.0445, -0.3657,  0.2953,  0.0962,  0.2330,  0.2524,  0.3320,  0.4832])),\n",
       "             ('2.weight',\n",
       "              tensor([[ 0.0723,  0.3215, -0.2724, -0.0400, -0.0260,  0.0734,  0.2320, -0.2839]])),\n",
       "             ('2.bias', tensor([-0.0304]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以直接输出神经网络的所有层参数信息，net[1]是relu激活函数，没有参数，所以就显示无\n",
    "net.state_dict() # 后续，torch.save(net.state_dict(), 'Pytorch_datasets/net_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.3.2. <a id='toc7_3_3_2_'></a>[参数初始化](#toc0_)\n",
    "```shell\n",
    "初始化，主要是为了不要再一开始训练就炸掉了，其实不用太迷信了。\n",
    "\n",
    "默认情况下，PyTorch会根据一个范围均匀地初始化权重和偏置矩阵， 这个范围是根据输入和输出维度计算出的。 \n",
    "PyTorch的nn.init模块提供了多种预置初始化方法。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.3.3.2.1. <a id='toc7_3_3_2_1_'></a>[内置初始化](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = net[0]\n",
    "nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.3.3.2.2. <a id='toc7_3_3_2_2_'></a>[自定义初始化](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.3.3.2.3. <a id='toc7_3_3_2_3_'></a>[参数绑定](#toc0_)\n",
    "```\n",
    "有时我们希望在多个层间共享参数： 我们可以定义一个稠密层，然后使用它的参数来设置另一个层的参数。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# 我们需要给共享层一个名称，以便可以引用它的参数\n",
    "shared = nn.Linear(8, 8)\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    nn.Linear(8, 1))\n",
    "net(X)\n",
    "# 检查参数是否相同\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "\n",
    "net[2].weight.data[0, 0] = 100\n",
    "\n",
    "# 确保它们实际上是同一个对象，而不只是有相同的值\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.4. <a id='toc7_3_4_'></a>[自定义-层](#toc0_)\n",
    "```shell\n",
    "深度学习成功背后的一个因素是神经网络的灵活性： \n",
    "我们可以用创造性的方式组合不同的层，从而设计出适用于各种任务的架构。 \n",
    "例如，研究人员发明了专门用于处理图像、文本、序列数据和执行动态规划的层。 \n",
    "有时我们会遇到或要自己发明一个现在在深度学习框架中还不存在的层。 \n",
    "在这些情况下，必须构建自定义层。本节将展示如何构建自定义层。\n",
    "```\n",
    "```shell\n",
    "块和层其实并无本质的区别，因为都是torch.nn.Module的子类\n",
    "\n",
    "e.g. \n",
    "    全连接层（FC）\n",
    "    池化层（Pooling）\n",
    "    BN层\n",
    "    Dropout层\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.4.1. <a id='toc7_3_4_1_'></a>[不带参数的层](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  0.,  1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()\n",
    "    \n",
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.5879e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在，我们可以将层作为组件合并到更复杂的模型中。\n",
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())\n",
    "\n",
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.4.2. <a id='toc7_3_4_2_'></a>[带参数的层](#toc0_)\n",
    "```shell\n",
    "用到nn.Parameter()可以将参数加入神经网络中，便于自动管理\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 2.6772],\n",
       "        [0.2502, 0.0000, 2.9337]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units)) \n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)\n",
    "    \n",
    "linear = MyLinear(5, 3)\n",
    "# linear.weight\n",
    "\n",
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.3980],\n",
       "        [19.6101]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们还可以使用自定义层构建模型，就像使用内置的全连接层一样使用自定义层。\n",
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. <a id='toc7_4_'></a>[专题-损失函数](#toc0_)\n",
    "```\n",
    "损失函数的输入是 (output, target) ，即网络输出和真实标签对的数据，然后返回一个数值表示网络输出和真实标签的差距。\n",
    "    1. 均方误差\n",
    "    2. 交叉熵\n",
    "    3. 自定义\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1. <a id='toc7_4_1_'></a>[均方误差](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2. <a id='toc7_4_2_'></a>[交叉熵](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3. <a id='toc7_4_3_'></a>[自定义](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y, y_hat):\n",
    "    '''例如真实值于预测值之差'''\n",
    "    error_values = y - y_hat\n",
    "    return error_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. <a id='toc7_5_'></a>[专题-反向传播（求梯度）](#toc0_)\n",
    "```\n",
    "求梯度（求偏导数）\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 见autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6. <a id='toc7_6_'></a>[专题-更新权重（优化算法）](#toc0_)\n",
    "```\n",
    "优化算法\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1. <a id='toc7_6_1_'></a>[小批量梯度下降（SGD）](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.SGD(params=net.parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2. <a id='toc7_6_2_'></a>[adam](#toc0_)\n",
    "```shell\n",
    "Adam对lr不敏感\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.Adam(params=net.parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.3. <a id='toc7_6_3_'></a>[RMSprop](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.RMSprop(params=net.parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7. <a id='toc7_7_'></a>[专题-训练](#toc0_)\n",
    "```shell\n",
    "训练的模板代码\n",
    "```\n",
    "```sehll\n",
    "net.train():\n",
    "    启用 Batch Normalization 和 Dropout。\n",
    "    如果模型中有BN层(Batch Normalization）和Dropout，需要在训练时添加model.train()\n",
    "    model.train()作用： 对BN层，保证BN层能够用到每一批数据的均值和方差，并进行计算更新；\n",
    "                        对于Dropout，model.train()是随机取一部分网络连接来训练更新参数。\n",
    "net.eval()\n",
    "    不启用 Batch Normalization 和 Dropout。\n",
    "    如果模型中有BN层(Batch Normalization）和Dropout，在测试时添加model.eval()。\n",
    "    model.eval()是保证BN层直接利用之前训练阶段得到的均值和方差，即测试过程中要保证BN层的均值和方差不变；\n",
    "                        对于Dropout，model.eval()是利用到了所有网络连接，即不进行随机舍弃神经元。\n",
    "with torch.no_grad():\n",
    "    pass\n",
    "    无论是train() 还是eval() 模式，各层的gradient计算和存储都在进行且完全一致，只是在eval模式下不会进行反向传播。\n",
    "    而with torch.no_grad()则主要是用于停止autograd模块的工作，以起到加速和节省显存的作用。\n",
    "    它的作用是将该with语句包裹起来的部分停止梯度的更新，从而节省了GPU算力和显存，但是并不会影响dropout和BN层的行为。\n",
    "    若想节约算力，可在test阶段带上torch.no_grad()，示例代码：\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# 数据准备\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "# import torch.nn.functional as F \n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=True, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "test_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=False, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, \n",
    "                             batch_size=128, \n",
    "                             shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(28*28, 256), nn.ReLU(),\n",
    "                                     nn.Linear(256, 10), nn.Softmax())\n",
    "    def forward(self, X):\n",
    "        return self.network(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程封装\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "import IPython.display as display\n",
    "\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device, train_figure=False):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "    # 拷贝数据和模型到device上\n",
    "    print('='*100)\n",
    "    print(f\"Runing on {device}\")\n",
    "    print('='*100)\n",
    "    ## 数据\n",
    "    train_all_data_gpu = train_dataset.data.to(device)                                      # .to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)                                # .to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)                                        # .to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)                                  # .to(device)\n",
    "    ## 模型\n",
    "    net.to(device)                                                                          # .to(device)\n",
    "\n",
    "    def dl_plot(epochs:int, epoch_list:list, train_loss_list:list, train_acc_list:list, test_acc_list:list):\n",
    "        '''绘图'''\n",
    "        plt.rcParams['font.sans-serif']=['Times new roman', 'Arial', 'KaiTi']\n",
    "        plt.style.context(['ggplot', 'seaborn'])\n",
    "        \n",
    "        plt.close()\n",
    "        fig = plt.figure(figsize=(5.0, 4.0))\n",
    "\n",
    "        # for y, label in zip([train_loss_list, train_acc_list, test_acc_list], ['train_loss', 'train_acc', 'test_acc']):\n",
    "        for y, label in zip([train_acc_list, test_acc_list], ['train_acc', 'test_acc']):\n",
    "            plt.plot(epoch_list, y, label=label)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.xlim((1, epochs))\n",
    "        plt.ylabel('Values')\n",
    "        plt.ylim((0, 1))\n",
    "        plt.yticks(torch.arange(0, 1, 0.05).numpy())\n",
    "        # plt.tight_layout()\n",
    "\n",
    "        display.display(fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    epoch_list = []\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_list.append(epoch+1)\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   ## 复制到device（GPU/CPU）上                    # .to(device)\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            net.train() # 训练模式\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            train_loss_list.append(train_loss.item())\n",
    "            # print(train_loss)\n",
    "\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) \n",
    "            train_acc_list.append(train_acc.item())\n",
    "            # print(train_acc)\n",
    "\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp))\n",
    "            test_acc_list.append(test_acc.item())\n",
    "            # print(test_acc)\n",
    "\n",
    "            if train_figure:\n",
    "                if epoch % 1 == 0:\n",
    "                    dl_plot(epochs, epoch_list, train_loss_list, train_acc_list, test_acc_list)\n",
    "            else:\n",
    "                print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "                \n",
    "    stop = time.time()\n",
    "    print('='*100)\n",
    "    print(f\"耗时： {stop - start} seconds.\")\n",
    "    return (train_loss, train_acc, test_acc)\n",
    "    # return (epoch_list, train_loss_list, train_acc_list, test_acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.1. <a id='toc7_7_1_'></a>[开始训练](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 871.3765966892242 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.5557), tensor(0.9193), tensor(0.9203))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 开始训练\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.01)\n",
    "\n",
    "train_steps(epochs=100, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device, \n",
    "            train_figure=True\n",
    "            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 94.04658675193787 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.7439), tensor(0.7981), tensor(0.8084))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 再试一次，会不会造成net的parameter的累加，结果表明不会\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()   \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.01)  \n",
    "    \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device, \n",
    "            train_figure=True\n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.2. <a id='toc7_7_2_'></a>[自己探索](#toc0_)\n",
    "#### 7.7.2.1. <a id='toc7_7_2_1_'></a>[lr的影响](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 80.98235154151917 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.4992), tensor(0.9675), tensor(0.9619))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()      \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "   \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device, \n",
    "            train_figure=True\n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7.2.2. <a id='toc7_7_2_2_'></a>[不同模型的效率](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 97.47868943214417 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.4942), tensor(0.9726), tensor(0.9656))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_acc一直在92%左右，如何才能提高？\n",
    "# 使用CNN会好一点吗？\n",
    "# 我们来试一试：\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "                                     nn.Linear(1024, 10), nn.Softmax()\n",
    "                                     )\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net1()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "   \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device, \n",
    "            train_figure=True\n",
    "            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "耗时： 232.07940006256104 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.4984), tensor(0.9647), tensor(0.9541))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 开始训练\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.network = nn.Sequential(nn.Flatten(),\n",
    "        #                              nn.Linear(28*28, 2**5), nn.ReLU(),\n",
    "        #                              nn.Linear(2**5, 10), nn.Softmax())\n",
    "        self.num_hidden = 2**5\n",
    "        self.layer1 = nn.Flatten()\n",
    "        self.layer2 = nn.Linear(28*28, self.num_hidden)\n",
    "        self.layer3 = nn.Linear(self.num_hidden, self.num_hidden)\n",
    "        self.ac = nn.ReLU()\n",
    "        # self.ac = nn.Tanh()\n",
    "        self.dp = nn.Dropout()\n",
    "        self.bn = nn.BatchNorm1d(self.num_hidden)\n",
    "        self.layer4 = nn.Linear(self.num_hidden, 10)\n",
    "        self.layer5 = nn.Softmax()\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        y = self.layer1(X)\n",
    "        y = self.layer2(y)\n",
    "        \n",
    "        for i in range(2):\n",
    "            y = y + self.dp(self.ac(self.bn(self.layer3(y))))\n",
    "                   \n",
    "        y = self.layer4(y)\n",
    "        y = self.layer5(y)\n",
    "        return y\n",
    "\n",
    "net = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)\n",
    "\n",
    "train_steps(epochs=30, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device, \n",
    "            train_figure=True\n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.3. <a id='toc7_7_3_'></a>[K折交叉验证](#toc0_)\n",
    "```\n",
    "简述：把数据分成K份，分别只取1份做Test_data，（K-1）做Train_data，做K次，计算Test_acc的平均值\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_cross_eval():\n",
    "    data / k \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8. <a id='toc7_8_'></a>[可视化训练过程](#toc0_)\n",
    "* 清理上一次\n",
    "    * figure plt.clf() # 只是清理figure内容\n",
    "    * figure plt.colse() # 关闭（释放）figure\n",
    "    * axes plt.cla() # 只是清理axes内容\n",
    "* 绘图plot\n",
    "* 用jupyter的display来显示\n",
    "* 保持yupyter上的display直至下一次展示再清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印图片耗时： 5.1197662353515625 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def dl_plot(x, y):\n",
    "    '''再jupyter中持续刷新展示图片'''\n",
    "    plt.close()                                 # close figure （推荐）\n",
    "    fig = plt.figure(figsize=(3.5, 2.5))\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "\n",
    "    # plt.show()                                # 普通展示\n",
    "    display.display(fig)                        # 在jupyter中展示 （推荐）\n",
    "    display.clear_output(wait=True)             # 等待 （必须）\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(50):\n",
    "    x = torch.arange(0, epoch+1, 0.1)\n",
    "    y = torch.sin(x)\n",
    "    if epoch % 2 == 0:\n",
    "        dl_plot(x, y)\n",
    "stop = time.time()\n",
    "print(f\"打印图片耗时： {stop - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10: \t train_loss=0.8999999761581421 \t train_acc=0.7833268642425537\n",
      "2/10: \t train_loss=1.899999976158142 \t train_acc=0.9463000893592834\n",
      "3/10: \t train_loss=2.9000000953674316 \t train_acc=0.23924924433231354\n",
      "4/10: \t train_loss=3.9000000953674316 \t train_acc=-0.6877662539482117\n",
      "5/10: \t train_loss=4.900000095367432 \t train_acc=-0.9824525713920593\n",
      "6/10: \t train_loss=5.900000095367432 \t train_acc=-0.37387657165527344\n",
      "7/10: \t train_loss=6.900000095367432 \t train_acc=0.5784398317337036\n",
      "8/10: \t train_loss=7.899999618530273 \t train_acc=0.9989413619041443\n",
      "9/10: \t train_loss=8.899999618530273 \t train_acc=0.5010212063789368\n",
      "10/10: \t train_loss=9.899999618530273 \t train_acc=-0.4575355648994446\n",
      "打印数值耗时： 0.06618285179138184 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(10):\n",
    "    x = torch.arange(0, epoch+1, 0.1)\n",
    "    y = torch.sin(x)\n",
    "    # dl_plot(x, y)\n",
    "    print(f\"{epoch+1}/{10}: \\t train_loss={x[-1]} \\t train_acc={y[-1]}\")\n",
    "stop = time.time()\n",
    "print(f\"打印数值耗时： {stop - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. <a id='toc8_'></a>[在 GPU 上训练](#toc0_)\n",
    "```shell\n",
    "要实行运算的Tensor必须在同一张GPU卡上：\n",
    "    1. 张量传到GPU上            x_gpu = x.to('cuda:0')\n",
    "    2. 神经网络传到GPU上        net.to('cuda:0')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. <a id='toc8_1_'></a>[查看GPU配置](#toc0_)\n",
    "```shell\n",
    "都在torch.cuda.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 是否有可用的GPU\n",
    "torch.cuda.is_available()           \n",
    "# True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可用的GPU数量\n",
    "torch.cuda.device_count()     \n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回gpu名字，设备索引默认从0开始；\n",
    "torch.cuda.get_device_name(0)\n",
    "# \"Tesla T4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回当前设备索引；\n",
    "torch.cuda.current_device()\n",
    "# 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "只有CPU\n"
     ]
    }
   ],
   "source": [
    "def check_device():\n",
    "    '''判断是否有GPU，并列出GPU的代号/名称'''\n",
    "    if torch.cuda.is_available(): # 判断是否支持cuda/GPU\n",
    "        gpu_num = torch.cuda.device_count() # cuda/GPU计数\n",
    "        if gpu_num == 1:\n",
    "            print(f\"单机单卡: {[torch.cuda.get_device_name(gpu_name) for gpu_name in range(gpu_num)]}\")\n",
    "        else:\n",
    "            print(f\"单机{gpu_num}卡: {[torch.cuda.get_device_name(gpu_name) for gpu_name in range(gpu_num)]}\")\n",
    "    else:\n",
    "        print(f\"只有CPU\")\n",
    "    return None \n",
    "\n",
    "check_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpu']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = [ 'cpu' if not torch.cuda.is_available() else ]\n",
    "device = [f'cuda:{i}' for i in range(torch.cuda.device_count())] if torch.cuda.is_available() else ['cpu']\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. <a id='toc8_2_'></a>[单机单卡（GPU）](#toc0_)\n",
    "```\n",
    "所有的张量必须存在于同一个设备上（同一个CPU或同一个GPU），才能正确计算，否则可能会出现异常错误。\n",
    "    1、模型上GPU：model.cuda() 或 model.to(device)   \n",
    "    2、数据上GPU：data_gpu = data.cuda() 或 data_gpu = data.to(device)   \n",
    "    3、输出下GPU：output = model(data)  output.detach().cpu().numpy()，\n",
    "\n",
    ".detach()的作用是将变量output从计算图中分离，使其不具有梯度，不进行反向传播。\n",
    ".cpu()是将GPU数据转CPU，\n",
    ".numpy()是将Tensor转numpy，\n",
    "如果需要继续反向传播，则不需要.detach().cpu().numpy()。\n",
    "一般如果要单独处理，如图像的显示，或者特征的保存，都需要做上述操作。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.]]),\n",
       " tensor([[1.],\n",
       "         [1.]]),\n",
       " device(type='cpu'),\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.ones((2, 1))\n",
    "y = torch.ones((2, 1))\n",
    "x, y, x.device, y.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.]]),\n",
       " tensor([[1.],\n",
       "         [1.]]),\n",
       " device(type='cpu'),\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x.to(device)\n",
    "y1 = y.to(device)\n",
    "x1, y1, x1.device, y1.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. <a id='toc8_3_'></a>[单机多卡（GPU）](#toc0_)\n",
    "```\n",
    "目前PyTorch的单机多卡训练，主要有两种方式：\n",
    "    # 第一种\n",
    "    torch.nn.DataParallel(module=net, device_ids=[0, 1], output_device=[0])    # 单机两卡\n",
    "    # 第二种\n",
    "    torch.nn.parallel.DistributedDataParallel()             # 单机多卡、多机多卡\n",
    "```\n",
    "\n",
    "```shell\n",
    "`DataParallel` (DP) 和 `DistributedDataParallel` (DDP) 都是用于在多GPU上进行训练的工具，但它们有一些关键的区别：\n",
    "\n",
    "1. **目标环境：**\n",
    "   - `DataParallel` 适用于单机多卡的情况，通过将模型复制到每个GPU上，每个GPU计算不同的批次，最后通过梯度累积或平均来更新模型参数。\n",
    "   - `DistributedDataParallel` 适用于分布式环境，可以在单机或多台机器上的多个GPU上运行，每个GPU计算不同的批次，并通过分布式通信来同步梯度和更新模型参数。\n",
    "\n",
    "2. **通信方式：**\n",
    "   - `DataParallel` 使用单个进程内的多个GPU，通信相对较简单，仅涉及到进程内的数据传输。\n",
    "   - `DistributedDataParallel` 通过分布式通信协议，如NCCL或Gloo，实现跨进程和可能跨机器的通信，因此需要更复杂的设置。\n",
    "\n",
    "3. **启动方式：**\n",
    "   - `DataParallel` 只需在模型实例上调用 `nn.DataParallel(model)` 即可。\n",
    "   - `DistributedDataParallel` 需要在训练脚本中设置分布式环境变量，如`torch.distributed.launch` 或手动设置`os.environ`。\n",
    "\n",
    "4. **维护性：**\n",
    "   - `DataParallel` 更容易使用，因为它不涉及复杂的分布式设置。\n",
    "   - `DistributedDataParallel` 适用于更复杂的分布式场景，但需要更多的设置和管理。\n",
    "\n",
    "在单机多卡的情况下，如果简单性和易用性是首要考虑的因素，可以使用 `DataParallel`。在需要更高级的分布式设置时，或者在多机多卡的环境中，`DistributedDataParallel` 提供了更大的灵活性。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1. <a id='toc8_3_1_'></a>[DP](#toc0_)\n",
    "```shell\n",
    "单机多线程\n",
    "```\n",
    "```python\n",
    "详解\n",
    "torch.nn.DataParallel(module, device_ids, output_device)  \n",
    "\n",
    "Parameters\n",
    "    module (Module) – module to be parallelized                                                 # 神经网络\n",
    "    device_ids (list of int or torch.device) – CUDA devices (default: all devices)              # 默认使用所用GPU\n",
    "    output_device (int or torch.device) – device location of output (default: device_ids[0])    # 在cuda:0上进行参数分配、计算、汇总、更新\n",
    "Variables\n",
    "    module (Module) – the module to be parallelized\n",
    "    \n",
    "1. 有一个前提: net模型被复制到cuda:[0, 1, 2等等]上，但是X, y必须提前在cuda:0上，而不能在cuda:1、cuda:2等等上；\n",
    "2. 那如果cuda:0有其他人占满了，怎么办？那就需要手动指定其他GPU为cuda:0了：\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"      # 一定一定要放在所有访问显卡的代码之前，否则则无效，给我困扰了好一段时间才发现了。我之前看到有一个说法是放到import os之后并且在import torch之前。\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2, 3\"         # 只识别2、3而抛弃了其他GPU，把2当成pytorch逻辑上的cuda:0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " Runing on cpu \n",
      " ====================================================================================================\n",
      "epoch 1/10: train_loss=1.6323208808898926, train_acc=83.99833679199219, test_acc=84.13999938964844\n",
      "epoch 2/10: train_loss=1.5583083629608154, train_acc=91.48500061035156, test_acc=91.79000091552734\n",
      "epoch 3/10: train_loss=1.5336382389068604, train_acc=93.64500427246094, test_acc=93.69000244140625\n",
      "epoch 4/10: train_loss=1.5234729051589966, train_acc=94.54167175292969, test_acc=94.27999877929688\n",
      "epoch 5/10: train_loss=1.5158753395080566, train_acc=95.2316665649414, test_acc=94.86000061035156\n",
      "epoch 6/10: train_loss=1.5113998651504517, train_acc=95.62666320800781, test_acc=95.09000396728516\n",
      "epoch 7/10: train_loss=1.506333351135254, train_acc=96.07833862304688, test_acc=95.74000549316406\n",
      "epoch 8/10: train_loss=1.502449870109558, train_acc=96.51166534423828, test_acc=95.97000122070312\n",
      "epoch 9/10: train_loss=1.498482346534729, train_acc=96.83332824707031, test_acc=96.21000671386719\n",
      "epoch 10/10: train_loss=1.49517023563385, train_acc=97.17500305175781, test_acc=96.43000030517578\n",
      "==================================================================================================== \n",
      " Total：0.0 d/ 0.0 h/ 1.0 m/ 35.65645790100098 s\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据准备\n",
    "dbs = './Pytorch_datasets/'\n",
    "train_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=True, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "test_dataset = torchvision.datasets.MNIST(root=dbs, \n",
    "                                           train=False, \n",
    "                                           download=True, \n",
    "                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                                                    #  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                                                     ]\n",
    "                                                                                     )\n",
    "                                                                                     )\n",
    "# 迭代型数据方式\n",
    "train_iter = data.DataLoader(dataset=train_dataset, \n",
    "                             batch_size=128, \n",
    "                             shuffle=True)\n",
    "# test_iter = data.DataLoader(dataset=test_dataset) # test不需要batch训练\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "                                     nn.Linear(1024, 10), nn.Softmax())\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "# 训练过程封装\n",
    "def train_steps(epochs, train_dataset, train_iter, test_dataset, net, loss_fn, opt, device):\n",
    "    '''\n",
    "    参数记录\n",
    "    epochs = epochs                         # epoch\n",
    "    train_dataset = train_dataset           # 全部train数据集\n",
    "    train_iter = train_iter                 # batch之后的train数据集\n",
    "    test_dataset = test_dataset             # 全部test数据集\n",
    "    net = net                               # 网络模型\n",
    "    loss_fn = loss_fn                       # 损失函数\n",
    "    opt = opt                               # 优化器\n",
    "    device = device                         # device GPU/CPU\n",
    "    '''\n",
    "    print('='*100, '\\n', f\"Runing on {device}\", '\\n','='*100)\n",
    "    train_all_data_gpu = train_dataset.data.to(device)\n",
    "    train_all_targets_gpu = train_dataset.targets.to(device)\n",
    "    test_all_data_gpu = test_dataset.data.to(device)\n",
    "    test_all_targets_gpu = test_dataset.targets.to(device)\n",
    "    net = nn.DataParallel(module=net)\n",
    "    # net = nn.DataParallel(module=net, device_ids=[0, 1], output_device=[0]) # 多GPU并行计算，等价于net = nn.DataParallel(module=net)\n",
    "    net.to(device)\n",
    "\n",
    "    # 开始迭代\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_record in train_iter:\n",
    "            X, y = batch_record                 # 分配X, y\n",
    "            X, y = X.to(device), y.to(device)   # 复制到device（GPU/CPU）上\n",
    "            # print(X[0])\n",
    "            # print(X[0].dtype)\n",
    "            # break\n",
    "            opt.zero_grad()                     # 默认是累加，此处从新求导\n",
    "            y_hat = net(X)          # 计算y_hat\n",
    "            loss = loss_fn(y_hat, y)# 计算loss\n",
    "            loss.backward()         # 计算梯度\n",
    "            opt.step()              # 更新网络参数\n",
    "\n",
    "        net.eval()  # 切换至评估模式\n",
    "                    # 模型默认是net.train()\n",
    "                    # 但是net中含有BN、Dropout等，在test时必须固定train时学好的参数，不能被test又改变了\n",
    "                    # 但net中没有BN、Dropout等时，加不加net.eval()都无所谓\n",
    "\n",
    "        with torch.no_grad(): # with下内容不进行grad计算，可以节省运算和内存\n",
    "            train_loss = loss_fn(net(train_all_data_gpu/256), train_all_targets_gpu)\n",
    "            # print(train_loss)\n",
    "            train_acc_cmp = net(train_all_data_gpu/256).argmax(axis=1) == train_all_targets_gpu\n",
    "            train_acc = (train_acc_cmp.sum() / len(train_acc_cmp)) * 100\n",
    "            # print(train_acc)\n",
    "            test_acc_cmp = net(test_all_data_gpu/256).argmax(axis=1) == test_all_targets_gpu\n",
    "            test_acc = (test_acc_cmp.sum() / len(test_acc_cmp)) * 100\n",
    "            # print(test_acc)\n",
    "            print(f\"epoch {epoch+1}/{epochs}: train_loss={train_loss}, train_acc={train_acc}, test_acc={test_acc}\")\n",
    "\n",
    "    stop = time.time()\n",
    "    seconds = stop - start\n",
    "    def convert_seconds(seconds):\n",
    "        days = seconds // (24 * 3600)\n",
    "        hours = (seconds % (24 * 3600)) // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        remaining_seconds = seconds % 60\n",
    "        return days, hours, minutes, remaining_seconds\n",
    "    days, hours, minutes, remaining_seconds = convert_seconds(seconds)\n",
    "    print('='*100, '\\n', f\"Total：{days} d/ {hours} h/ {minutes} m/ {remaining_seconds} s\")\n",
    "    # return (train_loss, train_acc, test_acc)\n",
    "    return None\n",
    "\n",
    "# lr 0.01 -> 0.5\n",
    "# 结果表明还是会快一点收敛\n",
    "net = Net()  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=net.parameters(), lr=0.5)   \n",
    "train_steps(epochs=10, \n",
    "            train_dataset=train_dataset, \n",
    "            train_iter=train_iter, \n",
    "            test_dataset=test_dataset, \n",
    "            net=net,                        \n",
    "            loss_fn=loss_fn, \n",
    "            opt=opt, \n",
    "            device=device \n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2. <a id='toc8_3_2_'></a>[DDP](#toc0_)\n",
    "```shell\n",
    "1. 与 DataParallel 的单进程控制多 GPU 不同，在 distributed 的帮助下，我们只需要编写一份代码，torch 就会自动将其分配给 \n",
    " 个进程，分别在 n 个 GPU 上运行。\n",
    "2. 单机多进程\n",
    "```\n",
    "```python\n",
    "详解\n",
    "torch.nn.parallel.DistributedDataParallel(module, device_ids, output_device)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import os \n",
    "\n",
    "def ddp_setup(rank, world_size):\n",
    "    '''\n",
    "    Args:\n",
    "        rank: unique identifier of each process\n",
    "        world_size: Total number of process\n",
    "    '''\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12357\"\n",
    "    dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2.1. <a id='toc8_3_2_1_'></a>[在colab上测试可用](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.multiprocessing import Process\n",
    "import os\n",
    "\n",
    "# 定义卷积神经网络模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train(local_rank, world_size):\n",
    "  \n",
    "  os.environ[\"MASTER_PORT\"] = \"12357\"\n",
    "  os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "\n",
    "  # 设置每个进程的GPU\n",
    "  torch.cuda.set_device(local_rank)\n",
    "  device = torch.device(\"cuda\", local_rank)\n",
    "\n",
    "  # 初始化进程组\n",
    "  dist.init_process_group(backend='nccl', world_size=world_size, rank=local_rank)\n",
    "\n",
    "  # 数据预处理和加载\n",
    "  transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "  trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "  # 使用DistributedSampler来对数据进行分布式采样\n",
    "  train_sampler = torch.utils.data.distributed.DistributedSampler(trainset)\n",
    "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=False, sampler=train_sampler)\n",
    "\n",
    "  # 创建CNN模型实例，并放入多个GPU上\n",
    "  model = CNN().to(device)\n",
    "  model = nn.parallel.DistributedDataParallel(model, device_ids=[local_rank])\n",
    "\n",
    "  # 定义损失函数和优化器\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "  # 训练模型\n",
    "  num_epochs = 5\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "      model.train()\n",
    "      running_loss = 0.0\n",
    "\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "          inputs, labels = data\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          running_loss += loss.item()\n",
    "\n",
    "      print(f\"Local Rank {local_rank}, Epoch {epoch + 1}/{num_epochs}, Training Loss: {running_loss / len(trainloader):.4f}\")\n",
    "\n",
    "  dist.destroy_process_group()\n",
    "\n",
    "# Process格式：\n",
    "if __name__ == \"__main__\":\n",
    "  # size = torch.cuda.device_count()\n",
    "  size = 10\n",
    "  processes = []\n",
    "  world_size = 1\n",
    "  for rank in range(size):\n",
    "      p = Process(target=train, args=(rank, world_size))\n",
    "      p.start()\n",
    "      processes.append(p)\n",
    "\n",
    "  for p in processes:\n",
    "      p.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4. <a id='toc8_4_'></a>[多机多卡（GPU）- 分布式训练](#toc0_)\n",
    "```shell\n",
    "目前PyTorch的多机多卡训练，主要有两种方式：   \n",
    "    1. torch.nn.parallel.DistributedDataParallel()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. <a id='toc9_'></a>[模型和参数的保存与加载](#toc0_)\n",
    "\n",
    "```shell\n",
    "torch.save(张量名, 位置)\n",
    "张量名称 = torch.load(位置)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. <a id='toc9_1_'></a>[加载和保存-张量](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.ones((3, 5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save()\n",
    "torch.save(x, './Pytorch_params/x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.load()\n",
    "x1 = torch.load('./Pytorch_params/x-file')\n",
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. <a id='toc9_2_'></a>[加载和保存-模型参数](#toc0_)\n",
    "```shell\n",
    "保存单个权重向量（或其他张量）确实有用， 但是如果我们想保存整个模型，并在以后加载它们， 单独保存每个向量则会变得很麻烦。 毕竟，我们可能有数百个参数散布在各处。 因此，深度学习框架提供了内置函数来保存和加载整个网络。 需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。 例如，如果我们有一个3层多层感知机，我们需要单独指定架构。 因为模型本身可以包含任意代码，所以模型本身难以序列化。 因此，为了恢复模型，我们需要用代码生成架构， 然后从磁盘加载参数。\n",
    "```\n",
    "```shell\n",
    "1. save和load函数可用于张量对象的文件读写。\n",
    "2. 我们可以通过参数字典保存和加载网络的全部参数。\n",
    "3. 保存架构必须在代码中完成，而不是在参数中完成。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save()\n",
    "# 接下来，我们将模型的参数存储在一个叫做“mlp.params”的文件中。\n",
    "torch.save(net.state_dict(), './Pytorch_params/mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.load()\n",
    "# 为了恢复模型，我们实例化了原始多层感知机模型的一个备份。 \n",
    "# 这里我们不需要随机初始化模型参数，而是直接读取文件中存储的参数。\n",
    "net_params = torch.load('./Pytorch_params/mlp.params')\n",
    "clone = MLP()\n",
    "\n",
    "clone.load_state_dict(net_params)\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. <a id='toc10_'></a>[神经网络类型](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1. <a id='toc10_1_'></a>[CNN](#toc0_)\n",
    "```\n",
    "CBAPD: 卷积，批量归一化，激活，池化，丢弃\n",
    "卷积层就是特征提取，随后将特征传入FC（全连接层）；\n",
    "卷积本身是线性的，但是经过激活函数后可以编程非线性的。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.1. <a id='toc10_1_1_'></a>[简单CNN](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1.1.1. <a id='toc10_1_1_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1.1.2. <a id='toc10_1_1_2_'></a>[简介实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.con = nn.Conv2d(in_channels=1, out_channels=2)\n",
    "        self.bn = nn.BatchNorm2d()\n",
    "        self.ave = nn.AvgPool2d()\n",
    "        self.dr = nn.Dropout()\n",
    "        self.fc = nn.Linear()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.fc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.2. <a id='toc10_1_2_'></a>[ResNet](#toc0_)\n",
    "```shell\n",
    "如果，CNN只需要弄懂一个神经网络模型的话，那就是ResNet。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1.2.1. <a id='toc10_1_2_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Flatten(), \n",
    "                                 nn.LSTM(), nn.ReLU()\n",
    "                                 )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1.2.2. <a id='toc10_1_2_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2. <a id='toc10_2_'></a>[序列数据](#toc0_)\n",
    "### 10.2.1. <a id='toc10_2_1_'></a>[序列](#toc0_)\n",
    "```sehll\n",
    "马尔可夫模型\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.2. <a id='toc10_2_2_'></a>[语言模型](#toc0_)\n",
    "语言模型 (language model)是定义在单词序列上的概率模型，可以用来计算一个句子或一段文字的概率\n",
    "```shell\n",
    "马尔可夫模型\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.3. <a id='toc10_2_3_'></a>[文本预处理](#toc0_)\n",
    "* token：最小单位（字符/单词/词组）\n",
    "* vocab：（token：indice）对照（查询）列表\n",
    "* cropus：token转化为indice后的文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.3.1. <a id='toc10_2_3_1_'></a>[下载《Time machine》并读取数据](#toc0_)\n",
    "首先，我们从H.G.Well的[时光机器](https://www.gutenberg.org/ebooks/35)中加载文本。\n",
    "这是一个相当小的语料库，只有30000多个单词，但足够我们小试牛刀，\n",
    "而现实中的文档集合可能会包含数十亿个单词。\n",
    "下面的函数(**将数据集读取到由多条文本行组成的列表中**)，其中每条文本行都是一个字符串。\n",
    "为简单起见，我们在这里忽略了标点符号和字母大写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 文本总行数: 3221\n",
      "the time machine by h g wells\n",
      "\n",
      "twinkled and his usually pale face was flushed and animated the\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import re\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#@save\n",
    "# 下载到../data/timemachine.txt\n",
    "d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt',\n",
    "                                '090b5e7e70c295757f55df93cb0a180b9691891a')\n",
    "\n",
    "def read_time_machine():  #@save\n",
    "    \"\"\"将时间机器数据集加载到文本行的列表中\"\"\"\n",
    "    with open(d2l.download('time_machine'), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
    "\n",
    "lines = read_time_machine()\n",
    "print(f'# 文本总行数: {len(lines)}')\n",
    "print(lines[0])\n",
    "print(lines[1]) # 空的\n",
    "print(lines[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.3.2. <a id='toc10_2_3_2_'></a>[词元化（Token）](#toc0_)\n",
    "* 按照char/word等拆分成列表格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['i']\n",
      "[]\n",
      "[]\n",
      "['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him']\n",
      "['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']\n",
      "['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n"
     ]
    }
   ],
   "source": [
    "# 按照word\n",
    "def tokenize(lines, token='word'):  #@save\n",
    "    \"\"\"将文本行拆分为单词或字符词元\"\"\"\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('错误：未知词元类型：' + token)\n",
    "\n",
    "tokens = tokenize(lines)\n",
    "for i in range(11):\n",
    "    print(tokens[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.3.3. <a id='toc10_2_3_3_'></a>[词表（vocab）](#toc0_)\n",
    "* 构建(token：索引)查询元组\n",
    "* 并将文本的token替换成索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:\t [('<unk>', 0), ('the', 1), ('i', 2), ('and', 3), ('of', 4), ('a', 5), ('to', 6), ('was', 7), ('in', 8), ('that', 9)]\n",
      "文本: ['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
      "索引: [1, 19, 50, 40, 2183, 2184, 400]\n",
      "文本: ['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n",
      "索引: [2186, 3, 25, 1044, 362, 113, 7, 1421, 3, 1045, 1]\n"
     ]
    }
   ],
   "source": [
    "class Vocab:  #@save\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # 按出现频率排序\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # 未知词元的索引为0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "\n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    # 这里的tokens是1D列表或2D列表\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # 将词元列表展平成一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "vocab = Vocab(tokens)\n",
    "print('vocab:\\t', list(vocab.token_to_idx.items())[:10])\n",
    "\n",
    "for i in [0, 10]:\n",
    "    print('文本:', tokens[i])\n",
    "    print('索引:', vocab[tokens[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.3.4. <a id='toc10_2_3_4_'></a>[整合所有功能](#toc0_)\n",
    "* 读取数据\n",
    "* 分割成token\n",
    "* 并构建(token, indice)查询表并替换token成indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170580, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按照char进行词元化 \n",
    "\n",
    "def load_corpus_time_machine(max_tokens=-1):  #@save\n",
    "    \"\"\"返回时光机器数据集的词元索引列表和词表\"\"\"\n",
    "    lines = read_time_machine()\n",
    "    tokens = tokenize(lines, 'char')\n",
    "    vocab = Vocab(tokens)\n",
    "    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n",
    "    # 所以将所有文本行展平到一个列表中\n",
    "    corpus = [vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[:max_tokens]\n",
    "    return corpus, vocab\n",
    "\n",
    "corpus, vocab = load_corpus_time_machine()\n",
    "len(corpus), len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.4. <a id='toc10_2_4_'></a>[语言模型数据集](#toc0_)\n",
    "#### 10.2.4.1. <a id='toc10_2_4_1_'></a>[顺序采样](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_iter_sequential(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用顺序分区生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始划分序列\n",
    "    offset = random.randint(0, num_steps)\n",
    "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
    "    Xs = torch.tensor(corpus[offset: offset + num_tokens])\n",
    "    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
    "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
    "    num_batches = Xs.shape[1] // num_steps\n",
    "    for i in range(0, num_steps * num_batches, num_steps):\n",
    "        X = Xs[:, i: i + num_steps]\n",
    "        Y = Ys[:, i: i + num_steps]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):\n",
    "#     print('X: ', X, '\\nY:', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 10.2.4.2. <a id='toc10_2_4_2_'></a>[随机采样](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seq_data_iter_random(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用随机抽样生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n",
    "    corpus = corpus[random.randint(0, num_steps - 1):]\n",
    "    # 减去1，是因为我们需要考虑标签\n",
    "    num_subseqs = (len(corpus) - 1) // num_steps\n",
    "    # 长度为num_steps的子序列的起始索引\n",
    "    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "    # 在随机抽样的迭代过程中，\n",
    "    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n",
    "    random.shuffle(initial_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        # 返回从pos位置开始的长度为num_steps的序列\n",
    "        return corpus[pos: pos + num_steps]\n",
    "\n",
    "    num_batches = num_subseqs // batch_size\n",
    "    for i in range(0, batch_size * num_batches, batch_size):\n",
    "        # 在这里，initial_indices包含子序列的随机起始索引\n",
    "        initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
    "        X = [data(j) for j in initial_indices_per_batch]\n",
    "        Y = [data(j + 1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(X), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_seq = list(range(35))\n",
    "# for X, Y in seq_data_iter_random(my_seq, batch_size=2, num_steps=5):\n",
    "#     print('X: ', X, '\\nY:', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.4.3. <a id='toc10_2_4_3_'></a>[包装](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataLoader:  #@save\n",
    "    \"\"\"加载序列数据的迭代器\"\"\"\n",
    "    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n",
    "        if use_random_iter:\n",
    "            # self.data_iter_fn = d2l.seq_data_iter_random\n",
    "            self.data_iter_fn = seq_data_iter_random\n",
    "        else:\n",
    "            # self.data_iter_fn = d2l.seq_data_iter_sequential\n",
    "            self.data_iter_fn = seq_data_iter_sequential\n",
    "        # self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)\n",
    "        self.corpus, self.vocab = load_corpus_time_machine(max_tokens)\n",
    "        self.batch_size, self.num_steps = batch_size, num_steps\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_time_machine(batch_size, num_steps,  #@save\n",
    "                           use_random_iter=False, max_tokens=10000):\n",
    "    \"\"\"返回时光机器数据集的迭代器和词表\"\"\"\n",
    "    data_iter = SeqDataLoader(\n",
    "        batch_size, num_steps, use_random_iter, max_tokens)\n",
    "    return data_iter, data_iter.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3. <a id='toc10_3_'></a>[RNN](#toc0_)\n",
    "* 可以处理有顺序的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.1. <a id='toc10_3_1_'></a>[RNN-循环神经网络原理](#toc0_)\n",
    "* 结构：\n",
    "    * 有一层（或多层）隐藏结构；\n",
    "    * 当前隐藏结构由上一侧隐藏结构和当前输入决定\n",
    "    * 依次类推\n",
    "\n",
    " <img src=\"./Pytorch_Pictures/RNN.jpg\" width = \"500\" height = \"300\" alt=\"图片名称\" align=center />\n",
    "\n",
    "更新隐藏状态：      \n",
    "$\\mathbf{h}_t=\\phi(\\mathbf{W}_{hh}\\mathbf{h}_{t-1}+\\mathbf{W}_{hx}\\mathbf{x}_{t-1}+\\mathbf{b}_h)$  \n",
    "输出：             \n",
    "$\\mathbf{o}_t=\\phi(\\mathbf{W}_\\textit{ho}\\mathbf{h}_t+\\mathbf{b}_o)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.1.1. <a id='toc10_3_1_1_'></a>[从头实现网络](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 28]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网络结构\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 初始化模型\n",
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = normal((num_inputs, num_hiddens))\n",
    "    W_hh = normal((num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 附加梯度\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params\n",
    "\n",
    "def init_rnn_state(batch_size, num_hiddens, device):                        # 初始化第一个隐变量的值\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )\n",
    "\n",
    "def rnn(inputs, state, params):\n",
    "    # inputs的形状：(时间步数量，批量大小，词表大小)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    # X的形状：(批量大小，词表大小)\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)         # 隐藏变量\n",
    "        Y = torch.mm(H, W_hq) + b_q                                         # 输出\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H,)\n",
    "\n",
    "class RNNModelScratch: #@save\n",
    "    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, device,\n",
    "                 get_params, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "\n",
    "    def __call__(self, X, state):\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)\n",
    "    \n",
    "# 测试一下\n",
    "X = torch.arange(10).reshape((2, 5))\n",
    "F.one_hot(X.T, 28).shape\n",
    "\n",
    "num_hiddens = 512\n",
    "net = RNNModelScratch(len(vocab), \n",
    "                      num_hiddens, \n",
    "                      d2l.try_gpu(), \n",
    "                      get_params,\n",
    "                      init_rnn_state, \n",
    "                      rnn)\n",
    "state = net.begin_state(X.shape[0], d2l.try_gpu())\n",
    "Y, new_state = net(X.to(d2l.try_gpu()), state)\n",
    "Y.shape, len(new_state), new_state[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.1.2. <a id='toc10_3_1_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (rnn): RNN(28, 512)\n",
       "  (linear): Linear(in_features=512, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, rnn_layer, vocab_size, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_hiddens = self.rnn.hidden_size\n",
    "        # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1\n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions = 1\n",
    "            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
    "        else:\n",
    "            self.num_directions = 2\n",
    "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        X = F.one_hot(inputs.T.long(), self.vocab_size)\n",
    "        X = X.to(torch.float32)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)\n",
    "        # 它的输出形状是(时间步数*批量大小,词表大小)。\n",
    "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        if not isinstance(self.rnn, nn.LSTM):\n",
    "            # nn.GRU以张量作为隐状态\n",
    "            return  torch.zeros((self.num_directions * self.rnn.num_layers,\n",
    "                                 batch_size, self.num_hiddens),\n",
    "                                device=device)\n",
    "        else:\n",
    "            # nn.LSTM以元组作为隐状态\n",
    "            return (torch.zeros((\n",
    "                self.num_directions * self.rnn.num_layers,\n",
    "                batch_size, self.num_hiddens), device=device),\n",
    "                    torch.zeros((\n",
    "                        self.num_directions * self.rnn.num_layers,\n",
    "                        batch_size, self.num_hiddens), \n",
    "                        device=device))\n",
    "\n",
    "batch_size, num_steps, num_hiddens = 32, 35, 512\n",
    "rnn_layer = nn.RNN(len(vocab), num_hiddens)\n",
    "# 我们(**使用张量来初始化隐状态**)，它的形状是（隐藏层数，批量大小，隐藏单元数）。\n",
    "state = torch.zeros((1, batch_size, num_hiddens))\n",
    "state.shape\n",
    "# [**通过一个隐状态和一个输入，我们就可以用更新后的隐状态计算输出。**]\n",
    "# 需要强调的是，`rnn_layer`的“输出”（`Y`）不涉及输出层的计算：\n",
    "# 它是指每个时间步的隐状态，这些隐状态可以用作后续输出层的输入。\n",
    "X = torch.rand(size=(num_steps, batch_size, len(vocab)))\n",
    "Y, state_new = rnn_layer(X, state)\n",
    "Y.shape, state_new.shape\n",
    "\n",
    "device = d2l.try_gpu()\n",
    "net = RNNModel(rnn_layer, vocab_size=len(vocab))\n",
    "net = net.to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.1.3. <a id='toc10_3_1_3_'></a>[训练和预测](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time traveller uuuuuuuuuu'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测\n",
    "def predict_ch8(prefix, num_preds, net, vocab, device):  #@save\n",
    "    \"\"\"在prefix后面生成新字符\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])\n",
    "\n",
    "# 测试以下\n",
    "predict_ch8('time traveller ', 10, net, vocab, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度剪裁\n",
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "困惑度 1.2, 36777.8 词元/秒 cpu\n",
      "time travelleryou can show black is white brea thing in s ou tra\n",
      "travelleryou can show black is white by argument tave peysa\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"252.646875pt\" height=\"183.35625pt\" viewBox=\"0 0 252.646875 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-01-24T13:43:04.547055</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 252.646875 183.35625 \n",
       "L 252.646875 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 235.903125 145.8 \n",
       "L 235.903125 7.2 \n",
       "L 40.603125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 76.474554 145.8 \n",
       "L 76.474554 7.2 \n",
       "\" clip-path=\"url(#pa38a3a3184)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"meb263472cf\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#meb263472cf\" x=\"76.474554\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(66.930804 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 116.331696 145.8 \n",
       "L 116.331696 7.2 \n",
       "\" clip-path=\"url(#pa38a3a3184)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#meb263472cf\" x=\"116.331696\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(106.787946 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 156.188839 145.8 \n",
       "L 156.188839 7.2 \n",
       "\" clip-path=\"url(#pa38a3a3184)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#meb263472cf\" x=\"156.188839\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(146.645089 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 196.045982 145.8 \n",
       "L 196.045982 7.2 \n",
       "\" clip-path=\"url(#pa38a3a3184)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#meb263472cf\" x=\"196.045982\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(186.502232 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 235.903125 145.8 \n",
       "L 235.903125 7.2 \n",
       "\" clip-path=\"url(#pa38a3a3184)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#meb263472cf\" x=\"235.903125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 500 -->\n",
       "      <g transform=\"translate(226.359375 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(123.025 174.076563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 40.603125 127.554159 \n",
       "L 235.903125 127.554159 \n",
       "\" clip-path=\"url(#pa38a3a3184)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <defs>\n",
       "       <path id=\"mf7601f94f8\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf7601f94f8\" x=\"40.603125\" y=\"127.554159\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(27.240625 131.353378) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 40.603125 103.038472 \n",
       "L 235.903125 103.038472 \n",
       "\" clip-path=\"url(#pa38a3a3184)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf7601f94f8\" x=\"40.603125\" y=\"103.038472\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(27.240625 106.837691) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 40.603125 78.522785 \n",
       "L 235.903125 78.522785 \n",
       "\" clip-path=\"url(#pa38a3a3184)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf7601f94f8\" x=\"40.603125\" y=\"78.522785\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(27.240625 82.322003) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 40.603125 54.007097 \n",
       "L 235.903125 54.007097 \n",
       "\" clip-path=\"url(#pa38a3a3184)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf7601f94f8\" x=\"40.603125\" y=\"54.007097\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(27.240625 57.806316) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 40.603125 29.49141 \n",
       "L 235.903125 29.49141 \n",
       "\" clip-path=\"url(#pa38a3a3184)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf7601f94f8\" x=\"40.603125\" y=\"29.49141\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(20.878125 33.290629) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- perplexity -->\n",
       "     <g transform=\"translate(14.798437 101.626563) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \n",
       "L 2247 1797 \n",
       "L 3578 0 \n",
       "L 2900 0 \n",
       "L 1881 1375 \n",
       "L 863 0 \n",
       "L 184 0 \n",
       "L 1544 1831 \n",
       "L 300 3500 \n",
       "L 978 3500 \n",
       "L 1906 2253 \n",
       "L 2834 3500 \n",
       "L 3513 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"166.113281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"229.589844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"257.373047\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-78\" x=\"317.146484\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"376.326172\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"404.109375\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"443.318359\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 40.603125 13.5 \n",
       "L 44.588839 40.296098 \n",
       "L 48.574554 51.14614 \n",
       "L 52.560268 54.035756 \n",
       "L 56.545982 59.85477 \n",
       "L 60.531696 63.308633 \n",
       "L 64.517411 62.94785 \n",
       "L 68.503125 70.154804 \n",
       "L 72.488839 77.534341 \n",
       "L 76.474554 90.772015 \n",
       "L 80.460268 106.04818 \n",
       "L 84.445982 114.997501 \n",
       "L 88.431696 122.596289 \n",
       "L 92.417411 127.974834 \n",
       "L 96.403125 131.33263 \n",
       "L 100.388839 133.118455 \n",
       "L 104.374554 134.125621 \n",
       "L 108.360268 135.407396 \n",
       "L 112.345982 135.710208 \n",
       "L 116.331696 136.239876 \n",
       "L 120.317411 136.678584 \n",
       "L 124.303125 136.746316 \n",
       "L 128.288839 138.234532 \n",
       "L 132.274554 138.33927 \n",
       "L 136.260268 138.902404 \n",
       "L 140.245982 138.891444 \n",
       "L 144.231696 139.284879 \n",
       "L 148.217411 139.007167 \n",
       "L 152.203125 139.086631 \n",
       "L 156.188839 139.016114 \n",
       "L 160.174554 139.179278 \n",
       "L 164.160268 139.333958 \n",
       "L 168.145982 139.306895 \n",
       "L 172.131696 139.323342 \n",
       "L 176.117411 139.216968 \n",
       "L 180.103125 139.369115 \n",
       "L 184.088839 139.319172 \n",
       "L 188.074554 139.1957 \n",
       "L 192.060268 139.358124 \n",
       "L 196.045982 139.355851 \n",
       "L 200.031696 139.381084 \n",
       "L 204.017411 139.204721 \n",
       "L 208.003125 139.432092 \n",
       "L 211.988839 139.112987 \n",
       "L 215.974554 139.365174 \n",
       "L 219.960268 139.5 \n",
       "L 223.945982 139.343973 \n",
       "L 227.931696 139.351558 \n",
       "L 231.917411 137.719876 \n",
       "L 235.903125 137.763192 \n",
       "\" clip-path=\"url(#pa38a3a3184)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 40.603125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 235.903125 145.8 \n",
       "L 235.903125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 235.903125 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 40.603125 7.2 \n",
       "L 235.903125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 173.628125 29.878125 \n",
       "L 228.903125 29.878125 \n",
       "Q 230.903125 29.878125 230.903125 27.878125 \n",
       "L 230.903125 14.2 \n",
       "Q 230.903125 12.2 228.903125 12.2 \n",
       "L 173.628125 12.2 \n",
       "Q 171.628125 12.2 171.628125 14.2 \n",
       "L 171.628125 27.878125 \n",
       "Q 171.628125 29.878125 173.628125 29.878125 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_22\">\n",
       "     <path d=\"M 175.628125 20.298438 \n",
       "L 185.628125 20.298438 \n",
       "L 195.628125 20.298438 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- train -->\n",
       "     <g transform=\"translate(203.628125 23.798438) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pa38a3a3184\">\n",
       "   <rect x=\"40.603125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练\n",
    "\n",
    "#@save\n",
    "import math \n",
    "\n",
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    \"\"\"训练网络一个迭代周期（定义见第8章）\"\"\"\n",
    "    state, timer = None, d2l.Timer()\n",
    "    metric = d2l.Accumulator(2)  # 训练损失之和,词元数量\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # 在第一次迭代或使用随机抽样时初始化state\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # state对于nn.GRU是个张量\n",
    "                state.detach_()\n",
    "            else:\n",
    "                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            # 因为已经调用了mean函数\n",
    "            updater(batch_size=1)\n",
    "        metric.add(l * y.numel(), y.numel())\n",
    "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()\n",
    "\n",
    "#@save\n",
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n",
    "              use_random_iter=False):\n",
    "    \"\"\"训练模型（定义见第8章）\"\"\"\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',\n",
    "                            legend=['train'], xlim=[10, num_epochs])\n",
    "    # 初始化\n",
    "    if isinstance(net, nn.Module):\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "    else:\n",
    "        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)\n",
    "    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
    "    # 训练和预测\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch_ch8(\n",
    "            net, train_iter, loss, updater, device, use_random_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(predict('time traveller'))\n",
    "            animator.add(epoch + 1, [ppl])\n",
    "    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))\n",
    "\n",
    "# 加载数据\n",
    "batch_size, num_steps = 32, 35\n",
    "# train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)\n",
    "train_iter, vocab = load_data_time_machine(batch_size, num_steps)\n",
    "\n",
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.1.4. <a id='toc10_3_1_4_'></a>[深层RNN](#toc0_)\n",
    "* 有多个隐藏层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "rnn_layer = nn.RNN(input_size=3,            # 输入大小\n",
    "                   hidden_size=3,           # 隐藏层大小\n",
    "                   bidirectional=False,     # 双向神经网络，默认是单向\n",
    "                   num_layers=1             # 深层神经网络，默认是1层\n",
    "                   )\n",
    "# dir(rnn_layer)      # 查看属性\n",
    "# help(rnn_layer)   # 查看方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.1.5. <a id='toc10_3_1_5_'></a>[双向RNN](#toc0_)\n",
    "* 双向（其实就是将输入倒过来再输入）\n",
    "* 不能用双向循环神经网络来预测未来，因为从一开始就透露未来的信息。\n",
    "* 那实际引用场景是什么？\n",
    "    * 翻译\n",
    "    * 文本句子分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "rnn_layer = nn.RNN(input_size=3,            # 输入大小\n",
    "                   hidden_size=3,           # 隐藏层大小\n",
    "                   bidirectional=False,     # 双向神经网络，默认是单向\n",
    "                   num_layers=1             # 深层神经网络，默认是1层\n",
    "                   )\n",
    "# dir(rnn_layer)      # 查看属性\n",
    "# help(rnn_layer)   # 查看方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.2. <a id='toc10_3_2_'></a>[GRU](#toc0_)\n",
    "* GRU实际晚于LSTM，但是作用效果相当而更容易理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.2.1. <a id='toc10_3_2_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.2.2. <a id='toc10_3_2_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "gru_layer = nn.GRU(input_size=3, \n",
    "                   hidden_size=3, \n",
    "                   num_layers=2, \n",
    "                   bidirectional=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.3. <a id='toc10_3_3_'></a>[LSTM](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.3.1. <a id='toc10_3_3_1_'></a>[从头实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.3.2. <a id='toc10_3_3_2_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "lstm_layer = nn.LSTM(input_size=3, \n",
    "                     hidden_size=3, \n",
    "                     num_layers=2, \n",
    "                     bidirectional=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.4. <a id='toc10_3_4_'></a>[Encoder-Decoder框架](#toc0_)\n",
    "```shell\n",
    "输入-Encoder-中间状态-Decoder-输出\n",
    "                       输入\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.4.1. <a id='toc10_3_4_1_'></a>[Encoder部分](#toc0_)\n",
    "```shell\n",
    "可变长度的输入，固定长度的输出中间状态\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "#@save\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.4.2. <a id='toc10_3_4_2_'></a>[Decoder部分](#toc0_)\n",
    "```shell\n",
    "固定长度中间状态\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.4.3. <a id='toc10_3_4_3_'></a>[Encoder-Decoder（合并编码器和解码器）](#toc0_)\n",
    "```shell\n",
    "Encoder-Decoder\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.5. <a id='toc10_3_5_'></a>[seq2seq (Sequence to sequence learning)](#toc0_)\n",
    "```shell\n",
    "基于RNN的编码器-解码器框架(Encoder-Decoder)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.5.1. <a id='toc10_3_5_1_'></a>[简洁实现](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4. <a id='toc10_4_'></a>[Attention](#toc0_)\n",
    "不是一个新的概念，很早之前就已经出现，只是在Google发表论文Attention is all you need后，越来越知名。  \n",
    "如果非要找一个依据，从心理学上讲： \n",
    " \n",
    "    1. 之前学习的神经网络（CNN、RNN等）都是提取特征->全连接网络，属于“非随意识注意力”-即非主观，如一排黑色水杯中有一个红色的就会很吸引人；  \n",
    "    2. Attention提出的是“随意识注意力”即主观的去注意那个物体。\n",
    "\n",
    "Query:主动去查询（注意）  \n",
    "Key:  \n",
    "Value:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.1. <a id='toc10_4_1_'></a>[非参数注意力汇聚（Attention Pooling）](#toc0_)\n",
    "在以前，统计学家计算机用的不是很溜。用统计模型进行预测，而不是利用计算机的计算资源进行迭代优化逼近真实分布。所得的结果就是只是利用统计模型进行预测的曲线会比较平滑但是准确性不高，可能随着数据量的增高可以提高准确性，但是，现实中能有那么多够用的数据吗？而利用计算迭代优化逼近的方法可以很准确的拟合现有的数据，虽然不是很平滑，优点是数据虽少但可以被充分利用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f(x) = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.2. <a id='toc10_4_2_'></a>[参数注意力汇聚（Attention Pooling）](#toc0_)\n",
    "```shell\n",
    "加入可学习的参数w。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.3. <a id='toc10_4_3_'></a>[注意力分数函数](#toc0_)\n",
    "#### 10.4.3.1. <a id='toc10_4_3_1_'></a>[加性注意力](#toc0_)\n",
    "```shell\n",
    "q和k的长度不一致。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.4.3.2. <a id='toc10_4_3_2_'></a>[缩放点积注意力](#toc0_)\n",
    "```shell\n",
    "q和k的长度一致。\n",
    "```\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.4. <a id='toc10_4_4_'></a>[自注意力机制](#toc0_)\n",
    "```shell\n",
    "自注意力机制：就是用同一个X分别于Wq、Wk和Wv矩阵相乘得到Q、K和V向量/矩阵。因为用的是同一个X同时作为q、k和v，所以得名为自注意力。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.5. <a id='toc10_4_5_'></a>[多头注意力机制](#toc0_)\n",
    "上述只求一次注意力的过程可以叫做单头注意力。多头注意力就是对同样的Q, K, V求多次注意力，并行计算h个得到h个不同的attention，再把这些不同的h个attention连接起来得到最终的attentions，每一个attention都是一个head（头），总共有h个head（头）。  \n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.6. <a id='toc10_4_6_'></a>[attention-seq2seq](#toc0_)\n",
    "```shell\n",
    "加入attention机制的Seq2Seq；\n",
    "基于Attention的Seq2Seq。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.7. <a id='toc10_4_7_'></a>[Transformer](#toc0_)\n",
    "```shell\n",
    "完全基于注意力机制的Encoder-Decoder架构。\n",
    "1.多头自注意力机制；\n",
    "2.掩码；\n",
    "3.Encoder-Decoder框架。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.4.7.1. <a id='toc10_4_7_1_'></a>[位置编码](#toc0_)\n",
    "```shell\n",
    "由于Transformer并行运算，没有顺序信息；\n",
    "Google一帮人发明了利用sin和cos函数编码位置信息并添加到输入X中；\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "max_len = 10\n",
    "num_hiddens = 3\n",
    "torch.zeros((1, max_len, num_hiddens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.4.7.2. <a id='toc10_4_7_2_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3112889997.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[55], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class Evoformer(nn.Module):\n",
    "    '''Encoder'''\n",
    "    def __init__(self):\n",
    "        self. \n",
    "\n",
    "    def forward(self, X):\n",
    "        return X \n",
    "    \n",
    "class Structure(nn.Module):\n",
    "    '''Decoder'''\n",
    "    def __init__(self):\n",
    "        self. \n",
    "\n",
    "    def forward(self, X):\n",
    "        return X \n",
    "\n",
    "class AlphaFold2(nn.Module):\n",
    "    '''The network of Encoder-Decoder'''\n",
    "    def __init__(self):\n",
    "        self.evoformer = Evoformer()\n",
    "        self.structure = Structure()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.4.7.3. <a id='toc10_4_7_3_'></a>[基于Attention的Seq2Seq网络](#toc0_)\n",
    "```shell\n",
    "基于Attention的Seq2Seq神经网络框架。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        return \n",
    "\n",
    "class MySeq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.8. <a id='toc10_4_8_'></a>[BERT](#toc0_)\n",
    "```shell\n",
    "就是Encoder部分\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.9. <a id='toc10_4_9_'></a>[GPT](#toc0_)\n",
    "```shell\n",
    "就是Transformer的Decoder部分。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. <a id='toc11_'></a>[CV](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. <a id='toc11_1_'></a>[数据增广](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. <a id='toc12_'></a>[NLP](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. <a id='toc13_'></a>[炼丹心得](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1. <a id='toc13_1_'></a>[关于调参](#toc0_)\n",
    "1. Pytorch没有变量、常量之分，不需要定义说明什么是变量，全部都是张量；\n",
    "2. 因为变量定义后需要初始化，就相当于常量；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyLayer(nn.Module):\n",
    "    '''带参数的，自定义层'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(2, requires_grad=True))  # 变量，立即初始化，相当于常量\n",
    "        self.bias = nn.Parameter(torch.zeros(1, requires_grad=True))    # 同上\n",
    "    \n",
    "    def forward(self, X):\n",
    "        y_hat = self.weight.data@X + self.bias.data\n",
    "        # y_hat = torch.matmul(self.weight.data, X) + self.bias.data    # 同上\n",
    "        return F.relu(y_hat)\n",
    "\n",
    "myLayer = MyLayer()\n",
    "X = torch.ones(2)\n",
    "myLayer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([-1.2126,  0.9969])), ('bias', tensor([0.]))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.state_dict() # 访问神经网络参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2. <a id='toc13_2_'></a>[模型选择](#toc0_)\n",
    "```shell\n",
    "模型的复杂度应该合适，不能太大，也不能太小。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3. <a id='toc13_3_'></a>[one-hot](#toc0_)\n",
    "```shell\n",
    "有向量无偏差表示；\n",
    "简单，但可能占空间\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_12228\\256218798.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(col_raw == raw) # 只是bool\n",
      "C:\\Users\\zhao\\AppData\\Local\\Temp\\ipykernel_12228\\256218798.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  one_hot = torch.tensor(col_raw == raw, dtype=torch.float32) # bool -> torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]]),\n",
       " tensor([[1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "col_raw = raw.reshape(5, 1); col_raw\n",
    "col_raw == raw # （5， 1） 和 （1， 5）先广播后比较\n",
    "torch.tensor(col_raw == raw) # 只是bool\n",
    "one_hot = torch.tensor(col_raw == raw, dtype=torch.float32) # bool -> torch.float32\n",
    "col_raw, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "\n",
    "# help(F.one_hot)\n",
    "F.one_hot(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.4. <a id='toc13_4_'></a>[embedding](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 先做广播，后比较即可\n",
    "raw = [0, 1, 2, 3, 4]\n",
    "raw = torch.tensor(raw); raw\n",
    "# 第一种\n",
    "# help(F.embedding)\n",
    "# F.embedding(raw)\n",
    "\n",
    "# 第二种\n",
    "# help(nn.Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.5. <a id='toc13_5_'></a>[BN和LN](#toc0_)\n",
    "Batch norm和Layer norm之间的区别  \n",
    "* BatchNorm：在同一特征（同一列），不同样品之间（不同行）之间做的normalization？ standerlization？\n",
    "* LayerNorm：在同一样品（同一行），不同特征（不同列）之间做的normalization？ standerlization？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "torch.nn.BatchNorm1d()\n",
    "torch.nn.LayerNorm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.6. <a id='toc13_6_'></a>[MLP、FC、FNN、CNN、RNN](#toc0_)\n",
    "Linear()：线性网络，即没有非线性激活函数  \n",
    "MLP()：多层感知机，有非线性激活函数  \n",
    "FNN()：前馈神经网络，同MLP（）  \n",
    "CNN()：卷积神经网络    \n",
    "RNN()：循环神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.7. <a id='toc13_7_'></a>[机器学习](#toc0_)\n",
    "```shell\n",
    "1. 监督学习  \n",
    "    自监督学习  \n",
    "    \n",
    "2. 半监督学习  \n",
    "3. 无监督学习  \n",
    "4. 强化学习  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.8. <a id='toc13_8_'></a>[迁移学习-Transfer learning](#toc0_)\n",
    "### 13.8.1. <a id='toc13_8_1_'></a>[Fine-tuning](#toc0_)\n",
    "```shell\n",
    "在今后的很长时间，深度学习的模型创新上会有很大的难度，基于已有的模型的微调（Fine-tuning）应用于新的可解决的问题是趋势。\n",
    "Fine-tuning in CV：\n",
    "    1.用Pre-trained的参数初始化特征提取器如Encoder的参数，而不是随机初始化；\n",
    "    2.用小的lerning-rate和小的epochs；\n",
    "    3.固定模型层的（其实就是learning-rate为0）。\n",
    "如何找到Pre-trained model？\n",
    "    TIMM（pytorch）-一个叫Ross的小哥自己维护的；\n",
    "    HugginFace - 一个早期只是东抄抄西抄抄的公司，逐渐发展为比较好的社区公司。\n",
    "Fine-tuning in NLP：\n",
    "    1.Self-supervised pre-training;\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
